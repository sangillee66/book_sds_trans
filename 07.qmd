---
date-modified: last-modified
number-sections: true
format: 
  html: 
    toc: true
code-link: true
code-copy: true
execute: 
  warning: false
  error: false
  freeze: auto
editor: visual
editor_options: 
  chunk_output_type: console
---

# sf와 stars 패키지 {#sec-sf-stars}

이 장에서는 R의 **sf**와 **stars** 패키지를 소개한다. **sf**는 피처의 지오메트리 정보를 리스트-컬럼 형태로 저장하는 심플 피처 테이블 포맷을 제공한다. **stars** 패키지는 래스터와 벡터 데이터 큐브(6장에서 다룸)를 지원하기 위해 개발되었으며, 래스터 레이어, 래스터 스택, 피처 시계열도 처리할 수 있다. **sf** 패키지는 2016년에 CRAN에 처음 공개되었고, **stars** 패키지는 2018년에 등장했다. 두 패키지는 R 컨소시엄의 지원과 활발한 커뮤니티 참여 속에서 개발되었으며, 상호 연동이 가능하도록 설계되었다. **sf**나 **stars** 객체를 대상으로 하는 함수 또는 메서드는 `st_`로 시작하는데, 이는 관련 함수를 쉽게 식별할 수 있게 해주면, 명령어 자동 완성 기능을 활용할 때 검색을 용이하게 한다.

## sf 패키지 {#sec-sf}

R의 **sf** 패키지(Pebesma 2018)는 기존의 R 패키지인 **sp**, **rgeos**, **rgdal**의 벡터 처리 기능을 대체하고 이를 성공적으로 계승하기 위해 개발되었다. 또한 산업계 및 오픈소스 프로젝트에서 널리 사용되는 표준 기반 접근법에 보다 근접하고, 최신 버전의 오픈소스 지리공간 소프트웨어 스택(그림 1.7)에 기반하며, 필요 시 R 공간 소프트웨어와 타이디버스(Wickham et al. 2019)의 통합을 가능하게 한다.

이를 위해 **sf** 패키지는 R에서 심플 피처 접근(Herring et al. 2011)을 네이티브로 제공한다.(역자주: 여기서 네이티브(native)는 추가적인 변환 과정이나 별도의 중간 계층 없이, 해당 환경에서 직접 실행되거나 지원되는 방식을 의미한다.) 이 패키지는 여러 **tidyverse** 패키지, 특히 **ggplot2**, **dplyr**, **tidyr**와의 인터페이스를 제공하며, GDAL을 통해 데이터를 읽고 쓰고, GEOS(투영 좌표의 경우) 또는 s2geometry(타원체 좌표의 경우)를 이용해 기하학 연산을 수행하고, PROJ를 사용하여 좌표 변환 및 전환 작업을 처리한다. 외부 C++ 라이브러리와 연동은 **Rcpp** 패키지(Eddelbuettel 2013)를 통해 이루어진다.

**sf** 패키지는 `sf` 객체로 심플 피처를 표현하며, 이는 `data.frame` 또는 티블(tibble)의 하위 클래스이다.(역자주: 티블은 **tidyverse** 패키지에서 제안한, 개선된 형태의 데이터 프레임 포맷이다.) `sf` 객체는 최소한 하나 이상의 `sfc` 클래스 지오메트리 *리스트 열*(list-column)을 포함하며, 이 리스트 열의 각 요소는 `sfg` 클래스의 R 객체로서 지오메트리 정보를 담고 있다. 지오메트리 리스트 열은 `data.frame`이나 티블 내에서 변수처럼 작동하지만, 숫자형이나 문자형 변수와 같은 기본 벡터보다 복잡한 구조를 갖는다(부록 B.3 참조).

`sf` 객체는 다음과 같은 메타데이터를 가진다.

-   (활성화된) 지오메트리 열의 이름: `sf_column` 속성에 저장됨.

-   각 비기하 변수의 속성-지오메트리 관계(5.1절 참조): `agr` 속성에 저장됨.

`sfc` 지오메트리 리스트 열은 `st_geometry`함수를 통해 `sf` 객체에서 추출할 수 있으며, 다음과 같은 메타데이터를 가진다

-   좌표참조계(CRS): `crs` 속성에 저장됨.

-   바운딩 박스: `bbox` 속성에 저장됨.

-   정밀도: `precision` 속성에 저장됨.

-   지오메트리 수: `n_empty` 속성에 저장됨.

이러한 속성들의 값을 확인하거나 수정하기 위해 `st_bbox()`, `st_crs()`, `st_set_crs()`, `st_agr()`, `st_set_agr()`, `st_precision()`, `st_set_precision()` 등의 함수를 사용할 수 있다.

### 생성

다음과 같은 방법으로 `sf` 객체를 생성할 수 있다.

```{r}
#| eval: false
library(sf)
# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE
p1 <- st_point(c(7.35, 52.42))
p2 <- st_point(c(7.22, 52.18))
p3 <- st_point(c(7.44, 52.19))
sfc <- st_sfc(list(p1, p2, p3), crs = 'OGC:CRS84')
st_sf(elev = c(33.2, 52.1, 81.2), 
      marker = c("Id01", "Id02", "Id03"), geom = sfc)
# Simple feature collection with 3 features and 2 fields
# Geometry type: POINT
# Dimension:     XY
# Bounding box:  xmin: 7.22 ymin: 52.2 xmax: 7.44 ymax: 52.4
# Geodetic CRS:  WGS 84
#   elev marker              geom
# 1 33.2   Id01 POINT (7.35 52.4)
# 2 52.1   Id02 POINT (7.22 52.2)
# 3 81.2   Id03 POINT (7.44 52.2)
```

![sf 객체의 구조](https://r-spatial.org/book/images/sf_obj.png){#fig-7-1}

그림 7.1은 출력된 구성 요소에 대한 설명을 보여준다. 객체를 처음부터 생성하는 경우도 있지만, R에서의 공간데이터는 대체로 외부 소스에서 읽어온다. 이러한 외부 소스에는 다음과 같은 것들이 있다.

-   외부 파일

-   데이터베이스 내의 테이블(또는 테이블 집합)

-   웹서비스 호출을 통해 획득한 데이터셋

-   R 패키지에 포함된 데이터셋

### 읽기와 쓰기

외부 '데이터 소스'(파일, 웹서비스, 문자열 등)에서 데이터셋을 읽어올 때는 `st_read()` 함수를 사용한다.

```{r}
#| eval: false
library(sf)
(file <- system.file("gpkg/nc.gpkg", package = "sf"))
# [1] "/home/edzer/R/x86_64-pc-linux-gnu-library/4.3/sf/gpkg/nc.gpkg"
nc <- st_read(file)
# Reading layer `nc.gpkg' from data source 
#   `/home/edzer/R/x86_64-pc-linux-gnu-library/4.3/sf/gpkg/nc.gpkg' 
#   using driver `GPKG'
# Simple feature collection with 100 features and 14 fields
# Geometry type: MULTIPOLYGON
# Dimension:     XY
# Bounding box:  xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6
# Geodetic CRS:  NAD27
```

여기서 사용된 파일 이름과 경로는 **sf** 패키지에 포함된 데이터를 가리키며, 이는 **sf** 패키지를 설치하는 과정에서 설정되므로 어떤 컴퓨터에서든 예외 없이 읽을 수 있다.

`st_read()` 함수는 두 개의 아규먼트, 즉 *데이터 소스 이름*(`dsn`)과 *레이어*(layer)를 가진다. 위의 예에서 사용된 *geopackage*(GPKG) 파일은 단일 레이어만 포함하고 있으며, 해당 레이어가 불러와진 것이다. 만약 여러 레이어가 포함되어 있었다면, 첫 번째 레이어가 읽히고 경고 메시지가 출력되었을 것이다. 데이터셋에서 사용 가능한 레이어 목록은 다음과 같이 조회할 수 있다.

```{r}
#| eval: false
st_layers(file)
# Driver: GPKG 
# Available layers:
#   layer_name geometry_type features fields crs_name
# 1    nc.gpkg Multi Polygon      100     14    NAD27
```

심플 피처 객체는 `st_write()` 함수를 사용하여 저장할 수 있다.

```{r}
#| eval: false
(file = tempfile(fileext = ".gpkg"))
# [1] "/tmp/Rtmpm9lGRF/file361e653fae4a9.gpkg"
st_write(nc, file, layer = "layer_nc")
# Writing layer `layer_nc' to data source 
#   `/tmp/Rtmpm9lGRF/file361e653fae4a9.gpkg' using driver `GPKG'
# Writing 100 features with 14 fields and geometry type Multi Polygon.
```

여기서 파일 형식(GPKG)은 파일 이름 확장자에서 결정된다. `st_write()` 함수의 `append` 아규먼트를 설정하면 기존 레이어에 레코드를 추가하거나, 기존 레이어를 교체할 수 있다. `append` 아규먼트 설정되지 않은 상태에서 동일한 레이어가 이미 존재하면 오류가 발생한다. 타이디버스 스타일의 `write_sf()` 함수는 `append`가 설정되지 않은 경우에도 오류 없이 레이어를 교체한다. 또한, `st_delete()` 함수를 사용하면 레이어를 삭제할 수 있으며, 이는 특히 데이터베이스의 테이블과 연결된 레이어를 다룰 때 유용하다.

WKT-2 좌표참조계를 지원하는 파일 형식의 경우, `st_read()`와 `st_write()`를 통해 이를 읽고 쓸 수 있다. 그러나 `csv`와 같은 간단한 포맷에서는 이 기능이 지원되지 않는다. 셰이프파일(shapefile) 형식은 CRS 인코딩에 매우 제한적인 지원만 제공한다.(역자주: 셰이프파일은 ESRI가 개발한 벡터 데이터 포맷으로, 현재 가장 널리 사용되는 형식 중 하나이다.)

### 일부 추출

매우 일반적인 작업 중 하나는 객체의 일부를 추출(subsetting)하는 것이며, 베이스 R에서는 이를 위해 대괄호 기호(`[]`) 를 사용한다. `data.frame` 객체에 적용되는 규칙을 `sf` 객체에도 동일하게 적용할 수 있다. 예를 들어, 다음 같은 코드를 사용하면 레코드 2\~5와 열 3\~7을 선택할 수 있다.

```{r}
#| eval: false
nc[2:5, 3:7]
```

여기에 몇몇 옵션을 부가적으로 적용할 수 있다.

-   `drop` 아규먼트는 기본값이 `FALSE`로 설정되어 있어, 지오메트리 열이 *항상* 선택되며 `sf` 객체가 반환된다. `TRUE`로 설정하면, 지오메트리 열이 선택되지 않은 경우 해당 열이 제거된 `data.frame`이 반환된다.

-   공간(`sf`, `sfc`, `sfg`) 객체를 첫 번째 아규먼트로 사용하여 선택하면, 해당 객체와 공간적으로 *인터섹션*하는 피처가 선택된다(다음 절 참조). 다른 프레디케이트를 사용하려면 `op` 아규먼트를 설정하여 `st_covers()`와 같은 함수나 3.2.2절에 나열된 다른 이항 프레디케이트 함수를 지정할 수 있다.

### 이항 프레디케이트

`st_intersects()`, `st_covers()`와 같은 이항 프레디케이트 함수(3.2.2절 참조)는 두 개의 피처 집합 또는 피처 지오메트리를 입력받아, 모든 쌍에 대해 조건이 `TRUE`인지 `FALSE`인지를 반환한다. 대규모 집합의 경우, 이러한 연산은 일반적으로 대부분이 `FALSE` 값으로 채워진 거대한 행렬을 생성하게 되며, 이 때문에 기본적으로 희소 표현(sparse representation)이 반환된다.(역자주: 희소 표현은 메모리 사용을 최적화하고 데이터 처리를 더욱 효율적으로 하는 방식으로, 일반적으로 `TRUE` 값만을 저장하고 `FALSE` 값은 저장하지 않는다.)

```{r}
#| eval: false
nc5 <- nc[1:5, ]
nc7 <- nc[1:7, ]
(i <- st_intersects(nc5, nc7))
# Sparse geometry binary predicate list of length 5, where the
# predicate was `intersects'
#  1: 1, 2
#  2: 1, 2, 3
#  3: 2, 3
#  4: 4, 7
#  5: 5, 6
```

```{r}
#| echo: false
#| eval: false
#| label: fig-7-2
#| fig-cap: "노스케롤라이나의 처음 일곱개 카운티"
library(sf)
plot(st_geometry(nc7))
plot(st_geometry(nc5), add = TRUE, border = "brown")
cc = st_coordinates(st_centroid(st_geometry(nc7)))
text(cc, labels = 1:nrow(nc7), col = "blue")
```

![노스케롤라이나의 처음 일곱개 카운티](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-fig57-1.png){#fig-7-2}

그림 7.2는 처음 다섯 개 카운티와 처음 일곱 개 카운티 간의 인터섹션을 이해하는 방법을 보여준다. 다음과 같은 방법으로 희소 논리 행렬을 조밀한 행렬(dense matrix)로 변환할 수 있다.

```{r}
#| eval: false
as.matrix(i)
#       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]
# [1,]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
# [2,]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE
# [3,] FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE
# [4,] FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE
# [5,] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE
```

`nc5`의 각 카운티와 인터섹션하는 `nc7` 카운티의 개수는 다음과 같이 계산할 수 있다.

```{r}
#| eval: false
lengths(i)
# [1] 2 3 2 2 2
```

역으로 `nc7`의 개별 카운티와 인터섹션하는 `nc5`의 카운티의 개수는 다음과 같이 계산할 수 있다.

```{r}
#| eval: false
lengths(t(i))
# [1] 2 3 2 1 1 1 1
```

객체 `i` 가 `sgbp`(sparse geometrical binary predicate) 클래스의 한 객체라고 할 때, 객체 `i`는 정수 벡터의 리스트로 표현되며, 이 리스트의 각 요소는 논리 프레디케이트 행렬의 한 행을 나타낸다. 논리 프레디케이트 행렬은 해당 행에 대해 `TRUE` 값을 갖는 열의 인덱스를 저장한다. 이 객체에는 사용된 프레디케이트와 총 열 수 등의 메타데이터도 포함된다. `sgbp` 객체에 적용할 수 있는 메소드에는 다음과 같은 것들이 있다.

```{r}
#| eval: false
methods(class = "sgbp")
#  [1] as.data.frame as.matrix     coerce        dim          
#  [5] initialize    Ops           print         show         
#  [9] slotsFromS3   t            
# see '?methods' for accessing help and source code
```

`sgbp` 클래스 객체에서 사용 가능한 유일한 `Ops` 메서드는 `!`(부정 연산자)이다.

### 타이디버스 패키지

**tidyverse** 패키지는 다양한 데이터사이언스 패키지를 함께 로드한다(Wickham and Grolemund 2017; Wickham et al. 2019). **sf** 패키지는 **tidyverse** 스타일의 읽기 및 쓰기 함수인 `read_sf()`와 `write_sf()`를 제공하며, 이 함수들은 다음과 같은 특징을 가진다.

-   `data.frame` 대신 `tibble`을 반환한다.

-   출력 내용을 콘솔에 인쇄하지 않는다.

-   기본적으로 기본 데이터를 덮어쓴다.

`sf` 객체에는 **tidyverse** 패키지의 `filter()`, `select()`, `group_by()`, `ungroup()`, `mutate()`, `transmute()`, `rowwise()`, `rename()`, `slice()`, `summarise()`, `distinct()`, `gather()`, `pivot_longer()`, `spread()`, `nest()`, `unnest()`, `unite()`, `separate()`, `separate_rows()`, `sample_n()`, `sample_frac()`등의 함수를 적용할 수 있다. 대부분의 함수는 `sf` 객체의 메타데이터만 처리하며, 지오메트리 정보는 변경하지 않는다. 사용자가 지오메트리를 제거하려면, `st_drop_geometry()` 함수를 사용하거나, 선택 작업 전에 간단히 `tibble` 또는 `data.frame`으로 강제 변환(coerce)하면 된다.

```{r}
#| eval: false
library(tidyverse) |> suppressPackageStartupMessages()
nc |> as_tibble() |> select(BIR74) |> head(3)
# # A tibble: 3 × 1
#   BIR74
#   <dbl>
# 1  1091
# 2   487
# 3  3188
```

`sf` 객체에 대한 `summarise()` 함수에는 두 가지 특별한 아규먼트가 있다

-   `do_union`(기본값: `TRUE`): 그룹화된 지오메트리가 반환될 때 유니언(합집합)할지 여부를 결정하여, 이를 통해 밸리드한 지오메트리가 형성되도록 한다.

-   `is_coverage`(기본값: `FALSE`): 그룹화된 지오메트리가 커버리지(겹침이 없는 경우)를 형성할 때, 이를 `TRUE`로 설정하면 유니언 과정이 더 빨라진다.

`distinct()` 함수는 고유한 레코드를 선택하며, `st_equals()` 함수는 지오메트리의 고유성을 평가한다.

`filter()` 함수는 일반적인 프레디케이트와 함께 사용할 수 있으며, 공간적 프레디케이트를 사용하고자 할 경우 예를 들어 오렌지 카운티에서 50km 이내에 있는 모든 카운티를 선택하려면 다음과 같이 사용할 수 있다.

```{r}
#| eval: false
orange <- nc |> dplyr::filter(NAME == "Orange")
wd <- st_is_within_distance(nc, orange, 
                            units::set_units(50, km))
o50 <- nc |> dplyr::filter(lengths(wd) > 0)
nrow(o50)
# [1] 17
```

(여기서 `dplyr::filter()`를 사용하는 것은 베이스 R의 `filter()` 함수와의 혼동을 피하기 위함이다.)

그림 7.3은 이 분석의 결과를 보여주며, 카운티 경계 주위에 버퍼도 추가되어 있다. 이 버퍼는 설명을 위한 것이며, 카운티를 선택하는 데에는 사용되지는 않았음을 유의하라.

```{r}
#| echo: false
#| eval: false
#| label: fig-7-3
#| fig-cap: "오렌지 카운티(오렌지색), 반경 50km 내의 카운티(검은색), 오랜지 카운티 주변의 버퍼(갈색), 나머지 카운티(회색)"
og <- st_geometry(orange)
buf50 <- st_buffer(og, units::set_units(50, km))
all <- c(buf50, st_geometry(o50))
plot(st_geometry(o50), lwd = 2, extent = all)
plot(og, col = 'orange', add = TRUE)
plot(buf50, add = TRUE, col = NA, border = 'brown')
plot(st_geometry(nc), add = TRUE, border = 'grey')
```

![오렌지 카운티(오렌지색), 반경 50km 내의 카운티(검은색), 오랜지 카운티 주변의 버퍼(갈색), 나머지 카운티(회색)](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-orangebuffer-1.png){#fig-7-3}

## 공간적 조인

일반적인 조인(왼쪽 조인, 오른쪽 조인, 내부 조인)에서는 두 테이블에서 하나 이상의 속성이 매치할 때 *조인*이 이루어진다. 공간적 조인도 이와 유사하지만, 레코드를 조인하는 기준이 속성의 매치가 아니라 공간적 프레디케이트라는 점이 다르다. 이로 인해 *공간적으로* 매치하는 레코드를 정의하는 데에는 여러 선택지가 있으며, 이는 3.2.2절에 나열된 이항 프레디케이트를 사용해 결정할 수 있다. '왼쪽', '오른쪽', '내부', '전체' 조인의 개념은 비공간 조인과 동일하게 유지되는데, 이는 공간적 매치를 고려하지 않고 레코드의 조인을 처리할 때 적용된다.

공간적 조인을 실행할 때, 각 레코드에 여러 일치하는 레코드가 존재할 수 있으므로 결과 테이블이 매우 커질 수 있다. 이러한 복잡성을 줄이는 방법 중 하나는, 일치하는 레코드 가운데 타깃 지오메트리와 가장 넓은 면적이 겹치는 레코드 하나만 선택하는 것이다. 이 방법의 시각적 예시는 그림 7.4에 나와 있으며, `st_join()` 함수에서 `largest = TRUE` 아규먼트를 설정해 이를 수행할 수 있다.

```{r}
#| echo: false
#| eval: false
#| label: fig-7-4
#| fig-cap: "largest = TRUE 아규먼트를 적용한 st_join() 함수의 예시: 아래쪽 그림의 폴리곤과 가장 넓은 면적이 겹치는 위쪽 그림의 폴리곤 라벨이 아래쪽 폴리곤에 할당되어 있다."
# example of largest = TRUE:
system.file("shape/nc.shp", package="sf") |> 
    read_sf() |>
    st_transform('EPSG:2264') -> nc
gr <- st_sf(
         label = apply(expand.grid(1:10, LETTERS[10:1])[,2:1], 1, paste0, collapse = ""),
         geom = st_make_grid(nc))
gr$col <- sf.colors(10, categorical = TRUE, alpha = .3)
# cut, to verify that NA's work out:
gr <- gr[-(1:30),]
suppressWarnings(nc_j <- st_join(nc, gr, largest = TRUE))
par(mfrow = c(2,1), mar = rep(0,4))
plot(st_geometry(nc_j), border = 'grey')
plot(st_geometry(gr), add = TRUE, col = gr$col)
text(st_coordinates(st_centroid(st_geometry(gr))), labels = gr$label, cex = .85)
# the joined dataset:
plot(st_geometry(nc_j), border = 'grey', col = nc_j$col)
text(st_coordinates(st_centroid(st_geometry(nc_j))), labels = nc_j$label, cex = .7)
plot(st_geometry(gr), border = '#88ff88aa', add = TRUE)
```

![`largest = TRUE` 아규먼트를 적용한 `st_join()` 함수의 예시: 아래쪽 그림의 폴리곤과 가장 넓은 면적이 겹치는 위쪽 그림의 폴리곤 라벨이 아래쪽 폴리곤에 할당되어 있다.](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-largest-1.png){#fig-7-4}

결과의 복잡성을 줄이는 또 다른 방법은 조인 후에 `aggregate` 함수를 사용하여 모든 일치하는 레코드를 결합함과 동시에 지오메트리도 병합하는 것이다. 이에 대한 자세한 내용은 5.4절을 참고하라.

### 샘플 추출, 그리드 생성, 인터폴레이션

`sf` 패키지가 제공하는 몇 가지 유용한 함수를 소개한다. `st_sample()` 함수는 타깃 지오메트리로부터 임의의 샘플 포인트를 생성하며, 타깃 지오메트리는 포인트, 라인, 폴리곤 등 다양할 수 있다. 샘플링 방식은 완전 무작위 방식, 규칙적 방식, 또는 폴리곤의 경우 삼각형 방식 중 선택할 수 있다. 11장에서 **spatstat** 패키지가 제공하는 공간 샘플링(또는 포인트 패턴 시뮬레이션) 방법이 `st_sample()` 함수를 통해 어떻게 구현되는지 설명한다.

`st_make_grid()` 함수는 특정 영역 위에 정사각형, 직사각형, 또는 육각형의 그리드를 생성한다. 옵션 설정에 따라 그리드 자체가 아닌 그리드의 중심점이나 모서리점을 생성할 수도 있다. 이 함수는 그림 7.4에서 직사각형 그리드를 생성하는 데 사용되었다.

함수 `st_interpolate_aw()` 함수는 5.3절에서 설명한 바와 같이, 공간 내포 변수와 공간 외연 변수를 새로운 구역으로 '인터폴레이션'하는 기능을 제공한다.

## 타원 좌표

비투영 데이터는 경위도로 표현된 타원체 좌표를 가진다. 4.1절에서 설명한 바와 같이, 포인트 간의 '직선'은 최단 곡선 경로인 '측지선(geodesic line)'이다. 기본적으로 **sf** 패키지는 `s2geometry` 라이브러를 사용해 기하학적 연산을 수행하며, 이는 **s2** 패키지를 통해 구현된다(Dunnington, Pebesma, and Rubak 2023). 예를 들어, 아래의 지점은 특정 폴리곤 *내부*에 위치한다(그림 7.5의 왼쪽: 정사 도법).

```{r}
#| eval: false
"POINT(50 50.1)" |> st_as_sfc(crs = "OGC:CRS84") -> pt
```

```{r}
#| eval: false
"POLYGON((40 40, 60 40, 60 50, 40 50, 40 40))" |>
  st_as_sfc(crs = "OGC:CRS84") -> pol
st_intersects(pt, pol)
# Sparse geometry binary predicate list of length 1, where the
# predicate was `intersects'
#  1: 1
```

```{r}
#| echo: false
#| eval: false
#| label: fig-7-5
#| fig-cap: "인터섹션의 결과는 측지선 혹은 대권호를 사용하느냐(왼쪽) 데카르트 좌표계를 사용하느냐에 따라 달라진다."
par(mfrow = c(1, 2))
par(mar = c(2.1, 2.1, 1.2, .5))
ortho <- st_crs("+proj=ortho +lon_0=50 +lat_0=45")
pol |> st_transform(ortho) |> plot(axes = TRUE, graticule = TRUE, 
                                   main = 's2geometry')
pt |> st_transform(ortho) |> plot(add = TRUE, pch = 16, col = 'red')
# second plot:
plot(pol, axes = TRUE, graticule = TRUE, main = 'GEOS')
plot(pt, add = TRUE, pch = 16, col = 'red')
```

![인터섹션의 결과는 측지선 혹은 대권호를 사용하느냐(왼쪽) 데카르트 좌표계를 사용하느냐에 따라 달라진다.](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-figs2-1.png){#fig-7-5}

**sf** 패키지가 타원체 좌표를 마치 데카르트 좌표처럼 처리하도록 하려면, **s2** 사용을 비활성화하면 된다.

```{r}
#| eval: false
old <- sf_use_s2(FALSE)
# Spherical geometry (s2) switched off
st_intersects(pol, pt)
# although coordinates are longitude/latitude, st_intersects assumes
# that they are planar
# Sparse geometry binary predicate list of length 1, where the
# predicate was `intersects'
#  1: (empty)
sf_use_s2(old) # restore
# Spherical geometry (s2) switched on
```

이렇게 하면 그림 7.5의 오른쪽(정거원통 도법)처럼, 엠프티 인터섹션이 반환된다. 경고 메시지에는 타원체 좌표를 평면 좌표로 취급하고 있다는 내용이 명시된다.

**s2** 사용은 성능상의 이유나 레거시 구현과의 호환성을 위해 비활성화할 수 있다. 데카르트 기하학을 위한 `GEOS` 라이브러리와 구체 기하학을 위한 `s2geometry` 라이브러리(그림 1.7)는 서로 다른 동기로 개발되었으며, **sf** 패키지를 통해 사용될 때 몇 가지 차이가 있다.

-   특정 오퍼레이션에서 속도 차이가 크게 발생할 수 있다.

-   일부 함수는 특정 라이브러리에만 존재한다(예를 들어 `st_relate()` 함수는 `GEOS` 라이브러리에만 존재)

-   변환자(transformer)를 사용할 때, `GEOS`는 외부 폴리곤 링을 시계 방향으로 노드로 반환하며, 이를 반시계 방향으로 되돌리기 위해 `st_sfc(..., check_ring_dir = TRUE)`를 사용한다. 반면, `s2geometry`는 외부 폴리곤 링을 반시계 방향으로 반환한다.

## stars 패키지

**sp** 패키지가 래스터 데이터 지원 측면에서 정체되어 있는 동안, **raster** 패키지(Hijmans 2023a)는 지난 10여년간 래스터 분석을 위한 강력하고 유연하며 확장 가능한 패키지로서 지배적인 위치를 공고히 해왔다. **raster** 패키지(및 그 후속인 **terra** 패키지(Hijmans 2023b)는 2차원 정규 래스터 또는 래스터 레이어 집합('래스터 스택')이라는 래스터 데이터 모델에 기반한다. 이러한 모델은 세상이 수많은 레이어로 구성되어 있고, 각 레이어가 특정 주제를 반영한다는 고전적인 정적 'GIS 뷰'와 일치한다. 그러나 오늘날의 많은 데이터는 동적이며, 시계열 래스터 또는 시계열 래스터 스택의 형태로 제공된다. 기존의 래스터 스택은 이러한 동적 특성을 제대로 반영하지 못하며, 사용자가 각 레이어가 무엇을 나타내는지 별도로 기록해야 한다.

또한, **raster** 패키지와 그 후속인 **terra** 패키지는 데이터 크기가 로컬 저장소(컴퓨터의 하드 드라이브)보다 크지 않을 때에만 우수한 연산 성능을 발휘한다. 그러나 최근의 데이터셋—예를 들어 위성 이미지, 기후 모델, 기상 예보 데이터—은 로컬 저장소의 용량으로는 더 이상 감당하기 어려운 수준에 도달했다(9장 참조). **spacetime** 패키지(Pebesma 2012, 2022)는 벡터 지오메트리 또는 래스터 그리드 셀의 시계열 분석을 어느 정도 지원하지만, 더 높은 차원의 어레이나 메모리가 한계를 넘어서는 대규모 데이터셋은 여전히 처리하기 어렵다.

여기서는 래스터 및 벡터 데이터 큐브 분석을 위한 패키지로 **stars**를 소개한다. 이 패키지는 다음과 같은 기능을 제공한다.

-   동적(시간 변화) 래스터 스택을 재현할 수 있다.

-   로컬 디스크 용량에 제한받지 않는 확장성을 목표로 한다.

-   `GDAL` 라이브러리의 래스터 기능과 강력하게 통합된다.

-   정규 그리드 뿐만 아니라 회전, 전단, 직선, 곡선 래스터도 처리할 수 있다(그림 1.6 참조).

-   **sf** 패키지와 긴밀하게 통합된다.

-   비래스터(non-raster) 공간 디맨션을 가진 어레이 데이터(벡터 데이터 큐브)를 처리할 수 있다.

-   타이디버스 디자인 원리를 따른다.

벡터 데이터 큐브에는 심플 피처의 시계열이나 출발지-목적지 매트릭스(및 그 시계열)를 포함한 공간 그래프 데이터가 포함된다. 공간적 벡터 및 래스터 데이터 큐브의 개념은 6장에서 설명되었다. 불규칙 시공간 관측치는 **sftime** 패키지(Teickner, Pebesma, and Graeler 2022)에서 제공하는 `sftime` 객체로 재현할 수 있으며, 이는 시간 열을 추가하는 방식으로 `sf` 객체를 확장한 것이다(13.3절 참조).

### 래스터 데이터의 읽기와 쓰기

래스터 데이터는 일반적으로 파일에서 불러온다. 여기서는 브라질의 올린다 시에 대한 30m 해상도의 Landsat 7 데이터셋(밴드 1\~5 및 7)을 사용한다. **stars** 패키지에서 정규 비회전 그리드에 대한 예제 GeoTIFF 파일을 읽어올 수 있다.

```{r}
#| eval: false
tif <- system.file("tif/L7_ETMs.tif", package = "stars")
library(stars)
# Loading required package: abind
(r <- read_stars(tif))
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     1      54     69 68.9      86  255
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
```

여기서 우리는 오프셋, 셀 크기, 좌표참조계, 그리고 디멘션을 확인할 수 있다. 디멘션 테이블은 각 디멘션에 대해 다음과 같은 필드를 포함한다.

-   `from`: 시작 인덱스 값

-   `to`: 종료 인덱스 값

-   `offset`: 첫 번째 픽셀의 시작(모서리)에서의 디멘션 값

-   `delta`: 셀 크기. 음의 값은 디멘션 값이 감소할수록 픽셀 인덱스 값이 증가함을 의미

-   `refsys`: 참조계

-   `point`: 셀 값이 포인트 서포트인지, 셀 서포트인지를 나타내는 논리 값

-   `x/y`: 디멘션이 래스터의 x- 축과 관련되는지, y-축과 관련되는지를 나타내는 값

여기에는 사용되지 않기 때문에 숨겨진 또 다른 필드인 `values`가 있다. 정규, 회전, 또는 전단 그리드와 같이 일정하게 이산화된 디멘션(예: 시간)의 경우, `offset`과 `delta`는 `NA`가 아니다. 반면 불규칙하게 이산하된 디멘션의 경우에는 `offset`과 `delta`가 `NA`이며, `values` 속성에는 다음 중 하나가 포함된다.

-   값 또는 구간의 시퀀스: 직선 공간 래스터 또는 불규칙 시간 디멘션의 경우

-   공간 디멘션과 연결된 지오메트리: 벡터 데이트 큐브의 경우

-   각 래스터 셀에 대한 좌표값이 포함된 매트릭스: 곡선 래스터의 경우

-   디멘션 값과 연결된 밴드 이름 또는 레이블: 이산 디멘션의 경우

`stars` 클래스 객체 `r`은 길이 1의 단순 리스트로 구성되어 있으며, 3차원 어레이를 포함한다.

```{r}
#| eval: false
length(r)
# [1] 1
class(r[[1]])
# [1] "array"
dim(r[[1]])
#    x    y band 
#  349  352    6
```

또한 이 객체는 어레이 디멘션이 무엇을 나타내는지 파악하는 데 필요한 모든 메타데이터를 포함한 디멘션 테이블을 속성으로 가진다. 이는 다음을 통해 확인할 수 있다.

```{r}
#| eval: false
st_dimensions(r)
```

다음과 같은 방법으로 어레이의 공간적 범위를 확인할 수 있다.

```{r}
#| eval: false
st_bbox(r)
#    xmin    ymin    xmax    ymax 
#  288776 9110729  298723 9120761
```

`write_stars()` 함수를 사용하여 래스터 데이터를 로컬 디스크에 저장할 수 있다.

```{r}
#| eval: false
tf <- tempfile(fileext = ".tif")
write_stars(r, tf)
```

파일 확장자를 통해 데이터 형식(이 경우 GeoTIFF)이 지정된다. 심플 피처와 마찬가지로 읽기 및 쓰기 작업은 `GDAL` 라이브러리를 사용하며, 래스터 데이터에 사용할 수 있는 드라이버 목록은 다음과 같이 확인할 수 있다.

```{r}
#| eval: false
st_drivers("raster")
```

### `stars` 데이터 큐브로부터 일부 추출

데이터 큐브는 `[]` 연산자를 사용하거나 타이디버스 동사를 사용하여 일부를 추출할 수 있다. 첫 번째 방식인 `[]` 연산자를 사용할 때는 다음 아규먼트를 쉼표로 구분하여 순서대로 지정한다.

-   속성: 이름, 인덱스, 또는 논리 벡터

-   디멘션

예를 들어, `r[1:2, 101:200,, 5:10]`는 `r`에서 속성 1\~2를 선택하고, 디멘션 1에 대해 인덱스 101\~200, 차원 3에 대해 인덱스 5\~10을 선택함을 의미한다. 이 경우 디멘션 2를 통한 선택은 이루어지지 않는다. 속성 선택 시에는 속성 이름, 인덱스, 또는 논리 벡터를 사용할 수 있다. 디멘션 선택 시에는 논리 벡터가 지원되지 않는다. 불연속 범위 선택은 정규 시퀀스일 때만 가능하다. `drop`는 기본값이 `FALSE`이며, `TRUE`로 설정하면 단일 값을 가진 디멘션은 모두 제거된다.

```{r}
#| eval: false
r[,1:100, seq(1, 250, 5), 4] |> dim()
#    x    y band 
#  100   50    1
r[,1:100, seq(1, 250, 5), 4, drop = TRUE] |> dim()
#   x   y 
# 100  50
```

특정 범위의 디멘션 *값*을 선택하려면 `filter()` 함수를 사용할 수 있으며, 이를 위해서는 **dplyr** 패키지를 먼저 로드해야 한다.

```{r}
#| eval: false
library(dplyr, warn.conflicts = FALSE)
filter(r, x > 289000, x < 290000)
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     5      51     63 64.3      75  242
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1  35  289004  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6       1     1                NA    NA
```

이는 차원의 오프셋을 변경한다. 특정 큐브 슬라이스는 `slice` 함수를 사용하여 얻을 수 있다.

```{r}
#| eval: false
slice(r, band, 3)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif    21      49     63 64.4      77  255
# dimension(s):
#   from  to  offset delta            refsys point x/y
# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
```

이는 단일 디멘션인 `band`를 제거한다. `mutate()` 함수는 `stars` 객체에서 기존 어레이를 기반으로 새로운 어레이를 추가하는 데 사용되며, `transmute()` 함수는 여기에 더해 기존 어레이를 제거한다.

### 클리핑

일부를 추출하는 또 다른 방법으로, `sf`, `sfc` 또는 `bbox` 클래스의 공간 객체를 사용하는 방법이 있다.

```{r}
#| eval: false
b <- st_bbox(r) |>
    st_as_sfc() |>
    st_centroid() |>
    st_buffer(units::set_units(500, m))
r[b]
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max. NA's
# L7_ETMs.tif    22      54     66 67.7    78.2  174 2184
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x     157 193  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y     159 194 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
```

예를 들어, 해당 지역에 대한 직경 500m의 원형 중심부를 추출할 수 있으며, 그림 7.6은 이를 첫 번째 밴드에 적용한 결과를 보여준다.

```{r}
#| echo: false
#| eval: false
#| label: "fig-7-6"
#| fig-cap: "Landsat 7 (band 1) 이미지의 원형 중심부"
plot(r[b][,,,1], reset = FALSE)
plot(b, border = 'brown', lwd = 2, col = NA, add = TRUE)
```

![Landsat 7 (band 1) 이미지의 원형 중심부](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-circr-1.png){#fig-7-6}

원형 공간 객체의 외부에 위치한 픽셀에는 `NA` 값이 할당되는 것을 확인할 수 있다. 이 원형 객체는 여전히 `r`의 `offset`과 `delta` 값에 대한 디멘션 인덱스를 가지고 있다. 다음과 같은 방법으로 `offset` 값을 재설정할 수 있다.

```{r}
#| eval: false
r[b] |> st_normalize() |> st_dimensions()
#      from to  offset delta            refsys point x/y
# x       1 37  293222  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 36 9116258 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1  6      NA    NA                NA    NA
```

기본적으로 결과 래스터는 선택 객체의 범위로 클리핑(clipping)된다. 입력 객체와 동일한 디멘션을 가진 객체는 다음과 같은 방식으로 얻을 수 있다.

```{r}
#| eval: false
r[b, crop = FALSE]
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's
# L7_ETMs.tif    22      54     66 67.7    78.2  174 731280
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
```

`stars` 객체의 클리핑은 `st_crop()` 함수를 사용해 직접 수행할 수도 있다.

```{r}
#| eval: false
st_crop(r, b)
```

### stars 객체의 차원재부여 및 결합

**stars** 패키지는 다양한 어레이 조작을 수행하기 위해 **abind** 패키지(Plate and Heiberger 2016)를 사용한다. 예를 들어, 어레이를 순열하여 전치하는 `aperm()` 함수가 있다.

```{r}
#| eval: false
aperm(r, c(3, 1, 2))
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     1      54     69 68.9      86  255
# dimension(s):
#      from  to  offset delta            refsys point x/y
# band    1   6      NA    NA                NA    NA    
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
```

`stars` 객체에 대한 메서드가 제공되며, 이를 통해 결과 객체의 디멘션 순서를 재배열할 수 있다.

속성과 디멘션을 교환할 수도 있으며, 이는 `split()`과 `merge()` 함수를 사용해 수행된다.

```{r}
#| eval: false
(rs <- split(r))
# stars object with 2 dimensions and 6 attributes
# attribute(s):
#     Min. 1st Qu. Median Mean 3rd Qu. Max.
# X1    47      67     78 79.1      89  255
# X2    32      55     66 67.6      79  255
# X3    21      49     63 64.4      77  255
# X4     9      52     63 59.2      75  255
# X5     1      63     89 83.2     112  255
# X6     1      32     60 60.0      88  255
# dimension(s):
#   from  to  offset delta            refsys point x/y
# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
merge(rs, name = "band") |> setNames("L7_ETMs")
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#          Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs     1      54     69 68.9      86  255
# dimension(s):
#      from  to  offset delta            refsys point    values x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE      NULL [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE      NULL [y]
# band    1   6      NA    NA                NA    NA X1,...,X6
```

`split()` 함수는 밴드 디멘션을 2차원 어레이의 여섯 개 속성으로 분리하며, `merge()` 함수는 그 반대 작업을 수행한다. `st_redimension()` 함수는 단일 어레이 디멘션을 두 개의 새로운 디멘션으로 분할하는 것과 같은 보다 일반적인 작업에 사용된다.

```{r}
#| eval: false
st_redimension(r, c(x = 349, y = 352, b1 = 3, b2 = 2))
# stars object with 4 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     1      54     69 68.9      86  255
# dimension(s):
#    from  to  offset delta            refsys point x/y
# x     1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y     1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# b1    1   3      NA    NA                NA    NA    
# b2    1   2      NA    NA                NA    NA
```

동일한 디멘션을 가진 여러 개의 `stars` 객체는 `c()` 함수를 사용해 결합할 수 있다. 결합된 어레이는 기본적으로 추가 속성으로 취급되지만, `along` 아규먼트를 지정하면 새로운 디멘션을 따라 병합할 수도 있다.

```{r}
#| eval: false
c(r, r, along = "new_dim")
# stars object with 4 dimensions and 1 attribute
# attribute(s), summary of first 1e+05 cells:
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif    47      65     76 77.3      87  255
# dimension(s):
#         from  to  offset delta            refsys point x/y
# x          1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y          1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band       1   6      NA    NA                NA    NA    
# new_dim    1   2      NA    NA                NA    NA
```

이 사용 예시는 7.5.2절에서 설명한다.

### 포인트 샘플 추출, 애그리게이션

래스터 데이터 큐브 분석에서 매우 흔한 작업 중 하나는 특정 위치에서 값을 추출하거나 지정된 지오메트리에 대해 집계값을 계산하는 것이다. `st_extract()` 함수는 포인트 위치의 값을 추출한다. 여기서는 `r` 객체의 바운딩 박스 범위 안에서 임의로 선택한 몇 개의 샘플링 포인트에 대해 이 오퍼레이션을 수행한다.

```{r}
#| eval: false
set.seed(115517)
pts <- st_bbox(r) |> st_as_sfc() |> st_sample(20)
(e <- st_extract(r, pts))
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif    12    41.8     63   61    80.5  145
# dimension(s):
#          from to            refsys point
# geometry    1 20 SIRGAS 2000 / ...  TRUE
# band        1  6                NA    NA
#                                           values
# geometry POINT (293002 ...,...,POINT (290941 ...
# band                                        NULL
```

이는 20개의 포인트와 6개의 밴드를 가진 벡터 데이터 큐브를 생성한다. 시드를 설정하면 반복 실행 시 동일한 샘플을 사용할 수 있다. 따라서 포인트를 무작위로 다시 생성하고자 하는 경우는 시드를 설정하지 않아야 한다.

데이터 큐브에서 정보를 추출하는 또 다른 방법은 집계값을 계산하는 것이다. 이를 수행하는 한 가지 방법은 공간 폴리곤이나 라인에 따라 값을 공간적으로 집계하는 것이다(6.4절 참조). 예를 들어, 그림 1.4(d)에 나타나나 세 개의 원 각각에 대해, 여섯 개 밴드에서의 최대 픽셀 값을 계산할 수 있다.

```{r}
#| eval: false
circles <- st_sample(st_as_sfc(st_bbox(r)), 3) |>
    st_buffer(500)
aggregate(r, circles, max)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif    73    94.2    117  121     142  205
# dimension(s):
#          from to            refsys point
# geometry    1  3 SIRGAS 2000 / ... FALSE
# band        1  6                NA    NA
#                                           values
# geometry POLYGON ((2913...,...,POLYGON ((2921...
# band                                        NULL
```

이는 세 개의 지오메트리와 여섯 개의 밴드를 가진 (벡터) 데이터 큐브를 생성한다. 시간 디멘션에 대한 집계는 `aggregate()` 함수의 두 번째 아규먼트로 시간 변수를 지정하여 수행한다. 시간 변수로는 다음과 같은 값들을 사용할 수 있다.

-   시간 간격의 시작을 나타내는 타임스탬프 집합

-   `make_intervals()` 함수로 정의된 시간 간격 집합

-   '주', '5일', '년'과 같이 기간을 나타내는 문자열

### 예측 모델

`R`에서의 일반적인 모델 예측 워크플로우는 다음과 같다.

-   응답 변수와 예측 변수(공변량)가 포함된 `data.frame`을 준비한다.

-   `data.frame`을 기반으로 모델 객체를 생성한다.

-   모델 객체와 대상 예측 변수 값이 포함된 `data.frame`을 사용하여 `predict()`함수를 호출한다.

`stars` 패키지는 `stars` 객체에 대한 `predict` 메서드를 제공하며, 이는 위 과정의 마지막 단계를 수행한다. 즉, `stars` 객체에서 `data.frame`을 생성한 뒤, `predict()`를 호출하고, 예측 값으로 다시 `stars` 객체를 재구성한다.

이 과정을 설명하기 위해, Landsat 데이터셋과 앞에서 추출한 샘플 포인트를 이용해, 육지를 바다에서 분리하는 간단한 이진 클래스 예제를 살펴본다. 결과는 그림 7.7에 제시되어 있다.

```{r}
#| echo: false
#| eval: false
#| label: fig-7-7
#| fig-cap: "트레이닝 데이터로 사용된 무작위 샘플 포인트: 빨간색은 해양부이고 노란색을 육지부를 나타낸다."
plot(r[,,,1], reset = FALSE)
col <- rep("yellow", 20)
col[c(8, 14, 15, 18, 19)] = "red"
st_as_sf(e) |> st_coordinates() |> text(labels = 1:20, col = col)
```

![트레이닝 데이터로 사용된 무작위 샘플 포인트: 빨간색은 해양부이고 노란색을 육지부를 나타낸다.](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-rsample-1.png){#fig-7-7}

이 그림에서 포인트 8, 14, 15, 18, 19는 수부에, 나머지 포인트는 육지부에 위치함을 "육안"으로 확인할 수 있다. 선형 판별('최대 우도') 분류기를 적용한 결과, 그림 7.8과 같은 모델 예측 결과를 얻을 수 있다.

```{r}
#| eval: false
rs <- split(r)
trn <- st_extract(rs, pts)
trn$cls <- rep("land", 20)
trn$cls[c(8, 14, 15, 18, 19)] <- "water"
model <- MASS::lda(cls ~ ., st_drop_geometry(trn))
pr <- predict(rs, model)
```

여기서는 `MASS::` 접두사를 사용하여 **MASS** 패키지를 로드하지 않았는데, 이는 **dplyr** 패키지의 `select()` 함수를 덮어쓰는 것을 방지하기 위함이다. `split` 단계는 밴드 디멘션을 속성으로 변환해 예측 변수로 사용하기 위해 필요한 과정이다.

```{r}
#| echo: false
#| eval: false
#| label: fig-7-8
#| fig-cap: "그림 7.7의 트레이닝 데이터를 기반으로 한 육지부/수부 구분 선형 판별 분류 결과"
plot(pr[1], key.pos = 4, key.width = lcm(3.5), key.length = lcm(2))
```

![그림 7.7의 트레이닝 데이터를 기반으로 한 육지부/수부 구분 선형 판별 분류 결과](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-lda-1.png){#fig-7-8}

또한, 그림 7.8에 표시된 레이어가 클래스 레이블을 가진 범주형 변수임을 확인할 수 있다.

### 래스터 데이터 플로팅

```{r}
#| echo: false
#| eval: false
#| label: fig-7-9
#| fig-cap: "30m 해상도의 Landsat 6개 밴드를 90m로 다운샘플한 결과로 브라질의 올린다 예시이다."
plot(r)
```

![30m 해상도의 Landsat 6개 밴드를 90m로 다운샘플한 결과로 브라질의 올린다의 예시이다.](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-firststars-1.png)

베이스 플롯 함수를 `stars` 객체에 적용할 수 있으며, `plot(r)`로 생성된 결과는 그림 7.9에 나타나 있다. 기본 색상 스케일은 회색 톤을 사용하고, 모든 밴드의 데이터 분위수에 맞춰 명암 대비를 조정하는 '히스토그램 평활화'가 적용된다.(역자주: 히스토그램 평활화는 데이터의 분포를 재조정하여 시각적으로 더 유용하게 하고 세부 사항을 더 잘 드르나게 하는 기법이다. 예를 들어, 어두운 영상에서는 어두운 영역의 픽셀 값이 한쪽에 몰려 있는데, 히스토그램 평활화를 적용하면 이 픽셀 값의 범위를 더 넓게 확장(stretch)시켜 이미지를 더 밝고 선명하게 만들 수 있다.) `breaks = "equal"`로 설정하면 급폭이 동일한 등간격 분류법이 적용되며, 계급 단절값을 임의로 지정하는 것도 가능하다. 그런데 더 익숙한 시각화 방식은 그림 7.10에 나타난 RGB 또는 폴스 컬러 합성일 것이다.

```{r}
#| echo: false
#| eval: false
#| label: fig-7-10
#| fig-cap: "컬러 합성의 두 가지 예시"
par(mfrow = c(1, 2))
plot(r, rgb = c(3,2,1), reset = FALSE, main = "RGB")    # rgb
plot(r, rgb = c(4,3,2), main = "False colour (NIR-R-G)") # false colour
```

![컬러 합성의 두 가지 예시](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-starsrgb-1.png){#fig-7-10}

보다 자세한 사항은 8장에서 다룬다.

### 래스터 데이터 분석

`stars` 객체의 개별 원소에는 수리 함수가 어레이에 직접 적용된다. 이는 사용자가 함수를 호출하여 표현식(expression)을 생성할 수 있음을 의미한다.

```{r}
#| eval: false
log(r)
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     0    3.99   4.23 4.12    4.45 5.54
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
r + 2 * log(r)
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     1      62   77.5 77.1    94.9  266
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
```

또는 특정 값을 마스킹할 수도 있다.

```{r}
#| eval: false
r2 <- r
r2[r < 50] <- NA
r2
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's
# L7_ETMs.tif    50      64     75   79      90  255 149170
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
```

또는 마스킹을 해제할 수도 있다.

```{r}
#| eval: false
r2[is.na(r2)] <- 0
r2
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     0      54     69   63      86  255
# dimension(s):
#      from  to  offset delta            refsys point x/y
# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
# band    1   6      NA    NA                NA    NA
```

`stars` 객체의 개별 디멘션에는 선택한 어레이 디멘션에 함수를 적용할 수 있으며, 이는 `apply()` 함수가 어레이에 대해 동작하는 방식과 유사하다(6.3.3절). 예를 들어, 각 픽셀에 대해 6개 밴드 값의 평균을 계산할 수 있다.

```{r}
#| eval: false
st_apply(r, c("x", "y"), mean)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#       Min. 1st Qu. Median Mean 3rd Qu. Max.
# mean  25.5    53.3   68.3 68.9      82  255
# dimension(s):
#   from  to  offset delta            refsys point x/y
# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
```

더 유의미한 함수의 예로는 NDVI(Normalized Difference Vegetation Index, 정규화 식생 지수) 계산이 있다.

```{r}
#| eval: false
ndvi <- function(b1, b2, b3, b4, b5, b6) (b4 - b3)/(b4 + b3)
st_apply(r, c("x", "y"), ndvi)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#         Min. 1st Qu.  Median    Mean 3rd Qu.  Max.
# ndvi  -0.753  -0.203 -0.0687 -0.0643   0.187 0.587
# dimension(s):
#   from  to  offset delta            refsys point x/y
# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]
# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]
```

또는 함수를 다음과 같이 정의할 수도 있다.

```{r}
#| eval: false
ndvi2 <- function(x) (x[4]-x[3])/(x[4]+x[3])
```

밴드 수가 많을 경우 이러한 방식은 더 편리하지만, 각 픽셀마다 호출해야 하므로 위에서 정의한 `ndvi` 함수보다 훨씬 느리다. 반면 `ndvi` 함수는 모든 픽셀이나 큰 픽셀 덩어리에 대해 한 번만 호출하면 된다. 전체 영상에 대해 각 밴드의 평균은 다음과 같이 계산된다.

```{r}
#| eval: false
st_apply(r, c("band"), mean) |> as.data.frame()
#   band mean
# 1    1 79.1
# 2    2 67.6
# 3    3 64.4
# 4    4 59.2
# 5    5 83.2
# 6    6 60.0
```

결과는 `data.frame`의 형태로 바로 출력해 볼 수 있을 만큼 작다. 위의 두 예제에서는 전체 디멘션이 모두 사라지지만, 항상 그런 것은 아니다(6.3.2절). 예를 들어, 각 밴드에 대해 세 개의 사분위수를 계산할 수도 있다.

```{r}
#| eval: false
st_apply(r, c("band"), quantile, c(.25, .5, .75))
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif    32    60.8   66.5 69.8    78.8  112
# dimension(s):
#          from to        values
# quantile    1  3 25%, 50%, 75%
# band        1  6          NULL
```

이렇게 하면 세 개의 값으로 이루어진 새로운 디멘션인 `quantile`이 *생성*된다. 또는, 각 픽셀에 대해 여섯 개 밴드 값의 세 사분위수를 다음과 같이 계산할 수도 있다.

```{r}
#| eval: false
st_apply(r, c("x", "y"), quantile, c(.25, .5, .75))
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     4      55   69.2 67.2    81.2  255
# dimension(s):
#          from  to  offset delta            refsys point
# quantile    1   3      NA    NA                NA    NA
# x           1 349  288776  28.5 SIRGAS 2000 / ... FALSE
# y           1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE
#                 values x/y
# quantile 25%, 50%, 75%    
# x                 NULL [x]
# y                 NULL [y]
```

### 곡선형 래스터

비정규 래스터가 발생하는 이유는 다양하다(그림 1.6). 우선, 데이터가 지구의 곡면 형태를 그대로 반영하는 경우, 정규 래스터는 곡면인 지구의 표면에 정확히 맞지 않는다. 다른 이유로는 다음과 같은 것들이 있다.

-   정규 래스터 데이터를 다른 좌표참조계로 변환하거나 재투영할 때, 워핑(7.8절)을 수행하지 않으면 곡선 형태로 나타난다. 그러나 워핑은 항상 데이터 손실을 수반하며, 이는 가역적이지 않다.

-   관측 방식 자체가 비정규 래스터를 만들어 낼 수 있다. 예를 들어 품질이 낮은 위성 영상의 경우, 위성의 진행 방향에서는 정규 래스터 형태를 유지 하지만($x$ 또는 $y$ 축과 정렬되지 않음), 진행 방향과 직각인 방향에서는 직교형 래스터가 된다(예: 센서가 시야*각*을 일정 간격으로 분할하여 관측하는 경우).

### GDAL 유틸리티

`GDAL` 라이브러리는 일반적으로 데이터 변환과 처리를 위한 여러 실행 파일, 즉 `GDAL` 명령줄 유틸리티와 함께 제공된다. 이들 유틸리티 가운데 상당수(Python으로 작성된 것을 제외한 모든 유틸리티)는 "GDAL Algorithms C API"를 통해 `GDA`L 라이브러리의 `C` 함수로도 제공된다. `GDAL` 라이브러리와 연동된 R 패키지(예: **sf** 패키지)가 이러한 `C API` 알고리즘을 사용한다면, 사용자는 별도로 `GDAL` 명령줄 유틸리티를 설치하지 않아도 된다.

**sf** 패키지는 `gdal_utils()` 함수를 통해 이러한 `C API` 알고리즘을 호출할 수 있다. 이때 첫 번째 아규먼트에는 `gdal` 접두사를 제외한 이름을 지정한다. 주요 명령과 기능은 다음과 같다.

-   `info`: GDAL 래스터 데이터셋에 대한 정보를 출력한다.

-   `warp`: 래스터를 새로운 래스터로 변환한다(CRS의 전환 포함).

-   `rasterize`: 벡터 데이터셋을 래스터화한다.

-   `translate`: 래스터 파일을 다른 형식으로 변환한다.

-   `vectortranslate`: 벡터 파일을 다른 형식으로 변환한다(`ogr2ogr`에 해당).

-   `buildvrt`: 가상 래스터 타일(여러 파일의 결합하여 생성된 단일 래스터)을 생성한다.

-   `demprocessing`: DEM(digital data model)에 대한 다양한 처리를 수행한다.

-   `nearblack`: 거의 검정색 또는 흰색인 경계 부분을 검정색으로 변환한다.

-   `grid`: 흩어진 데이터로부터 정규 그리드를 생성한다.

-   `mdiminfo`: 다차원 어레이에 대한 정보를 출력한다.

-   `mdimtranslate`: 다차원 어레이를 다른 형식으로 변환한다.

이러한 유틸리티는 기본적으로 파일 단위로 작동하며, `sf` 또는 `stars` 객체에 직접 작용되지는 않는다. 그러나 `stars_proxy` 객체는 본질적으로 파일에 대한 포인터 역할을 하므로, 다른 객체들도 파일로 저장하여 사용할 수 있다. 이러한 유틸리티 중 일부는(항상 혹은 선택적으로) `st_mosaic()`, `st_warp()`, 또는 `st_write()` 등의 함수를 통해 호출된다. R의 **gdalUtilities**(O’Brien 2022) 패키지는 `sf::gdal_utils`에 기반하여, 명령줄 유틸리티 아규먼트 이름과 동일한 아규먼트 이름을 사용하는 편의성 래퍼 함수를 제공한다.

## 벡터 데이터 큐브 예제

### 예제: 대기질 시계열 데이터 애그리게이션 실행

유럽 대기질 데이터를 사례로, 벡터 데이터 큐브의 애그리게이션 작업을 설명한다. 이 데이터는 Gräler, Pebesma, Heuvelink (2016)에서 사용된 것과 동일하며, 12장과 13장에서도 다시 사용될 예정이다. 독일 농촌 지역 관측소에서 1998\~2009년 동안 수집한 데이터를 바탕으로 일평균 $\text{PM}_{10}$ 값을 계산하였다.

`air` 데이터 매트릭스, 날짜 벡터 `date`s, 그리고 `SpatialPoints` 객체 `stations`을 결합하여 `stars` 객체를 생성할 수 있다.

```{r}
#| eval: false
load("data/air.rda") # this loads several datasets in .GlobalEnv
dim(air)
# space  time 
#    70  4383
stations |>
    st_as_sf(coords = c("longitude", "latitude"), crs = 4326) |>
    st_geometry() -> st
d <- st_dimensions(station = st, time = dates)
(aq <- st_as_stars(list(PM10 = air), dimensions = d))
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#       Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's
# PM10     0    9.92   14.8 17.7      22  274 157659
# dimension(s):
#         from   to     offset  delta refsys point
# station    1   70         NA     NA WGS 84  TRUE
# time       1 4383 1998-01-01 1 days   Date FALSE
#                                          values
# station POINT (9.59 53.7),...,POINT (9.45 49.2)
# time                                       NULL
```

그림 7.11에서는 시간 시계열이 상당히 길지만, 큰 결측 구간도 존재함을 확인할 수 있다. 그림 7.12는 평균 $\text{PM}_{10}$ 값과 함께 측정소의 공간 분포를 보여준다.

![시간과 스테이션별로 계산된 PM10 값에 대한 시공간 다이어그램](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-airst-1.png){#fig-7-11}

![관측 스테이션별 PM10 평균값](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-airmap-1.png){#fig-7-12}

간단한 실습 차원에서, 측정소별 시간 시계열 데이터를 지역 평균으로 애그리게이션할 수 있다. 이를 위해 `stars` 객체에 대한 `aggregate` 메소드를 사용한다.

```{r}
#| eval: false
(a <- aggregate(aq, de_nuts1, mean, na.rm = TRUE))
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#       Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's
# PM10  1.08    10.9   15.3 17.9    21.8  172 25679
# dimension(s):
#      from   to     offset  delta refsys point
# geom    1   16         NA     NA WGS 84 FALSE
# time    1 4383 1998-01-01 1 days   Date FALSE
#                                       values
# geom MULTIPOLYGON (...,...,MULTIPOLYGON (...
# time                                    NULL
```

또한, 아래 코드를 통해 임의로 선택한 여섯 날짜의 지도를 표시할 수 있다(그림 7.13).

```{r}
#| eval: false
library(tidyverse)
a |> filter(time >= "2008-01-01", time < "2008-01-07") |> 
    plot(key.pos = 4)
```

![임의의 여섯 날짜에 대한 지역 평균 PM10](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-airagg-1.png){#fig-7-13}

또한, 아래 코드를 이용해 단일 주의 평균값 시계열 플롯을 생성할 수 있다(그림 7.14).

```{r}
#| eval: false
library(xts) |> suppressPackageStartupMessages()
plot(as.xts(a)[,4], main = de_nuts1$NAME_1[4])
```

![단일 측정소에 대한 지역 평균 PM10의 시계열](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-airts-1.png){#fig-7-14}

### 예제: 브리스톨 출발지-도착지 데이터 큐브

이 예제에 사용된 데이터는 Lovelace, Nowosad, Muenchow (2019)에서 가져온 출발지-목적지(OD) 매트릭스로, A 지역에서 B 지역으로 이동하는 인구 수를 교통수단별로 나타낸 것이다. 102개 지역의 피처 지오메트리는 `sf` 객체인 `bristol_zones`에 포함되어 있다.

```{r}
#| echo: false
#| eval: false
library(spDataLarge)
plot(st_geometry(bristol_zones), axes = TRUE, graticule = TRUE)
plot(st_geometry(bristol_zones)[33], col = 'red', add = TRUE)
```

![영국 브리스톨의 102개 구역 현황(33번 구역(E02003043)이 빨간색으로 표시되어 있음)](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-bristol1-1.png){#fig-7-15}

`bristol_od` 테이블에 OD 쌍(이동량이 0인 경우는 제외)이 레코드로 저장되어 있으며, 서로 다른 교통수단이 변수로 포함되어 있다.

```{r}
#| eval: false
head(bristol_od)
# # A tibble: 6 × 7
#   o         d           all bicycle  foot car_driver train
#   <chr>     <chr>     <dbl>   <dbl> <dbl>      <dbl> <dbl>
# 1 E02002985 E02002985   209       5   127         59     0
# 2 E02002985 E02002987   121       7    35         62     0
# 3 E02002985 E02003036    32       2     1         10     1
# 4 E02002985 E02003043   141       1     2         56    17
# 5 E02002985 E02003049    56       2     4         36     0
# 6 E02002985 E02003054    42       4     0         21     0
```

제외된 무이동 OD 쌍의 개수는 모든 OD 조합 수에서 데이터에 포함된 OD 쌍 수를 빼서 구할 수 있다.

```{r}
#| eval: false
nrow(bristol_zones)^2 - nrow(bristol_od) 
# [1] 7494
```

우리는 출발지, 목적지, 교통수단을 디멘션으로 하는 3차원 벡터 데이터 큐브를 만들 것이다. 이를 위해 먼저 `pivot_longer()` 함수를 사용하여 `bristol_od` 테이블을 정리해, 출발지(`o`), 목적지(`d`), 교통수단(`mode`), 빈도(`n`) 변수를 갖도록 한다.

```{r}
#| eval: false
# create O-D-mode array:
bristol_tidy <- bristol_od |> 
    select(-all) |> 
    pivot_longer(3:6, names_to = "mode", values_to = "n")
head(bristol_tidy)
# # A tibble: 6 × 4
#   o         d         mode           n
#   <chr>     <chr>     <chr>      <dbl>
# 1 E02002985 E02002985 bicycle        5
# 2 E02002985 E02002985 foot         127
# 3 E02002985 E02002985 car_driver    59
# 4 E02002985 E02002985 train          0
# 5 E02002985 E02002987 bicycle        7
# 6 E02002985 E02002987 foot          35
```

그리고 나서 0으로 채워진 3차원 어레이 `a`를 생성한다.

```{r}
#| eval: false
od <- bristol_tidy |> pull("o") |> unique()
nod <- length(od)
mode <- bristol_tidy |> pull("mode") |> unique()
nmode = length(mode)
a = array(0L,  c(nod, nod, nmode), 
    dimnames = list(o = od, d = od, mode = mode))
dim(a)
# [1] 102 102   4
```

해당 어레이의 세 차원에 구역 이름(`o`, `d`)과 교통수단 이름(`mode`)이 부여되어 있음을 확인할 수 있다. 이렇게 함으로써 `bristol_tidy`의 각 행은 해당 어레이의 한 단위(엔트리)에 해당하게 된다. `bristol_tidy` 테이블에 있는 인덱스(`o`, `d` 및 `mode`)와 값(`n`)을 이용해 해당 어레이(`a`)의 0이 아닌 부분을 채울 수 있다.

```{r}
#| eval: false
a[as.matrix(bristol_tidy[c("o", "d", "mode")])] <- 
        bristol_tidy$n
```

`bristol_zones`의 구역과 `bristol_tidy`의 구역명이 서로 다른 순서를 가질 수 있으므로, 아래와 같이 인덱스를 일치 시키는 정렬 절차를 수행한다.

```{r}
#| eval: false
order <- match(od, bristol_zones$geo_code)
zones <- st_geometry(bristol_zones)[order]
```

순서가 이미 올바른 수도 있지만, 그런 가정은 배제하고 위 코드를 그대로 실행하는 편이 안전하다. 다음으로, 구역과 교통수단을 이용해 `stars` 디멘션 객체를 생성한다.

```{r}
#| eval: false
library(stars)
(d <- st_dimensions(o = zones, d = zones, mode = mode))
#      from  to refsys point                                  values
# o       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# d       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# mode    1   4     NA FALSE                       bicycle,...,train
```

마지막으로, 어레이 `a`와 디멘션 `d`를 이용해 최종 `stars` 객체를 생성한다.

```{r}
#| eval: false
(odm <- st_as_stars(list(N = a), dimensions = d))
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#    Min. 1st Qu. Median Mean 3rd Qu. Max.
# N     0       0      0  4.8       0 1296
# dimension(s):
#      from  to refsys point                                  values
# o       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# d       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# mode    1   4     NA FALSE                       bicycle,...,train
```

이 3차원 어레이에서 단일 슬라이스를 추출할 수 있다. 예를 들어, 구역 33에 대한 데이터를 `odm[,,33]`으로 추출한 뒤 플롯을 그릴 수 있다(그림 7.16).

```{r}
#| eval: false
plot(adrop(odm[,,33]) + 1, logz = TRUE)
```

![33번 존에 대한 OD 데이터를 추출한 후 교통수단별로 지도화하였다.](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-odm33-1.png){#fig-7-16}

이렇게 일부 추출을 수행하면, 첫 번째 아규먼트가 비어 있으므로 모든 속성(여기서는 하나만 존재: `N`)을 선택하고, 두 번째 아규먼트가 비어 있어 모든 출발지를 선택하며, 세 번째 아규먼트로 목적지 구역 33을 선택하고, 네 번째 아규먼트가 비어 있어 모든 교통 수단을 선택하게 된다.

이 특정 구역을 목적지로 선택한 이유는 해당 구역이 가장 많은 여행자를 보유하고 있기 때문이다. 이는 목적지별로 모든 출발지와 여행 수단을 합산해 확인할 수 있다.

```{r}
#| eval: false
d <- st_apply(odm, 2, sum)
which.max(d[[1]])
# [1] 33
```

다른 애그리게이션도 수행할 수 있다. 예를 들어, OD(102x102)의 총통행량은 다음과 같이 구할 수 있다.

```{r}
#| eval: false
st_apply(odm, 1:2, sum)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#      Min. 1st Qu. Median Mean 3rd Qu. Max.
# sum     0       0      0 19.2      19 1434
# dimension(s):
#   from  to refsys point                                  values
# o    1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# d    1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
```

교통수단별로 출발지 총계를 구할 수 있다.

```{r}
#| eval: false
st_apply(odm, c(1,3), sum)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#      Min. 1st Qu. Median Mean 3rd Qu. Max.
# sum     1    57.5    214  490     771 2903
# dimension(s):
#      from  to refsys point                                  values
# o       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# mode    1   4     NA FALSE                       bicycle,...,train
```

교통수단별로 도착지 총계를 구할 수 있다.

```{r}
#| eval: false
st_apply(odm, c(2,3), sum)
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#      Min. 1st Qu. Median Mean 3rd Qu.  Max.
# sum     0      13    104  490     408 12948
# dimension(s):
#      from  to refsys point                                  values
# d       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...
# mode    1   4     NA FALSE                       bicycle,...,train
```

모드별 합산 출발지 총계를 구할 수 있다.

```{r}
#| eval: false
o <- st_apply(odm, 1, sum)
```

모드별 합산 도착지 총계를 구할 수 있다.

```{r}
#| eval: false
d <- st_apply(odm, 2, sum)
```

`o`와 `d`를 결합한 뒤 함께 플롯할 수 있다(그림 7.17).

```{r}
#| eval: false
x <- (c(o, d, along = list(od = c("origin", "destination"))))
plot(x, logz = TRUE)
```

![출발지별 총통근(왼쪽)과 목적지별 총통근(오른쪽)](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-odjoined-1.png){#fig-7-17}

이 지도는 현상의 본질을 왜곡할 수 있다는 우려가 있다. 그 이유는 실질적인 값의 크기(컬러) 뿐만 아니라 구역의 면적 역시 시각적으로 인지되는 양의 크기에 영향을 미치기 때문이다. 이를 감안해 밀도값(카운트/$\text{km}^2$)을 계산해 나타낼 수 있다(그림 7.18).(역자주: 지도학적 원칙에 따르면, 총통근과 같은 카운트 변수를 코로플레스 맵으로 표현하는 것은 적절하지 않다. 보다 바람직한 방법은 도형표현도로 나타내는 것이다.)

```{r}
#| eval: false
library(units)
a <- set_units(st_area(st_as_sf(o)), km^2)
o$sum_km <- o$sum / a
d$sum_km <- d$sum / a
od <- c(o["sum_km"], d["sum_km"], along = 
        list(od = c("origin", "destination")))
plot(od, logz = TRUE)
```

![출발지별 총통근 밀도(왼쪽)와 목적지별 총통근 밀도(오른쪽)](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-odbykm-1.png){#fig-7-18}

카운트 속성을 정규화하는 또 다른 방법은 값을 면적이 아닌 인구수로 나누는 것이다.

### 타이디 어레이 데이터

Wickham(2014)의 타이디 데이터 논문은 3차원 데이터를 어레이 데이터 형식보다는 각 행이 (지역, 클래스, 연도, 값)으로 구성된 긴(비정규화된) 테이블 형식으로 처리되는 것이 더 바람직하다고 제안한다. 이는 가능하다면 항상 좋은 접근이다. 그러나 기본 처리나 저장 목적에서는 이 방법을 적용할 수 없는 경우가 있으며, 그 이유는 다음과 같다.

-   많은 어레이 데이터는 처음부터 어레이 형식으로 수집되거나 생성된다. 예를 들어, 원격탐사를 통해 수집된 데이터나 기후 모델을 통해 생성된 데이터가 이에 해당한다.

-   어레이 형식을 긴 테이블 형태로 변환하는 것이 그 반대보다 훨씬 쉽다.

-   긴 테이블 형식의 데이터는 훨씬 더 많은 메모리를 요구한다. 디멘션 $i$의 기수(크기)를 $n_i$라고 할 때, 디멘션 값이 차지하는 메모리 공간은 $O(\sum{n_i})$가 아니라 $O(\prod{n_i})$로 주어진다.

-   결측값이 있는 셀이 삭제하면, 긴 테이블 형식은 어레이 형식이 내재하고 있는 인덱싱을 상실하게 된다.

이 주장을 극단적으로 표현하자면, 모든 이미지, 비디오, 음성 데이터가 어레이 형식으로 저장된다고 가정해 보자. 실제로 이를 긴 테이블 형식으로 저장해야 한다고 주장하는 사람은 거의 없을 것이다. 그럼에도 불구하고 **tsibble**(Wang et al. 2022)과 같은 R 패키지는 긴 테이블 형식을 취하고 있으며, 동일한 시간 스텝을 가진 다수의 공간적 피처에 순서를 매기는 작업이 매우 모호함에도 불구하고 어쨋든 인덱싱을 해야 한다는 문제점이 있다. 이러한 문제는 **stars** 패키지에서 제공하는 어레이 형식을 사용함으로써 *자동*으로 해결된다. 물론 이는 조밀한 어레이를 사용해야한다는 대가를 치루는 것이기도 하다.

**stars** 패키지는 어레이 집합을 처리하는 문제에 있어 타이디 데이터 원칙(tidy manifesto)을 따르려 하며, 특히 하나 이상의 디멘션이 공간 및/또는 시간을 참조하는 경우에 그러하다.

### 벡터 데이터 큐브를 위한 파일 포맷

정규 테이블 형식(긴 테이블 형식을 포함)은 하나의 대안이지만 사용하기에는 불편하다. 위의 출발지-목적지 데이터 예제와 13장에서 다룰 내용은 테이블 형식에서 벡터 데이터 큐브를 재구성하는 작업이 매우 복잡하다는 점을 잘 보여준다. NetCDF나 Zarr와 같은 어레이 형식은 어레이 데이터를 저장하기 위해 설계되었으나, 사실상 모든 데이터 구조를 저장할 수 있다. 다만, 한 번 작성된 파일은 재사용하기 어렵다는 위험이 있다. 포인트, (멀티)라인스트링, (멀티)폴리곤으로 구성된 단일 지오메트리 디멘션을 가진 벡터 데이터 큐브의 경우, CF 규칙(Eaton et al. 2022)은 이러한 지오메트리를 인코딩하는 방법을 설명한다. `stars::read_mdim()` 함수와 `stars::write_mdim()` 함수는 이 규칙을 따르는 벡터 데이터 큐브를 읽고 쓸 수 있다.

## 래스터-벡터 전환과 벡터-래스터 전환

1.3절에서 래스터-벡터 전환과 벡터-래스터 전환의 몇 가지 예제를 이미 다루었다. 이 절에서는 이에 대한 코드와 예제를 추가로 제시한다.

### 벡터-래스터 전환

`st_as_stars()` 함수는 객체를 `stars` 객체로 변환하도록 설계된 메서드이다. 그러나 모든 `stars` 객체가 래스터 객체인 것은 아니며, `sf` 객체에 이 메서드들 적용하면 지오메트리를 공간적(벡터) 디멘션으로, 속성을 속성 디멘션을 가지는 벡터 데이터 큐브가 생성된다. 피처 *지오메트리*(`sfc`) 객체가 주어지면, `st_as_stars()` 함수는 이를 래스터화한다(7.8절과 그림 7.19).

```{r}
#| eval: false
#| label: fig-7-19
#| fig-cap: "st_as_stars() 함수를 활용한 백터 지오메트리의 래스터화"
file <- system.file("gpkg/nc.gpkg", package="sf")
read_sf(file) |> 
    st_geometry() |>
    st_as_stars() |>
    plot(key.pos = 4)
```

![`st_as_stars()` 함수를 활용한 백터 지오메트리의 래스터화](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-asstars-1.png){#fig-7-19}

`st_as_stars()` 함수는 셀 크기, 셀 수 그리고/또는 범위를 제어하는 파라미터를 설정할 수 있다. 반환되는 셀 값은 중심점이 지오메트리 외부에 있는 경우 `0`이고, 지오메트리 내부 또는 경계에 있는 경우 `1`이다. 기존 피처를 래스터화하는 작업은 `st_rasterize()` 함수를 사용해 수행하며, 이는 그림 1.5에서도 확인할 수 있다.

```{r}
#| eval: false
library(dplyr)
read_sf(file) |>
    mutate(name = as.factor(NAME)) |>
    select(SID74, SID79, name) |>
    st_rasterize()
# stars object with 2 dimensions and 3 attributes
# attribute(s):
#      SID74           SID79            name       
#  Min.   : 0      Min.   : 0      Sampson :  655  
#  1st Qu.: 3      1st Qu.: 3      Columbus:  648  
#  Median : 5      Median : 6      Robeson :  648  
#  Mean   : 8      Mean   :10      Bladen  :  604  
#  3rd Qu.:10      3rd Qu.:13      Wake    :  590  
#  Max.   :44      Max.   :57      (Other) :30952  
#  NA's   :30904   NA's   :30904   NA's    :30904  
# dimension(s):
#   from  to offset   delta refsys point x/y
# x    1 461  -84.3  0.0192  NAD27 FALSE [x]
# y    1 141   36.6 -0.0192  NAD27 FALSE [y]
```

라인과 포인트 지오메트리도 이와 유사하게 래스터화할 수 있다(그림 7.20).

```{r}
#| eval: false
#| label: fig-7-20
#| fig-cap: "노스캐롤라이나 카운티 경계를 래스터로 전환하기"
read_sf(file) |>
    st_cast("MULTILINESTRING") |>
    select(CNTY_ID) |>
    st_rasterize() |>
    plot(key.pos = 4)
```

![노스캐롤라이나 카운티 경계를 래스터로 전환하기](https://r-spatial.org/book/07-Introsf_files/figure-html/fig-lineras-1.png){#fig-7-20}

## 좌표변환 및 좌표전환

### `st_crs` 함수

`sf` 또는 `stars` 클래스의 공간 객체는 CRS(좌표참조계)를 포함하고 있다. `st_crs()` 함수를 사용하여 해당 객체의 CRS를 확인하거나 다른 CRS로 교체할 수 있다. 또한, `st_set_crs()`함수를 사용하여 CRS를 설정하거나 교체할 수 있다. CRS는 EPSG 코드로 설정할 수 있으며, 예를 들어 `st_crs(4326)`는 `st_crs('EPSG:4326')`로 변환된다. 또는 `"+proj=utm +zone=25 +south"`와 같은 PROJ.4 문자열, `"WGS84"`와 같은 이름, `"OGC"`처럼 기관명이 앞에 붙은 이름으로도 설정할 수 있다. 대안으로 WKT, WKT-2(2.5절), 또는 PROJJSON 형식의 CRS 정의를 사용할 수 있다. `st_crs()` 함수가 반환하는 객체는 다음 두 개의 필드를 포함한다.

-   `wkt`: WKT-2 형식으로 표현된 CRS

-   `input`: 사용자 입력(있는 경우), 또는 CRS에 대한 인간 가독 설명(가능한 경우)

PROJ.4 문자열은 일부 CRS을 *정의*하는 데는 사용할 수 있지만, CRS 전체를 *대표*하는 용도로는 적합하지 않다. 예를 들어, `crs` 객체의 WKT-2를 `$proj4string` 메서드를 사용해 proj4string으로 전환하려면 다음과 같이 한다.

```{r}
#| eval: false
x <- st_crs("OGC:CRS84")
x$proj4string
# [1] "+proj=longlat +datum=WGS84 +no_defs"
```

그러나, 이 과정이 성공적으로 이루어졌다 하더라도, 일반적으로 정보 손실이 수반되며 가역적으로 전환되지 않는다. PROJ.4 문자열을 사용해 CRS를 *정의*하는 경우(예: 파라미터가 지정된 투영 CRS), 해당 투영 CRS가 WGS84 데이텀과 관련되는 한에는 문제가 없다.

### `st_transform()`함수와 `st_project()` 함수

`sf` 또는 `stars` 객체의 좌표 변환이나 좌표 전환은 `st_transform()`함수를 사용해 수행한다.(역자주: 좌표 변환과 좌표 전환은 많은 경우 혼용되지만, 여기서는 좌표 변환을 데이텀 간 좌표 재계산, 좌표 전환은 동일한 데이텀 내에서의 좌표 재계산으로 구분한다. 예를 들어, EPSG:4326을 EPSG:5179로 바꾸는 것은 좌표 변환에 해당하며, EPSG:5179 내에서 경위도 표기를 도분초 형식에서 십진도 형식으로 변경하거나 단위를 미터에서 킬로미터로 변경하거나 축 순서를 변경하는 등의 작업은 좌표 전환에 해당한다.) 이 함수의 첫 번째 아규먼트는 CRS가 설정된 `sf` 또는 `stars` 클래스의 공간 객체이고, 두 번째 아규먼트는 `crs` 객체(또는 `st_crs` 함수로 변환 가능한 값)이다. 소스 `crs`에서 타깃 `crs`로 변환 또는 전환하는 방법이 여러 가지인 경우, PROJ는 가장 높은 명시(declared) 정확도를 가진 방법을 선택한다. 더 세밀한 옵션은 7.7.5절에서 설명된다. 정규 래스터 디멘션을 가진 `stars` 객체의 경우, `st_transform()` 함수는 좌표*만* 변환하며 항상 곡선형 그리드를 생성한다. 새로운 CRS에서 정규 래스터를 생성하려면, 재그리딩(regridding)을 수행하는 `st_warp()` 함수를 사용하면 된다(7.8절).

`sf`나 `stars` 객체가 아닌 경우의 좌표 변환이나 좌표 전환은 저수준(lower-level) 함수인 `sf_project()`를 통해 수행된다. 이 함수는 좌표가 담긴 행렬과 소스 및 타깃 CRS(`crs`)를 입력받아, 변환 또는 전환된 좌표를 반환한다.

### `sf_proj_info()` 함수

`sf_proj_info()` 함수는 PROJ 소프트웨어에서 사용 가능한 투영, 타원체, 단위 및 본초 자오선에 대한 정보를 조회하는 데 사용된다. 이 함수는 단일 매개변수 `type`을 받으며, `type`에는 다음과 같은 값을 지정할 수 있다.

-   `type = "proj"`: 사용 가능한 투영법의 짧은 이름과 긴 이름을 나열한다. 짧은 이름은 `“+proj=name”` 문자열에서 사용할 수 있다.

-   `type = "ellps"`: 사용 가능한 타원체를 나열하며, 이름, 긴 이름 및 타원체의 파라미터 정보를 포함한다.

-   `type = "units"`: 사용 가능한 길이 단위를 나열하며, 미터로의 변환 상수 정보를 포함한다.

-   `type = "prime_meridians"`: 본초 자오선을 나열하고, 그리니치 자오선과의 상대적 위치 정보를 포함한다.

### 데이텀 그리드, proj.db, cdn.proj.org. 로컬 캐쉬

데이텀 그리드(2.4절 참조)는 로컬에 설치하거나 PROJ 측량 그리드 CDN(https://cdn.proj.org/)에서 불러 올 수 있다. 로컬에 설치된 경우, 데이텀 그리드는 PROJ 검색 경로를 통해 불러오며, 이 경로는 다음과 같이 표시된다.

```{r}
#| eval: false
sf_proj_search_paths()
# [1] "/home/edzer/.local/share/proj" "/usr/share/proj"
```

핵심 PROJ 데이터베이스는 `proj.db`이며, 일반적으로 다음 위치에서 불러올 수 있는 `sqlite3` 데이터베이스이다.

```{r}
#| eval: false
paste0(tail(sf_proj_search_paths(), 1), .Platform$file.sep, 
       "proj.db")
# [1] "/usr/share/proj/proj.db"
```

각 PROJ 릴리스에 포함된 EPSG 데이터베이스 스냅샷의 버전은 `proj.db`의 `"metadata"` 테이블에 명시되어 있으며, **sf** 패키지에서 사용되는 PROJ 런타임 버전은 다음과 같이 표시된다.

```{r}
#| eval: false
sf_extSoftVersion()["PROJ"]
#    PROJ 
# "9.1.1"
```

특정 좌표 변환에 필요한 데이텀 그리드가 로컬에 없을 경우, PROJ는 PROJ CDN에서 온라인 데이텀 그리드를 검색한다. 단, 아래의 결과가 `TRUE`인 경우에 한한다.

```{r}
#| eval: false
sf_proj_network()
# [1] FALSE
```

기본값은 `FALSE`로 설정되어 있지만, 이를 `TRUE`로 변경하면 해당 네트워크 리소스의 URL을 반환한다. 이 리소스는 더 빠르거나 제한이 덜한 다른 리소스로 변경할 수도 있다.

```{r}
#| eval: false
sf_proj_network(TRUE)
# [1] "https://cdn.proj.org"
```

CDN에서 데이텀 그리드를 조회한 후, PROJ는 조회된 그리드의 *일부만*(기본값은 전체 그리드가 아님) 로컬 캐시에 기록한다. 이 캐시는 사용자 디렉터리에 저장된 또 다른 `sqlite3` 데이터베이스이며, 다음과 같이 표시된다.

```{r}
#| eval: false
list.files(sf_proj_search_paths()[1], full.names = TRUE)
# [1] "/home/edzer/.local/share/proj/cache.db"
```

차후의 데이텀 그리드 조회는 이 데이터베이스를 우선적으로 참조한다.

### 변환 파이프라인

내부적으로 PROJ는 소스 CRS에서 타겟 CRS로 변환하는 오퍼레이션 시퀀스를 나타내기 위해, 이른바 *좌표 오퍼레이션 파이프라인*(coordinate operation pipeline)을 사용한다. 소스에서 타겟으로 가는 여러 옵션이 있을 경우, `st_transform()` 함수는 가장 높은 정확도의 옵션을 선택한다. 사용 가능한 옵션을 조회하려면 `sf_proj_pipelines()` 함수를 사용하면 된다.

```{r}
#| eval: false
(p <- sf_proj_pipelines("OGC:CRS84", "EPSG:22525"))
# Candidate coordinate operations found:  5 
# Strict containment:     FALSE 
# Axis order auth compl:  FALSE 
# Source:  OGC:CRS84 
# Target:  EPSG:22525 
# Best instantiable operation has accuracy: 2 m
# Description: axis order change (2D) + Inverse of Corrego Alegre
#              1970-72 to WGS 84 (2) + UTM zone 25S
# Definition:  +proj=pipeline +step +proj=unitconvert +xy_in=deg
#              +xy_out=rad +step +inv +proj=hgridshift
#              +grids=br_ibge_CA7072_003.tif +step
#              +proj=utm +zone=25 +south +ellps=intl
```

해당 변환에서 가장 높은 정확도를 보이는 오퍼레이션 파이프라인이 요약되어 있으며, 특정 데이텀 그리드의 사용이 지정되어 있음을 확인할 수 있다. 네트워크 검색을 활성화하지 않았다면 다른 결과가 나왔을 것이다.

```{r}
#| eval: false
sf_proj_network(FALSE)
# character(0)
sf_proj_pipelines("OGC:CRS84", "EPSG:22525")
# Candidate coordinate operations found:  5 
# Strict containment:     FALSE 
# Axis order auth compl:  FALSE 
# Source:  OGC:CRS84 
# Target:  EPSG:22525 
# Best instantiable operation has accuracy: 2 m
# Description: axis order change (2D) + Inverse of Corrego Alegre
#              1970-72 to WGS 84 (2) + UTM zone 25S
# Definition:  +
```

이 경우에는 데이텀 그리드 관련 정보가 누락되어 있음을 확인할 수 있다. `sf_proj_pipelines()` 함수가 반환하는 객체는 서브클래스화된 데이터 프레임으로, 다음과 같은 열을 포함한다.

```{r}
#| eval: false
names(p)
# [1] "id"           "description"  "definition"   "has_inverse" 
# [5] "accuracy"     "axis_order"   "grid_count"   "instantiable"
# [9] "containment"
```

예를 들어 다음과 같이 정확도를 나열할 수 있다.

```{r}
#| eval: false
p |> pull(accuracy)
# [1]  2  5  5  8 NA
```

여기서 `NA`는 "대략적인 정확도"를 의미하며, 이는 30\~120m 범위 내의 값을 가진다.

```{r}
#| eval: false
p |> filter(is.na(accuracy))
# Candidate coordinate operations found:  1 
# Strict containment:     FALSE 
# Axis order auth compl:  FALSE 
# Source:  OGC:CRS84 
# Target:  EPSG:22525 
# Best instantiable operation has only ballpark accuracy 
# Description: Ballpark geographic offset from WGS 84 (CRS84) to
#              Corrego Alegre 1970-72 + UTM zone 25S
# Definition:  +proj=pipeline +step +proj=unitconvert +xy_in=deg
#              +xy_out=rad +step +proj=utm +zone=25
#              +south +ellps=intl
```

`st_transform()` 함수가 선택한 가장 정확한 오프레이션 파이프라인이 기본값이지만, `pipeline` 아규먼트를 지정하면 결과를 변경할 수도 있다. 이 경우 `p$definition`에 있는 옵션 중 하나를 선택하면 된다.

### 축 순서와 방향

2.5절에서 언급했듯이, EPSG:4326은 첫 번째 축을 위도에, 두 번째 축을 경도에 대응하도록 정의한다. 이는 많은 다른 타원체 CRS에서도 동일하다. 이러한 방식은 해당 기관(EPSG)이 규정한 것이지만, 현재 대부분의 데이터셋은 이러한 방식을 따르지 않는다. 대부분의 다른 소프트웨어와 마찬가지로, **sf** 패키지는 이를 무시하고 기본값으로 타원체 좌표 쌍을 (경도, 위도)로 해석한다. 그러나 해당 기관의 규정을 준수하는 데이터 원천(예: WFS 서비스)에서 생성된 데이터를 읽어야 하는 경우, 다음과 같이 지정할 수 있다.

```{r}
#| eval: false
st_axis_order(TRUE)
```

이렇게 하면 **sf** 패키지가 GDAL과 PROJ 루틴을 호출할 때, 규정 준수(위도ㆍ경도 순서)가 항상 전제되도록 할 수 있다. 그러나 이러한 규정 준수 과정에서 많은 문제가 발생할 수 있으며, 예를 들어 데이터를 플로팅할 때 그 문제가 드러난다. `sf` 객체를 위한 플롯 메서드는 축 순서 규정을 준수하며, 플로팅 전에 변환 파이프라인 `"+proj=pipeline +step +proj=axisswap +order=2,1"`을 사용해 위도ㆍ경도 순서를 바꾸지만, **ggplot2** 패키지의 `geom_sf`는 이러한 수정 과정을 거치지 않는다. 앞서 언급했듯이, `EPSG:4326`에서 발견되는 축 순서의 모호성은 `OGC:CRS84`를 사용하면 모두 해결된다.

축 순서와는 별개의 문제로, 모든 CRS가 북쪽과 동쪽 방향을 양의 값으로 지정하는 것은 아니라는 점도 매우 중요하다. R의 대부분의 플로팅 함수는 이와 반대로 정의된 축을 가진 데이터에서는 제대로 작동하지 않는다. 축의 방향과 단위에 대한 정보는 다음과 같이 확인할 수 있다.

```{r}
#| eval: false
st_crs(4326)$axes
#                 name orientation
# 1  Geodetic latitude           1
# 2 Geodetic longitude           3
st_crs(4326)$ud_unit
# 1 [°]
st_crs("EPSG:2053")$axes
#       name orientation
# 1  Westing           4
# 2 Southing           2
st_crs("EPSG:2053")$ud_unit
# 1 [m]
```

## 래스터 변환 및 워프

래스터 데이터셋에 대해 `st_transform()` 함수를 사용할 때는 다음과 같이 한다.

```{r}
#| eval: false
tif <- system.file("tif/L7_ETMs.tif", package = "stars")
read_stars(tif) |>
    st_transform('OGC:CRS84')
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max.
# L7_ETMs.tif     1      54     69 68.9      86  255
# dimension(s):
#      from  to refsys point                    values x/y
# x       1 349 WGS 84 FALSE [349x352] -34.9,...,-34.8 [x]
# y       1 352 WGS 84 FALSE [349x352] -8.04,...,-7.95 [y]
# band    1   6     NA    NA                      NULL    
# curvilinear grid
```

이제 *곡선형* 그리드가 생성된 것을 확인할 수 있다 이는 새로운 CRS에 따라 모든 그리드 셀의 좌표가 재계산되므로 더 이상 *정규* 그리드로 존재할 수 없음을 의미한다. 이러한 데이터를 플로팅하면 속도가 극도로 느려지는데, 그 이유는 각 그리드 셀에 대해 작은 폴리곤을 먼저 계산한 뒤 플로팅하기 때문이다. 장점은 정보가 손실되지 않는다는 점으로, 투영 이후에도 그리드 셀의 값은 그대로 유지된다.

정규 그리드를 입력하여 새로운 CRS에서도 *정규* 그리드를 산출하려면 *워프* 오퍼레이션을 적용해야 한다. 즉, 새로운 위치에 그리드를 재생성하고 새로운 그리드 셀에 값을 할당하는 특정 규칙을 사용해야 한다. 이 과정에는 가장 가까운 값을 사용하거나 방법이나, 어떤 형태의 보간법을 적용하는 방법도 포함될 수 있다.(역자주: 이러한 작업은 GIS 래스터 분석인 원격탐사 분야에서는 재샘플링(resampling)이라고 하는데, 최근린(nearest neighbor), 양선형(bilibear), 3차 회선(cubic convolution) 등의 인터폴레이션 기법이 사용된다.) 다만, 이 오퍼레이션은 정보 손실이 발생하며, 한 번 수행되면 원래 데이터로 되돌릴 수 없다.

워프를 수행하는 가장 좋은 방법은 타깃 그리드를 `stars` 객체로 지정하는 것이다. 타깃 CRS만 지정할 경우, 문제에 전혀 맞지 않는 기본 옵션이 선택될 수 있다. 타깃 CRS만 사용하는 예시 워크플로우는 다음과 같다.

```{r}
#| eval: false
read_stars(tif) |>
    st_warp(crs = st_crs('OGC:CRS84')) |>
    st_dimensions()
#      from  to offset     delta refsys x/y
# x       1 350  -34.9  0.000259 WGS 84 [x]
# y       1 352  -7.95 -0.000259 WGS 84 [y]
# band    1   6     NA        NA     NA
```

이는 상당한 근사 래스터를 생성하지만, 변환량은 상대적으로 작다. 소스 래스터와 정확히 동일한 행과 열을 갖는 타깃 래스터를 먼저 생성하려는 워크플로우의 경우, 다음과 같이 하면 된다.

```{r}
#| eval: false
r <- read_stars(tif)
grd <- st_bbox(r) |>
        st_as_sfc() |>
        st_transform('OGC:CRS84') |>
        st_bbox() |>
        st_as_stars(nx = dim(r)["x"], ny = dim(r)["y"])
st_warp(r, grd)
# stars object with 3 dimensions and 1 attribute
# attribute(s):
#              Min. 1st Qu. Median Mean 3rd Qu. Max. NA's
# L7_ETMs.tif     1      54     69 68.9      86  255 6180
# dimension(s):
#      from  to offset     delta refsys x/y
# x       1 349  -34.9   0.00026 WGS 84 [x]
# y       1 352  -7.95 -0.000259 WGS 84 [y]
# band    1   6     NA        NA     NA
```

여기서 $x$와 $y$의 방향의 그리드 해상도가 조금 달라졌음을 확인할 수 있다.

## 연습문제

R을 사용하여 다음 연습문제를 해결하시오.

1.  `nc` 카운티 중 `LINESTRING(-84 35, -78 35)`와 인턱센션하는 카운티의 이름을 찾으시오. 이를 위해 `[]`를 사용하고, 대안으로 `st_join()` 함수를 사용하시오.

2.  `sf_use_s2(FALSE)`를 설정한 후 위 작업을 반복하고, 차이를 *계산*하시오(힌트: `setdiff()`사용). 차이가 나타나는 카운티는 색상 `‘#88000088’`로 채색하시오.

3.  두 지점 사이의 직선과 대권을 하나의 플롯에 그리시오. 현재 사용 중인 투영법에서는 R이 직선을 항상 직선으로 그린다는 점을 명심하시오. `st_segmentize()` 함수를 사용하여 직선 또는 타원 좌표의 대권 상에 포인트를 추가하시오.

4.  NDVI는 `(NIR-R)/(NIR+R)`로 계산되며, 여기서 NIR은 근적외선 밴드, R은 적색 밴드이다. `L7_ETMs.tif` 파일을 객체 `x`로 읽고, `split(x, "band")`를 사용하여 밴드 디멘션을 속성으로 분리하시오. 그런 다음 NIR(밴드 4)과 R(밴드 3) 속성을 직접 사용하는 표현식을 이용해 이 객체에 NDVI 속성을 추가하시오.

5.  `L7_ETMs.tif` 이미지의 밴드 디맨션을 축소하여 NDVI를 계산하시오. 이를 위해 `st_apply()` 함수와 `ndvi = function(x) { (x[4]-x[3])/(x[4]+x[3]) }` 함수를 사용하시오. 결과를 플로팅하고, GeoTIFF 형식으로 저장하시오.

6.  `L7_ETMs.tif`에서 읽은 `stars` 객체를 `st_transform()` 함수를 사용하여 `OGC:CRS84`로 변환하시오. 객체를 출력하시오. 이것이 정규 그리드인지 확인하시오. 첫 번째 밴드를 `axes=TRUE`, `border=NA` 아규먼트와 함께 플로팅하고, 왜 이렇게 시간이 오래 걸리는지 설명하시오.

7.  `L7_ETMs.tif` 객체를 `st_warp()` 함수를 사용하여 `OGC:CRS84`로 변환하시오. 결과 객체를 `axes=TRUE`로 플로팅하시오. 왜 `st_transform()` 함수에 비해 플롯이 훨씬 더 빨리 생성되는지 설명하시오.

8.  래스터 `L7_ETMs`의 벡터 표현을 사용하여 `POINT(293716 9113692)`를 중심으로 반지름 75m인 원형 영역과의 인터센션을 플로팅하고, 이 원의 면적-가중 평균 픽셀 값을 계산하시오. 벡터 데이터를 이용해 애그리게이션한 값과 래스터 데이터를 이용해 애그리게이션한 값(`exact=FALSE` 및 `exact=TRUE` 각각) 비교하고, 차이점을 설명하시오.
