[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "공간데이터사이언스 개론",
    "section": "",
    "text": "서장\n데이터사이언스는 주어진 데이터를 바탕으로 질문에 대한 해답을 찾고, 그 과정을 서로 소통하는 학문이다. 데이터사이언스에서의 소통은 단순히 결과를 보여주는 것에 그치지 않고, 사용된 데이터를 공유하고, 답을 도출하는 과정을 포괄적이고 재현 가능한 방식으로 제시하는 것을 포함한다. 또한 데이터사이언스는 주어진 데이터가 질문에 답하기에 충분치 않을 수 있음을, 그리고 비록 답이 도출되었다 하더라도 데터 수집 또는 표집 방식에 따라 답이 달라질 수 있음을 인정한다.\n이 책은 공간적 데이터의 기본 개념을 소개하고 설명한다. 포인트, 라인, 폴리곤, 래스터, 커버리지, 지오메트리 속성, 데이터 큐브, 참조계와 같은 기초 개념에서부터 속성이 지오메트리와 어떻게 연결되는지와 이것이 분석에 어떤 영향을 끼치는지 등과 관련된 보다 고차원적인 개념도 다룬다. 속성과 지오메트리의 관계를 서포트(support)라고 하는데, 서포트가 변경되면 속성의 특성도 변화한다. 어떤 데이터는 공간적 연속성에 기반해 생성되기 때문에 모든 지점에서 관찰될 수 있다. 반면, 다른 데이터는 공간적 이산성에 기반해 생성되기 때문에 특정한 구획 체계에 의거해 관찰된다. 현대 공간데이터분석에서는 이러한 구획 체계 방식이 빈번히 사용되며, 포인트 데이터, 지구통계학적 데이터, 에어리어 데이터를 가리지 않고 폭넓게 적용되고 있다. 공간적 재현의 중요성을 뒷받침하는 것이 바로 서포트(그리고 서포트에 대한 이해)이다. 이 책은 공간데이터를 자신의 분석에 활용하고자 하는 데이터 과학자를 대상으로 하고 있다. 어떻게 공간데이터분석을 행하는 지를 예시하기 위해 R를 사용한다. 향후에 파이썬(Python)(예: Bivand 2022a)과 줄리아(Julia)을 사용한 예시도 추가할 예정이다.\n사람들은 종종 공간데이터란 관측 개체의 경위도값이 데이터셋에 포함되어 있는 것을 의미하고, 경위도값을 여타의 변수와 마찬가지로 취급하면 된다고 생각한다. 이는 기회를 놓치고 무의미한 분석을 초래할 위험이 있다. 다음과 같은 예를 들 수 있다.\n우리는 공간데이터, 좌표참조계, 공간분석과 관련된 다양한 개념을 소개하고, 더불어 sf (Pebesma 2018, 2022a), stars (Pebesma 2022b), s2 (Dunnington, Pebesma, and Rubak 2023) and lwgeom (Pebesma 2023)와 같은 다양한 R 패키지를 소개한다. 또한 공간적 타이디버스 (Wickham et al. 2019; Wickham 2022) 확정 패키지 및 이들 패키지와 함께 사용할 수 있는 공간분석 및 시각화 패키지인 gstat (Pebesma 2004; Pebesma and Graeler 2022), spdep (Bivand 2022b), spatialreg (Bivand and Piras 2022), spatstat (Baddeley, Rubak, and Turner 2015; Baddeley, Turner, and Rubak 2022), tmap (Tennekes 2018, 2022), mapview (Appelhans et al. 2022)도 포함된다.\n데이터사이언스와 마찬가지로, 공간데이터사이언스도 특정 과학 분야의 하위 분야로 발전한 것이 아니라 공간데이터의 적용과 관련된 수많은 학문 혹은 산업 영역로부터 상향식으로 발전해 온 분야인 것으로 보인다. 학술 컨퍼런스, 심포지움, 학회, 연구 프로그램 등을 통해 공간데이터사이언스를 규정하려는 다양한 시도들이 이루어지고는 있지만, 공간데이터의 적용 영역이 너무나 다양하기 때문에 이러한 활동이 결실을 맺기는 쉽지 않아 보인다. 이 책에 “공간데이터사이언스”라는 제목을 붙이는 것은 이 분야의 경계를 획정하려는 또 다른 시도가 아니라, 연구 주제, 데이터, 소프트웨어를 활용한 연구 과정, 이 모두를 기꺼이 공유하고자 한 수 많은 분야의 수 많은 연구자들과 함께 한 지난 30~40년간의 경험을 이 분야의 발전을 위해 쓰고 싶기 때문이다. 따라서 이 책에서 다루는 주제의 선택은 우리 자신의 연구 관심 분야와 경험에 의해 어느정도 편향되어 있을 수 밖에 없다.\n개방형 연구 커뮤니티를 만드는 데 도움을 준 플랫폼으로는 ai-geostats 및 r-sig-geo 메일링 리스트, sourceforge, r-forge, GitHub, 그리고 2006년부터 매년 개최되는 OpenGeoHub 여름 학교가 있다. 데이터사이언스의 언어 장벽을 넘고자 한 수 많은 노력의 결과 현재 우리는 새롭고도 가슴뛰는 퍼스펙티브가 열리고 있음을 목도하고 있다. 이 분야에 기여하고자 하는 것은 오픈사이언스가 더 나은 과학으로 이어지며, 더 나은 과학이 보다 지속 가능한 세상에 기여할 수 있다는 믿음 때문이다.",
    "crumbs": [
      "서장"
    ]
  },
  {
    "objectID": "part_1.html",
    "href": "part_1.html",
    "title": "공간데이터",
    "section": "",
    "text": "이 첫 번째 파트에서는 공간데이터사이언스의 핵심 개념을 다룬다. 지도, 투영, 벡터와 래스터 데이터 구조, 소프트웨어, 속성과 서포트, 데이터 큐브와 같은 개념들에 대해 배울 것이다. R은 이 파트에서는 별로 중요하지 않다. 주로 텍스트 아웃풋이나 그래프 작성을 위해서만 사용될 것이다. 따라서 내용에 집중한다는 의미에서 R코드 자체를 보여주거나 설명하는 일은 없을 것이다. R은 두 번째 파트에서 집중적으로 다루어진다. 그래도 이 책의 온라인 버전(https://r-spatial.org/book/)을 통해 감춰진 R 코드를 펼쳐 볼 수 있고, 필요한 경우 클립보드에 복사하여 실행해 볼 수 있다. R 코드를 실행한 결과는 # 기호로 시작하며 코드 폰트를 사용하여 나타낸다.\n\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\n\n공간데이터사이언스 문제에 답을 제시하기 위한 R 코드에 대한 보다 상세한 설명은 이 책의 두 번째 파트에서 시작한다. 부록 B — R 기초 에는 R 데이터 구조에 대한 간략한 설명이 나타나 있다. 보다 자세한 사항은 Wickham (2019) 을 참고하라.\n\n\n\n\nWickham, Hadley. 2019. Advanced R. 2nd edition. Boca Raton: Chapman; Hall/CRC.",
    "crumbs": [
      "공간데이터"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wickham, Hadley. 2019. Advanced r. 2nd edition. Boca Raton:\nChapman; Hall/CRC.",
    "crumbs": [
      "부록",
      "References"
    ]
  },
  {
    "objectID": "06.html",
    "href": "06.html",
    "title": "6  데이터 큐브",
    "section": "",
    "text": "6.1 4차원 데이터 큐브\n그림 6.2는 4차원 래스터 데이터 큐브를 보여준다(Appel and Pebesma 2019). 여기서 스펙트럼 차원(“밴드”)을 가진 3차원 래스터 데이터 큐브가 네 번째 차원인 시간 축을 따라 조직된다. 컬러 이미지 데이터는 항상 세 개의 밴드(파란색, 녹색, 빨간색)를 가지며, 이 예제는 스펙트럼 원격탐사 데이터에서 일반적으로 발견되는 네 번째 밴드(근적외선, NIR)를 포함하고 있다.\n그림 6.3은 정확히 동일한 데이터를 보여주지만, 평면적으로 배열한 패싯 플롯(또는 산점도 행렬)으로 나타내고 있다. 플롯의 두 차원(\\(x\\) 및 \\(y\\))은 기본적으로는 밴드와 시간 차원을 의미하지만, 세부 플롯 내부에서는 실제 좌표계를 의미한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "01.html",
    "href": "01.html",
    "title": "1  시작하기",
    "section": "",
    "text": "1.1 첫 번째 지도\n공간데이터를 표현하는 전형적인 방법은 지도를 그리는 것이다. 그림 1.1에는 단순한 지도가 나타나 있다.\n이 지도에는 몇 가지 그래픽 요소들이 나타나 있다.\n폴리곤은 특정한 형태의 지오메트리이다. 공간적 지오메트리(포인트, 라인, 폴리곤, 픽셀)에 대해서는 3장에서 자세히 다룬다. 폴리곤은 여러 개의 포인트들로 구성되어 있고, 포인트들은 선분으로 서로 이어져 있다. 공간데이터의 포인트 위치가 어떻게 표현되고 측정되는지에 대해서는 2장에서 다룬다. 그림 1.1에서 볼 수 있는 것처럼, 모든 경위선이 직선으로 표현되는 것이 아니다. 이것은 지도에 특정한 형태의 투영법이 적용되어 있음을 의미한다. 지도투영에 대해서는 2장과 8.1절에서 다룬다.\n그림 1.1에서 컬러로 표현되어 있는 것은 BIR74라는 변수의 값이다. 값 하나는 지오메트리 혹은 피쳐(feature) 하나와 연결되어 있다. 5장은 이러한 피처 속성 및 그것들이 피처 지오메트리와 어떻게 관련되어 있는지에 대해서 다룰 것이다. BIR74 변수는 출생아수를 나타내며, 이는 지역별 빈도값이다. 지역별 빈도값이라는 말은 이 값이 지역 내의 모든 지점과 관련되어 있는 것이 아니라는 것을 의미하는데, 지도의 컬러가 연속적인 값을 취하고 있기 때문에 이렇게 오해할 수 있지만, 사실 빈도값은 폴리곤에 전체와 연결되어 있는 일종의 적분값을 의미한다.\n그림 1.1을 그리기 위해서는 당연히 데이터가 필요한데, 7.1절에서 사용된 파일을 읽어 들였다. 세 개의 속성 변수에 대한 첫 세 개 레코드의 데이터 요약을 출력하면 다음과 같다.\n이 데이터 요약은 다음의 사항을 알려준다:\n패싯(facet) 플롯을 활용하면 그림 1.2에서 보는 것과 같은 보다 복잡한 형태의 지도를 그릴 수 있다.\n리플릿(leaflet)을 활용하면 그림 1.3 에서 보는 것과 같은 상호작용형 지도를 만들 수 있다.\n그림 1.3: mapview로 그린 상호작용형 지도: 팬과 줌을 이용해 지도 스케일에 변화를 줄 수 있고 카운티를 클릭하면 해당 카운티의 속성을 보여주는 팝업 윈도우가 뜬다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#첫-번째-지도",
    "href": "01.html#첫-번째-지도",
    "title": "1  시작하기",
    "section": "",
    "text": "그림 1.1: 첫 번째 지도: 미국 노스캐롤라이나의 카운티별 출생아수, 1974~78년\n\n\n\n\n검은색 외곽선을 가진 폴리곤이 나타나 있고, 폴리곤의 내부는 BIR74라는 변수(제목)의 값에 따라 상이한 컬러로 채워져 있다.\n범례는 서로 다른 컬러가 무엇을 의미하는지를 설명하고 있는데, 특정한 컬러 팔레트가 적용되어 있고, 컬러가 변하는 지점에 컬러 단절값이 나타나 있다.\n경위선망(그래티큘)이 지도의 배경에 나타나 있다.\n축의 눈금은 특정한 경도값과 위도값이다.\n\n\n\n\n# Simple feature collection with 100 features and 3 fields\n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6\n# Geodetic CRS:  NAD27\n# # A tibble: 100 × 4\n#    AREA BIR74 SID74                                             geom\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;                               &lt;MULTIPOLYGON [°]&gt;\n# 1 0.114  1091     1 (((-81.5 36.2, -81.5 36.3, -81.6 36.3, -81.6 36…\n# 2 0.061   487     0 (((-81.2 36.4, -81.2 36.4, -81.3 36.4, -81.3 36…\n# 3 0.143  3188     5 (((-80.5 36.2, -80.5 36.3, -80.5 36.3, -80.5 36…\n# # ℹ 97 more rows\n\n\n데이터셋은 100개의 피처(레코드)와 3개의 필드(속성)으로 구성되어 있다.\n지오메트리 유형은 MULTIPOLYGON (3장)이다.\n디멘션(dimension)은 XY이다. 즉, 개별 포인트는 두 개의 좌표값으로 구성되어 있다.\nCRS(coordinate reference system, 좌표참조계)는 측지(geodetic) 좌표계이며, NAD27 데이텀(datum)에 의거한 경위도값을 가지고 있다(2장).\n세 개의 속성 변수 바로 다음에 MULTIPOLYGON 유형의 geom 변수가 있는데, 이것은 폴리곤 정보를 도(degree) 형식으로 담고있다.\n\n\n\n\n\n\n\n그림 1.2: “미국 노스캐롤라이나 카운티별 영아돌연사증후군에 의한 사망아수의 패싯 지도, 1974~78년과 1979~84년”",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "08.html",
    "href": "08.html",
    "title": "8  공간데이터의 플로팅",
    "section": "",
    "text": "8.1 모든 지도는 투영법을 가지고 있다.\n세상은 둥글지만, 플로팅 장치는 평평하다. 2.2.2절에서 언급했듯이, 세상을 평평한 장치에 어떤 방식으로든 플로팅한다는 것은 우리가 특정한 투영법을 적용하고 있는 것을 의미한다. 즉, 타원체 좌표를 특정한 방식으로 데카르트 좌표로 전환하고 있는 것이다. 이는 우리가 아무것도 하지 않았다고 생각하는 경우(역자주: 투영법을 적용하지 않았다고 생각하는 경우)(그림 8.1의 왼쪽)나, 우주에서 본 것처럼 세상을 “있는 그대로” 보여준다고 생각하는 경우(그림 8.1의 오른쪽)에도 마찬가지이다. 평면 상의 모든 지도는 투영법을 가지고 있다.\n왼쪽 지도는 다음의 코드로 그렸다.\nlibrary(sf)\nlibrary(rnaturalearth)\nw &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nplot(st_geometry(w))\n타원 좌표로 지구 전체를 나타내고자 할 때, 해당 투영법이 디폴트 투영법이라는 점을 다음을 통해 알 수 있다.\nst_is_longlat(w)\n# [1] TRUE\n그림 8.1(왼쪽)에 사용된 투영법은 등장방형 도법(정거원통 도법)으로, 경도를 \\(x\\)-축과 위도를 \\(y\\)-축과 선형적으로 연결지어 나타냄으로써 지도의 가로세로의 거리 단위가 동일하게 유지되게 한 것이다(역자주: 지구의 동서 길이는 360도이고 남북 길이는 180도이므로, 이 지도의 가로세로비는 정확히 2:1로 나타난다). 그러므로 지구의 일부분에 대해 이 투영법을 적용하여 플롯할 경우, 지도의 동서 방향과 남북 방향의 거리 단위가 동일하게 유지되도록 플롯 비율을 선택해야 한다. 이는 비투영 sf 또는 stars 데이터셋에 대한 plot 메서드의 디폴트 동작이며, ggplot2::geom_sf의 기본 설정이기도 하다(8.4절)(역자주: 비투영 객체는 경위도 좌표계를 가지고 있다는 것인데, 그것을 plot 메서드를 통해 플롯하게되면, 디폴트로 경위도 좌표를 마치 \\(xy\\) 좌표처럼 나타낸다는 의미이다. 지구 전체에 대한 비투영 객체를 이러한 방식으로 플롯하면 시각적으로는 등장방형 도법과 동일하게 나타난다.).\n플로팅 전에 투영법을 적용하여 데이터를 변형할 수도 있다. 예를 들어 독일을 플로팅하려고 한다면, 국가 경계를 불러온 후, st_transform 함수를 사용하여 투영을 수행한다.\nDE &lt;- st_geometry(ne_countries(country = \"germany\",\n                              returnclass = \"sf\"))\nDE |&gt; st_transform(\"+proj=eqc +lat_ts=51.14 +lon_0=90w\") -&gt;\n    DE.eqc\n여기서 eqc는 PROJ의 “등장방형 도법”을 의미한다. lat_ts는 투영 파라미터로 표준 위선(축척의 왜곡이 없는 위선)의 위치를 지정할 수 있다. 이 표준 위선 상에서 동서 방향과 남북 방향의 길이 단위가 동일해진다. 이 값은 지도의 바운딩 박스의 중간 지점에 해당한다.\n그림 8.2에 나타난 두 지도를 보면, 축의 값들을 제외하고는 두 지도는 동일하다는 점을 알 수 있다. 왼쪽 지도의 축 값은 타원 좌표(도 단위)이고, 오른쪽 지도의 축 값은 투영 좌표(데카르트 좌표)(미터 단위)이다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "03.html",
    "href": "03.html",
    "title": "3  지오메트리",
    "section": "",
    "text": "3.1 심플 피쳐 지오메트리\n심플 피처 지오메트리는 피처의 지오메트리를 설명하는 방법이다. 여기서 피처란 지오메트리를 가진 사물을 의미하는데, 암묵적으로 시간 속성을 가질 수 있고, 사물 자체를 묘사하기 위한 라벨이나 사물을 정량적으로 측정한 값과 관련된 속성을 가질 수 있다. 단순 피처 지오메트리의 주된 용도는 2차원 공간의 기하학적 형태를 포인트, 라인, 또는 폴리곤에 의거해 설명하는 것이다. “심플”이라는 형용사가 붙은 이유는 라인이나 폴리곤 지오메트리 역시 포인트 지오메트리와 그것을 연결한 직선으로 표현될 수 있기 때문이다.\n심플 피처 억세스(access)는 심플 피처 지오메트리를 설명하는 표준으로(Herring 2011, 2010; ISO 2004), 다음의 사항을 포함한다.\n먼저 가장 일반적으로 사용되는 7가지 심플 피처 지오메트리 유형에 대해 논의할 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "part_2.html",
    "href": "part_2.html",
    "title": "공간데이터사이언스와 R",
    "section": "",
    "text": "이 책의 두 번째 파트는 첫 번째 파트에서 다루어진 개념이 R을 통해 어떻게 실행되는지를 설명한다. 7장은 공간데이터의 기본적인 처리 방법을 다루며, 데이터 읽기, 쓰기, 하위 집합 만들기, 공간적 프레디케이트(조건, 술어)에 따른 선택, 버퍼나 인터섹션과 같은 기하학적 변환, 래스터-벡터 및 벡터-래스터 변환, 데이터 큐브 처리, 구면 기하학, 좌표 변환 및 전환 등을 포함한다. 이어서 8장에서는 공간 및 시공간 데이터의 시각화에 대한 내용을 집중적으로 다루는데, R의 기본 플롯 기능 뿐만 아니라 ggplot2, tmap 및 mapview와 같은 패키지를 활용한다. 이 장에서는 투영, 컬러, 컬러 단절값, 그래티큘, 범례와 같은 지도 그래픽 요소, 그리고 대화형(인터렉티브) 지도에 대해 다룬다. 9장에서는 메모리 사용량이 너무 크거나 다운로드하기에는 너무 큰 대형 벡터 또는 래스터 데이터셋 또는 데이터 큐브를 처리하는 접근 방법에 대해 논의한다.\n이 파트에서 다루는 내용은 패키지에 대한 완전한 튜토리얼이나 매뉴얼이 아니라, 여러 일반적인 워크플로우에 대한 설명과 예시를 제공하는 것이다. 보다 완전하고 상세한 정보는 패키지 문서, 특히 sf와 stars 패키지의 비네트에서 확인할 수 있다. 이들에 대한 링크는 각 패키지의 CRAN 랜딩 페이지에서 찾을 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R"
    ]
  },
  {
    "objectID": "index.html#사사",
    "href": "index.html#사사",
    "title": "공간데이터사이언스 개론",
    "section": "사사",
    "text": "사사\n우리는 r-spatial 커뮤니티 전체에 감사하며, 특히 다음에 기여한 분들께 특별한 감사의 마음을 전한다.\n\nr-spatial 패키지를 개발하거나 그 개발에 기여한 분들\n트위터 #rspatial 또는 GitHub에서 디스커션에 참여한 분들\n강좌, 여름 학교, 또는 컨퍼런스에서 의견을 주거나 질문을 한 분들\n\n우리는 s2 패키지를 구현한 Dewey Dunnington, 적극적인 도움을 준 Sahil Bhandari, 6  데이터 큐브 의 그래프 제작을 도와준 Jonathan Bahlmann, 그리고 Claus Wilke와 Jakub Nowosad에게 특별한 감사의 마음을 전한다. 2021년과 2022년에 있었던 “R을 활용한 공간데이터사이언스(Spatial Data Science with R)” 강좌로부터 큰 도움을 받았다. GitHub의 이슈, 풀 리퀘스트 또는 디스커션에 적극적으로 기여한 분들께도 감사의 마음을 표한다.\n\n책 리포지터리에 기여한 분들 (Nowosad, jonathom, JaFro96, singhkpratham, liuyadong, hurielreichel, PPaccioretti, Robinlovelace, Syverpet, jonas-hurst, angela-li, ALanguillaume, florisvdh, ismailsunni, andronaco)\nsf 리포지터리에 기여한 분들 (aecoleman, agila5, andycraig, angela-li, ateucher, barryrowlingson, bbest, BenGraeler, bhaskarvk, Bisaloo, bkmgit, christophertull, chrisyeh96, cmcaine, cpsievert, daissi, dankelley, DavisVaughan, dbaston, dblodgett-usgs, dcooley, demorenoc, dpprdan, drkrynstrng, etiennebr, famuvie, fdetsch, florisvdh, gregleleu, hadley, hughjonesd, huizezhang-sherry, jeffreyhanson, jeroen, jlacko, joethorley, joheisig, JoshOBrien, jwolfson, kadyb, karldw, kendonB, khondula, KHwong12, krlmlr, lambdamoses, lbusett, lcgodoy, lionel-, loicdtx, marwahaha, MatthieuStigler, mdsumner, MichaelChirico, microly, mpadge, mtennekes, nikolai-b, noerw, Nowosad, oliverbeagley, Pakillo, paleolimbot, pat-s, PPaccioretti, prdm0, ranghetti, rCarto, renejuan, rhijmans, rhurlin, rnuske, Robinlovelace, robitalec, rubak, rundel, statnmap, thomasp85, tim-salabim, tyluRp, uribo, Valexandre, wibeasley, wittja01, yutannihilation, Zedseayou)\nstars 리포지터리에 기여한 분들(a-benini, ailich, ateucher, btupper, dblodgett-usgs, djnavarro, ErickChacon, ethanwhite, etiennebr, flahn, floriandeboissieu, gavg712, gdkrmr, jannes-m, jeroen, JoshOBrien, kadyb, kendonB, mdsumner, michaeldorman, mtennekes, Nowosad, pat-s, PPaccioretti, przell, qdread, Rekyt, rhijmans, rubak, rushgeo, statnmap, uribo, yutannihilation)\ns2 리포지토리에 기여한 분들(kylebutts, spiry34, jeroen, eddelbuettel)",
    "crumbs": [
      "서장"
    ]
  },
  {
    "objectID": "07.html",
    "href": "07.html",
    "title": "7  sf와 stars",
    "section": "",
    "text": "7.1 sf 패키지\nR 패키지 sf(Pebesma 2018)는 기존의 R 패키지인 sp, rgeos 및 rgdal의 벡터 부분을 대체하고 성공적으로 이어받기 위해 개발되었으며, 산업계 및 오픈 소스 프로젝트에서 볼 수 있는 표준 기반 접근법에 더 가까이 다가가고, 최신 버전의 오픈소스 지리공간 소프트웨어 스택(그림 1.7)을 기반으로 하며, 필요 시 R 공간 소프트웨어와 타이디버스(Wickham et al. 2019)의 통합을 가능하게 한다.\n이를 위해 sf는 R에 네이티브로 심플 피처 접근(Herring et al. 2011)을 제공한다. 이 패키지는 여러 타이디버스 패키지, 특히 ggplot2, dplyr, tidyr와의 인터페이스를 제공하며, GDAL을 통해 데이터를 읽고 쓰고, GEOS(투영 좌표의 경우) 또는 s2geometry(타원체 좌표의 경우)를 사용하여 기하학적 연산을 수행하며, PROJ를 이용해 좌표 변환 또는 좌표 전환 작업을 수행할 수 있다. 외부 C++ 라이브러리와의 인터페이싱(연결)은 Rcpp 패키지(Eddelbuettel 2013)를 통해 이루어진다.\nsf는 sf 객체로 심플 피처를 나타내며, 이는 data.frame 또는 티블(tibble)의 하위 클래스이다. sf 객체는 최소 하나 이상의 sfc 클래스의 지오메트리 리스트 열(list-column)을 포함하는데, 각 요소는 sfg 클래스의 R 객체로서 지오메트리 정보를 담고 있다. 지오메트리 리스트 열은 data.frame 또는 티블 내에서 변수처럼 작동하지만, 숫자나 문자형 변수와 같은 기본 벡터보다 더 복잡한 구조를 가지고 있다(부록 B.3 참조).\nsf 객체는 다음과 같은 메타데이터를 가진다.\nsfc 지오메트리 리스트 열은 st_geometry함수를 통해 sf 객체에서 추출되며, 다음과 같은 메타데이터를 가진다\n이러한 속성들의 값을 확인하거나 수정하기 위해 st_bbox, st_crs, st_set_crs, st_agr, st_set_agr, st_precision, st_set_precision 같은 함수를 사용할 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "01.html#crs",
    "href": "01.html#crs",
    "title": "1  시작하기",
    "section": "\n1.2 CRS",
    "text": "1.2 CRS\n\n\n\n그림 1.1: 첫 번째 지도: 미국 노스캐롤라이나의 카운티별 출생아수, 1974~78년\n그림 1.2: 미국 노스캐롤라이나 카운티별 영아돌연사증후군에 의한 사망아수의 패싯 지도, 1974~78년과 1979~84년",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#좌표참조계",
    "href": "01.html#좌표참조계",
    "title": "1  시작하기",
    "section": "\n1.2 좌표참조계",
    "text": "1.2 좌표참조계\n그림 1.1의 배경에 그어진 회색선은 경위선망, 즉 그래티큘(graticule)이다. 경위선이 두 축과 직교하는 직선이 아니라는 점이 명백하다. 이것은 데이터에 특정한 투영법이 적용되어 있음을 의미한다. 그런데 그림 1.3에는 노스케롤라이나의 북쪽 경계가 곡선이 아닌 직선으로 표현되어 있는데, 이것은 또 다른 투영법이 적용되었음을 의미한다.\n그림 1.1에 나타나 있는 경위도 좌표는 특정한 데이텀(여기서는 NAD27)과 연결되어 있다(역자주: 경위도 좌표는 절대적인 것이 아니라 데이텀에 따라 달라지는 상대적인 것이라는 점을 반드시 이해해야 한다. 동일한 지점이 데이텀에 따라 다른 경위도 좌표값을 부여받고, 동일한 경위도 좌표값이 데이텀에 따라 지표 상의 다른 지점을 의미한다). 데이텀은 지구를 모델화하기 위해 어떤 지구타원체가 선택되고, 그 지구타원체를 지구와 어떠한 방식으로 일치시킬 것인가(지구타원체의 원점을 지구의 어떤 지점과 어떠한 방향으로 일치시킬 것인가)와 관련된 몇 가지 사항들을 규정한다. GPS 수신기(예: 모바일 폰)를 통해 획득된 좌표값은 WGS84(World Geodetic System 1984) 데이텀에 의거한 것인데, 만일 NAD27(North American Datum 1927)에 의거한 것이라면 동일한 좌표값에 대해 대략 30m 정도의 편차를 나타낼 것이다.\n투영법은 두 개의 좌표값을 연결하는 함수이다.\n\n타원체 좌표(ellipsoidal coordinates): 지구에 대한 수학적 모델(지구타원체 혹은 지구구체) 상의 3차원 좌표로, 경도와 위도로 나타낸 것이다.\n투영 좌표(projected coordinates): 지도 상의 2차원 평면 좌표로, x 좌표와 y 좌표 혹은 동거(easting)와 북거(northing)로 나타낸 것이다.\n\n한 데이텀을 다른 데이텀으로 바꾸는 것을 데이텀 변환이라고 한다. 투영과 좌표계는 공간참조계(spatial reference system)의 설정과 관련되어 있고, 2장에서 상세히 다룬다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#래스터-데이터와-벡터-데이터",
    "href": "01.html#래스터-데이터와-벡터-데이터",
    "title": "1  시작하기",
    "section": "\n1.3 래스터 데이터와 벡터 데이터",
    "text": "1.3 래스터 데이터와 벡터 데이터\n포인트, 라인, 폴리곤 지오메트리는 벡터(vector) 데이터의 예시이다. 벡터 지오메트리를 구성하는 좌표값은 지표 상의 “정확한” 위치를 의미한다. 이에 반해 래스터 데이터는 주로 정사각형 픽셀로 구성된 격자망(이것을 래스터라고 부름)에 속성값이 부여되어 있는 데이터이다. 래스터 데이터의 예가 그림 1.4에 나타나 있다.\n\n\n\n\n\n그림 1.4: “브라질의 대서양 연안 도시 올린다에 대한 래스터 지도: (a) Landsat-7의 블루 탐지대를 타나낸 것으로 서로 다른 컬러는 속성값의 차이를 나타냄. (b) 좌상의 10X10 픽셀만 확대하여 나타낸 것임. (c) 3개의 샘플 포인트로 구성된 벡터 데이터를 중첩하여 나타냄. (d) 샘플 포인트로부터 반경 500m를 나타낸 3개의 폴리곤으로 구성된 벡터 데이터를 중첩하여 나타냄.”\n\n\n벡터 데이터와 래스터 데이터를 여러 가지 방식으로 결합될 수 있다. 예를 들어, 그림 1.4(c)에 나타나 있는 세 포인트에 해당하는 래스터 값만을 추출할 수도 있고, 그림 1.4(d)에 나타나 있는 원과 결부된 모든 래스터 값을 추출할 수도 있다.\n래스터-투-벡터 전환은 7.6절에서 다루어지는데, 다음과 같은 내용이 포함된다.\n\n래스터 픽셀값을 포인트 속성값으로 전환하기\n래스터 픽셀값을 폴리곤 속성값으로 전환한 후, 동일한 속성값을 가진 폴리곤을 머지하기(“폴리곤 생성”)\n특정한 범위의 값을 가진 연속적인 픽셀 연속체를 나타내는 라인이나 폴리곤을 생성하기(“등치선 생성”)\n\n\n\n\n\n\n그림 1.5: 그림 1.1에 나타나 있는 카운티별 출생아수(1974~78)를 래스터화하여 나타낸 지도\n\n\n벡터-투-래스터 전환은 그림 1.5에 나타나 있는 것(폴리곤의 래스터화)처럼 매우 간단한 것일 수 있다. 그러나 다른 형태의 벡터-투-래스터 전환은 통계적 모델링을 수반할 수 있다.\n\n포인트 속성값을 인터폴레이션을 통해 그리드 셀에 할당하기 (12장)\n포인트의 밀도 분포를 추정하여 그리드 셀에 할당하기 (11장)\n폴리곤의 속성값을 에어리어-가중 인터폴레이션을 통해 그리드 셀에 할당하기 (5.3절)\n포인트, 라인, 폴리곤을 래스터로 직접 변환하기 (7.6절)",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#래스터-유형",
    "href": "01.html#래스터-유형",
    "title": "1  시작하기",
    "section": "\n1.4 래스터 유형",
    "text": "1.4 래스터 유형\n래스터 디멘션은 행과 열이 공간 좌표계와 어떻게 관련되어 있는가에 의해 결정된다. 그림 1.6은 다양한 가능성을 예시로 보여주고 있다.\n\n\n\n\n\n그림 1.6: 다양한 래스터 지오메트리 유형\n\n\n그림 1.6에 나타나 있는 레귤러(regular) 래스터는 일정한 모양(반드시 정사각형일 필요는 없다)의 그리드 셀로 이루어져 있고, 가로추과 세로축이 x-축(동거축)과 y-축(북거축)과 일치한다. 그러나 다른 래스터 유형도 존재할 수 있는데, 가로축과 세로축이 더 이상 x-축 및 y-축과 일치하지 않거나(rotated), 가로축과 세로축이 직교하지 않거나(sheared), 셀 크기가 동일 축 상에서 조차 다르게 나타날 수 있다(rectilinear). 심지어 curvilinear 래스터의 경우는 셀의 크기 및 방향 속성이 더 이상 또 다른 래스터 디멘션으로부터 독립적이지 않다(?).\n특정한 좌표참조계에 의거해 regular한 지오메트리 유형을 가진 래스터가 있다고 하자. 이것을 셀 구조는 그대로둔 상태로 다른 투영법으로 전환하게 되면, rectilinear 하게 될 수도 있고(예를 들어, 그림 1.3에서처럼, 측지좌표를 메르카토르 도법으로 전환하는 경우), curvilinear 해 질 수도 있다(예를 들어, 그림 1.1에서처럼, 측지좌표를 람베르트 정형원추 도법으로 전환하는 경우). 이 전환을 역으로 수행하게 되면 정확히 동일한 래스터를 회복할 수 있다.\n새로운 투영법이 적용된 새로운 레귤러 그리드를 생성하는 것을 래스터(혹은 이미지) 재투영(reprojection) 혹은 워핑(warping)이라고 한다(7.8절). 워핑은 정보 손실이 발생하고, 불가역적이며, 다양한 옵션의 설정이 필수적이다. 예를 들어, 새로운 셀 값을 생성하기 위해 인터폴레이션을 적용할지, 평균값을 산출할지, 합산값을 산출할지를 결정해야 하며, 이웃값을 활용한 재표집(resampling)이 적용되어야 할지의 여부를 결정해야 한다. 이러한 선택은 래스터 셀 값이 범주형인지 연속형인지에 따라 달라질 수 있다(1.6절).",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#시계열-어레이-데이터-큐브",
    "href": "01.html#시계열-어레이-데이터-큐브",
    "title": "1  시작하기",
    "section": "\n1.5 시계열, 어레이, 데이터 큐브",
    "text": "1.5 시계열, 어레이, 데이터 큐브\n많은 공간데이터는 단지 공간적이기만 한 것이 아니라 시간적이기도 하다. 모든 관측치는 그것이 관측된 특정한 지점과 결부되어 있을 뿐만 아니라 관측이 이루어진 특정한 시간과도 결부되어 있다. 노스캐롤라이나 카운티 데이터셋은 그림 1.2에서 보는 것처럼 두 기간의 관측값을 가지고 있다. 원 데이터셋에서는 두 기간이 두 개의 변수로 저장되어 있었겠지만, 그림 1.2처럼 두 개의 패싯 지도로 표현되기 위해서는 지오메트리의 반복을 통해 두 변수가 하나의 컬럼에 길게 이어져 있는 형태로 변형되어야 한다. 이러한 형태를 위컴(Wickham)(2014)은 타이디(tidy) 형태라고 부른바 있다. 그런데 지오메트리와 연결된 긴 시계열(time series) 데이터를 가지고 있을 때, 두 개의 옵션(시간을 여러 개의 컬럼에 할당하거나 지오메트리의 반복을 통해 시간을 하나의 컬럼에 길게 배열하는 것) 중 어는 것도 적절해 보이지는 않는다. 이런 경우 보다 효과적인 방법은 메트릭스나 어레이(array) 형식을 취해, 하나의 차원에는 시간을 할당하고 나머지 차원에는 공간을 할당하는 것이다. 이미지나 래스터 데이터는 이미 이러한 방식대로 매트릭스 형태로 저장되어 있고, 여기에 시간이 첨가되면 3차원의 어레이 형태가 된다. 그러한 데이터를 부를는 일반 용어가 바로 (시공간적) 데이터 큐브이다. 큐브는 차원의 개수에 구애받지 않는 어레이를 의미한다. 데이터 큐브는 벡터 데이터와 래스터 데이터 모두를 지칭하는데 사용될 수 있고, 예시들이 6장에서 제시될 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#서포트",
    "href": "01.html#서포트",
    "title": "1  시작하기",
    "section": "\n1.6 서포트",
    "text": "1.6 서포트\n단순한 포인트 지오메트리가 아니라 포인트 집합체의 지오메트리(다중-포인트, 라인, 폴리곤, 픽셀)를 가지 공간데이터의 경우 결부되어 있는 속성값은 지오메트리와 몇 가지 상이한 방식의 관련성을 갖는다.\n\n지오메트리의 모든 포인트에 공통적으로 적용되는 동일값\n지오메트리의 모든 포인트를 집합적으로 대표하는 합산값\n개별 지오메트리의 고유성을 표현하는 식별값\n\n동일값의 예로 폴리곤의 토지이용 속성이나 기반암 유형 속성을 들 수 있고, 합산값의 예로 카운티의 출생아수를 들 수 있고, 식별값으로 카운티 이름을 들 수 있다(역자주: 폴리곤의 토지이용은 폴리곤 내의 모든 지점에 공통적으로 적용될 수 있고, 카운티의 출생아수는 카운티 내 모든 지점의 출생아수를 합산했다는 의미이므로 카운티 내의 모든 지점에 그 값이 적용될 수는 없고, 카운티 전체를 집합적으로 대표한다).\n한 속성값과 결부되어 있는 공간적 개체를 속성값의 서포트라고 한다. 합산값은 “블록” (폴리곤 혹은 라인) 서포트를 갖고 동일값은 “포인트” 서포트를 갖는다 (동일값은 모든 포인트에 적용된다). 예를 들어, 그림 1.5는 폴리곤 서포트를 갖는 변수(카운티별 출생아수)로부터 도출된 것으로, 카운티별 속성값을 카운티를 구성하는 픽셀의 속성값으로 할당한 것이다. 이러한 래스터화를 통해 생성된 지도는 무의미한다. 즉, 속성값인 카운티별 “총출생아수”는 래스터 셀과 무관하며, 속성값과 결부되어 있는 카운티의 경계는 표시 조차되어 있지 않다. 이 지도로부터 노스캐롤라이나 주 전체의 출생아수나 출생아 밀도를 재계산하는 것은 불가능하다. 이처럼 서포트를 무시하는 것은 무의미한 지도의 산출로 귀결된다. 5장에서 좀 더 심도있게 다룰 것이다.\n래스터 셀 속성은 포인트 서포트를 가질 수도 있고 블록 스포트를 가질 수도 있다. 포인트 서포트의 예로 고도를 들 수 있는데, 디지털고도모델(digital elevation model)의 경우 보통 셀 중심점의 고도값을 셀의 속성값으로 저장한다. 블록 서포트 (혹은 셀 서포트)의 예로 위성영상을 들 수 있는데, 이미지 픽셀의 속성값은 주로 픽셀(혹은 픽셀을 중심으로 한 특정 영역) 내부의 값들의 평균값이다. 대부분의 파일 포맷은 이러한 정보를 제공하지 않는다. 그러나 래스터 데이터를 애그리게이팅(aggregating), 리그리딩(regridding), 워핑하거나(7.8절), 포인트별 값을 추출할 때 매우 중요한 사안이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#공간데이터사이언스를-위한-소프트웨어",
    "href": "01.html#공간데이터사이언스를-위한-소프트웨어",
    "title": "1  시작하기",
    "section": "\n1.7 공간데이터사이언스를 위한 소프트웨어",
    "text": "1.7 공간데이터사이언스를 위한 소프트웨어\n이 책의 기본 프로그래밍 언어는 R이고, 공간데이터사이언스를 위한 다양한 R 패키지를 활용한다. 그런데 우리가 사용할 R 패키지 중 많은 것들이 R만을 위해서 개발되지는 않은 다양한 소프트웨어 라이브러리를 활용하고 있다. 하나의 예로서, 그림 1.7은 sf 패키지의 의존계(dependency), 즉 sf 패키지가 어떤 R 패키지나 어떤 시스템 라이브러리에 의존하고 있는지를 보여주고 있다.\n\n\n\n\n\n그림 1.7: sf의 의존계: 직선은 강한 의존성을 점선은 약한 의존성을 나타낸다.\n\n\nC 혹은 C++ 라이브러리(GDAL, GEOS, PROJ, liblwgeom, s2geometry, NetCDF, udunits2)는 모두 R 커뮤니티와는 직접 관련성이 없는 (공간) 데이터사이언스 커뮤니티에 의해 개발, 유지 및 사용되고 있다. 이러한 라이브러리를 활용함으로써 R 사용자들은 이러한 다른 커뮤니티와 무엇을 공유하고 협업하고 있는지를 이해하게 된다. R, 파이썬, 줄리아는 상호작용형 인터페이스를 제공하고 있기 때문에 동일한 라이브러리를 활용하는 다른 소프트웨어의 사용자들과는 달리 이러한 라이브러리에 보다 가깝게 접근할 수 있다. 이 책의 첫 번째 파트에서는 이러한 라이브러리에 어떤한 개념이 녹아들어 있는지를 설명하고자 하는데, 공간데이터사이언스 일반을 이해하는데 도움이 될 것이다.\n\n1.7.1 GDAL\nGDAL(Geospatial Data Abstraction Library)는 공간데이터에 대한 스위스 아미 나이프(Swiss army knife)정도로 생각할 수 있다. GDAL는 R, 파이썬, PostGIS 외에 100개가 넘는 다른 소프트웨어 프로젝트에서 사용되고 있다.\nGDAL은 공간데이터를 읽고 쓸수 있게 해주는 라이브러리 중의 라이브러리로, 수많은 다른 라이브러리를 필요로 한다. 대략 100개가 넘는 라이브러리와 연결되어 있는데, 개별 라이브러리는 특정한 데이터 파일 포맷, 특정한 데이터베이스, 특정한 웹서비스, 특정한 압축 코덱을 다룰 수 있다.\nCRAN(역자주: CRAN은 The Comprehensive R Archive Network의 약자로서, R의 수많은 패키지의 저장소로 이해하면 된다. R 언어 자체의 과거와 현재의 버전들 뿐만 아니라 현재 대략 20,000개 이상의 R 패키지가 모여 있다. 1997년 Kurt Hornik와 Friedrich Leisch에 의해 처음 만들어졌으며 현재에도 Hornik와 많은 자원봉사자들에 의해 운영되고 있다)에서 배포되는 바이너리 형식의 R 패키지에는 스태틱 링크 코드(statically linked code)만 포함되어 있는데, 이는 CRAN이 패키지의 호스트 시스템에 서드파티(third-party) 라이브러리가 존재하는지 그렇지 않은지에 대한 가정을 하지 않으려 하기 때문이다. 그 결과 CRAN으로부터 바이너리 형식의 sf 패키지를 인스톨하면, sf 패키지의 의존계 뿐만 아니라 모든 외부 라이브러리도 함께 다운로드되기 때문에 용량이 100 Mb에 달한다.\n\n1.7.2 PROJ\nPROJ(혹은 PR\\(\\phi\\)J)는 지도투영과 데이텀변환을 위한 라이브러리이다. 공간 좌표를 하나의 CRS로부터 다른 CRS로 바꾸어 준다. PROJ 속에는 현재까지 알려져 있는 수많은 투영법에 대한 데이터베이스가 포함되어 있으며, 데이터 그리드(데이텀변환을 위한 고정밀 계수값)에 접근할 수 있게 해준다. CRS의 국제 표준에 맞추어져 있다(Lott 2015). 2장에서 좌표계와 PROJ를 자세히 다룬다.\n\n1.7.3 GOES와 s2geometry\nGOES(Geometry Engine Open Source)와 s2geometry는 지오메트리 오퍼레이션을 위한 라이브러리이다. 이 라이브러리를 활용해 기하학적 측정(길이, 면적, 거리), 논리적 판단(두 지오메트리가 포인트를 공유하고 있는지의 여부), 새로운 지오메트리의 생성(두 지오메트리가 공유하고 있는 포인트) 등의 오퍼레이션을 수행할 수 있다. GEOS는 이러한 오퍼레이션을 2차원 평면(\\(R^2\\))에서 수행할 수 있게 해주고, s2geometry는 3차원 구면(\\(S^2\\))에서 수행할 수 있게 해준다. 2장에서 CRS를 다루며, 4장에서는 2차원 공간과 3차원 공간을 다루는 데 있어 차이점에 대해 더 자세히 논의한다.\n\n1.7.4 NetCDF, udunits2, liblwgeom\nNetCDF(UCAR 2020)은 파일 형식이자 NetCDF 파일을 읽고 쓰기 위한 C 라이브러리를 의미한다. NetCDF를 통해 모든 차원의 어레이를 정의할 수 있으며, 특히 (기후) 모델링 커뮤니티에서 공간 및 시공간 정보를 다루는데 널리 사용된다. Udunits2(UCAR 2014; Pebesma, Mailud, and Hiebert 2016; Pebesma et al. 2022)는 측정 단위와 관련된 데이터베이스이자 소프트웨어 라이브러리이다. Udunits2를 통해 측정 단위간 전환 및 파생 단위의 처리를 할 수 있고, 사용자-정의 단위에 대한 지원을 받을 수 있다. liblwgeom “라이브러리”는 POSTGIS(Obe and Hsu 2015)의 소프트웨어 요소로서 GDAL이나 GEOS에서는 다루지 않는 몇 가지 루틴을 포함하고 있다. 예를 들어 PROJ를 장착하고 있는 GeographicLib 루틴에 쉽게 접근할 수 있게 해준다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#연습문제",
    "href": "01.html#연습문제",
    "title": "1  시작하기",
    "section": "\n1.8 연습문제",
    "text": "1.8 연습문제\n\n래스터 데이터와 백터 데이터의 차이점 다섯 가지를 나열하라.\n그림 1.1 아래에 나열되어 있는 것 외에, 지도의 그래픽 요소 다섯 개를 더 나열하라.\n그림 1.5에 나타나 있는 수치 정보가 왜 오해를 불러일으키는지(혹은 무의미한지)에 대해 얘기해 보라.\n지오메트리 오퍼레이션을 \\(S^2\\)에서 행하는 것과 \\(R^2\\)에서 행하는 것의 차이가 가장 극명하게 드러나는 상황을 예를 들어 설명해 보라.\n\n\n\n\n그림 1.1: 첫 번째 지도: 미국 노스캐롤라이나의 카운티별 출생아수, 1974~78년\n그림 1.2: “미국 노스캐롤라이나 카운티별 영아돌연사증후군에 의한 사망아수의 패싯 지도, 1974~78년과 1979~84년”\n그림 1.4: “브라질의 대서양 연안 도시 올린다에 대한 래스터 지도: (a) Landsat-7의 블루 탐지대를 타나낸 것으로 서로 다른 컬러는 속성값의 차이를 나타냄. (b) 좌상의 10X10 픽셀만 확대하여 나타낸 것임. (c) 3개의 샘플 포인트로 구성된 벡터 데이터를 중첩하여 나타냄. (d) 샘플 포인트로부터 반경 500m를 나타낸 3개의 폴리곤으로 구성된 벡터 데이터를 중첩하여 나타냄.”\n그림 1.5: 그림 1.1에 나타나 있는 카운티별 출생아수(1974~78)를 래스터화하여 나타낸 지도\n그림 1.6: 다양한 래스터 지오메트리 유형\n그림 1.7: sf의 의존계: 직선은 강한 의존성을 점선은 약한 의존성을 나타낸다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "02.html",
    "href": "02.html",
    "title": "2  좌표계",
    "section": "",
    "text": "2.1 퀀티티, 단위, 데이텀\nVIM(International Vocabulary of Metrology, BIPM et al., 2012)는 콴티티에 대해 “현상, 물체 또는 물질의 속성으로, 이 속성은 숫자로 표현할 수 있는 크기와 준거를 가진다.” 여기서 “준거는 측정 단위, 측정 절차, 기준 물질 또는 이러한 것들의 조합일 수 있다.”라고 기술한다. 모든 데이터가 퀀티티로 구성되어 있는지에 대해 논의할 수 있지만, 적절한 데이터 처리를 위해서는 숫자(또는 기호)와 자체 뿐만 아니라 숫자가 무엇을 의미하는지, 특히 숫자가 어떤 준거에 기반하고 있는지에 대한 정보가 함께 제공되어야 한다는 점에 대해서는 논의할 필요가 없다.\n측정 시스템은 기본 퀀티티에 대한 기본 단위와 파생 퀀티티에 대한 파생 단위로 구성된다. 예를 들어, SI 단위계(Bureau International des Poids et Mesures 2006)는 일곱개의 기본 단위로 구성된다: 길이(미터, m), 질량(킬로그램, kg), 시간(초, s), 전류(암페어, A), 열역학적 온도(켈빈, K), 물질의 양(몰, mol), 그리고 광도(칸델라, cd). 파생 단위는 기본 단위의 정수 거듭제곱의 곱으로 구성되며, 예를 들어 속도(\\(\\text{m s}^{-1}\\))나 밀도(\\(\\text{kg s}^{-1}\\)), 면적( \\(\\text{m}^{2}\\)) 등이 있다. 특별한 경우에는 무단위 측정이 있을 수 있는데, 단위가 서로 소거되는 경우(예: 질량 분율: kg/kg 또는 라디안으로 측정된 각: m/m)나 물체나 사건의 빈도를 세는 경우(예: “5개의 사과”)이다. 각도와 사과의 개수를 더하는 것은 의미가 없지만, 5개의 사과와 3개의 오렌지를 더하는 것은 의미가 있을 수 있으며, 이 경우 결과를 상위 클래스(즉, 과일의 개수)로 재해석할 수 있다. Hand(2004)는 측정 단위의 맥락에서 다양한 측정 스케일에 대해 논의한 바 있는데, 예를 들어 사회과학에서 지능과 같은 변수를 측정하는데 사용되는 측정 스케일과 같은 것이다.\n많은 퀀티티의 경우 값의 자연적인 원점은 0이다. 이러한 자연적 원점의 개념은 양(amount)이라는 퀀티티에 잘 들어맞는다. 두 양의 차는 의미 있는 음의 값일 수 있다. 위치와 시간의 차도 이러한 자연적 원점 개념으로 해석될 수 있다. 즉, 위치의 차는 거리이고, 시간의 차는 지속기간이다. 절대적인 위치와 시간은 고정된 원점이 필요하며, 이를 기준으로 다른 절대적인 시공간적 지점을 의미 있게 측정할 수 있다. 이러한 기준을 우리는 데이텀이라고 부른다. 공간의 경우, 데이텀은 하나 이상의 차원을 포함한다. 데이텀과 측정 단위(스케일)의 조합이 하나의 참조계를 구성한다.\n이제 공간적 위치를 타원체 좌표 또는 데카르트 좌표로 표현하는 방법에 대해 자세하게 설명하고자 한다. 다음 섹션에서는 시간 및 공간 참조계과 R에서 이러한 참조계를 처리하는 방법에 대해 다룰 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#타원좌표계",
    "href": "02.html#타원좌표계",
    "title": "2  좌표계",
    "section": "\n2.2 타원좌표계",
    "text": "2.2 타원좌표계\n\n\n\n\n\n그림 2.1: 2차원 극 좌표계와 데카르트 좌표계\n\n\n그림 2.1은 2차원 극 좌표계와 데카르트 좌표계를 보여주고 있다. 해당 지점의 데카르트 좌표는 \\((x,y)=(3,4)\\)으로 주어지고, 극 좌표는 \\((r,\\phi)=(5,\\text{arctan(4/3)})\\)으로 주어지는데 \\(\\text{arctan(4/3)}\\)는 대략 \\(0.93\\) 라디안 혹은 \\(53^\\circ\\)이다. 여기서 \\(x\\), \\(y\\), \\(r\\)은 모두 길이 단위이고 \\(\\phi\\)는 각도 단위(무단위 길이/길이 비)라는 점에 유의할 필요가 있다. 데카르트 좌표와 극 좌표 간의 변환은 매우 간단하다.\n\\[\nx=r\\cos\\phi,\\quad y=r\\sin\\phi, \\text{and}\n\\]\n\\[\nr=\\sqrt{x^2+y^2}, \\quad \\phi=\\text{atan2}(y,x)\n\\]\n여기서 \\(\\text{atan2}\\)이 \\(\\text{atan}(y/x)\\)대신 사용되었는데, 오른쪽 일사분면에 위치가 있기 때문이다.\n\n2.2.1 구체 혹은 타원체 좌표계\n3차원의 경우, 데카르트 좌표계는 \\((x,y,z)\\)로 주어지고, 극 좌표계는 \\((r,\\lambda,\\phi)\\)로 주어진다.\n\n\\(r\\)은 구체의 반지름이다.\n\\(\\lambda\\)는 경도로, \\((x,y)\\) 평면에서 양의 \\(x\\)축으로부터 반시계방향으로 측정된다.\n\\(\\phi\\)는 위도로, \\((x,y)\\) 평면과 해당 벡터가 이루는 각도이다.\n\n그림 2.2는 데카르트 지심 좌표계와 타원체 좌표계를 보여준다.\n\n\n\n\n\n그림 2.2: 세 개의 거리로 표현되는 데카르트 지심 좌표계(왼편)와 두 개의 각도와 하나의 타원체고로 표현되는 타원체 좌표계(오른편)\n\n\n\\(\\lambda\\)는 \\(-180^\\circ\\)에서 \\(180^\\circ\\) 사이의 값(혹은 \\(0^\\circ\\)에서 \\(360^\\circ\\) 사이의 값)을 갖고, \\(\\phi\\)는 \\(-90^\\circ\\)에서 \\(90^\\circ\\) 사이의 값을 갖는다. 타원체가 아니라 고정된 반지름 갖는 구체 상의 위치만을 상정할 경우 위의 \\(r\\)을 생략한 \\((\\lambda,\\phi)\\) 만으로도 모든 위치를 규정하기에 충분하다.\n이것은 단지 하나의 정의일 뿐이며, 예를 들어 위도 대신 해당 벡터와 \\(z\\) 축 사이의 각도인 극각을 측정할 수도 있다는 점에 유의해야 한다. 좌표값을 \\((\\phi,\\lambda)\\)의 형태로 나타내는 오랜 전통이 있지만 이 책에서는 경도-위도 형식(\\(\\lambda,\\phi\\))을 사용할 것이다. 그림 2.2에 표시된 지점은 각도값으로 구성된 \\((\\lambda,\\phi)\\) 혹은 타원체 좌표값을 가지며 도 단위로 주어진다.\n# POINT (60 47)\n지심좌표값은 미터 단위로 주어진다.\n# POINT Z (2178844 3773868 4641765)\n타원체 상의 지점에 대해서는 각도를 나타내는 두 가지 방법이 있다(그림 2.3). 하나는 타원체의 중심을 기준으로 측정된 각도(\\(\\psi\\)), 또는 해당 지점을 지나는 접선에 수직으로 측정된 각도(\\(\\phi\\))이다.\n\n\n\n\n\n그림 2.3: 타원체 상의 각도: 측지 위도(푸른색)와 지심 위도(붉은색)\n\n\n\n2.2.2 투영좌표계, 거리\n종이 지도와 컴퓨터 화면이 지구본보다 훨씬 더 실용적이고 널리 사용되기 때문에, 우리는 공간데이터를 보통 2차원 평면 상에 투영된 형태로 보게 된다. 이차원 공간에서 위치를 계산한다는 것은 우리가 투영 좌표를 사용한다는 것을 의미한다. 타원체 좌표를 투영한다는 것은 형태, 방향, 면적 또는 이 세 가지 모두가 왜곡된다는 것을 의미한다(Iliffe and Lott 2008).\n데카르트 좌표계에서 두 지점 \\(p_i\\)와 \\(p_j\\) 간의 거리는 유클리드 거리로 계산되며, 2차원의 경우 \\(p_i=(x_i,y_i)\\)이므로 다음의 수식으로 주어진다.\n\\[\nd_{ij}=\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}\n\\]\n3차원의 경우는 \\(p_i=(x_i,y_i,z_i)\\)이므로, 다음의 수식으로 주어진다.\n\\[\nd_{ij}=\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2}\n\\]\n이 거리는 지점 \\(i\\)와 지점 \\(j\\) 사이의 직선 거리의 길이를 의미한다.\n원 상의 두 지점의 경우, 두 지점 \\(c_i=(r,\\phi_1)\\)와 \\(c_j=(r,\\phi_2)\\) 사이의 호의 길이는 다음과 같이 주어진다. \\[\ns_{ij}=r|\\phi_1-\\phi_2|=r\\theta\n\\] 여기서 \\(\\theta\\)는 \\(\\phi_1\\)과 \\(\\phi_2\\) 사이의 각도를 라디안으로 나타낸 것이다. \\(\\theta\\)의 값이 매우 작다면 호가 직선에 가깝기 때문에 \\(s_{ij}\\approx d_{ij}\\)가 성립한다.\n반지름이 \\(r'\\)인 구체 상의 두 지점 \\(p_1=(\\lambda_1,\\phi_1)\\)과 \\(p_2=(\\lambda_2,\\phi_2)\\)의 경우, 두 지점 \\(p_1\\)과 \\(p_2\\)를 통과하는 원(이 원의 중심은 구체의 중심과 일치) 상에서의 두 지점 사이의 호의 길이를 대권거리(great circle distance)라고 하며, \\(s_{12}=r\\theta_{12}\\)로 주어진다. 따라서 \\(p_1\\)과 \\(p_2\\) 사이의 각도(라디안)는 다음과 같이 주어진다.\n\\[\n\\theta_{12}=\\arccos(\\sin\\phi_1\\cdot \\sin\\phi_2+\\cos\\phi_1\\cdot \\cos\\phi_2\\cdot\\cos(|\\lambda_1-\\lambda_2|))\n\\]\n타원체 상의 두 지점 간의 호의 길이를 계산하는 것은 훨씬 더 복잡하다. Karney (2013)은 이와 관련하여 심도 있는 논의를 제공하였으며, PROJ 라이브러리의 일부인 GeographicLib에서 구현된 방법에 대한 자세한 설명을 제시한다.\n이 거리 측정 방식들이 실제로 서로 다른 값을 산출함을 보여주기 위해, 우리는 베를린과 파리 간의 거리를 계산했다. WGS84 타원체와 완전 구체에 각각에 대해 거리를 계산했는데, gc_는 대권거리를, str_은 지심좌표값을 이용한 직선거리를 나타낸다.\n# Units: [km]\n#  gc_ellipse str_ellipse   gc_sphere  str_sphere \n#      879.70      879.00      877.46      876.77\n\n2.2.3 한정 공간과 비한정 공간\n2차원 및 3차원 유클리드 공간(\\(R^2\\)와 \\(R^3\\))는 비한정 공간이다. 이 공간의 모든 선은 무한한 길이를 가지며, 면적이나 부피는 자연적인 상한이 없다. 이와는 대조적으로 구(\\(S^1\\)) 혹은 구체(\\(S^2\\))의 공간은 한정 공간이다. 무한히 많은 점이 있을 수는 있지만, 원의 길이와 면적, 구의 반지름, 면적 및 부피는 유한하다.\n이것은 사소하게 들릴 수 있지만, 공간데이터를 처리할 때 흥미로운 도전 과제로 이어진다. \\(R^2\\) 상의 폴리곤은 명확하게 내부와 외부를 가진다. \\(S^2\\) 공간인 구체 상에서 모든 폴리곤은 구체를 두 부분으로 나누며, 이 두 부분 중 어느 쪽을 내부로 간주하고 어느 쪽을 외부로 간주할지는 애매하며, 이는 탐색 방향(traversal direction)에 의해 정의되어야 한다(역자주: 탐색 방향은 보통 시계 방향과 반시계 방향으로 나누는데, 예를 들어, 삼각형의 변을 시계 방향으로 탐색하면 왼쪽에 있는 영역이 내부로 간주되고, 반시계 방향으로 탐색하면 오른쪽에 있는 영역이 내부로 간주된다.). 4장에서 \\(S^2\\) 지오메트리를 다룰 때의 결과에 대해 추가로 논의할 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#구체-혹은-타원체-좌표계",
    "href": "02.html#구체-혹은-타원체-좌표계",
    "title": "2  좌표계",
    "section": "\n2.3 구체 혹은 타원체 좌표계",
    "text": "2.3 구체 혹은 타원체 좌표계\n3차원의 경우, 데카르트 좌표계는 \\((x,y,z)\\)로 주어지고, 극 좌표계는 \\((r,\\lambda,\\phi)\\)로 주어진다.\n\n\\(r\\)은 구체의 반지름이다.\n\\(\\lambda\\)는 경도로, \\((x,y)\\) 평면에서 양의 \\(x\\)축으로부터 반시계방향으로 측정된다.\n\\(\\phi\\)는 위도로, \\((x,y)\\) 평면과 해당 벡터가 이루는 각도이다.\n\n그림 2.2는 데카르트 지심 좌표계와 타원체 좌표계를 보여준다.\n\n\n\n\n\n\n\n\n\\(\\lambda\\)는 \\(-180^\\circ\\)에서 \\(180^\\circ\\) 사이의 값(혹은 \\(0^\\circ\\)에서 \\(360^\\circ\\) 사이의 값)을 갖고, \\(\\phi\\)는 \\(-90^\\circ\\)에서 \\(90^\\circ\\) 사이의 값을 갖는다. 타원체가 아니라 고정된 반지름 갖는 구체 상의 위치만을 상정할 경우 위의 \\(r\\)을 생략한 \\((\\lambda,\\phi)\\) 만으로도 모든 위치를 규정하기에 충분하다.\n이것은 단지 하나의 정의일 뿐이며, 예를 들어 위도 대신 해당 벡터와 \\(z\\) 축 사이의 각도인 극각을 측정할 수도 있다는 점에 유의해야 한다. 좌표값을 \\((\\phi,\\lambda)\\)의 형태로 나타내는 오랜 전통이 있지만 이 책에서는 경도-위도 형식(\\(\\lambda,\\phi\\))을 사용할 것이다. 그림 2.2에 표시된 지점은 각도값으로 구성된 \\((\\lambda,\\phi)\\) 혹은 타원체 좌표값을 가지며 도 단위로 주어진다.\n\n\nPOINT (60 47)\n\n\n지심좌표값은 미터 단위로 주어진다.\n\n\nPOINT Z (2178844 3773868 4641765)\n\n\n타원체 상의 지점에 대해서는 각도를 나타내는 두 가지 방법이 있다(그림 2.3). 하나는 타원체의 중심을 기준으로 측정된 각도(\\(\\psi\\)), 또는 해당 지점을 지나는 접선에 수직으로 측정된 각도(\\(\\phi\\))이다.\n\n\n\n\n\n\n\n그림 2.2: 타원체 상의 각도: 측지 위도(푸른색)와 지심 위도(붉은색)\n\n\n\n\n\n\n\n그림 2.1: 2차원 극 좌표계와 데카르트 좌표계\n그림 2.2: 타원체 상의 각도: 측지 위도(푸른색)와 지심 위도(붉은색)",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#crs",
    "href": "02.html#crs",
    "title": "2  좌표계",
    "section": "\n2.3 CRS",
    "text": "2.3 CRS\nLott(2015)를 따라 다음과 같은 개념 정의를 사용할 것이다(이탤릭체는 Lott의 정의를 그대로 옮겨 쓴 것이다)\n\n좌표계는 지점에 좌표를 할당하는 방법을 지정하는 수학적 규칙의 집합이다.\n데이텀은 좌표계의 원점, 축척, 방향을 정의하는 파라미터 또는 파라미터의 집합이다.\n측지데이텀은 2차원 또는 3차원 좌표계와 지구와의 관계를 설명하는 데이텀이다(역자주: 다시 말해, 지구에 부여된 2차원 또는 3차원 좌표계를 설명하는 데이텀이다).\nCRS(좌표참조계)는 특정한 데이텀에 의거해 특정한 객체에 부여된 좌표계이다. 측지데이텀과 수직데이텀의 경우, 객체는 지구이다(역자주: 측지데이텀은 지구 상의 위치를 규정하는 수평데이텀이고 수직데이텀은 말그대로 지표 상의 높이를 규정하는 데이텀이다).\n\n이 개념을 더 자세히 설명하는 읽기 쉬운 텍스트는 Iliffe and Lott(2008)이다.\n지구는 규칙적인 형태를 따르지 않는다. 지표 기복이 매우 불규칙적인 형상을 띤다는 것을 잘 알려져 있지만, 평균해수면과 관련하여 일정한 중력에 의해 형성된 표면인 지오이드(geoid) 또한 불규칙적이다. 지오이드에 대한 모델 중 가장 일반적으로 사용되는 것은 회전타원체로, 이는 두 개의 동일한 반단축을 가진 타원이다. 이런 회전타원체를 지구와 어떠한 방식으로 일치시킬 것인가가 데이텀을 규정한다. 그런데 타원체를 지구의 어떤 부분에 일치시킬지, 혹은 어떤 준거 지점을 사용하여 일치시킬지에 따라 타원체의 적합도는 다양할 수 있고, 이런 연유로 인해 다양한 데이텀이 존재할 수 있는 것이다. 어떤 데이텀은 특정한 지각판에 대한 적합도에 집중하며(ETRS89), 어떤 데이텀은 전세계의 평균적인 적합도를 지향한다(WGS84). 국지적인 적합도에 치중할수록 해당 지역에서의 근사 오류는 낮아지게 된다.\n위에서 제시된 정의를 살펴보면, 경도와 위도로 주어진 좌표값은 해당 데이텀이 주어질 경우에만 지구 좌표계로서의 의미를 부여받을 수 있고, 해석이 모호성이 사라질 수 있음을 함축하고 있다.\n특정한 투영법이 적용된 데이터는 반드시 특정한 참조타원체(데이텀)와 결부되어 있음을 주의해야 한다. 데이텀 전환 없이 투영법만 바꾸는 것을 좌표전환(coordinate conversion)이라고 하는데, 이 좌표변환은 해당 데이텀과 결부되어 있는 특정 타원체의 좌표값에 의거해 이루어진다. 이 좌표변환의 과정은 정보의 비손실적이며 가역적이다. 변환을 위한 파라미터와 함수식은 불변이다.\n새로운 데이텀에 의거해 좌표를 재계산하는 것을 좌표변환(coordinate transformation)이라고 한다. 좌표전환과 달리 좌표변환은 근사적으로 이루어진다. 왜냐하면 데이텀이 모델 적합의 결과이기 때문에 데이텀 간 변환 또한 적합된 모델이기 때문이다. 변환 함수도 경험적으로 얻어지는 것이며, 적합도와 정확성에 대한 설정을 달리하는 다양한 변환 경로가 가능할 수 있다.\n판구조론은 글로벌 데이텀을 위한 고정된 객체의 위치가 시간이 흐름에 따라 변할 수 있음을 우리들에게 알려준다. 이는 데이텀 간 좌표변환이 시간 의존적일 수 있음을 시사하는 것이다. 지진으로 인해 특정 지역의 좌표가 갑작스럽게 변화할 수 있다. 국지 데이텀을 특정한 지각판에 고정시킬 수도 있지만(ETRS89), 보다 역동적으로 변화시킬 수도 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#proj와-지도-정확도",
    "href": "02.html#proj와-지도-정확도",
    "title": "2  좌표계",
    "section": "\n2.4 PROJ와 지도 정확도",
    "text": "2.4 PROJ와 지도 정확도\n현재 오픈소스 지리공간 소프트웨어에서 활동하는 사람들 중 PROJ 이전의 시간을 기억하는 사람은 거의 없다. PROJ(Evenden 1990)는 1970년대에 포트란 프로젝트로 시작되어 1985년에 지도투영을 위한 C 라이브러리로 출시되었다. 이 라이브러리는 직접 투영 및 역 투영을 위한 명령줄 인터페이스를 제공하였으며, 소프트웨어와 연결하여 투영과 재투영을 곧바로 실행하는 것이 가능했다. 데이텀은 그냥 주어지는 것으로 간주되었으며 데이텀 변환은 허용되지 않았다.\n2000년대 초 PROJ는 PROJ.4가 되었는데, 불변의 버전 번호가 붙은 것이다. GPS의 대두 등 여러 요인으로 인해 데이터 변환에 대한 필요성이 증가하였고, PROJ.4는 기본적인 데이텀 지원 기능을 장착하게 되었다. PROJ는 CRS를 다음과 같은 형식으로 정의한다.\n+proj=utm +zone=33 +datum=WGS84 +units=m +no_defs\n“키=값”쌍은 + 기호로 시작하고 공백으로 구분된다. 이 형식은 PROJ 프로젝트가 수십 년 동안 4.x 버전으로 유지되었기 때문에 ’PROJ.4 문자열’로 알려지게 되었다. 다른 예를 들면 다음과 같다.\n+ellps=bessel +towgs84=565.4,50.3,465.6,-0.399,0.344,-1.877,4.072\n이 문자열은 해당 데이텀이 다른 타원체(Bessel)를 사용하며, 이 타원체를 WGS84(GPS때문에 널리 알려짐)로 변환하기 위해서는 7개(또는 3개)의 파라미터가 필요하다는 점을 잘 나타낸다.\nPROJ.4 외에 널리 사용되고 있는 투영법에 대한 데이터베이스가 구축되었는데, 그것들 중 가장 널리 알려진 것인 EPSG(European Petroleum Survey Group) 레지스트리이다. 국가지도제작기관은 자국의 CRS에 대한 +towgs84 파라미터(WGS84로 변환하기 위한 파라미터)에 대한 최선의 추정치를 계산 및 업데이트하여, EPSG 등록부를 통해 배포하였다. 일부 변환의 경우, 데이텀 그리드가 제공되었는데 PROJ.4의 일부로 배포되었다. 이러한 그리드는 결국 래스터 지도를 의미하는데, 데이텀 변환이 야기하는 경도, 위도, 또는 고도의 변화값을 모든 지점에 대해 미리 계산해 둔 것이다.\nPROJ.4에서는 모든 좌표변환이 WGS84로의 변환을 거쳐야 했다. 전혀 다른 데이텀을 가진 데이터를 재투영할 때도 WGS84로의 변환을 거쳐야 했다. 최대 100m의 오류는 비교적 큰 지역의 지도 제작 목적으로는 허용 가능했지만, 일부 응용 프로그램은 더 높은 정확도의 변환이 필요하다. 예를 들어, 정밀 농업, UAV(역자주: Unmanned Aerial Vehicle의 약자로 무인항공기로 번역될 수 있지만, 보통 드론을 지칭할 때 사용된다.) 비행 계획 또는 객체 추적이 있다.\n2018년, 성공적인 ‘GDAL 좌표계 공동 개발’ 이니셔티브 이후, 오픈소스 지리공간 소프트웨어 스택에서 이익을 얻는 여러 회사들이 PROJ에서 보다 현대적이고 진보된 좌표변환 시스템 개발을 지원했다. 몇 년 동안 PROJ.4는 5, 6, 7, 8, 9 버전을 거치며 발전하였고, 따라서 PROJ(또는 PR\\(\\phi\\)J)로 이름이 변경되었다.\n가장 주목할만한 변화에 다음의 것들이 있다.\n\n비록 PROJ.4 문자열이 새로운 CRS를 정의하는데 여전히 사용될 수 있지만, 모든 CRS를 포괄하기에 충분하지 않다는 점이 드러났다. 새로운 형식인 WKT-2(다음 섹션에서 설명됨)가 이를 대체한다.\n허브 데이텀으로서의 WGS84의 지위를 박탈한다. 좌표변환이 더 이상 특정 데이텀을 거칠 필요가 없다.\nCRS A에서 CRS B로 가는 여러 변환 또는 전환 경로(소위 파이프라인)가 가능하며, 정확도 정보만 제시된다면 등재될 수 있다. PROJ는 디폴트로 가장 정확한 경로를 사용하지만 사용자가 제어할 수 있다.\n변환 파이프라인은 축 교환 및 단위 변환을 포함하여 다수의 기본 변환 작업을 연결할 수 있다.\n데이텀 그리드는 라이브러리와 함께 배포되지 않고 CDN(content delivery network)에서 접근할 수 있다. PROJ는 이러한 그리드에 대한 네트워크 접근을 활성화하거나 비활성화할 수 있도록 하며, 실제로 필요한 그리드 섹션만 다운로드하여 사용자의 기기에 캐시로 저장하여 향후 사용할 수 있게 한다.\n에포케(epoche) 좌표변환, 즉 시간-의존적 좌표변환이 가능하다. 따라서 소스 및 타깃 시간을 포함하는 4차원 자표계에 대한 변환이 가능하다(역자주: 지구의 좌표계가 시간이 지남에 따라 변화해 왔으므로 특정 시대(에포케)에 의거한 변환임으로 하나의 정보로 포함시킬 수 있게 되었다는 점을 의미한다.).\n기등록 CRS를 가진 데이터셋의 경우는 SQLite 데이터베이스에서 관리된다.\n축 순서(경도, 위도)를 다르게 정의하는 것이 가능하다.\n\n많은 개선이 이루어졌으며, 변환의 정확도는 이제 1미터 이하일 수 있다. 흥미로운 점은 마지막 부분이다. 수십년 동안 타원체 좌표를 가진 공간데이터의 축 순서(경도, 위도)를 자명한 것으로 가정할 수 있었지만, 이제는 더 이상 그렇지 않다. 섹션 7.7.6에서 이를 처리하는 방법을 살펴볼 것이다.\n\n\n\n\n\n그림 2.4: 영국의 OSGB 1936(EPSG:4277)를 ETRS89(EPSG:4258)로 변환하는데 사용되는 수평 데이텀 그리드\n\n\n\n\n\n\n\n그림 2.5: 영국의 ETRS89(EPSG:4937를 ODN 고도(EPSG:5701)로 변환하는데 사용되는 수직 데이텀 그리드\n\n\n그림 2.4에 나타나 있는 수평 데이텀 그리드와 그림 2.5에 나타나 있는 수직 데이텀 그리드의 예는 cdn.proj.org로부터 다운로드 받았다. 데이텀 그리드는 픽셀별 정화도 값을 포함할 수 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#wkt-2",
    "href": "02.html#wkt-2",
    "title": "2  좌표계",
    "section": "\n2.5 WKT-2",
    "text": "2.5 WKT-2\nLott (2015)는 CRS의 인코딩과 CRS 간의 변환을 WKT(well-known text) 통해 나타내는 표준을 정리한 바 있다. 이 표준(및 포맷)을 비공식적으로 WKT-2라고 부른다. 앞에서 언급했듯이, GDAL과 PROJ는 이 표준을 지원한다. 예로서 특정 CRS(EPSG:4326)은 WKT-2로 다음과 같이 표시된다.\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n이 예시는 축 순서가 위도, 경도로 설정된 좌표계를 보여주고 있다. 물론 실제로 사용되고 있는 대부분의 좌표계는 축 순서가 경도, 위도이다. WGS84 타원체에 대한 앙상블(ENSEMBLE)은 다양한 업데이트를 나열하고 있다. 이 앙상블 중 어떤 것를 사용하는냐에 따라 수 미터의 오차가 발생할 수 있다. OGS:CRS84는 축 순서를 경도, 위도의 순서를 명확히 하였기 때문에 GRS84에 대한 대안으로 권장된다. 그러나 데이텀 앙상믈 문제는 해결하지 못한다.\nPROJ의 역사와 최근 변화에 대한 자세한 소개는 Knudsen and Evers(2017), Evers and Knudsen(2017)의 연구를 토대로 정리한 Bivand(2020)에 잘 나타나 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#연습문제",
    "href": "02.html#연습문제",
    "title": "2  좌표계",
    "section": "\n2.6 연습문제",
    "text": "2.6 연습문제\nR을 활용하여 아래의 연습문제를 풀되 패키지의 사용은 금지이다. 적절한 함수를 찾도록 노력하라.\n\n자연적 원점 0을 갖지 않는 지리적 측도 세가지를 나열하라.\n다음의 \\((x,y)\\) 좌표, \\((10,2)\\), \\((-10,-2)\\), \\((10,-2)\\), \\((0,10)\\)을 극 좌표로 전환하라.\n다음의 \\((r,\\phi)\\) 좌표, \\((10,45^\\circ)\\), \\((0,100^\\circ)\\), \\((5,359^\\circ)\\)를 데카르트 좌표로 전환하라.\n지구를 반지름이 6371km인 완전한 구체라고 가정하고, 다음의 두 지점 간의 대권거리를 구하라. \\((10,10)\\)과 \\((11,10)\\), \\((10,80)\\)과 \\((11,80)\\), \\((10,10)\\)과 \\((10,11)\\), \\((10,80)\\)과 \\((10,81)\\)(단위: 각도)의 대권거리는 몇 도인가?\n\n\n\n\n그림 2.1: 2차원 극 좌표계와 데카르트 좌표계\n그림 2.2: 세 개의 거리로 표현되는 데카르트 지심 좌표계(왼편)와 두 개의 각도와 하나의 타원체고로 표현되는 타원체 좌표계(오른편)\n그림 2.3: 타원체 상의 각도: 측지 위도(푸른색)와 지심 위도(붉은색)\n그림 2.4: 영국의 OSGB 1936(EPSG:4277)를 ETRS89(EPSG:4258)로 변환하는데 사용되는 수평 데이텀 그리드\n그림 2.5: 영국의 ETRS89(EPSG:4937를 ODN 고도(EPSG:5701)로 변환하는데 사용되는 수직 데이텀 그리드",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "03.html#심플-피쳐-지오메트리",
    "href": "03.html#심플-피쳐-지오메트리",
    "title": "3  지오메트리",
    "section": "",
    "text": "클래스 위계\n오퍼레이션의 집합\n이항 엔코딩과 텍스트 엔코딩\n\n\n\n3.1.1 7개의 대표 지오메트리\n단일(single) 피처를 나타내기 위해 사용되는 가장 일반적인 심플 피처 지오메트리 유형은 다음과 같다.\n\n\n\n\n\n\n유형\n설명\n\n\n\nPOINT\n단일 포인트 지오메트리\n\n\nMULTIPOINT\n포인트의 집합\n\n\nLINESTRING\n단일 라인스트링(두개 이상의 포인트가 직선으로 연결되어 있음)\n\n\nMULTILINESTRING\n라인스트링의 집합\n\n\nPOLYGON\n내부 링(구멍을 의미)을 가질 수 있는 외부 링\n\n\nMULTIPOLYGON\n폴리곤의 집합\n\n\nGEOMETRYCOLLECTION\n위에서 언급된 모든 지오메트리의 집합\n\n\n\n\n\n\n\n\n그림 3.1: 심플 피처 지오메트리의 주요 유형\n\n\n그림 3.1은 이러한 기본 지오메트리 유형의 예를 보여준다. 지오메트리를 표현한 사람이 읽을 수 있는 WKT 표기법은 다음과 같다.\nPOINT (0 1)\nMULTIPOINT ((1 1), (2 2), (4 1), (2 3), (1 4))\nLINESTRING (1 1, 5 5, 5 6, 4 6, 3 4, 2 3)\nMULTILINESTRING ((1 1, 5 5, 5 6, 4 6, 3 4, 2 3), (3 0, 4 1, 2 1))\nPOLYGON ((2 1, 3 1, 5 2, 6 3, 5 3, 4 4, 3 4, 1 3, 2 1),\n    (2 2, 3 3, 4 3, 4 2, 2 2))\nMULTIPOLYGON (((2 1, 3 1, 5 2, 6 3, 5 3, 4 4, 3 4, 1 3, 2 1),\n    (2 2, 3 3, 4 3, 4 2, 2 2)), ((3 7, 4 7, 5 8, 3 9, 2 8, 3 7)))\nGEOMETRYCOLLECTION (\n    POLYGON ((2 1, 3 1, 5 2, 6 3, 5 3, 4 4, 3 4, 1 3, 2 1),\n      (2 2 , 3 3, 4 3, 4 2, 2 2)),\n    LINESTRING (1 6, 5 10, 5 11, 4 11, 3 9, 2 8),\n    POINT (2 5),\n    POINT (5 4)\n)\n좌표는 공백으로 구분되고, 포인트는 쉼표로 구분된다. 집합은 괄호로 묶여 있으며, 쉼표로 구분된다. 폴리곤은 외부 링과 (만일 있다면) 내부 링(구멍을 나타냄)으로 구성된다.\n지오메트리의 개별 포인트는 최소한 두 개의 좌표를 포함하며, 이 좌표는 x와 y 순서로 나열된다. 이 좌표가 타원체 좌표를 나타내는 경우, x는 일반적으로 경도를, y는 위도를 의미하지만, 경우에 따라 위도와 경도의 순서로 나열될 수도 있다(섹션 2.4 및 섹션 7.7.6 참조).\n\n3.1.2 심플 지오메트리, 타당한 지오메트리, 링 디렉션\n라인리스팅은 자기 교차하지 않을 때 심플이라고 부를 수 있다.\n# LINESTRING (0 0, 1 1, 2 2, 0 2, 1 1, 2 0)\n# is_simple \n#     FALSE\n타당한 폴리곤과 멀티폴리곤은 다음의 모든 프로프티를 보유한다.\n\n폴리곤 링은 닫혀있다(첫번째 포인트와 마지막 포인트는 동일하다)\n폴리곤 구멍(내부 링)은 외부 링의 안쪽에 있다.\n폴리곤 내부 링은 외부 링과 한 지점에서 만날 수는 있지만 라인을 공유할 수는 없다.\n폴리곤 링은 자신의 경로를 반복하지 않는다.\n멀티폴리곤에서 외부 링은 다른 외부 링과 한 지점에서 만날 수는 있지만 라인을 공유할 수는 없다.\n\n이것들 어느 하나라도 만족시키지 못한다면 해당 지오메트리는 타당하지 않다. 타당하지 않는 지오메트리는 일반적으로 오퍼레이션 과정에서 오류를 발생시키지만, 보통 사전에 타당한 지오메트리로 수정된다.\n또 다른 규칙은 폴리곤의 외부 링은 반시계 방향으로 감겨야 하며, 구멍은 시계 방향으로 감겨야 한다는 것이다. 그러나 이러한 규칙을 따르지 않는 폴리곤도 여전히 타당한 것으로 간주된다. 이러한 ‘시계 방향’ 개념은 구체에서의 그리 유용하지 않다. 예를 들어, 적도를 폴리곤으로 간주할 경우, 북반구와 남반구 중 어느 쪽이 ’내부’라고 할 수 있는가? 여기서 채택된 규칙은 폴리곤을 변을 시계 방향으로 탐색할 때 왼쪽에 있는 영역을 폴리곤의 내부로 간주하는 것이다(7.3절 참조).\n\n3.1.3 Z 좌표와 M 좌표\n심플 피처 지오메트리의 단일 포인트(버텍스)는 X 좌표와 Y 좌표 외에 다음을 가질 수 있다.\n\nZ 좌표: 고도\nM 좌표: 측정치\n\nM 속성이 버텍스의 프로퍼티라는 점을 염두에 두면 M 좌표는 유용하게 사용될 수 있을 것으로 보인다. 예를 들어, LINESTRING을 통해 일종의 경로 데이터를 엔코딩한다고 하면, 개별 버텍스에 시간 속성을 할당할 수 있다. 그러나 경로가 자기-교차하게 되면 비타당 혹은 비심플(non-simple)이 된다. 자기-교차성을 검토하기 위해 X 좌표와 Y 좌표만을 고려할 때는 드러나지 않는다.\nZ와 M은 자주 사용되지 않으며, 이를 유용하게 활용할 수 있는 소프트웨어 지원도 (아직) 드물다. 그래도 Z와 M의 WKT 표현은 비교적 쉽게 이해할 수 있다.\n# POINT Z (1 3 2)\n# POINT M (1 3 2)\n# LINESTRING ZM (3 1 2 4, 4 4 2 2)\n\n3.1.4 엠프티 지오메트리\n피쳐 지오메트리 프레임워크에서 매우 중요한 개념이 엠프티(empty) 지오메트리이다. 엠프티 지오메트리는 기하학적 오퍼레이션(3.2절)을 실행할 때 자연스럽게 생성된다. 예를 들어 POINT (0 0)과 POINT (1 1)의 인터섹션 여부를 검토한다고 하자.\n# GEOMETRYCOLLECTION EMPTY\n두 포인트는 교차하지 않으므로 엠프티 집합이 도출된다. 엠프티 포인트를 비어있지 않은 지오메트리와 결합하면(합집합을 구하면) 엠프티 포인트는 소실된다.\n모든 지오메트리 유형은 엠프티 지오메트리를 나타내는 특정한 값을 가지고 있다.\n# POINT EMPTY\n# LINESTRING M EMPTY\n엠프티 집합이 생성된다는 점에서는 동일하고 단지 디멘션만 다를 뿐이다(3.2절 참조).\n\n3.1.5 10개의 부수적인 지오메트리\n다음의 10가지 지오메트리는 매우 드물게 사용되지만, 사용 빈도가 증가하는 경향이 있다.\n\n\n\n\n\n\n유형\n설명\n\n\n\nCIRCULARSTRING\n서큘러스트링은 기본적인 곡선 유형으로 직선 유형의 LINESTRING과 유사하다. 단일 세그먼트는 세 점이 필요하며, 시작점과 끝점(첫 번째와 세 번째 점) 및 호 상의 다른 점이 필요하다. 예외는 닫힌 원의 경우로, 이 경우 시작점과 끝점이 동일하다. 이 경우 두 번째 점은 반드시 호의 중심, 즉 원의 반대편이어야 한다. 호를 연결하려면 이전 호의 마지막 점이 다음 호의 첫 번째 점이 되며, 이는 LINESTRING에서도 동일하다. 따라서 타당한 서큘러 문자열은 1보다 큰 홀수 개의 점을 가져야 한다.\n\n\nCOMPOUNDCURVE\n컴파운트커브는 곡선(서큘러) 세그먼트와 선형 세그먼트를 모두 포함하는 단일 연속 곡선이다. 구성 요소를 잘 갖추고 있어야 하며, 모든 구성 요소의 끝점(마지막을 제외하고)은 다음 구성 요소의 시작점과 일치해야 한다.\n\n\nCURVEPOLYGON\n커브폴리곤 속에 컴파운트커브가 포함된 예: CURVEPOLYGON( COMPOUNDCURVE( CIRCULARSTRING(0 0,2 0, 2 1, 2 3, 4 3),(4 3, 4 5, 1 4, 0 0)), CIRCULARSTRING(1.7 1, 1.4 0.4, 1.6 0.4, 1.6 0.5, 1.7 1))\n\n\n\nMULTICURVE\n멀티커브는 곡선으로 구성된 1차원 지오메트리 컬렉션이다. 이 컬렉션은 라인 문자열, 서큘러 문자열 또는 컴파운드 문자열을 포함할 수 있다.\n\n\nMULTISURFACE\n멀티서피스는 동일한 CRS를 사용하는 서피스로 구성된 2차원 지오메트리 컬렉션이다.\n\n\nCURVE\n커브는 일반적으로 몇 개의 점의 연결로 정의되는 1차원 지오메트리 객체이며, 점들 간의 인터폴레이션 형태에 따라 커브의 하위 유형이 정의된다.\n\n\nSURFACE\n서피스는 2차원 지오메트리 객체이다.\n\n\nPOLYHEDRALSURFACE\n폴리헤드럴서피스는 공통 경계 세그먼트를 공유하는 연속적인 폴리곤의 컬렉션이다.\n\n\nTIN\n불규칙삼각망(triangulated irregular network)은 오직 삼각형으로만 구성된 폴리헤드럴서피스이다.\n\n\nTRIANGLE\n트라이앵글은 세 개의 비공선적(non-collinear) 버텍스로 구성된(역자주: 세 점이 일직선 상에 놓이지 않음을 의미한다), 내부 경계가 없는 폴리곤이다.\n\n\n\nCIRCULARSTRING, COMPOUNDCURVE, CURVEPOLYGON은 SFA 표준에 언급되지 않지만 SQL-MM 파트3 표준에는 포함되어 있다. 위 표의 설명 부분은 PostGIS 매뉴얼에서 그대로 가져온 것이다.\n\n3.1.6 텍스트 엔코딩과 바이너리 엔코딩\n심플 피처 표준에는 도 가지 엔코딩 방식이 포함되어 있다. 하나는 텍스트 인코딩이고 다른 하나는 바이너리 인코딩이다. 위에서 사용된 KWT는 인간-해독가능(human-readable)이고, KWB(well-known binary) 인코딩은 기계-해동가능(machine-readable)이다. WKB 인코딩은 정보 손실이 없으며 일반적인 텍스트 인코딩(및 디코딩)보다 작업 속도가 빠르다. 이는 R 패키지 sf와 GDAL, GEOS, liblwgeom, s2geometry 라이브러리 간의 모든 통신에서 사용된다(그림 1.7).",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "03.html#지오메트리에-적용되는-오퍼레이션",
    "href": "03.html#지오메트리에-적용되는-오퍼레이션",
    "title": "3  지오메트리",
    "section": "\n3.2 지오메트리에 적용되는 오퍼레이션",
    "text": "3.2 지오메트리에 적용되는 오퍼레이션\n심플 피처 지오메트리의 프로퍼티를 추출하는 것이 가능하며, 심플 피처 지오메트리의 결합을 통해 새로운 지오메트리가 생성된 경우, 그것의 프로퍼티를 추출하는 것 역시 가능하다. 이 섹션에서는 기하학적 프로퍼티에 전적으로 초점을 맞춘 오퍼레이션에 대해서만 간략하게 다룬다. 5장에서는 비기하학적 피처 속성 분석에 초점을 맞춘다. 이 섹션의 일부 내용은 Pebesma (2018)로부터 가져온 것이다.\n기하학적 프로퍼티에 대한 오퍼레이션을 투입과 산출에 의거해 분류하는 것이 가능하다. 우선 산출의 관점에서, 다음과 같이 구분할 수 있다.\n\n프레디케이트(predicate): 특정 프로퍼티가 TRUE임을 주장하는 논리값\n측정치(measure): 양(수치, 측정 단위가 있을 수 있음)\n변형(transformation): 새롭게 생성된 지오메트리\n\n오퍼레이션이 어떤 지오메트리에 적용되느냐에 따라 다음과 같이 분류하는 것이 가능하다.\n\n유너리(unary)단일 지오메트리에 적용\n바이너리(binary): 지오메트리의 쌍에 적용\n에너리(n-ary): 지오메트리의 집합에 적용\n\n\n3.2.1 유너리 프리디케이트: 단항 조건식(unary predicate)\n유너리 프리디케이트는 하나의 지오메트리의 하나의 프로퍼티를 설명한다. is_simple, is_valid, is_empty와 같는 프리디케이트는 각각 지오메트리가 심플한지, 타당한지, 엠프티한지의 여부에 대한 논리값을 반환한다. is_longlat 프리디케이트는 주어진 CRS가 경위도 좌표계에 기반하고 있는지 평면 좌표계에 기반하고 있는지의 여부를 반환한다. is(geometry, class)는 지오메트리가 특정한 클래스에 속하는지의 여부를 확인한다.\n\n3.2.2 바이너리 프리디케이트와 DE-9IM: 이항 조건식(binary predicate)과 DE-9IM\nDE-9IM(Dimensionally Extended Nine-Intersection Model)(Clementini, Di Felice, and Oosterom 1993; Egenhofer and Franzosa 1991)은 2차원 공간(\\(R^2\\))에서 두 지오메트리간의 정성적 관계를 설명하는 모델이다. 모든 지오메트리는 디멘션 값을 가진다.\n\n포인트는 0\n라인 지오메트리는 1\n폴리곤 지오메트리는 2\n엠프티 지오메트리는 F(거짓)\n\n모든 지오메트리는 내부(I), 경계(B), 외부(E)를 가지며, 이것들이 어떤 역할은 하는지는 폴리곤의 경우에 보다 명확히 드러난다.\n\n라인의 경계는 종점에 의해 형성되고, 선상의 모든 비종점이 내부를 구성한다.\n포인트는 0차원의 내부를 가지지만, 경계는 없다.\n\n\n\n\n\n\n그림 3.2: DE-9IM: 폴리곤의 내부, 경계, 외부(행)와 라인스트링의 내부, 경계, 외부(열) 간의 인터섹션\n\n\n그림 3.2는 폴리곤과 라인스트링의 I, B 및 E 간의 인터섹션을 빨간색으로 표시한 것이다. 개별 그래프의 제목에 인터섹션의 결과 도출되는 디멘션(0, 1, 2, 또는 F)이 표시되어 있다. 폴리곤 지오메트리와 라인 지오메트리의 관계는 바로 이러한 디멘션의 연속(concatenation)이다.\n#      [,1]       \n# [1,] \"1020F1102\"\n첫 세 문자는 첫 번째 지오메트리(폴리곤)의 내부와 관련이 있다. 그림 3.2에는 첫 번째 지오메트리가 행에 배열되어 있다. 더 나아가 지오메트리의 쌍에 대해 마스크(mask) 문자열로 표현된 특정한 조건의 만족 여부도 질의할 수 있다. 예를 들어, 문자열 \"0******\"는 두 번째 지오메트리가 첫 번째 지오메트리의 내부와 하나 이상의 경계 점을 공유할 때 TRUE로 평가된다. 여기서 기호 *는 디멘션(0, 1, 2 또는 F)을 의미하는 것으로 네 개 중 어는 것도 올 수 있다. 마스크 문자열 \"T********\"은 내부가 서로 교차하는 지오메트리 쌍을 찾아내느데, 여기서 기호 T는 차원 디멘션이 0, 1, 2이면서 비엠프티 인터섹션인 경우를 의미한다.\n더 나아가 바이너리 프리디케이트는 DE-9IM에서 규정된 정의를 활용함으로써 일반 언어 동사로 표현될 수 있다. 예를 들어, 프리디케이트 equals는 관계 \"T*F**FFF*\"와 동일하다. 어떤 두 지오메트리가 이러한 관계를 만족한다면, 그 둘은 (위상적으로)는 동일하지만, 노드의 순서가 다를 수 있다.\n바이너리 프리디케이트를 나열하면 다음과 같다.\n\n\n\n\n\n\n\n프리디케이트\n의미\n역프리디케이트\n\n\n\ncontains\nA 포인트 어느 것도 B의 외부에 있지 않다.\nwithin\n\n\ncontains_properly\nA는 B를 포함하며, B의 어떤 포인트도 A의 경계 상에 있지 않다.\n\n\n\ncovers\nB의 어떤 포인트도 A의 외부에 있지 않다.\ncovered_by\n\n\ncovered_by\ncovers의 반대\n\n\n\ncrosses\nA와 B는 일부 내부 포인트를 공유하지만 모든 포인트를 공유하는 것은 아니다.\n\n\n\ndisjoint\nA와 B는 어떤 포인트도 서로 공유하지 않는다.\nintersects\n\n\nequals\nA와 B는 위상적으로 동일하다. 노드 순서나 노드 수가 다를 수 있으며, A가 B를 포함하고 A가 B의 내부에 있는 것과 동일하다.\n\n\n\nequals_exact\nA와 B는 기하학적으로 동일하며, 노드 순서도 동일하다.\n\n\n\nintersects\nA와 B가 완전 분리의 관계를 가지지 않는다.\ndisjoint\n\n\nis_within_distance\nA가 주어진 거리보다 B에 더 가깝게 위치해 있다.\n\n\n\nwithin\nB의 어떤 포인트도 A의 외부에 있지 않다.\ncontains\n\n\ntouches\nA와 B는 최소한 한 개의 경계 포인트를 공유한다. 내부 포인트를 공유하는 것은 아니다.\n\n\n\noverlaps\nA와 B가 다수의 포인트를 공유한다. 디멘션은 A와 B의 디멘션과 동일하다.\n\n\n\nrelated\nA와 B가 주어진 마스크 패턴을 준수하는지의 여부를 반환한다.\n\n\n\n\n위키피디어의 DE-9IM 페이지를 가면, 개별 동사에 해당하는 relate 마스크 패턴을 확인할 수 있다. 왜냐하면 covers와 contains와 같은 동사(그 역도 마찬가지)는 그 의미를 직관적으로 파악하기 어려울 때가 있다.\n\n만일 A가 B를 포함한다면, B는 A의 외부나 경계와 어떠한 공유 포인트도 없다.\n만일 A가 B를 덮으면, B는 A의 외부와 어떠한 공유 포인트도 없다.\n\n3.2.3 유너리 측도\n유너리 측도는 지오메트리의 퍼로퍼티를 설명하는 측정값이나 양을 반환한다.\n\n\n\n\n\n\n측도\n반환값\n\n\n\ndimension\n포인트는 0, 라인은 1, 폴리곤은 2, 엠프티 지오메트리에 대해서는 NA\n\n\narea\n지오메트리의 면적\n\n\nlength\n라인 지오메트리의 길이\n\n\n\n3.2.4 바이너리 측도\ndistance는 지오메트리 간의 거리를 반환한다. 질적 측도로서의 (마스크가 없는) relate는 관계 패턴을 제공한다. 두 지오메트리간의 기하학적 관련성에 대한 설명은 섹션 3.2.2에 나타나 있다.\n\n3.2.5 유너리 변환자\n유너리 변환자는 지오메트리별로 작동하며, 각 지오메트리에 대해 새로운 지오메트리를 반환한다.\n\n\n\n\n\n\n변환자\n반환 지오메트리\n\n\n\ncentroid\n투입 지오메트리의 센트로이드로 구성된 POINT 유형의 지오메트리\n\n\nbuffer\n투입 지오메트리보다 더 큰(혹은 더 작은) 지오메트리: 버퍼 사이즈에 따라 산출 지오메트리의 크기가 달라짐\n\n\njitter\n이변량 균등 분포를 이용하여 조금 전위된 지오메트리\n\n\nwrap_dateline\n날짜 변경선(데이라인)을 더 이상 덮거나 교차하지 않는 조각으로 분할된 지오메트리\n\n\nboundary\n투입 지오메트리의 경계를 가진 지오메트리\n\n\nconvex_hull\n투입 지오메트리의 컨벡스헐을 가진 지오메트리(그림 3.3)\n\n\nline_merge\nMULTILINESTRING 내의 LINESTRING 요소들을 결합하여 더 긴 LINESTRING을 형성한 지오메트리\n\n\nmake_valid\n타당하게 교정된 지오메트리\n\n\nnode\n노드가 없는 교차점에 노드를 추가한 라인 지오메트리. 개별적인 라인 지오메트리에만 적용됨\n\n\npoint_on_surface\n서피스에 임의의 포인트를 가진 지오메트리\n\n\npolygonize\n폐쇄 링을 형성하는 라인으로부터 생성된 폴리곤 지오메트리\n\n\nsegmentize\n주어진 밀도 또는 최소 거리를 만족하는 노드로 구성된 라인 지오메트리\n\n\nsimplify\n버텍스/노드를 제거함으로써 단순화된 라인 혹은 폴리곤 지오메트리\n\n\nsplit\n라인스트링에 의해 분할된 지오메트리\n\n\ntransform\n새로운 CRS로 변형 혹은 전환된 지오메트리(2장)\n\n\ntriangulate\n들로네(Delauney) 삼각망으로 구성된 지오메트리(그림 3.3)\n\n\nvoronoi\n투입 지오메트리로부터 형성된 보로노이(Voronoi) 테셀레이션(그림 3.3)\n\n\nzm\nZ 좌표 및 M 좌표가 수정된(일부 좌표의 삭제 혹은 새로운 좌표의 첨가) 지오메트리\n\n\ncollection_extract\n특정 유형의 GEOMETRYCOLLECTION으로부터 일부를 추출한 지오메트리\n\n\ncast\n유형이 전환된 지오메트리\n\n\n+\n주어진 벡터만큼 전위된 지오메트리\n\n\n*\n스칼라 또는 매트릭스가 곱해진 지오메트리\n\n\n\n\n\n\n\n\n그림 3.3: 포인트의 집합, 왼편은 컨벡스 헐(빨간색), 가운데는 보로노이 폴리곤, 오른편은 들로네 삼각망\n\n\n\n3.2.6 바이너리 변환자\n바이러니 변환자는 지오메트리 쌍에 적용되어 새로운 지오메트리를 생성하는 함수이다. 다음과 같은 것이 있다.\n\n\n\n\n\n\n\n함수\n반환 지오메트리\n인픽스 오퍼레이터\n\n\n\nintersection\n두 지오메트리 겹치는 부분에 대한 지오메트리\n&\n\n\nunion\n두 지오메트리를 결합한 지오메트리로, 내부 경계를 제거하고, 중복되는 포인트, 노드, 또는 라인을 삭제한다.\n|\n\n\ndifference\n두 번째 지오메트리와 중복되는 부분을 제거한 첫 번째 지오메트리\n/\n\n\nsym_difference\n중복되는 부분을 제거한 이후에 두 지오메트리를 결한한 지오메트리로 intersection의 반대\n%/%\n\n\n\n3.2.7 에너리 변환자\n에너리 변환자는 지오메트리의 집합에 작용한다. union을 적용하면 모든 지오메트리의 결합 결과를 얻을 수 있다. 이런 방식이 아니라면, 동일한 차원을 가진 지오메트리 집합은 MULTI-유형 지오메트리로 결합하거나 GEOMETRYCOLLECTION으로 결합할 수 있다. 이 경우, union을 적용하지 않았기 때문에 두 폴리곤 링이 공유 경계선을 가질 때와 같이 타당하지 않은 지오메트리가 생성될 수 있다.\n에너리 intersection과 difference의 경우 형식적으로는 단일 아규먼트를 취하지만 모든 쌍, 세 쌍, 네 쌍 등에 대해 순차적으로 작동한다. 그림 3.4를 살펴보자. 세 개의 상자가 모두 겹치는 영역을 어떻게 식별할 수 있을까? 바이너리 intersection을 사용하면 모든 쌍(1-1, 1-2, 1-3, 2-1, 2-2, 2-3, 3-1, 3-2, 3-3)에 대한 intersection을 얻을 수 있다. 하지만 두 개 이상의 지오메트리가 교차하는 영역을 식별할 수는 없다. 그림 3.4의 오른쪽 그림은 에너리 intersection을 보여주는데, 한 개, 두 개, 또는 더 많은 지오메트리의 교차를 통해 생성된 7개의 겹치지 않는 고유한 지오메트리를 확인할 수 있다.\n\n\n\n\n\n그림 3.4: 왼쪽: 세 개의 겹치는 정사각형이 있는데, 모든 사각형이 겹치는 부분을 어떻게 확인할 수 있을까 오른쪽: 서로 겹치지 않는 고유한 에너리 교차\n\n\n유사하게, 집합 \\(\\{s_1,s_2,s_3,...\\}\\)에 에너리 difference를 적용하여 \\(\\{s_1,s_2-s_1,s_3-s_2-s_1,...\\}\\)를 생성할 수 있다. 결과가 그림 3.5에 나타나 있는데, 왼편에는 원래 집합을 보여주고 있고, 오른편에는 투입 지오메트리의 순서를 바꾼 후의 집합을 보여주고 있다. 이는 결과가 입력 지오메트리의 순서에 의존한다는 사실을 명확히 하기 위함이다. 결과로 얻어진 지오메트리는 서로 겹치지 않는다.\n\n\n\n\n\n그림 3.5: 박스를 서로다른 순서에 따라 differece를 적용한 결과: 왼쪽은 원리 순서이고 오른쪽은 반대 순서",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "03.html#정밀도",
    "href": "03.html#정밀도",
    "title": "3  지오메트리",
    "section": "\n3.3 정밀도",
    "text": "3.3 정밀도\n기하학적 오퍼레이션, 예를 들어 특정 점이 선 위에 있는지 여부를 찾는 오퍼레이션은 R에서 사용되는 8바이트 더블과 같은 배정밀도 부동소수점 수로 좌표가 표현될 때 실패할 수 있다. 자주 선택되는 해결책은 연산 전에 좌표의 정밀도를 제한하는 것이다. 이를 위해 정밀도 모델이 채택된다. 가장 일반적인 방법은 하나의 계수 \\(p\\)를 선택하고, 원래 좌표 \\(c\\)에에서 반올림된 좌표 \\(c'\\)를 계산하는 것이다.\n\\[\nc'=\\text {round} (p\\cdot c)/p\n\\]\n이러한 종류의 반올림은 좌표를 간격이 \\(1/p\\) 인 규칙적인 그리드 상의 점으로 변환하며, 이는 기하학적 연산에 유익하다. 물론, 이러한 반올림은 면적이나 거리와 같은 모든 계산에도 영향을 미치며, 유효한 기하를 무효하게 만들 수 있다. 어떤 정밀도 값이 특정 애플리케이션에 가장 적합한지는 일반적으로 상식과 시행착오를 결합해 결정된다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "03.html#커버리지-테셀레이션과-래스터",
    "href": "03.html#커버리지-테셀레이션과-래스터",
    "title": "3  지오메트리",
    "section": "\n3.4 커버리지: 테셀레이션과 래스터",
    "text": "3.4 커버리지: 테셀레이션과 래스터\nOGC(Open Geospatial Consortium, 오픈지리공간컨소시움)는 커버리지(coverage)를 “시공간적 도메인 내의 임의의 직접 위치에 대해 그 범위에서 값을 반환하는 함수로 작용하는 피처”라고 정의한다 (Baumann, Hirschorn, and Masó 2017). 함수가 존재한다는 것은 시공간적 도메인 내의 모든 “포인트”, 즉 특정한 지점과 특정한 시점의 모든 조합마다 범위에 대해 단일 값을 우리가 얻을 수 있다는 것을 의미한다. 이는 시공간적 현상에서 매우 일반적인 상황이며, 몇 가지 예를 들 수 있다.\n\n경계 분쟁을 제외하고 얘기한다면, 특정 시점의 특정 지역 내 모든 지점(도메인)은 단일 행정 단위(범위)에 속한다.\n특정 시점의 특정 지역 내 모든 지점(도메인)은 특정한 토지피복 유형(범위)을 갖는다.\n특정 지역(도메인)의 모든 지점은 단일한 고도값(범위)을 가지며, 이는 주어진 평균 해수면을 기준으로 측정될 수 있다.\n3차원 기체의 모든 시공간적 지점(도메인)은 온도(범위)에 대해 단일 값을 갖는다.\n\n여기서 주의해야 할 점은 관찰이나 측정은 항상 시간과 공간을 소요하기 때문에, 측정된 값은 항상 시공간적 부피(volume)에 대한 평균값일 수 밖에 없다는 점이다. 따라서 범위 변수를 무부피의 “포인트”에 대해 측정하는 경우는 극히 드물다. 그러나 많은 실제 사례에서 측정된 부피는 “포인트”로 간주될 만큼 충분히 작기는 하다. 토지 피복 유형과 같은 변수의 경우, 구별되는 유형이 측정된 면적 단위와 관련하여 의미가 있도록 부피를 선택해야 한다.\n주어진 예의 처음 두 가지에서 범위 변수는 범주형이며, 마지막 두 가지에서 범위 변수는 연속형이다. 범주형 범위 변수의 경우, 넓은 지역이 동일한 범위 값을 가지면, 이러한 데이터를 효율적으로 표현하는 방법은 동일한 값을 가진 지역의 경계를 저장하는 것이다. 예를 들어, 국가 경계와 같은 경계가 이에 해당한다. 이는 단순 피처 지오메트리(폴리곤 또는 멀티폴리곤)을 사용하여 수행할 수 있지만, 이로 인해 몇 가지 도전 과제가 발생할 수 있다.\n\n단순 피처 폴리곤들이 서로 겹치지 않고 틈새도 없어야 하지만, 이러한 점이 반드시 보장된다고 말하기 어렵다.\n단순 피처는 인접한 두 폴리곤의 경계 상에 놓인 포인트를 하나의 폴리곤에만 할당하지 못하는데, 이는 커버리지로서의 해석과 충돌한다.\n\n\n3.4.1 토폴로지 모델\n폴리곤 커버리지의 겹침과 틈새가 없도록 보장된 데이터 모델을 토폴로지 모델(topological model)이라고 하는데, GRASS GIS나 ArcGIS와 같은 지리정보시스템(GIS)에서 그 예를 찾을 수 있다. 토폴로지 모델은 폴리곤 경계를 한 번만 저장하고, 경계의 양쪽에 어떤 폴리곤이 있는지를 등록한다.\n토폴로지 모델에서 동일한 범위 값을 가진 지역들에 대해 (멀티)폴리곤 집합을 도출하는 것은 간단하다. 폴리곤의 세트로부터 토폴로지를 재정의하는 역의 과정을 수행하기 위해서는 오류에 대한 임계값을 설정해야하고 겹침과 틈새를 처리하는 특정한 방법을 고려해야 한다.\n\n3.4.2 래스터 테셀레이션\n테셀레이션은 공간(2차원 또는 3차원)을 폴리곤을 이용해 더 작은 요소로 세분화한 것을 말한다. 규칙(정규) 테셀레이션은 정규 폴리곤(삼각형, 사각형 또는 육각형)으로 구성되는 테셀레이션을 의미한다. 정사각형을 사용하는 테셀레이션이 공간데이터에 일반적으로 사용되는 이를 래스터 데이터라고 부른다. 래스터 데이터는 공간적 디멘션 \\(d\\)를 정규 셀로 세분하는데, 각 셀 \\(d_i\\)는 좌측 닫힘 및 우측 개방 범위(구간)로 형성된다(역자주: 어떤 범위가 좌측 닫힘 치 우측 개방의 형식으로 규정되었다는 것은 범위의 왼쪽 끝점은 포함되지만, 범위의 오른쪽 끝점은 포함되지 않는다는 것을 의미한다.)\n\\[\nd_i=d_0+[i\\times \\delta,(i+1)\\times \\delta)\n\\]\n여기서 \\(d_0\\)는 오프셋값, \\(\\delta\\)는 구간(셀 또는 픽셀) 크기, 셀 인덱스인 \\(i\\)는 임의의 값을 취할 수 있지만 연속적인 정수값이어야한다. \\(\\delta\\)는 \\(y\\)-축(북거)에 대해서는 보통 음의 값을 취하는데 래스터의 행은 남쪽으로 갈수록 증가하는 반면 \\(y\\)-좌표값은 감소하는 것과 보조를 맞추기 위함이다.\n일반적인 폴리곤 테셀레이션에서는 두 개의 폴리곤이 공유하는 경계에 위치한 점의 할당이 모호하지만, 정규 테셀레이션에서는 좌측 닫힘 “[” 및 우측 개방 “)” 구간을 사용하기 때문에 이러한 모호성이 해소된다. 이는 \\(y\\)-좌표에 음의 \\(\\delta\\)값이 \\(x\\)-좌표에 양의 \\(\\delta\\)값이 적용된 적용된 래스터의 경우, 각 셀의 모서리 점들 중 좌측 상단의 것만이 해당 셀의 부분으로 간주된다는 것을 의미한다. 이로 인해 발생할 수 있는 예기치 못한 결과중 한 예가 그림 3.6에 나타나 있다.\n\n\n\n\n\n그림 3.6: 래스터화의 예기치 못한 결과: 각 셀의 좌측 상단 지점만 셀의 내부로 간주되기 때문에 대각선 아래에서 붉은 선에 접촉한 셀들도 래스터로 전환되었다.\n\n\n시간 차원을 좌측 닫힘 및 우측 개방 구간으로 세분하는 것은 매우 일반적이며, 이는 R의 xts 패키지와 같은 시계열 소프트웨어의 암묵적인 기본 가정이다. 즉, 시간 스탬프(시점)는 시간 간격의 시작을 나타낸다. 다른 모델이 결합될 수도 있다. 예를 들어, 심플 피처 폴리곤을 사용하여 공간을 세분하고 이를 정규 시간 테셀레이션과 결합하여 시공간 벡터 데이터 큐브 개념을 구현할 수 있다. 래스터 및 벡터 데이터 큐브에 대한 논의는 6장에서 다룬다.\n위에서 언급한 것처럼, \\(R^2\\)에 대한 정규 테셀레이션을 생성하는데 활용될 수 있는 폴리곤으로 정사각형 외에 삼각형과 육각형도 있다. 3차원 구체로 확장하면 더 많아지는데, 큐브, 정팔면체, 정이십면체, 정십이면체 등을 포함한다. 큐브를 기반으로 하는 공간 인덱스는 s2geometry이며, H3 라이브러리는 정이십면체를 사용하는데, 밀집화를 위해 (주로) 육각형을 사용한다. 지구 전체를 포괄하는 모자이크 역시 이산 글로벌 그리드라고 불린다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "03.html#네트워크",
    "href": "03.html#네트워크",
    "title": "3  지오메트리",
    "section": "\n3.5 네트워크",
    "text": "3.5 네트워크\n공간적 네트워크느 일반적으로 라인(LINESTRING) 요소로 구성되지만, 네트워크로서의 완결성을 위한 추가적인 위상적 특성을 가진다.\n\n라인스트링의 시작점과 끝점은 다른 라인스트링의 시작점이나 끝점에 연결될 수 있으며, 이를 통해 노드와 엣지의 집합이 형성된다.\n엣지는 방향성을 가질 수 있으며, 이 경우 연결(흐름, 수송)은 한 방향으로만 가능하다.\n\nosmar(Schlesinger and Eugster 2013), stplanr(Lovelace, Ellison, and Morgan 2022), sfnetworks(van der Meer et al. 2022)와 같은 R 패키지는 네트워크 객체를 구성하고 이를 다루는 기능을 제공하며, 네트워크를 통한 최단 또는 최속 경로를 계산할 수 있게 해준다. spatstat 패키지(Baddeley, Turner, and Rubak 2022; Baddeley, Rubak, and Turner 2015)는 포인트 패턴 분석을 선형 네트워크 상에서도 할 수 있는 기능을 제공한다(11장). Lovelace, Nowosad, and Muenchow (2019)의 12장은 네트워크 데이터를 사용한 교통 애플리케이션에 대해 다루고 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "03.html#연습문제",
    "href": "03.html#연습문제",
    "title": "3  지오메트리",
    "section": "\n3.6 연습문제",
    "text": "3.6 연습문제\n다음의 연습문제를 풀되, 적절한 곳에서 R을 활용하라.\n\n2차원(평면) 공간에서 심플 피처 지오메트리로 표현될 수 없는 지오메트리의 두 가지 예를 제시하고, 그림으로 표현하시오.\n좌표 10.542, 0.01, 45321.6789를 정밀도 값 1, 1e3, 1e6, 및 1e-2를 사용하여 재계산하시오.\n에너리 인터섹션이 요구되는 현실 문제를 제시하시오.\n지점별로 하나의 폐쇄 폴리곤을 가지는 보로노이 다이어그램(그림 3.3)을 어떻게 만들 수 있는지 설명하시오.\n다음의 지오메트리에 대해 유너리 측도 dimension을 계산하시오. POINT Z (0 1 1), LINESTRING Z (0 0 1,1 1 2), POLYGON Z ((0 0 0,1 0 0,1 1 0,0 00))\nLINESTRING(0 0,1 0)과 LINESTRING(0.5 0,0.5 1)의 DE-9IM 관계를 설명하시오. 개별 문자의 의미도 함께 설명하시오.\n심플 피처 폴리곤의 집합을 가지고 커버리지 하나를 만들 수 있을지의 여부에 대해 답하시오. 만약 답이 그렇다이면 어떤 제약조건 하에서 그것이 가능한지 설명하시오.\nsf 패키지에 들어 있는 nc 카운티 데이터를 가지고, 네 개의 카운티가 동시에 접촉하고 있는 포인트들을 추출하시오.\n\\(y\\)-축을 위한 \\(\\delta\\)값이 양수라면, 그림 3.6은 어떻게 달라질지 설명하시오.\n\n\n\n\n그림 3.1: 심플 피처 지오메트리의 주요 유형\n그림 3.2: DE-9IM: 폴리곤의 내부, 경계, 외부(행)와 라인스트링의 내부, 경계, 외부(열) 간의 인터섹션\n그림 3.3: 포인트의 집합, 왼편은 컨벡스 헐(빨간색), 가운데는 보로노이 폴리곤, 오른편은 들로네 삼각망\n그림 3.4: 왼쪽: 세 개의 겹치는 정사각형이 있는데, 모든 사각형이 겹치는 부분을 어떻게 확인할 수 있을까 오른쪽: 서로 겹치지 않는 고유한 에너리 교차\n그림 3.5: 박스를 서로다른 순서에 따라 differece를 적용한 결과: 왼쪽은 원리 순서이고 오른쪽은 반대 순서\n그림 3.6: 래스터화의 예기치 못한 결과: 각 셀의 좌측 상단 지점만 셀의 내부로 간주되기 때문에 대각선 아래에서 붉은 선에 접촉한 셀들도 래스터로 전환되었다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>지오메트리</span>"
    ]
  },
  {
    "objectID": "04.html",
    "href": "04.html",
    "title": "4  구체 지오메트리",
    "section": "",
    "text": "4.1 직선\n3장에서 다룬 심플 피처의 기본 전제는 지오메트리가 직선으로 연결된 포인트들의 시퀀스로 표현된다는 것이다. \\(R^2\\)(또는 데카르트 공간)에서는 이는 자명하지만, 구체 상에서는 직선이 존재하지 않는다. 두 지점을 연결하는 가장 짧은 선은 두 지점을 지나는 원의 호로, 이를 대권호(grate circle segment)라고도 한다. 이로 인해, 구의 반대편에 있는 두 점을 연결하는 가장 짧은 거리의 선은 존재하지 않으며, 이들을 연결하는 모든 대원호가 같은 길이를 갖는다. GeoJSON 표준(Butler et al. 2016)은 측지 좌표에서 직선이 무엇인지에 대한 독자적인 정의를 제시하고 있다(이 장의 끝에 있는 연습문제 1 참조).",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>구체 지오메트리</span>"
    ]
  },
  {
    "objectID": "04.html#링-디렉션과-완전-폴리곤",
    "href": "04.html#링-디렉션과-완전-폴리곤",
    "title": "4  구체 지오메트리",
    "section": "\n4.2 링 디렉션과 완전 폴리곤",
    "text": "4.2 링 디렉션과 완전 폴리곤\n구체 상에 존재하는 폴리곤은 구 표면을 유한한 면적을 가진 두 부분, 즉 내부와 외부로 나눈다. \\(R^2\\)의 경우에 적용된 “반시계 방향 규칙”은 잘 작동하지 않는데, 이는 방향 해석이 무엇을 내부로 정의할 것이냐에 따라 달라지기 때문이다. 통상적인 방식은, 폴리곤의 점을 순서대로 순회할 때 다각형 경계의 왼쪽(또는 오른쪽)을 내부로 정의하는 것이다. 노드 순서를 반대로 하면 내부와 외부가 뒤바뀐다.\n3장에서 빈 폴리곤에 대해 배웠는데, 정반대로 지표면 전체를 포괄하는 완전 폴리곤 개념을 생각해 볼 수 있다. 이 개념은, 예를 들어, 완전 폴리곤과 육지부의 합집합의 기하학적 차이를 통해 해양부를 정의할 때, 유용할 수 있다(그림 8.1과 그림 11.6 참고).",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>구체 지오메트리</span>"
    ]
  },
  {
    "objectID": "04.html#바운딩-박스-직사각형-캡",
    "href": "04.html#바운딩-박스-직사각형-캡",
    "title": "4  구체 지오메트리",
    "section": "\n4.3 바운딩 박스, 직사각형, 캡",
    "text": "4.3 바운딩 박스, 직사각형, 캡\n\\(R^2\\)에서는 \\(x\\)와 \\(y\\) 좌표의 범위로 바운딩 박스를 쉽게 정의할 수 있지만, 타원체 좌표의 경우 지오메트리가 반대자오선(antimeridian)(경도 \\(\\pm 180\\))(역자주: 반대자오선은 본초자오선의 반대편에 위치한 자오선을 의미하는 것으로 동경 180도 혹은 서경 180도 경선을 지칭한다.) 이나 극점을 가로지를 때 이러한 범위는 그다지 유용하지 않다.\n낮은 \\(x\\) 값이 높은 값의 서쪽에 있다는 \\(R^2\\)에서의 가정은 반대 자오선을 넘을 때 성립하지 않는다. 구체 상의 영역을 획정하는 보다 자연스러운 대안은 바운딩 캡(bounding cap)인데, 영역의 중심 좌표와 반지름으로 만으로 정의할 수 있다. 남극대륙의 경우, 그림 4.1의 (a)와 (c)에 나타나 있는 것처럼, 바운딩 박스는 다음의 좌표 범위를 통해 정의된다.\n\n\n      xmin       ymin       xmax       ymax \n-180.00000  -85.19218  179.62032  -60.52090 \n\n\n이 바운딩 박스는 명백히 ymin이 -90이고 xmax가 180인 지역을 포함하지 않는다. 바운딩 캡은 해당 지역을 포함한다.\n\n\n  lng lat   angle\n1   0 -90 29.4791\n\n\n해당 지역을 포함하는 또 다른 지오메트리에 바운딩 직사각형(rectangle)이 있다.\n\n\n  lng_lo lat_lo lng_hi   lat_hi\n1   -180    -90    180 -60.5209\n\n\n반대자오선을 가로지르는 지역의 예로 피지 제도를 들 수 있는데, 피지 제도의 바운딩 박스는 다음과 같이 주어진다.\n\n\n      xmin       ymin       xmax       ymax \n-179.86734  -21.70586  180.17769  -12.47695 \n\n\n지구를 한바퀴 도는 정도의 크기이다. 동일한 지역에 대한 바운딩 직사각형은 다음과 같이 주어진다.\n\n\n    lng_lo    lat_lo    lng_hi    lat_hi\n1 174.5872 -21.70586 -178.2511 -12.47695\n\n\n여기서 lng_lo가 lng_hi 보다 더 큰 값을 갖는데, 이는 바운딩 직사각형이 반대자오선을 가로지른다는 것을 나타낸다. 좌표 범위를 가지고 이러한 위치 관계를 추로하는 것은 불가능하다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>구체 지오메트리</span>"
    ]
  },
  {
    "objectID": "04.html#구체-상의-유효성-개념",
    "href": "04.html#구체-상의-유효성-개념",
    "title": "4  구체 지오메트리",
    "section": "\n4.4 구체 상의 유효성 개념",
    "text": "4.4 구체 상의 유효성 개념\n많은 글로벌 데이터셋은 타원체 좌표로 제공되지만 [-180,180]\\(\\times\\)[-90,90]의 \\(R^2\\)에서도 잘 작동하도록 사전 조치되어 있다. 이것은 다음과 같은 사항을 의미한다.\n\n반대자오선(경도 \\(\\pm 180\\))을 가로지르는 지오메트리는 양쪽으로 분할되어 횡단은 발생하지 않는다(하지만 둘은 거의 서로 닿아 있다).\n극점을 포함하는 지오메트리, 예를 들어 남극은 \\(\\pm 180\\)를 기준으로 분할되어 -180,-90과 180,-90가 다른 것으로 취급되지만 실질적으로는 둘 다 지리적 남극(Geographic South Pole)을 나타낸다.\n\n그림 4.1은 남극의 두 가지 다른 표현을 보여준다. 위쪽은 \\(R^2\\)을 상정한 타원체 좌표로 나타낸 것이고, 아래쪽은 극평사도법(Polar Stereographic projection)으로 나타낸 것이다. 왼쪽은 지리적 남극을 중심으로한 분할이 없는 경우이고, 오른쪽은 지리적 남극을 중심으로한 분할이 있는 경우이다.\n폴리곤 (b)와 (c)는 유효하지만, 폴리곤 (a)는 자기-교차하기 때문에 유효하지 않고, 폴리곤 (d)는 남극을 향한 같은 변을 두 번 지나기 때문에 유효하지 않다. 구(\\(S^2\\))에서는 폴리곤 (a)는 유효하지만, (b)는 (d)와 같은 이유로 유효하지 않다.\n\n\n\n\n\n그림 4.1: 남극 폴리곤으로 (a)와 (c)는 POINT(-180 90)을 통과하지 않고, (b)와 (d)는 POINT(-180 -90)과 POINT(180 -90)을 통과한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>구체 지오메트리</span>"
    ]
  },
  {
    "objectID": "04.html#연습문제",
    "href": "04.html#연습문제",
    "title": "4  구체 지오메트리",
    "section": "\n4.5 연습문제",
    "text": "4.5 연습문제\n다음의 연습문제를 풀되, 적절한 곳에서 R을 활용하라.\n\nGeoJSON 형식(Butler et al. 2016)은 타원체 좌표 간의 “직선”을 어떻게 정의하는가(섹션 3.1.1)? 이 직선 정의를 사용했을 때, LINESTRING(0 85, 180 85)는 극투영법에서 어떻게 나타나는가? 북극을 통과하게 하려면 이 지오메트리를 어떻게 수정해야 할까?\n\\(S^2\\)의 전형적인 폴리곤의 링 디렉션을 어떻게 확인할 수 있을까?\n바운딩 박스 대신 바운딩 캡을 사용하는 것의 이점이 있는가? 이점이 있다면 열거해 보시오.\n왜 작은 지역에 대해 해당 지역을 중심으로 한 정사도법이 \\(S^2\\)에서 다루어진 지오메트리의 좋은 근사가 되는가?\nrnaturalearth::ne_countries(country = \"Fiji\", returnclass = \"sf\")를 사용하여 피지의 기하학이 \\(R^2\\)에서 유효한지, 피지를 중심에 둔 정사도법에서 유효한지, \\(S^2\\)에서 유효한지 확인하시오. \\(S^2\\)에서 지오메트리를 유효하게 하기 위해서는 어떻게 해야 하는가? 결과 지오메트리를 \\(R^2\\)로 되돌려 지도로 그려보시오. 피지의 센트로이드를 \\(R^2\\)와 \\(S^2\\) 각각에 대해 구하고 두 센트로이드 간의 거리를 구하시오.\ngiscoR 패키지의 gisco_countries 데이터셋에서 NAME_ENGL == \"Fiji\"인 국가를 선택하시오. 이 국가의 지오메트리가 구체 상에서 유효한가? 그렇다면, 어떻게 그렇게 되었는지 설명하시오.\n\n\n\n\n그림 4.1: 남극 폴리곤으로 (a)와 (c)는 POINT(-180 90)을 통과하지 않고, (b)와 (d)는 POINT(-180 -90)과 POINT(180 -90)을 통과한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>구체 지오메트리</span>"
    ]
  },
  {
    "objectID": "04.html#바운딩-박스-바운딩-직사각형-바운딩-캡",
    "href": "04.html#바운딩-박스-바운딩-직사각형-바운딩-캡",
    "title": "4  구체 지오메트리",
    "section": "\n4.3 바운딩 박스, 바운딩 직사각형, 바운딩 캡",
    "text": "4.3 바운딩 박스, 바운딩 직사각형, 바운딩 캡\n\\(R^2\\)에서는 \\(x\\)와 \\(y\\) 좌표의 범위로 바운딩 박스를 쉽게 정의할 수 있지만, 타원체 좌표의 경우 지오메트리가 반대자오선(antimeridian)(경도 \\(\\pm 180\\))(역자주: 반대자오선은 본초자오선의 반대편에 위치한 자오선을 의미하는 것으로 동경 180도 혹은 서경 180도 경선을 지칭한다.) 이나 극점을 가로지를 때 이러한 범위는 그다지 유용하지 않다.\n낮은 \\(x\\) 값이 높은 값의 서쪽에 있다는 \\(R^2\\)에서의 가정은 반대 자오선을 넘을 때 성립하지 않는다. 구체 상의 영역을 획정하는 보다 자연스러운 대안은 바운딩 캡(bounding cap)인데, 영역의 중심 좌표와 반지름으로 만으로 정의할 수 있다. 남극대륙의 경우, 그림 4.1의 (a)와 (c)에 나타나 있는 것처럼, 바운딩 박스는 다음의 좌표 범위를 통해 정의된다.\n#   xmin   ymin   xmax   ymax \n# -180.0  -85.2  179.6  -60.5\n이 바운딩 박스는 명백히 ymin이 -90이고 xmax가 180인 지역을 포함하지 않는다. 바운딩 캡은 해당 지역을 포함한다.\n#   lng lat angle\n# 1   0 -90  29.5\n해당 지역을 포함하는 또 다른 지오메트리에 바운딩 직사각형(rectangle)이 있다.\n#   lng_lo lat_lo lng_hi lat_hi\n# 1   -180    -90    180  -60.5\n반대자오선을 가로지르는 지역의 예로 피지 제도를 들 수 있는데, 피지 제도의 바운딩 박스는 다음과 같이 주어진다.\n#   xmin   ymin   xmax   ymax \n# -179.9  -21.7  180.2  -12.5\n지구를 한바퀴 도는 정도의 크기이다. 동일한 지역에 대한 바운딩 직사각형은 다음과 같이 주어진다.\n#   lng_lo lat_lo lng_hi lat_hi\n# 1    175  -21.7   -178  -12.5\n여기서 lng_lo가 lng_hi 보다 더 큰 값을 갖는데, 이는 바운딩 직사각형이 반대자오선을 가로지른다는 것을 나타낸다. 좌표 범위를 가지고 이러한 위치 관계를 추로하는 것은 불가능하다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>구체 지오메트리</span>"
    ]
  },
  {
    "objectID": "05.html",
    "href": "05.html",
    "title": "5  속성과 서포트",
    "section": "",
    "text": "5.1 속성-지오메트리 관계와 서포트\n피처 속성은 변경하지 않고 피처의 기하 특성만 변경해도 피처는 변화한 것이다. 왜냐하면 피처는 지오메트리와 속성의 조합으로 이루어지기 때문이다. 예를 들어, 해당 지오메트리를 컨벡스 헐이나 센트로이로 대체할 때, 산출되는 피처가 여전히 속성 값과 의미 있게 관계를 맺을 것인지를 미리 예측할 수 있을까? 이건 그때마다 다르다.\nLINESTRING의 지오메트리를 갖는 도로망을 예를 들어보자. 데이터셋에 도로폭이라는 속성이 포함되어 있고, 어떤 도로의 속성값이 10m라고 하자. 이 때 해당 도로의 특정 부분의 도로폭에 대해 우리는 뭐라고 얘기할 수 있을까? 이는 속성인 도로폭이 도로의 모든 지점의 도로폭을 의미하는지, 즉 도로폭이 일정하다는 것을 의미하는지, 아니면 최소 또는 평균 도로폭과 같은 집합적 속성을 의미하는지에 따라 달라진다. 최소의 경우를 좀 더 따져보자. 최소 도로폭은 해당 도로에서 임의로 특정 구간을 선택했을 때 그것의 최소 도로폭이 주어진 최소 도로폭보다 작지 않을 것이라는 점을 함축하고 있지만, 그 하위 구간의 최소 도로폭이 아닐 수도 있다. 이는 두 가지 유형의 속성-지오메트리 관계(AGR)가 있음을 함축한다.\n폴리곤 데이터의 경우, 고정 AGR(포인트 서포트)의 예로 다음을 변수를 들 수 있다.\n이러한 변수의 전형적인 특성은 지오메트리가 인위적으로 생성된 것이 아니며, 센서 장치(예: 원격탐사의 이미지 픽셀 경계)와도 관련이 없다는 것이다. 대신, 지오메트리는 관찰된 변수를 매핑함으로써 결정된다. 집계 AGR의 예로는 다음과 같은 변수를 들 수 있다.\n이러한 변수의 전형적인 특성은 지오메트리가 법률적 규정, 관측 장치 또는 분석 선택과 같은 것으로부터 비롯된 것으로, 관찰 변수 그 자체와 본질적으로 연결되어 있지는 않다는 점이다.\n세 번째 유형의 AGR는 속성이 피처 기하의 식별자 역할을 하는 경우에 발생한다. 개별 지오메트리가 변수의 특정 값과 고유한 관련성을 맺고 있을 때, 우리는 이 속성을 식별 변수(identity variable)라고 부른다(같은 값을 가진 다른 지오메트리가 없다). 카운티 이름의 예를 들어보자. 이름이 해당 카운티를 식별하고, 카운티 내의 어떤 하위-지역에 대해서도 동일 이름이 적용될 수 있다(포인트 서포트). 그러나 임의의 하위-구역을 염두에 두면 해당 변수는 더 이상 식별자로서의 역할을 할 수 없는 고정 속성값으로 변모한다. 하나의 예를 들면 다음과 같다.\n여기서 중요한 것은 공간정보(단순화를 위해 시간을 무시할 경우)가 서로 다른 현상 유형으로 나뉘어질 수 있다는 점이다(Scheider et al. 2016).\n그런데 이러하 현상 유형이 지오메트리 유형(포인트, 라인, 폴리곤, 래스터 셀)과 일대일 대응의 관계에 있는 것은 아니다.\n속성-지오메트리 관계를 적절히 정의하고, 속성-지오메트리 관계에 대한 정보가 부존하거나 지오메트리의 변화(서포트의 변화)가 정보의 변화를 야기하는 경우에 대해 경고 메시지를 표출하는 것은 공간데이터의 서포트와 관련된 일반적인 공간데이터 분석 오류(Stasch et al. 2014)를 피하는 데 도움이 될 수 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#속성-지오메트리-관계와-서포트",
    "href": "05.html#속성-지오메트리-관계와-서포트",
    "title": "5  속성과 서포트",
    "section": "",
    "text": "고정(constant) AGR: 속성값이 지오메트리의 모든 부분에 적용된다. 피처가 무수히 많은 지점으로 구성되어 있고, 모든 지점이 동일한 속성값을 가지는 경우라고 생각하면 된다. 지구통계학적 용어로는 이것을 포인트 서포트를 보유한 변수라고 부른다.\n집계(aggregate) AGR: 속성값이 지오메트리의 전체에 대한 요약값이다. 피처가 하나의 관측값을 갖고 그 값은 지오메트리 전체에 적용되는 경우라고 생각하면 된다. 이러한 변수를 블록 서포트를 보유한 변수라고 부른다.\n\n\n\n토지이용도에서의 토지이용\n지질도에서의 암석 단위 또는 지질층\n토양도에서의 토양 유형\n기복도에서의 고도 클래스\n기후구분도에서의 기후 지역\n\n\n\n인구: 인구수 혹은 인구밀도\n지역별로 요약된 사회경제적 변수\n원격탐사 픽셀별 평균 반사율\n지역별 총 오염물질 배출량\n이산화질소 농도에 대한 블록 평균: 보통 정사각형 블록에 대한 블로 크리깅(12.5절) 또는 구역 평균값을 예측하는 분산 모델을 통해 획득된다.\n\n\n\n\n카운티 내부의 임의 점(또는 지역)은 여전히 그 카운티의 일부이며 카운티 이름이라는 변수에 대해 동일한 변수값을 가져야 한다. 하지만 해당 지점(또는 지역)은 더 이상 해당 카운티의 (총체적인) 지오메트리에 대한 식별자 구실을 할 수 없다.\n\n\n\n필드: 연속적 공간 상의 모든 지점이 특정한 속성 값을 갖는 경우(예를 들어, 고도, 대기질 또는 토지이용)\n객체: 위치의 이산적 집합으로 규정되는 경우(예를 들어, 주택, 나무 또는 사람)\n집계값: 필드별 총합 혹은 평균, 라인 혹은 폴리곤 객체의 총빈도 혹은 밀도로 계산되는 값\n\n\n\n포인트는 필드 상의 표집 위치일 수도 있고(대기질) 객체의 위치일 수도 있다.\n라인은 객체(도로와 강)일수도 있고, 필드를 위한 등치선일 수 있고, 행정구역의 경계일 수도 있다.\n래스터 픽셀과 폴리곤은 토지이용(커버리지)과 같은 범주형 필드와 연관될 수도 있고, 인구밀도와 같은 집계값과도 관련될 수 있다.\n래스터 혹은 다른 종류의 메시 삼각망은 노드(포인트), 엣지(라인), 페이스(에어리어, 셀)와 관련된 서로 다른 변수를 가질 수 있다. 스태거드(staggered) 그리드를 이용해 편미분 방정식을 근사하는 상황(Haltiner and Williams 1980; Collins et al. 2013)이 이러한 예가 될 수 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#합형과-요약",
    "href": "05.html#합형과-요약",
    "title": "5  속성과 서포트",
    "section": "\n5.2 합형과 요약",
    "text": "5.2 합형과 요약\n테이블 레코드의 합형은 다음의 두 간계를 통해 이루어진다.\n\n그룹 프리디케이트에 기반해 레코드를 분류하기\n합형 함수를 적용해 그룹별로 단일한 요약 속성값을 계산하기\n\nSQL에서 합형 과정은 다음의 예시처럼 이루어진다.\nSELECT GroupID, SUM(population) FROM table GROUP BY GroupID;\n여기서 합형 함수는 SUM이고 그룹 프리디케이트는 GroupID이다.\nR 패키지인 dplyr은 이를 수행하기 위해 두 단계를 사용한다. 함수 group_by는 레코드의 그룹 멤버십을 지정하고, summarise는 각 그룹에 대한 데이터 요약(예: 합계 또는 평균)을 계산한다. 베이스 R의 aggregate 함수는 테이블, 그룹화 조건, 및 집계 함수를 아규먼트로 받아 두 가지 작업을 단일 함수로 해결한다.\n노스캐롤라이나 카운티의 예는 그림 5.1에 나타나 있다. 타원 좌표 POINT(-79, 35.5)를 기준으로 사분면을 설정하고 카운티의 센트로이드가 어느 사분면에 위치하느냐에 따라 카운티를 그룹화하고, 각 그룹별로 질병 사례 수를 합산했다. 그 결과, 그룹별로 통합된 지오메트리가 생성되었음을 알 수 있다(3.2.6절 참조). 이러한 그룹별 합형은 필수적인데, 만일 카운티 지오메트리를 단순히 한데 묶어 MULTIPOLYGON을 생성했다면 수 많은 중복 경계가 생겨나 유효하지 않은 지오메트리가 생성되었을 것이기 때문이다(3.1.2절 참조).\n\n\n\n\n\n\n\n그림 5.1: SID74가 네 개의 지역별로 합산되었다.\n\n\n\n\n결합된 카운티 폴리곤을 지도로 나타내는 것은 기술적으로 아무런 문제가 없지만, 그룹 합계가 그룹화된 카운티에 관련된 것이 아니라 개별 카운티와 관련된 것이라는 잘못된 암시를 줄 수 있다. 이러한 방식의 합형의 특징은 각 레코드가 하나의 그룹에만 할당된다는 점이다. 이렇게 하면 그룹별 합계의 총합이 그룹화 이전 데이터의 총합과 동일하다는 장점이 있다. 즉, 정량적인 변수의 경우, 정보가 손실되거나 추가되는 일이 없다. 새로 형성된 기오메트리는 원 레코드의 지오메트리를 그룹에 의거해 유니온한 결과이다.\n\n\n\n\n\n\n\n그림 5.2: 노스케롤라이나 카운티 상의 타깃 블록\n\n\n\n\n지오메트리의 결합 없이 그룹별 합산값을 산출할 필요가 있을 수 있다. 이 경우, 우리는 공간적 프리디케이트를 사용하는데, 하나의 레코드가 여러개의 그룹과 관련될 수 있다. 그림 5.2의 직사각형을 타깃 에어리어로 하여 직사각형별로 교차하는 카운티의 유병자를 합산하게 되면 전체 합계는 훨씬 더 큰 값을 갖게 될 것이다.\n\n\n  sid74_sum_counties sid74_sum_rectangles \n                 667                 2621 \n\n\n반대로 contains 또는 covers와 같은 다른 프리디케이트를 사용하면 훨씬 더 적은 값이 산출된다. 왜냐하면 많은 카운티가 직사각형 속에 완전히 포함되지 않기 때문이다. 그러나 이러한 결과가 좋을 수 있는 상황도 충분히 존재할 수 있다.\n\nPOINT 지오메트리를 폴리곤에 의거해 합형하고자 하는 경우. 이 때 모든 포인트는 해당 포인트를 완전 포함하는 폴리곤에 할당된다. 만일 경계 상에 위치하게 되면 양쪽 폴리곤 모두에 할당된다(DE-9IM-기반 GEOG 라이브러리가 이러한 방식을 취한다. s2geometry 라이브러리는 “반-개방” 폴리곤을 지정할 수 있게 해주는데, 폴리곤의 중첩만 없다면, 반드시 하나의 폴리곤에 포인트를 할당해준다.\n매우 작은 폴리곤이나 래스터 픽셀을 더 큰 에어리어로 합역하는 경우. 예를 들어 노스케롤라이나에 대한 30m 해상도의 고도 데이터를 카운티별로 평균내는 경우가 해당될 수 있는데 다중 대응으로 인한 데이터 오류는 무시할 만하다.\n다대다 대응에 최대면적대응이 적용된 경우(그림 7.4 참조)\n\n보다 작은 에어리어를 보다 큰 에어리어로 합역하는 보다 포괄적인 접근 방법은 면적-가중 인터폴레이션(area-weighted interpolation)을 적용하는 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#에어리어-가중-인터폴레이션",
    "href": "05.html#에어리어-가중-인터폴레이션",
    "title": "5  속성과 서포트",
    "section": "\n5.3 에어리어-가중 인터폴레이션",
    "text": "5.3 에어리어-가중 인터폴레이션\n\n5.3.1 공간적으로 외연적인 변수와 공간적으로 내포적인 변수\n\n5.3.2 대시메트릭 매핑\n\n5.3.3 파일 포맷에서의 서포트",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#상향-스케일링과-하향-스케일링",
    "href": "05.html#상향-스케일링과-하향-스케일링",
    "title": "5  속성과 서포트",
    "section": "\n5.4 상향 스케일링과 하향 스케일링",
    "text": "5.4 상향 스케일링과 하향 스케일링\n상향 및 하향 스케일링(upscaling and downscaling)은 일반적으로 저해상도 데이터에서 고해상도 정보를 얻는 과정(하향 스케일링) 또는 고해상도 데이터에서 저해상도 정보를 얻는 과정(상향 스케일링)을 의미한다. 이 두 과정은 속성과 지오메트리의 관계에서의 변화, 즉 서포트에서의 변화를 야기한다. 상향 스케일링은 집계(aggregation), 하향 스케일링은 분해(disaggregation)와 동의어로 사용할 수 있다. 하향 스케일링의 가장 단순한 형태는 폴리곤, 라인, 또는 격자 셀의 값을 주어진 포인트에 대해 샘플링(또는 추출)하는 것이다. 이는 포인트-서포트를 가진 변수(“고정” AGR)에는 적합하지만, 변수 값이 합산값일 경우에는 대략적인 결과만을 제공할 수 있다. 하향 스케일링의 도전 과제로는 저해상도 기상 예측 모델 또는 기후 변화 모델을 통해 얻은 변수를 고해상도로 예측하는 것, 그리고 다른 시공간적 해상도를 가진 센서의 융합을 기반으로 위성 이미지에서 파생된 변수를 고해상도로 예측하는 작업이 포함된다.\n식 5.1과 이에 기반한 식 5.2(공간적으로 외연적인 변수)와 식5.3(공간적으로 내포적인 변수)는 소스 구역 \\(S_i\\)와 타깃 구역 \\(T_i\\) 간에 겹침이 존재하기만 하면 두 구역 사이에서 정보를 이동시키는 것이 가능하다는 점을 보여준다. 이는 임의로 더 큰 구역 단위로 이동(집계)하거나 더 작은 구역 단위로 이동(분해)할 수 있음을 의미한다. 물론 이러한 방식의 유의성은 다음의 가정이 성립하는 정도에 의존적이다. 즉, 소스 구역에서 외연적인 변수는 균등 분포해야 하고, 내포적인 변수는 일정한 값을 가져야 한다.\n디스애그리게이션은 라인이나 폴리곤 데이터로부터 포인트 값을 추출하는 것에서 시작된다. 포인트는 면적을 갖지 않기 때문에(\\(|A_{ij}|=0\\)) 식 5.2와 5.3은 적용할 수 없다. 그러나 지오메트리 내부의 값이 일정하다는 가정을 할 수 있다면, 내포적인 변수인 경우에는 \\(Y_i(S_i)\\)이 포인트에 할당될 수 있다. 단, 모든 지점이 고유한 방식으로 단일한 소스 지점 \\(S_i\\)에 할당될 수 있어야 한다. 폴리곤 데이터를 예를 들자면, \\(Y\\)가 커버리지 변수(3.4절)여야만 한다는 것을 함축한다. 외연적인 변수의 경우, 포인트에 대한 변수값을 추출한다는 것이 무의미하다. 항상 0이 추출될 것이기 때문이다.\n영역과 관련된 값이 해당 영역의 집계 값인 경우, 면적-가중 인터폴레이션이나 대시매트릭 매핑에서 가정하는 균일 분포 또는 일정한 값이라는 가정은 매우 비현실적이다. 이러한 경우에라 하더라도 이러한 단순한 접근법이 합리적인 근사치를 제공할 수 있으며, 예를 들어 다음과 같은 상황에서 가능하다.\n\n소스 구역과 타깃 구역이 거의 동일하다.\n소스 구역 내의 변동성이 매우 작아서, 변수값이 거의 균등 분포하거나 일정한 값을 보인다.\n\n다른 경우에는 이러한 방법을 사용하여 얻은 결과는 그저 타당성이 결여된 가정의 결과일 뿐이다. 점 또는 더 작은 구역으로부터 더 큰 구역에 대한 퀀티티를 추정할 수 있는 통계적 애그리게이션 방법에는 다음이 포함된다.\n\n디자인-기반(design-based) 방법: 타깃 지역에서 확률 샘플이 이용 가능하고, 포함 확률(inclusion probability)이 알려져 있어야 한다(Brus 2021, 10.4 절).\n모델-기반(model-based) 방법: 공간적 자기상관을 수용하는 랜덤 필드 모델을 가정한다(블록 크리깅, 12.5절).\n\n다른 디스애그리게이션 기법에 다음과 같은 것들이 있다.\n\n결정론적, 평활화-기반 접근: 커널-기반 또는 스플라인-기반의 평활화 기법 포함\n통계적, 모델-기반 접근: 에어리어-투-에어리어 크리깅과 에어리어-투-포인트 크리깅",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#연습문제",
    "href": "05.html#연습문제",
    "title": "5  속성과 서포트",
    "section": "\n5.5 연습문제",
    "text": "5.5 연습문제\n다음의 연습문제를 풀되, 적절한 곳에서 R을 활용하라.\n\n노스케롤라이나 데이터셋(nc)에 nc$State = \"North Carolina\"와 같은 방식으로 변수를 첨가한다고 할 때(모든 카운티에 동일한 주 이름이 할당), 속성-지오메트리 관계(AGR)을 위해 이 변수에 어떤 값을 첨가할 수 있을까?\nst_union(nc)으로 얻은 지오메트리로부터 새로운 sf 객체를 생성하고, State라는 변수에 \"North Carolina\"라는 값을 할당하라. 이 변수에 어떤 대한 속성-지오메트리 관계(AGR)을 속성 변수에 할당할 수 있을까?\nnc 데이터셋에 st_area를 사용하여 이름이 area인 변수를 추가하시오. area 변수와 AREA 변수를 비교하시오. AREA의 단위는 무엇인가? 두 변수는 선형적인 관련성이 있는가? 불일치가 존재한다면, 그 원인은 무엇일까?\narea는 내포적인 변수인가 외연적인 변수인가? area의 AGR은 constant인가, identity인가, 아니면 aggregate인가?\n그림 5.3에서 5.3.1 절에 나타나 있는 방정식을 이용하여 (a) 점선 셀과 (b)네 개의 실선 셀을 모두 포함하는 정사각형에 대해 면적-가중 인터폴레이션의 결과를 구하시오. 후자에 대해서는 (i) 외연적인 변수인 경우와 (ii) 내포적인 변수인 경우로 나누어 계산하시오. 빨간 숫자는 소스 구역의 데이터 값이다.\n\n\n\n\n\n\n그림 5.3: 면적-가중 인터폴레이션의 예제 데이터\n\n\n\n\n\n그림 5.1: SID74가 네 개의 지역별로 합산되었다.\n그림 5.2: 노스케롤라이나 카운티 상의 타깃 블\n그림 5.3: 면적-가중 인터폴레이션의 예제 데이터",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#면적-가중-인터폴레이션",
    "href": "05.html#면적-가중-인터폴레이션",
    "title": "5  속성과 서포트",
    "section": "\n5.3 면적-가중 인터폴레이션",
    "text": "5.3 면적-가중 인터폴레이션\n두 개의 데이터셋의 지오메트리와 속성을 결합함으로써 소스 데이터셋의 속성 값을 타겟 데이터셋의 지오메트리에 의거한 요약값으로 전환하고자 한다면, 면적-가중 인터폴레이션(area-weighted interpolation)이 가장 간단한 접근 방법이 될 수 있다. 이 방법은 소스와 타겟의 지오메트리가 겹치는 면적을 고려하여 소스 속성 값을 타겟 속성 값으로 전환하기 위한 가중치로 사용한다(Goodchild and Lam 1980; Do, Thomas-Agnan, and Vanhems 2015a, 2015b; Do, Laurent, and Vanhems 2021). 이 기법은 보수적 합역(conservative region aggregation) 또는 재그리드(regridding)로도 알려져 있다(Jones 1999). 여기서는 Do, Thomas-Agnan, and Vanhems(2015b)의 표기법을 따르도록 한다.\n면적-가중 인터폴레이션은 타깃 에어리어 \\(T_j\\)에 대한 가중평균값을 산출해 주는데, 해당 타깃 에어리어와 결부되어 있는 \\(p\\)개의 타깃 에어리어 \\(S_i\\)의 속성값 \\(Y_i\\)에 대한 가중평균값이다.\n\\[\n\\hat Y_j(T_j)=\\sum\\limits_{ij}^pw_{ij}Y_i(S_i)\n\\tag{5.1}\\]\n여기서 \\(w_{ij}\\)는 \\(T_j\\)와 \\(S_i\\)의 겹침의 정도에 따라 달라지는 데, 겹침의 정도는 \\(A_{ij}=T_j\\cap S_i\\)로 표현된다. \\(w_{ij}\\)와 \\(A_{ij}\\)의 관계는 아래에서 자세히 설명하고자 한다.\n가중치를 계산하는 다양한 옵션이 있으며, 외부 변수를 활용하는 방법(대시메트릭 매핑은 Mennis 2003 참조)도 그 중 하나이다. 외부 변수를 사용하지 않고 가중치를 계산하는 두 가지 단순한 방식이 존재하는데, 변수 \\(Y\\)가 공간적으로 외연적인(extensive) 변수인지 내포적인(intensive) 변수인지에 따라 달라진다.\n\n5.3.1 공간적으로 외연적인 변수와 공간적으로 내포적인 변수\n공간적으로 외연적인 변수는 길이, 면적, 부피, 또는 카운트와 같은 물리적 크기와 관련된 양을 나타낸다. 외연적인 변수의 예로 인구 수를 들 수 있다. 인구 수는 특정 크기의 영역과 관련된 값이며, 그 영역이 더 작은 영역으로 분할되면 인구 수 또한 분할되어야 한다. 인구가 공간적으로 균일하지 분포하지 않은 경우가 많기 때문에, 이 분할이 반드시 면적에 비례하여 이루어질 필요는 없지만, 더 작은 영역의 인구 수의 합계는 전체 영역의 인구 수와 일치해야 한다.\n공간적으로 내포적인 변수는 영역의 면적에 비례적으로 작동하지 않는 변수이다. 즉, 영역이 분할되더라도 평균적인 의미에서는 값이 그대로 유지된다. 내포적인 변수의 예로 인구밀도를 들 수 있다. 영역이 더 작은 영역으로 분할되더라도 연구밀도 값이 면적에 비례하여 할당되지는 않는다. 더 작은 영역의 인구밀도의 합산값은 아무런 의미가 없으며, 작은 영역의 인구밀도의 평균의 전체 영역의 인구밀도와 유사할 것이다.\n외연적인 변수 \\(Y\\)가 공간상에 균등하게 분포한다고 했을 때, 소스 데이터의 지역 \\(S_i\\)의 변수값 \\(Y_i\\)로부터 타깃 지역과의 겹침을 통해 생성된 구역(\\(A_{ij}=T_j\\cap S_i\\))의 속성값 \\(Y_{ij}\\)를 다음의 공식에 의거해 구할 수 있다.\n\\[\n\\hat Y_{ij}(A_{ij})=\\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\]\n여기서 \\(|\\cdot|\\)는 면적을 의미한다. \\(Y_j(T_j)\\)를 추청하려면, \\(T_j\\)와 겹쳐서 생성되는 모든 하위 영역의 값을 합산해야 한다.\n\\[\n\\hat Y_j(T_j)=\\sum\\limits_{i=1}^p\\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\tag{5.2}\\]\n내포적인 변수의 경우, 해당 변수값이 개별 소스 구역 \\(S_i\\) 내에서 일정한 값을 나타낸다고 가정하기 때문에, 겹침에 의해 생성된 하위 구역의 추정값은 해당 소스 구역의 전체 값과 동일하다.\n\\[\n\\hat Y_{ij}=Y_i(S_i)\n\\]\n따라서 소스 구역의 값에 대해 면적-가중 평균을 구하면 타깃 구역 \\(T_j\\)에 대한 추정값을 구할 수 있다.\n\\[\n\\hat Y_j(T_j)=\\sum\\limits_{i=1}^p\\frac{|A_{ij}|}{|T_j|}Y_i(S_i)\n\\tag{5.3}\\]\n\n5.3.2 대시메트릭 매핑\n다시메트릭 매핑은 보다 큰 크기의 구역 체계의 변수값(예: 인구 수)을 보다 크기가 작은 구역 체계의 변수값으로 분배하는 방법이다. 이때 인구 분포와 연관된 다른 변수들, 예를 들어 토지 이용, 건물 밀도, 도로 밀도 등을 활용한다. 대시매트릭 매핑을 위한 가장 간단한 방식은 식 5.2에서 나타나 있는 비 \\(|A_{ij}|/|S_i|\\) 대신 또 다른 외연적인 변수와 관련된 비 \\(X_{ij}(S_{ij})/X_i(S_i)\\)를 사용하는 것이다. 이 방법을 사용하기 위해서는 소스 구역과 겹침 구역 모두에 대해 변수 값을 알고 있어야 한다.\n\n5.3.3 파일 포맷에서의 서포트\nGDAL의 벡터 API는 필드 도메인(field domains)이라고 불리는 것을 읽고 쓰는 기능을 지원하며, 이는 지오메트리가 분할되거나 결합될 때 속성 변수에 대해 어떤 처리를 해야 할지 나타내는 “분할 정책(split policy)”과 “병합 정책(merge policy)”을 가질 수 있다. 이러한 값은 공간적으로 내표적인 변수의 경우, 분할 시 “중복(duplicate)”이, 병합 시 “기하 가중(geometry weighted)”가 될 수 있으며, 공간적으로 외연적인 변수의 경우, 분할 시 “기하 비율(geometry ratio)”이, 병합 시 “합(sum)”이 될 수 있다. 이 기능을 지원하는 파일 형식으로는 GeoPackage와 FileGDB가 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "06.html#차원-속성-서포트",
    "href": "06.html#차원-속성-서포트",
    "title": "6  데이터 큐브",
    "section": "\n6.2 차원, 속성, 서포트",
    "text": "6.2 차원, 속성, 서포트\n시공간 상의 현상은 정의역이 공간과 시간이며, 치역이 하나 이상의 관찰된 속성인 함수로 생각할 수 있다. 명확하게 식별 가능한 이산적인 사건이나 객체의 경우, 치역은 일반적으로 이산적이며, 이산성은 시작과 끝의 정밀한 좌표를 설정하는 것으로 부터 확보될 수 있고, 이는 벡터 지오메트리에 잘 들어맞는다. 반면에 기온이나 토지이용 유형처럼 어느 곳에서나 값을 가지는 연속적인 현상에서는 무한히 많은 값을 나타내야 하며, 보통 해당 시공간 도메인(범위)을 일정하게 이산화하는 전략이 사용된다. 이러한 고려는 널리 알려져 있는 여러 데이터 구조로 이어진다.\n\n시계열: 시간의 함수로서 타임라인으로 표시되는 데이터 구조\n이미지 혹은 래스터: 2차원 공간데이터를 위한 데이터 구조\n이미지의 시간적 시퀀스: 동적인 공간데이터를 위한 데이터 구조\n\n세 번째의 데이터 구조는 변수 \\(Z\\)가 \\(x, y, t\\)에 의존한다.\n\\[\nZ=f(x,y,t)\n\\]\n이는 시공간 어레이 또는 데이터 큐브의 전형적인 형태이다. 정의역을 규칙적으로 이산화한 지점들이 형성하는 입체적 모양이 큐브 형태를 띠기 때문이다. 치역을 형성하는 변수(여기서는 \\(x, y, t\\) )를 큐브 차원이라고 부른다. 데이터 큐브는 여러 속성을 가질 수 있다.\n\\[\n\\{Z_1,Z_2,...,Z_p\\}=f(x,y,t)\n\\]\n만약 \\(Z\\)가 함수형이라면, 예를 들어 전자기 스펙트럼에서 측정된 반사율 값이라면, 스펙트럼 파장 \\(\\lambda\\)가 추가적인 차원을 형성할 수 있다(\\(Z=f(x,y,t,\\lambda)\\)). 6.5절에서는 컬러 밴드를 속성으로 표현하는 대안적 방식을 다룬다.\n다중 시간 차원도 가능하다. 여러 다른 시간 \\(t\\)에 대해 미래의 여러 다른 시점 \\(t'\\)에 대한 예측을 할 때나, 시간이 여러 차원으로 나누어질 때(연도, 연중 일자, 하루 중 시간 등)이다. 데이터 큐브의 가장 일반적인 정의는 \\(n\\)개의 차원에서 \\(p\\)개의 속성으로의 함수적 매핑이다.\n\\[\n\\{Z_1,Z_2,...,Z_p\\}=f(D_1,D_2,...,D_n)\n\\]\n여기에서는 1개 이상의 공간 차원과 0개 이상의 시간 차원을 가진 모든 데이터셋을 데이터 큐브로 간주한다. 이렇게 하면 다음의 모든 것을 포괄할 수 있다.\n\n심플 피처(3.1절)\n피처 집합에 대한 시계열\n래스터 데이터\n다분광 래스터 데이터(이미지)\n다분광 래스터 데이터의 시계열(비디오)\n\n\n6.2.1 정규 차원, GDAL’의 지오트랜스폼\n데이터 큐브는 보통 다차원 어레이에 저장되며, 1-기반 배열 인덱스 \\(i\\)와 관련된 규칙적으로 이산화된 차원 변수 \\(x\\) 사이의 일반적인 관계는 다음과 같다.\n\\[\nx=o_x+(i-1)d_x\n\\]\n여기서 여기서 \\(o_x\\)는 원점이고, \\(d_x\\) 이 차원의 그리드 간격이다.\n그림 1.6 b-c와 같은 보다 일반적인 경우에서 \\(x\\)와 \\(y\\) 및 배열 인덱스 \\(i\\)와 \\(j\\) 사이의 관계는 다음과 같다.\n\\[\nx=o_x+(i-1)d_x+(j-1)a_1\n\\]\n\\[\ny=o_y+(i-1)a_2+(j-1)d_y\n\\]\n여기서 \\(a_1\\)과 \\(a_2\\)를 아핀(affine) 파라미터라고 하면, 이것은 GDAL에서 사용되는 소위 지오변환(geostransform)이다. \\(a_1=a_2=0\\)일 경우, 수식은 \\(d_x=d_y\\)인 정사각형 셀을 가진 그림 1.6a의 규칙적 래스터로 축소된다. 정수 인덱스의 경우, 좌표는 그리드 셀의 시작 가장자리의 좌표이며, 셀 면적(픽셀)은 인덱스 값이 \\(i\\)(포함)에서 \\(i+1\\)(제외)로 범위가 설정된 셀을 차지한다. 가장 일반적인 이미지 형식의 경우, \\(d_y\\)는 음수로, 이는 이미지 행 인덱스가 \\(y\\)값이 감소함에 따라(남쪽으로) 증가함을 나타낸다. 왼쪽 상단 그리드 셀의 중심 좌표를 얻기 위해서는(\\(d_y\\)가 음수인 경우) \\(i=1.5\\)와 \\(j=1.5\\)를 사용한다.\n직교(rectilinear) 래스터의 경우(역자주: 그림 1.6의 네 번째 사례), 어레이 인덱스를 차원 값에 매핑하기 위한 테이블이 필요하다. 예를 들어 NetCDF 파일은 공간 차원(좌표) 변수의 모든 값을 항상 저장하는데, 주로 공간 그리드 셀의 중심 좌표값이거나 오프셋 값을 저장한다. 추가로, 그리드 셀의 경계를 저장하여 직교 차원을 정의하거나 좌표 변수 값과 셀 경계 간의 관계를 명확히 나타낼 수도 있다.\n곡선형(curvilinear) 래스터의 경우(역자주: 그림 1.6의 다섯 번째 사례), 모든 \\(i,j\\) 조합을 \\(x,y\\) 쌍에 매핑하는 어레이가 필요하거나, 이를 수행하는 파라미터 함수(투영 또는 역투영 함수)가 필요하다. NetCDF 파일은 보통 두 가지를 모두 제공한다. GDAL은 이러한 어레이를 지리위치 (geolocation) 어레이라고 부르며, 이와 관련된 변환에 대해 광범위한 지원을 제공한다.\n\n6.2.2 큐브 차원과 서포트\n5.1절에서는 속성 변수의 공간적 서포트를 특정 관측 또는 예측과 관련된 지오메트리의 크기(길이, 면적, 부피)로 정의하였다. 동일한 개념이 시간적 서포트에도 적용된다. 시간은 시작 및 종료 시간이 명시된 기간으로 보고되는 경우가 드물지만, 많은 경우 타임스탬프 자체가 기간을 암시하거나(ISO-8601에서는 “2021”는 해당 연도의 한해 전체를, “2021-01”은 해당 연월의 전체를 의미하는 것으로 정의한다) 현재 레코드의 타임스탬프에서 다음 레코드의 타임스탬프까지(타임스템프 그 자체는 제외)를 기간으로 간주된다.\n예를 들어, MODIS 위성 이미지는 16일 합성의 식생 지수(NDVI 및 EVI)를 제공하는데, 이는 16일 기간 동안 모든 사용 가능한 이미지를 단일 이미지로 집계한 것이다. 이러한 합성 이미지는 시간적 “블록 서포트”를 가진다. 반면에 Sentinel-2 또는 Landsat-8 데이터는 “스냅샷” 이미지를 제공하는데, 시간적 “포인트 서포트”를 가진다. 시간적 포인트 서포트 데이터를 월별 값으로 집계할 때는, 목표 시간 구간에 해당하는 모든 이미지를 선택한다. MODIS의 16일 합성과 같은 시간적 블록 서포트 이미지를 집계할 때는, 16일 합성 기간과 목표 기간이 겹치는 양에 따라 이미지에 가중치를 부여해야 하며, 이는 5.3절의 면적-가중 인터폴레이션과 유사한 것으로 시간-가중을 하는 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#데이터-큐브에-작용하는-오퍼레이션",
    "href": "06.html#데이터-큐브에-작용하는-오퍼레이션",
    "title": "6  데이터 큐브",
    "section": "\n6.3 데이터 큐브에 작용하는 오퍼레이션",
    "text": "6.3 데이터 큐브에 작용하는 오퍼레이션\n\n6.3.1 큐브의 분할: 필터\n데이터 큐브는 특정 값으로 한 차원을 고정하여 다수의 서브-큐브로 분할할 수 있다. 그림 6.4는 시간, 스펙트럼 또는 공간 차원에서 이러한 방식으로 얻어진 서브-큐브를 보여준다. 이 그림에서 공간 필터링은 특정 공간 차원을 단일 값으로 고정하는 것이 아니라 특정 하위-영역을 선택함으로써 이루어는데, 이것이 보다 일반적인 작업이다. \\(x\\) 또는 \\(y\\)를 고정하면 일정한 \\(x\\) 또는 \\(y\\)의 횡단면을 따라 서브 큐브가 생성되며, 이는 하나의 공간 차원과 하나의 시간 차원에서 속성이 플롯(색상으로 표현)된 호브몰러 다이어그램(Hovmöller diagram)을 보여주는 데 사용할 수 있다.\n\n\n\n\n\n그림 6.4: 시간, 밴드 혹은 공간에 의거한 데이터 큐브 필터링\n\n\n\n6.3.2 차원에 함수를 적용하기\n잘 사용되는 또 다른 오퍼레이션에 하나 이상의 큐브 차원에 대해 함수를 적용하는 것이 있다. 간단한 경우는 abs, sin 또는 sqrt와 같은 함수를 큐브의 모든 값에 적용하거나, 큐브의 모든 값을 단일 스칼라로 반환하는 경우(예: 큐브 전체에 대한 평균 또는 최대값을 계산하는 경우)이다. 다른 옵션으로는 선택된 차원에 함수를 적용하는 것이 있는데, 예를 들어 그림 6.5에서 볼 수 있는 것처럼 개별(픽셀/밴드) 시계열에 시간적 로-패스 필터(low-pass filter)를 적용하거나, 그림 6.6에서 볼 수 있는 것처럼 모든 밴드/시간 조합에 대해 각 공간 슬라이스에 공간적 로패스 필터를 적용하는 경우가 있다.\n\n\n\n\n\n그림 6.5: 시계열 데이터에 로-패스 필터링 적용하기\n\n\n\n\n\n\n\n그림 6.6: 공간 슬라이스에 로-패스 필터링 적용하기\n\n\n\n6.3.3 차원의 삭감\n전체 데이터 큐브에 평균이라는 함수를 적용하면, 모든 차원이 사라지게 된다. 결과로 생성된 “데이터 큐브”는 차원 0을 갖는다. 또한, 특정한 차원 집합에 함수를 적용할 수도 있다. 이렇게 되면 해당 차원만 사라지거나 축소된다. 필터링이 이러한 차원 삭감의 특별한 경우라는 것을 이미 보았지만, 모든 시계열의 최대값을 계산하거나, 각 공간 슬라이스에 대한 평균을 구하거나, NDVI와 같은 밴드 지수를 계산하여 서로 다른 스펙트럼 값을 단일의 새로운 “밴드”로 요약하는 것도 모두 차원 삭감과 관련되어 있다. 그림 6.7은 이러한 옵션을 설명한다.\n\n\n\n\n\n그림 6.7: 데이터 큐브의 차원 삭감하기",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#래스터-큐브를-벡터-큐브로-애그리게이팅하기",
    "href": "06.html#래스터-큐브를-벡터-큐브로-애그리게이팅하기",
    "title": "6  데이터 큐브",
    "section": "\n6.4 래스터 큐브를 벡터 큐브로 애그리게이팅하기",
    "text": "6.4 래스터 큐브를 벡터 큐브로 애그리게이팅하기",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#차원을-속성으로-교체하기",
    "href": "06.html#차원을-속성으로-교체하기",
    "title": "6  데이터 큐브",
    "section": "\n6.5 차원을 속성으로 교체하기",
    "text": "6.5 차원을 속성으로 교체하기\n차원이 무순서의 범주적 성격을 띨 수도 있는데, 이럴 경우에는 속성 집합을 단일 차원으로 쉽게 교환할 수 있다. 즉, 아래의 첫 번째 수식을 두 번째 수식으로 대체할 수 있다.\n\\[\n\\{Z_1,Z_2,...,Z_p\\}=f(D_1,D_2,...,D_n)\n\\]\n\\[\nZ=f(D_1,D_2,...,D_n,D_{n+1})\n\\]\n여기서 \\(D_{n+1}\\)는 기수 \\(p\\)를 가지며 레이블로서 \\(Z_1,Z_2,...,Z_p\\)(라는 이름)을 갖는다. 그림 6.9는 대기질 스테이션에 대한 벡터 데이터 큐브를 보여주는데, 한 차원이 대기질 파라미터들로 이루어져 있음을 볼 수 있다. 그림 6.9에서처럼 \\(Z_i\\)가 전혀 다른 측정 단위를 가지고 있는 경우에는 “파라미터” 차원 \\(D_{n+1}\\)을 축소할 때는 주의해야 한다. 즉, mean 또는 max와 같은 함수는 무의미할 것이다. 그러나 각 변수의 임계값을 초과하는 수를 세는 것은 의미가 있을 수 있다.\n\n\n\n\n\n그림 6.9: 대기질의 시계열 데이터를 가진 벡터 데이터 큐브\n\n\n차원과 속성을 유연하게 교환할 수 있게 되면 매우 유연한 분석이 이루어질 가능성을 높여준다(Brown, 2010).",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#기타-동적-공간데이터",
    "href": "06.html#기타-동적-공간데이터",
    "title": "6  데이터 큐브",
    "section": "\n6.6 기타 동적 공간데이터",
    "text": "6.6 기타 동적 공간데이터\n우리는 데이터 큐브 구조와 잘 맞는 여러 동적 래스터 및 벡터 데이터 예제를 보았다. 그러나 다른 데이터 예제는 덜 그러하다. 특히 시공간 포인트 패턴(11장)과 경로[이동 데이터; 최근 리뷰는 Joo et al. (2020) 참조]는 종종 데이터 큐브로 처리하기보다는 보다 간편한 방식으로 다루어진다. 시공간 포인트 패턴은 사건이나 물체의 시공간 좌표의 집합이다. 즉, 사고, 발병, 교통 체증, 번개와 같은 것들이다. 경로 데이터는 이동하는 물체(사람, 자동차, 위성, 동물)의 공간적 위치의 시간적 시퀀스이다. 경로 데이터의 주요 정보는 좌표값인데, 이러한 좌표값을 규칙적으로 분할된 그리드 셀의 체계에서의 위치값으로 치환하여 사용할 수 있다. 이러한 치환은 고밀도 지역에서 패턴을 빠르게 탐색하는 등 일부 분석에서 도움이 될 수 있지만, 정확한 좌표의 손실로 말미암아 거리, 방향 또는 속도 계산을 포함하는 여러 접근 방식을 어렵게 한다. 그럼에도 불구하고, 이러한 데이터를 데이터 큐브 형태로 전환하여 사용하는 경우가 많은데, 시간을 고정한 상태에서 공간을 이산화하거나 공간을 고정한 상태에서 시간을 이산화한다.\n포인트 패턴이나 경로 데이터를 희소 어레이 형태로 재현하는 것이 가능한데, SciDB(Brown, 2010) 또는 TileDB(Papadopoulos et al., 2016)를 활용할 수 있다. 이러한 방법은 좌표 정확도 손실의 문제를 상당히 해결할 수 있는데, 극단적으로 조밀한 그리드 차원을 선택하거나 데이터 포인트를 포함하는 그리드 셀만을 선택하는 것이다. 경로 데이터의 경우, 개체 단위를 식별하거나 연속적인 이동 시퀀스의 개별 단위를 식별하기 위한 그룹화 차원을 추가해야 한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#연습문제",
    "href": "06.html#연습문제",
    "title": "6  데이터 큐브",
    "section": "\n6.7 연습문제",
    "text": "6.7 연습문제\n다음의 연습문제에 대해 글로 대답하라. 필요한 경우 주장을 설명하기 위해 R 코드를 사용하라.\n\n데이터 큐브를 사용하여 이동하는 물체를 추적하여 얻은 (x, y, t)의 경로 및 시퀀스를 표현하는 것이 왜 어려운가? 이 장의 내용에 기반하여 답하시오.\n인구, 기대 수명, 국내 총생산과 같은 변수로 구성된 사회경제적 벡터 데이터 큐브에서, 국가와 연도를 차원으로 하여 정렬할 때, 어떤 변수들이 공간 차원에 대한 블록 지원을 가지며, 어떤 변수들이 시간 차원에 대한 블록 지원을 가지는가?\nSentinel-2 위성은 12개의 스펙트럼 밴드로 이미지를 수집한다. 이를 (i) 밴드별로 서로 다른 데이터 큐브로, (ii) 12개 밴드를 12개 속성으로 가진 데이터 큐브로, (iii) 스펙트럼 차원을 가진 단일 속성 데이터 큐브로 표현할 때의 장점과 단점을 나열하라.\n그림 1.6에 나타나 있는 곡선 래스터가 특별한 데이터 큐브로 간주될 수 있는 이유를 설명하라.\n\n다음 문제들이 데이터 큐브 오퍼레이션인 필터, 적용, 축소 및/또는 애그리게이트를 사용하여 어떻게 해결될 수 있는지, 또 어떤 순서로 적용해야하는지 설명하라. 또한 각 문제에 대해 적용되는 함수와 결과 데이터 큐브의 차원(있는 경우)을 언급하라.\n\n대기질 모니터링 스테이션의 시간별 \\(PM_{10}\\) 측정치로부터, 스테이션별 일평균 50 \\(\\mu g/m^3\\)를 초과하는 연간 일수를 계산하라.\n석유 유출의 항공 이미지 시퀀스를 사용하여, 석유 유출이 가장 넓은 범위를 가졌던 시점과 해당 범위를 찾으라.\n10년 동안의 전 세계 일일 해수면 온도(SST) 래스터 맵을 사용하여, SST 값의 시간적 추세에서 상위 10%에 해당하는 지역과 하위 10%에 해당하는 지역을 찾으라.\n\n\n\n\n\n\n그림 6.1: 위도, 경도, 시간의 세 차원을 가지 래스터 데이터 큐브\n그림 6.2: x, y, 밴드, 시간의 네 차원을 가진 4차원 래스터 데이터 큐브\n그림 6.3: 두 차원에 의거해 평면적으로 배열된 4차원 래스터 데이터\n그림 6.4: 시간, 밴드 혹은 공간에 의거한 데이터 큐브 필터링\n그림 6.5: 시계열 데이터에 로-패스 필터링 적용하기\n그림 6.6: 공간 슬라이스에 로-패스 필터링 적용하기\n그림 6.7: 데이터 큐브의 차원 삭감하기\n그림 6.8: 래스터 데이터 큐브를 벡터 데이터 큐브로 애그리게이션 하기\n그림 6.9: 대기질의 시계열 데이터를 가진 벡터 데이터 큐브",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#차원-데이터-큐브",
    "href": "06.html#차원-데이터-큐브",
    "title": "6  데이터 큐브",
    "section": "",
    "text": "그림 6.2: x, y, 밴드, 시간의 네 차원을 가진 4차원 래스터 데이터 큐브\n\n\n\n\n\n\n\n\n\n그림 6.3: 두 차원에 의거해 평면적으로 배열된 4차원 래스터 데이터",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "06.html#래스터-큐브를-벡터-큐브로-애그리게이션-하기",
    "href": "06.html#래스터-큐브를-벡터-큐브로-애그리게이션-하기",
    "title": "6  데이터 큐브",
    "section": "\n6.4 래스터 큐브를 벡터 큐브로 애그리게이션 하기",
    "text": "6.4 래스터 큐브를 벡터 큐브로 애그리게이션 하기\n그림 6.8은 4차원 래스터 데이터 큐브를 3차원 벡터 데이터 큐브로 애그리게이션 하는 과정을 보여준다. 래스터의 픽셀은 벡터 지오메트리와의 공간적 교차 양상에 의거해 그룹화되며, 각 그룹은 평균 또는 최대값과 같은 집계 함수를 통해 단일 값으로 축소된다. 예를 들어, 두 개의 공간적 차원 \\(x\\)와 \\(y\\)는 피처 지오메트리의 1차원적 시퀀스로 구성된 단일 차원으로 축소되는데, 피처 지오메트리는 \\(x\\)와 \\(y\\)의 좌표를 가진 공간 상에서 정의된다. POINT 지오메트리에 의거해 애그리게이팅을 실행할 수도 있으며, 이 경우 집계 함수는 필요하지 않다. POINT 위치에서의 속성값은 픽셀 값을 쿼리하거나 가장 가까운 픽셀에서 인터폴레이션함으로써 추출할 수 있다.\n\n\n\n\n\n그림 6.8: 래스터 데이터 큐브를 벡터 데이터 큐브로 애그리게이션 하기\n\n\n또 다른 벡터 데이터 큐브의 사례로 대기질 데이터를 들 수 있는데, 2차원의 \\(PM_{10}\\)를 다음에 의거해 획득할 수 있다.\n\n모니터링 스테이션\n시간 간격\n\n이와 유사하게, 인구 수로 구성된 시계열 인구 데이터나 환자 수로 구성된 시계열 역학 데이터의 예를 들 수 있는데, 다음에 의거해 정의될 수 있다.\n\n지역: \\(n\\)개의 지역\n연령 그룹: \\(m\\)개의 연령 그룹\n연도: \\(p\\)개의 연도\n\n이는 \\(nmp\\)로 구성된 어레이를 형성한다.\n공간데이터사이언스에서 벡터 및 래스터 데이터 큐브를 다루는 것은 매우 유용하다. 우선 많은 변수가 공간적으로 그리고 시간적으로 변동하기 때문이다. 또한 차원의 변경 및 애그리게이션과 같은 과업을 완전히 유연한 방식하고도 질서있는 방식으로 수행할 수 있게 도와주기 때문이다. 차원을 변경하는 예는 다음과 같다.\n\n대기질의 측정값을 규칙 그리드(래스터) 상에 인터폴레이션하는 것(12장)\n포인트나 라인으로부터 밀도 값을 추정하는 것, 예를 들어 주 1회 비행기 통과 수를 1km 탐색반경을 기준으로 추정하는 것(11장)\n기후 모델의 예측값을 행정구역별로 요약 지표로 애그리게이션하는 것\nMODIS(250m 픽셀, 16일 주기)와 Sentinel-2(10m 픽셀, 5일 주기)와 같은 서로 다른 센서의 지구 관측 데이터를 결합하는 것\n\n하나 이상의 차원을 완전히 애그리게이션하는 사례에는 다음과 같은 것이 있다.\n\n어떤 대기 질 모니터링 스테이션이 나쁨 수준을 보이는지(시간)\n어떤 지역이 질병 발생률에서 가장 높은 증가를 보이는지(공간, 시간)\n지구 온난화(10년 당 지구 전체의 섭씨 온도 변화)",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 큐브</span>"
    ]
  },
  {
    "objectID": "07.html#sec-sf",
    "href": "07.html#sec-sf",
    "title": "7  sf와 stars",
    "section": "",
    "text": "(활성화된) 지오메트리 열의 이름: sf_column 속성에 저장되어 있음.\n각 비기하 변수의 속성-지오메트리 관계 (5.1절 참조): agr 속성에 저장되어 있음.\n\n\n\n좌표참조계: crs 속성에 저장되어 있음.\n바운딩 박스: bbox 속성에 저장되어 있음.\n정밀도: precision 속성에 저장되어 있음.\n지오메트리 수: n_empty 속성에 저장되어 있음.\n\n\n\n7.1.1 생성\n다음과 같은 방식으로 sf 객체를 생성할 수 있다.\n\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\np1 &lt;- st_point(c(7.35, 52.42))\np2 &lt;- st_point(c(7.22, 52.18))\np3 &lt;- st_point(c(7.44, 52.19))\nsfc &lt;- st_sfc(list(p1, p2, p3), crs = 'OGC:CRS84')\nst_sf(elev = c(33.2, 52.1, 81.2), \n      marker = c(\"Id01\", \"Id02\", \"Id03\"), geom = sfc)\n# Simple feature collection with 3 features and 2 fields\n# Geometry type: POINT\n# Dimension:     XY\n# Bounding box:  xmin: 7.22 ymin: 52.2 xmax: 7.44 ymax: 52.4\n# Geodetic CRS:  WGS 84\n#   elev marker              geom\n# 1 33.2   Id01 POINT (7.35 52.4)\n# 2 52.1   Id02 POINT (7.22 52.2)\n# 3 81.2   Id03 POINT (7.44 52.2)\n\n\n\n\n\n\n그림 7.1: sf 객체의 구조\n\n\n그림 7.1은 출력된 구성 요소에 대한 설명을 제공한다. 객체를 처음부터 생성하는 대신, R에서의 공간데이터는 보통 외부 소스에서 읽어오며, 그 외부 소스에는 다음과 같은 것이 있다.\n\n외부 파일\n데이터베이스 내의 테이블(또는 테이블 집합)\n웹서비스에서 호출을 통해 획득된 데이터셋\nR 패키지에 포함되어 있는 데이터셋\n\n7.1.2 읽기와 쓰기\n외부 “데이터 소스”(파일, 웹서비스 또는 문자열)로부터 데이터셋을 읽어오는 것은 st_read() 함수를 사용하여 수행된다.\n\nlibrary(sf)\n(file &lt;- system.file(\"gpkg/nc.gpkg\", package = \"sf\"))\n# [1] \"/home/edzer/R/x86_64-pc-linux-gnu-library/4.3/sf/gpkg/nc.gpkg\"\nnc &lt;- st_read(file)\n# Reading layer `nc.gpkg' from data source \n#   `/home/edzer/R/x86_64-pc-linux-gnu-library/4.3/sf/gpkg/nc.gpkg' \n#   using driver `GPKG'\n# Simple feature collection with 100 features and 14 fields\n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6\n# Geodetic CRS:  NAD27\n\n여기서 파일 이름과 경로는 sf 패키지에서 읽어오는 것인데, sf 패키지를 설치하는 과정에서 설정된 것이므로 어떤 컴퓨터에서건 예외없이 읽어들여진다.\nst_read() 명령어는 두 개의 아규먼트(데이터 소스 이름(dsn)과 레이어(layer))를 가진다. 위의 예에서 geopackage(GPKG) 파일은 단일 레이어만 포함하고 있으며, 해당 레이어가 불러들여진 것이다. 만약 여러 레이어가 포함되어 있었다면, 첫 번째 레이어가 읽히고 경고 메시지가 표출되었을 것이다. 데이터셋의 사용 가능한 레이어는 다음과 같이 조회할 수 있다.\n\nst_layers(file)\n# Driver: GPKG \n# Available layers:\n#   layer_name geometry_type features fields crs_name\n# 1    nc.gpkg Multi Polygon      100     14    NAD27\n\n심플 피처 객체는 st_write 함수를 사용하여 저장할수 있다.\n\n(file = tempfile(fileext = \".gpkg\"))\n# [1] \"/tmp/Rtmpm9lGRF/file361e653fae4a9.gpkg\"\nst_write(nc, file, layer = \"layer_nc\")\n# Writing layer `layer_nc' to data source \n#   `/tmp/Rtmpm9lGRF/file361e653fae4a9.gpkg' using driver `GPKG'\n# Writing 100 features with 14 fields and geometry type Multi Polygon.\n\n여기서 파일 형식(GPKG)은 파일 이름 익스텐션에서 파생된다. st_write() 함수의 append 아규먼트 설정을 통해 기존 레이어에 레코드를 추가하거나 아예 레이어를 교체할 수 있는데, append 아규먼트 설정되지 않으면 레이어가 이미 존재할 경우 오류가 발생한다. 타이디버스 스타일의 write_sf() 함수는 append가 설정되지 않은 경우 오류 표출 없이 레이어를 교체한다. 또한, st_delete() 함수를 사용하여 레이어를 삭제할 수 있으며, 이는 특히 데이터베이스의 테이블과 연결되어 있는 레이어를 다룰 때 편리하다.\nWKT-2 좌표참조계를 지원하는 파일 형식의 경우, st_read()와 st_write()는 이를 읽고 쓸 수 있다. 그러나 csv와 같은 간단한 포맷에서는 이 기능이 작동하지 않는다. 또한, 셰이프파일(shapefile) 형식은 CRS에 대해 매우 제한된 인코딩만 지원한다.\n\n7.1.3 부분을 골라내기\n매우 일반적인 작업 중 하나는 객체의 일부분을 골라내기(subset)하는 것이며, 베이스 R에서는 이를 위해 대괄호 기호([) 를 사용한다. data.frame 객체에 적용되는 규칙을 sf 객체에 그대로 적용할 수 있다. 예를 들어, 다음과 같은 코드를 통해 레코드 2에서 5와 열 3에서 7을 선택할 수 있다.\n\nnc[2:5, 3:7]\n\n여기에 몇몇 옵션을 부가적으로 적용할 수 있다.\n\ndrop 아규먼트가 디폴트로 FALSE로 설정되어 있는데, 지오메트리 열이 항상 선택되며 sf 객체가 반환된다. TRUE로 설정되면, 지오메트리열이 선택되지 않으면 해당 열이 제거된 data.frame이 반환된다.\n공간(sf, sfc 또는 sfg) 객체를 첫 번째 아규먼트로 사용한 선택은 해당 객체와 공간적으로 교차하는 피처를 선택하는 결과를 가져온다(다음 절 참조). 다른 프레디케이트를 선택하고자 할 경우, op 아규먼트를 설정하여 st_covers와 같은 함수 또는 3.2.2절에 나열된 다른 이항 프레디케이트 함수로 지정할 수 있다.\n\n7.1.4 바이너리 프레디케이트\nst_intersects, st_covers와 같은 이항 프레디케이트 함수(3.2.2절 참조)는 두 개의 피처 집합 또는 피처 지오메트리를 입력받아 모든 쌍에 대해 조건이 TRUE인지 FALSE인지를 반환한다. 대규모 집합의 경우, 이는 일반적으로 대부분 FALSE 값으로 채워진 거대한 행렬을 생성할 수 있으며, 이러한 이유로 기본적으로 희소 표현(sparse representation)이 반환된다(역자주: 희소 표현은 메모리 사용을 최적화하고, 데이터 처리를 더욱 효율적으로 만들어 준다. 희소 표현을 일반적으로 TRUE 값만을 저장하고, FALSE 값은 저장하지 않는다.)\n\nnc5 &lt;- nc[1:5, ]\nnc7 &lt;- nc[1:7, ]\n(i &lt;- st_intersects(nc5, nc7))\n# Sparse geometry binary predicate list of length 5, where the\n# predicate was `intersects'\n#  1: 1, 2\n#  2: 1, 2, 3\n#  3: 2, 3\n#  4: 4, 7\n#  5: 5, 6\n\n\n\n\n\n\n그림 7.2: 노스케롤라이나의 첫 7개의 카운티\n\n\n그림 7.2는 첫 다섯 개 카운티와 첫 일곱 개 카운티의 교차를 이해하는 방법을 보여준다. 다음과 같은 방식으로 희소 논리 행렬을 조밀한 행렬(dense matrix)로 변환할 수 있다.\n\nas.matrix(i)\n#       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]\n# [1,]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n# [2,]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n# [3,] FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE\n# [4,] FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE\n# [5,] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n\nnc5의 개별 카운티가 교차하는 nc7 카운티의 수는 다음과 같이 계산할 수 있다.\n\nlengths(i)\n# [1] 2 3 2 2 2\n\n역으로 nc7의 개별 카운티가 교차하는 nc5의 카운티의 수는 다음과 같이 계산할 수 있다.\n\nlengths(t(i))\n# [1] 2 3 2 1 1 1 1\n\n객체 i 가 sgbp(sparse geometrical binary predicate) 클래스의 한 객체라고 했을 때, 객체 i는 정수 벡터의 리스트로 주어지는데, 리스트의 각 요소는 논리 프레디케이트 행렬의 한 행을 나타내고, 논리 프레디케이트 행렬은 해당 행에 대해 TRUE 값을 갖는 열의 인덱스를 보유하고 있다. 이 객체는 사용된 프레디케이트 및 총 열 수와 같은 메타데이터도 포함하고 있다. sgbp 객체에 적용할 수 있는 메소드에 다음과 같은 것들이 있다.\n\nmethods(class = \"sgbp\")\n#  [1] as.data.frame as.matrix     coerce        dim          \n#  [5] initialize    Ops           print         show         \n#  [9] slotsFromS3   t            \n# see '?methods' for accessing help and source code\n\nsgbp 클래스의 객체에서 사용 가능한 유일한 Ops 메서드는 !(부정 연산자)이다.\n\n7.1.5 타이디버스\ntidyverse 패키지는 다양한 데이터사이언스 패키지를 함께 로드한다(Wickham and Grolemund 2017; Wickham et al. 2019). sf 패키지는 tidyverse 스타일의 읽기 및 쓰기 함수인 read_sf()와 write_sf()를 제공하며, 이 함수들은 다음과 같은 특징이 있다.\n\ndata.frame 대신 tibble을 반환한다.\n출력 내용을 인쇄하지 않는다.\n기본적으로 기본 데이터를 덮어쓴다.\n\nsf 객체에 사용될 수 있는 tidyverse 로 filter, select, group_by, ungroup, mutate, transmute, rowwise, rename, slice, summarise, distinct, gather, pivot_longer, spread, nest, unnest, unite, separate, separate_rows, sample_n, 및 sample_frac등과 같은 것이 있다. 대부분의 함수는 sf 객체의 메타데이터를 관리하기만 할 뿐 지오메트리 정보를 건드리지 않는다. 사용자가 지오메트리를 제거하고자 할 경우, st_drop_geometry를 사용하거나 선택하기 전에 간단히 tibble 또는 data.frame으로 강제 변환(coerce)할 수 있다.\n\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nnc |&gt; as_tibble() |&gt; select(BIR74) |&gt; head(3)\n# # A tibble: 3 × 1\n#   BIR74\n#   &lt;dbl&gt;\n# 1  1091\n# 2   487\n# 3  3188\n\nsf 객체에 대한 summarise 함수는 두 가지 특별한 아규먼트를 가지고 있다\n\ndo_union (기본값: TRUE): 그룹화된 지오메트리가 반환 시 유니언(합집합)되는지 여부를 결정하여, 유효한 지오메트리가 형성하도록 한다.\nis_coverage (기본값: FALSE): 그룹화된 지오메트리가 커버리지(겹침이 없는 경우)를 형성하는 경우, 이를 TRUE로 설정하면 유니언 과정이 빨라진다.\n\ndistinct 함수는 고유한 레코드를 선택하며, st_equals 함수는 지오메트리의 고유성을 평가한다.\nfilter 함수는 일반적인 프레디케이트와 함께 사용할 수 있으며, 공간적 프레디케이트를 사용하고자 할 경우, 예를 들어 오렌지 카운티에서 50km 이내에 있는 모든 카운티를 선택하려면 다음과 같이 사용할 수 있다.\n\norange &lt;- nc |&gt; dplyr::filter(NAME == \"Orange\")\nwd &lt;- st_is_within_distance(nc, orange, \n                            units::set_units(50, km))\no50 &lt;- nc |&gt; dplyr::filter(lengths(wd) &gt; 0)\nnrow(o50)\n# [1] 17\n\n(여기서 dplyr::filter를 사용하는 것은 베이스 R의 filter 함수와의 혼동을 피하기 위함이다.)\n그림 7.3은 이 분석의 결과를 보여주며, 카운티 경계 주위에 버퍼도 추가되어 있다. 이 버퍼는 설명을 위한 것이며, 카운티를 선택하는 데 사용되지는 않았음을 주의하라.\n\n\n\n\n\n그림 7.3: 오렌지 카운티(오렌지색), 반경 50km 내의 카운티(검은색), 오랜지 카운티 주변의 버퍼(갈색), 나머지 카운티(회색)",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#공간적-조인",
    "href": "07.html#공간적-조인",
    "title": "7  sf와 stars",
    "section": "\n7.2 공간적 조인",
    "text": "7.2 공간적 조인\n일반적인 조인(왼쪽, 오른쪽 또는 내부 조인)에서는 두 테이블 사이에서 하나 이상의 속성이 일치할 때 조인이 이루어진다. 공간적 조인도 이와 유사하지만, 레코드를 조인하는 기준은 속성의 일치가 아니라 공간적 프레디케이트이다. 이로 인해 공간적으로 일치하는 레코드를 정의하는 다양한 선택지가 있으며, 이는 3.2.2절에 나열된 바이너리 프레디케이트를 사용하여 결정할 수 있다. “왼쪽,” “오른쪽,” “내부,” 또는 “전체” 조인의 개념은 비공간 조인과 동일하게 유지되는데, 이 경우는 공간적 일치를 상정하지 않은 상태에서 레코드의 조인을 처리할 때이다.\n공간적 조인을 실행할 때, 각 레코드에 여러 일치하는 레코드가 있을 수 있어 결과 테이블이 매우 커질 수 있다. 이 복잡성을 줄이는 방법으로, 일치하는 레코드 중에서 타깃 지오메트리와 가장 넓은 면적이 겹치는 레코드 하나를 선택하는 방식이 있다. 이 방법의 시각적 예시는 그림 7.4에 나타나 있으며, st_join 함수에서 largest = TRUE 아규먼트를 사용하여 이를 수행할 수 있다.\n\n\n\n\n\n그림 7.4: largest = TRUE 아규먼트를 적용한 st_join 함수의 예: 아래쪽 그림의 폴리곤과 가장 넓은 면적이 겹치는 위쪽 그림의 폴리곤 라벨이 아래쪽 폴리곤에 할당되어 있다.\n\n\n결과의 복잡성을 줄이는 또 다른 방법은 조인 후에 aggregate 함수를 사용하여 모든 일치하는 레코드를 결합함과 동시에 지오메트리도 병합하는 것이다. 이에 대한 자세한 내용은 5.4절을 참고하라.\n\n7.2.1 샘플링, 그리딩, 인터폴레이팅\nsf 패키지가 제공하는 유용한 함수 몇 가지를 소개하고자 한다. st_sample 함수는 타깃 지오메트리로부터 임의의 샘플링 포인트를 생성해 주는데, 타깃 지오메트리는 점, 선, 또는 폴리곤 등 다양할 수 있다. 샘플링 방식으로 완전 무작위 방식, 규칙적 방식, 또는 폴리곤의 경우 삼각형 방식이 선택될 수 있다. 11장에서 spatstat 패키지에서 제공하는 공간적 샘플링(또는 포인트 패턴 시뮬레이션) 방법들이 어떻게 st_sample 함수를 통해 이루어지는지 설명한다.\nst_make_grid 함수는 특정 영역 위에 정사각형, 직사각형, 또는 육각형의 그리드를 생성해준다. 옵션을 다르게 적용하면 그리드 자체가 아니라 그리드의 중심점 혹은 구석점을 생성해준다. 이 함수는 그림 7.4에서 직사각형 그리드를 생성하는 데 사용되었다.\n함수 st_interpolate_aw는 5.3절에서 설명된 대로 공간적으로 내포적인 변수와 공간적으로 외연적인 변수를 새로운 영역으로 “인터폴레이션”하는 기능을 제공한다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#타원좌표",
    "href": "07.html#타원좌표",
    "title": "7  sf와 stars",
    "section": "\n7.3 타원좌표",
    "text": "7.3 타원좌표",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#패키지-stars",
    "href": "07.html#패키지-stars",
    "title": "7  sf와 stars",
    "section": "7.4 패키지 stars",
    "text": "7.4 패키지 stars\n\n7.4.1 래스터 데이터의 불러오기와 쓰기\n\n\n7.4.2 stars 데이터 큐브 일부분 골라내기\n\n\n7.4.3 잘라내기\n\n\n7.4.4 stars 객체를 차원 다시 부여하기와 결합하기\n\n\n7.4.5 포인트 샘플 추출하기, 애그리게이팅하기\n\n\n7.4.6 예측 모델\n\n\n7.4.7 래스터 데이터 플로팅\n\n\n7.4.8 래스터 데이터 분석하기\n\n\n7.4.9 곡선 래스터\n\n\n7.4.10 GOAL utils",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#벡터-데이터-큐브-사례",
    "href": "07.html#벡터-데이터-큐브-사례",
    "title": "7  sf와 stars",
    "section": "\n7.5 벡터 데이터 큐브 사례",
    "text": "7.5 벡터 데이터 큐브 사례\n\n7.5.1 사례: 대기질 시계열 데이터에 대한 애그리게이션 실행\n유럽 대기질 데이터를 사례로 벡터 데이터 큐브에 대한 애그리게이션 작업을 설명한다. 동일한 데이터가 Gräler, Pebesma, Heuvelink (2016)에서 사용되었으며, 12장과 13장에서도 사용될 예정이다. 독일의 농촌 지역 관측소의 1998~2009년 데이터로부터 일평균 \\(\\text{PM}_{10}\\) 값을 계산하였다.\nair 데이터 매트릭스, 날짜 벡터인 dates, 그리고 SpatialPoints 객체인 stations을 결합해 stars 객체를 생성할 수 있다.\n\nload(\"data/air.rda\") # this loads several datasets in .GlobalEnv\ndim(air)\n# space  time \n#    70  4383\nstations |&gt;\n    st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |&gt;\n    st_geometry() -&gt; st\nd &lt;- st_dimensions(station = st, time = dates)\n(aq &lt;- st_as_stars(list(PM10 = air), dimensions = d))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's\n# PM10     0    9.92   14.8 17.7      22  274 157659\n# dimension(s):\n#         from   to     offset  delta refsys point\n# station    1   70         NA     NA WGS 84  TRUE\n# time       1 4383 1998-01-01 1 days   Date FALSE\n#                                          values\n# station POINT (9.59 53.7),...,POINT (9.45 49.2)\n# time                                       NULL\n\n그림 7.11에서 시간 시계열이 상당히 길지만, 큰 결측값 간격도 있다는 것을 알 수 있다. 그림 7.12는 평균 \\(\\text{PM}_{10}\\) 값과 함께 측정소의 공간 분포를 보여준다.\n\n\n\n\n\n그림 7.11: 시간과 스테이션별로 계산된 PM10 값에 대한 시공간 다이어그램\n\n\n\n\n\n\n\n그림 7.12: 관측 스테이션별 PM10 평균값\n\n\n간단한 실습 차원에서, 측정 스테이션별 시간 시계열 데이터를 지역 평균으로 집계할 수 있다. 이를 위해 stars 객체에 대한 aggregate 메소드를 사용한다.\n\n(a &lt;- aggregate(aq, de_nuts1, mean, na.rm = TRUE))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\n# PM10  1.08    10.9   15.3 17.9    21.8  172 25679\n# dimension(s):\n#      from   to     offset  delta refsys point\n# geom    1   16         NA     NA WGS 84 FALSE\n# time    1 4383 1998-01-01 1 days   Date FALSE\n#                                       values\n# geom MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# time                                    NULL\n\n그리고, 아래의 코드를 통해 임의로 선택한 여섯 개의 날짜에 대한 지도를 보여줄 수 있다(그림 7.13).\n\nlibrary(tidyverse)\na |&gt; filter(time &gt;= \"2008-01-01\", time &lt; \"2008-01-07\") |&gt; \n    plot(key.pos = 4)\n\n\n\n\n\n\n그림 7.13: 임의의 6일에 대한 지역 평균 PM10\n\n\n또한 다음의 코드를 이용해 단일 주에 대한 평균 값의 시계열 플롯을 생성할 수 있다(그림 7.14).\n\nlibrary(xts) |&gt; suppressPackageStartupMessages()\nplot(as.xts(a)[,4], main = de_nuts1$NAME_1[4])\n\n\n\n\n\n\n그림 7.14: 단일 스테이션에 대한 지역 평균 PM10의 시계열\n\n\n\n7.5.2 사례: 브리스톨 출발지-도착지 데이터 큐브\n\n7.5.3 타이디 어레이 데이터\n\n7.5.4 벡터 데이터 큐브를 위한 파일 포멧",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#래스터-투-벡터와-벡터-토-래스터",
    "href": "07.html#래스터-투-벡터와-벡터-토-래스터",
    "title": "7  sf와 stars",
    "section": "7.6 래스터-투-벡터와 벡터-토-래스터",
    "text": "7.6 래스터-투-벡터와 벡터-토-래스터\n\n7.6.1 벡터-투-래스터",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#좌표변환-및-좌표전환",
    "href": "07.html#좌표변환-및-좌표전환",
    "title": "7  sf와 stars",
    "section": "\n7.7 좌표변환 및 좌표전환",
    "text": "7.7 좌표변환 및 좌표전환\n\n7.7.1 st_crs 함수\nsf 또는 stars 클래스의 공간 객체는 CRS(좌표참조계)를 포함하고 있다. st_crs 함수를 사용하여 해당 객체의 CRS를 확인하거나 다른 CRS로 교체할 수 있다. 또한, st_set_crs함수를 사용하여 CRS를 설정하거나 교체할 수 있다. CRS는 EPSG 코드로 설정할 수 있으며, 예를 들어 st_crs(4326)는 st_crs('EPSG:4326')로 변환된다. 또는 “+proj=utm +zone=25 +south”와 같은 PROJ.4 문자열, “WGS84”와 같은 이름, 또는 “OGC”와 같이 기관명이 앞에 붙은 이름으로 설정할 수 있다. 대안으로는 WKT, WKT-2(섹션 2.5) 또는 PROJJSON 형식의 CRS 정의가 있다. st_crs 함수에 의해 반환된 객체는 다음의 두 개의 필드를 포함한다.\n\nwkt: WKT-2 형식으로 표현된 CRS\ninput: 사용자 입력(있는 경우), 또는 CRS에 대한 인간가독설명(가능한 경우)\n\nPROJ.4 문자열은 일부 CRS을 정의하는 데 사용할 수 있지만, CRS를 대표하는 데는 사용할 수 없다. 예를 들어, crs 객체의 WKT-2를 $proj4string 메서드를 사용하여 proj4string으로 전환하려면 다음과 같이 할 수 있다.\n\nx &lt;- st_crs(\"OGC:CRS84\")\nx$proj4string\n# [1] \"+proj=longlat +datum=WGS84 +no_defs\"\n\n그런데, 이 과정이 성공적으로 이루어졌다 하더라도, 보통 정보의 손실이 수반되고 가역적으로 전환되지 않는다. PROJ.4 문자열을 CRS를 정의하기 위해 사용하는 경우(예를 들어 파라미터가 지정되어 있는 투영 CRS), 투영 CRS가 WGS84 데이텀과 관련되는 한은 문제가 없다.\n\n7.7.2 st_transform함수와 st_project 함수\nsf 또는 stars 객체에 대한 좌표 변환이나 좌표 전환은 st_transform함수를 사용하여 수행된다. 이 함수의 첫 번째 아규먼트는 CRS가 설정된 sf 또는 stars 클래스의 공간 객체이고, 두 번째 아규먼트는 crs 객체(또는 st_crs 함수로 변환 가능한 값)이다. 소스 crs에서 타깃 crs로 변환 혹은 전환할 수 있는 방법이 여러 가지인 경우, PROJ는 가장 높은 명시(declared) 정확도를 가진 방법을 선택한다. 더 세밀한 옵션은 7.7.5에서 설명된다. 규칙 래스터 디멘션을 가진 stars 객체의 경우, st_transform 함수는 좌표만 변환하며 항상 곡선형 그리드를 생성한다. 새로운 CRS에서 규칙 래스터를 생성하려면 재그리딩(regridding)을 사용하는 st_warp 함수를 활용하면 된다(Section 7.8).\nsf나 stars 객체가 아닌 상황에서의 좌표 변환 혹은 좌표 전환은 저수준(lower-level) 함수인 sf_project를 통해 이루어진다. 이 함수는 좌표가 담긴 행렬과 소스 및 타깃 CRS(crs)를 입력으로 받아, 변환된 혹은 전환된 좌표를 반환한다.\n\n7.7.3 sf_proj_info 함수\nsf_proj_info 함수는 PROJ 소프트웨어에서 사용 가능한 투영, 타원체, 단위 및 본초 자오선에 대한 정보를 조회하는 데 사용된다. 이 함수는 단일 매개변수 type을 받으며, 이 매개변수는 다음과 같은 값을 가질 수 있다.\n\ntype = \"proj\": 사용 가능한 투영법의 짧은 이름과 긴 이름을 나열한다. 짧은 이름은 “+proj=name” 문자열에서 사용할 수 있다.\ntype = \"ellps\": 사용 가능한 타원체를 나열하며, 이름, 긴 이름 및 타원체의 파라미터 정보를 포함한다.\ntype = \"units\": 사용 가능한 길이 단위를 나열하고, 미터로의 변환 상수 정보를 포함한다.\ntype = \"prime_meridians\": 본초 자오선을 나열하고, 그리니치 자오선과의 상대적 위치 정보를 포함한다.\n\n7.7.4 데이텀 그리드, proj.db, cdn.proj.org. 로컬 캐쉬\n데이텀 그리드(2.4절)는 로컬에 설치하거나 PROJ 측량 그리드 CDN(https://cdn.proj.org/)에서 불러 올 수 있다. 로컬에 설치된 경우, 데이텀 그리드는 PROJ 검색 경로를 통해 불러올 수 있는데, 이 경로는 다음과 같이 표시된다.\n\nsf_proj_search_paths()\n# [1] \"/home/edzer/.local/share/proj\" \"/usr/share/proj\"\n\n핵심 PROJ 데이터베이스는 proj.db로, 일반적으로 다음 위치에서 불러올 수 있는 sqlite3 데이터베이스이다.\n\npaste0(tail(sf_proj_search_paths(), 1), .Platform$file.sep, \n       \"proj.db\")\n# [1] \"/usr/share/proj/proj.db\"\n\n각 PROJ 릴리스에 포함된 EPSG 데이터베이스 스냅샷의 버전은 proj.db의 \"metadata\" 테이블에 명시되어 있으며, sf에서 사용되는 PROJ 런타임의 버전은 다음과 같이 표시된다.\n\nsf_extSoftVersion()[\"PROJ\"]\n#    PROJ \n# \"9.1.1\"\n\n특정 좌표 변환에 필요한 데이텀 그리드가 로컬에 없을 경우, PROJ는 PROJ CDN의 온라인 데이텀 그리드를 검색하게 된다. 단 아래의 결과가 TRUE인 경우이다.\n\nsf_proj_network()\n# [1] FALSE\n\n디폴트는 FALSE로 설정되어 있지만, 이를 TRUE로 바꾸면 해당 네트워크 리소스의 URL을 반환한다. 이 리소스는 더 빠르거나 제한이 덜한 다른 리소스로 설정할 수도 있다.\n\nsf_proj_network(TRUE)\n# [1] \"https://cdn.proj.org\"\n\nCDN에서 데이텀 그리드를 조회한 후, PROJ는 조회된 그리드의 일부분(디폴트는 전체 그리드가 아님)을 로컬 캐시에 기록한다. 이 캐시는 사용자 디렉토리의 또 다른 sqlite3 데이터베이스로 다음과 같이 표시된다.\n\nlist.files(sf_proj_search_paths()[1], full.names = TRUE)\n# [1] \"/home/edzer/.local/share/proj/cache.db\"\n\n차후의 데이텀 그리드 조회는 이 데이터베이스에 대해 우선적으로 이루어진다.\n\n7.7.5 변환 파이프라인\n내부적으로 PROJ는 소스 CRS에서 타겟 CRS로 가는 오퍼레이션 시퀀스를 나타내기 위해 이른바 좌표 오퍼레이션 파이프라인(coordinate operation pipeline)을 사용한다. 소스에서 타겟으로 가는 여러 옵션이 있을 경우, st_transform 함수는 가장 높은 정확도를 가진 옵션을 선택한다. 사용 가능한 옵션을 조회하려면 sf_proj_pipelines 함수를 사용하면 된다.\n\n(p &lt;- sf_proj_pipelines(\"OGC:CRS84\", \"EPSG:22525\"))\n# Candidate coordinate operations found:  5 \n# Strict containment:     FALSE \n# Axis order auth compl:  FALSE \n# Source:  OGC:CRS84 \n# Target:  EPSG:22525 \n# Best instantiable operation has accuracy: 2 m\n# Description: axis order change (2D) + Inverse of Corrego Alegre\n#              1970-72 to WGS 84 (2) + UTM zone 25S\n# Definition:  +proj=pipeline +step +proj=unitconvert +xy_in=deg\n#              +xy_out=rad +step +inv +proj=hgridshift\n#              +grids=br_ibge_CA7072_003.tif +step\n#              +proj=utm +zone=25 +south +ellps=intl\n\n해당 변환에서 가장 높은 정확도를 보이는 파이프라인이 요약되어 있고 특정한 데이텀 그리드의 사용이 지정되어 있음을 알 수 있다. 만약 네트워크 검색을 활성화하지 않았다면, 다른 결과를 얻었을 것이다.\n\nsf_proj_network(FALSE)\n# character(0)\nsf_proj_pipelines(\"OGC:CRS84\", \"EPSG:22525\")\n# Candidate coordinate operations found:  5 \n# Strict containment:     FALSE \n# Axis order auth compl:  FALSE \n# Source:  OGC:CRS84 \n# Target:  EPSG:22525 \n# Best instantiable operation has accuracy: 2 m\n# Description: axis order change (2D) + Inverse of Corrego Alegre\n#              1970-72 to WGS 84 (2) + UTM zone 25S\n# Definition:  +\n\n이 경우에는 데이텀 그리드에 대한 사항이 누락되어 있음을 볼 수 있다. sf_proj_pipelines이 반환하는 객체는 서브클래스화된 데이터 프레임으로, 다음과 같은 열을 포함한다.\n\nnames(p)\n# [1] \"id\"           \"description\"  \"definition\"   \"has_inverse\" \n# [5] \"accuracy\"     \"axis_order\"   \"grid_count\"   \"instantiable\"\n# [9] \"containment\"\n\n예를 들어 다음과 같이 정확도를 나열할 수 있다.\n\np |&gt; pull(accuracy)\n# [1]  2  5  5  8 NA\n\n여기서 NA는 “대략적인 정확도”를 의미하며, 이는 30~120m 범위 내의 한 값을 가진다.\n\np |&gt; filter(is.na(accuracy))\n# Candidate coordinate operations found:  1 \n# Strict containment:     FALSE \n# Axis order auth compl:  FALSE \n# Source:  OGC:CRS84 \n# Target:  EPSG:22525 \n# Best instantiable operation has only ballpark accuracy \n# Description: Ballpark geographic offset from WGS 84 (CRS84) to\n#              Corrego Alegre 1970-72 + UTM zone 25S\n# Definition:  +proj=pipeline +step +proj=unitconvert +xy_in=deg\n#              +xy_out=rad +step +proj=utm +zone=25\n#              +south +ellps=intl\n\nst_transform 함수가 선택한 가장 정확한 파이프라인이 디폴트이지만, pipeline 아규먼트를 지정하면 결과를 바꿀 수도 있다. 이 경우 p$definition에 있는 옵션 중 하나를 선택하면 된다.\n\n7.7.6 축 순서와 방향\n2.5절에서 언급한 것처럼, EPSG:4326은 첫 번째 축이 위도와 관련되고 두 번째 축이 경도와 관련되도록 정의한다. 이것은 수많은 다른 타원체 CRS에서도 마찬가지이다. 이러한 방식은 해당 기관(EPSG)이 규정한 것이지만, 현재 대부분의 데이터셋은 이러한 방식으로 저장되지 않는다. 대부분의 다른 소프트웨어와 마찬가지로, sf 패키지는 이를 무시하고 디폴트로 타원체 좌표 쌍을 (경도, 위도)로 해석한다. 하지만 해당 기관의 규정을 준수하는 데이터 원천(예를 들어 WFS 서비스)이 생산한 데이터를 읽어야 할 경우 다음과 같이 지정할 수 있다.\n\nst_axis_order(TRUE)\n\n이렇게 하면 sf가 GDAL과 PROJ 루틴을 호출할 때 규정 준수(위도, 경도 순서)가 항상 전제되게 할 수 있다. 이러한 규정 준수에 많은 문제가 발생할 수 있다고 예상되며, 예를 들어 데이터를 플로팅할 때 문제가 드러난다. sf 객체를 위한 플롯 메소드는 축 순서 규정을 준수하며 플로팅 전에 변환 파이프라인 \"+proj=pipeline +step +proj=axisswap +order=2,1\"을 사용하여 위경도의 순서를 바꾸지만, ggplot2 패키지의 geom_sf는 이러한 수정 과정을 거치지 않는다. 앞서 언급한 바와 같이, EPSG:4326에서 발견되는 축 순서 상의 모호성은 OGC:CRS84로 교체하면 모두 해결된다.\n축의 순서와는 다른 문제로, 모든 CRS가 북쪽과 동쪽 방향을 양의 값으로 지정하지는 않는다는 점 또한 매우 중요하다. R의 대부분의 플로팅 함수는 위와는 반대로 정의된 축을 가진 데이터와는 제대로 작동하지 않는다. 축의 방향과 단위에 대한 정보는 다음과 같이 검색할 수 있다.\n\nst_crs(4326)$axes\n#                 name orientation\n# 1  Geodetic latitude           1\n# 2 Geodetic longitude           3\nst_crs(4326)$ud_unit\n# 1 [°]\nst_crs(\"EPSG:2053\")$axes\n#       name orientation\n# 1  Westing           4\n# 2 Southing           2\nst_crs(\"EPSG:2053\")$ud_unit\n# 1 [m]",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#래스터-변환-및-워프",
    "href": "07.html#래스터-변환-및-워프",
    "title": "7  sf와 stars",
    "section": "\n7.8 래스터 변환 및 워프",
    "text": "7.8 래스터 변환 및 워프\n래스터 데이터셋에 대해 st_transform 함수를 사용할 때는 다음과 같이 할 수 있다.\n\ntif &lt;- system.file(\"tif/L7_ETMs.tif\", package = \"stars\")\nread_stars(tif) |&gt;\n    st_transform('OGC:CRS84')\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     1      54     69 68.9      86  255\n# dimension(s):\n#      from  to refsys point                    values x/y\n# x       1 349 WGS 84 FALSE [349x352] -34.9,...,-34.8 [x]\n# y       1 352 WGS 84 FALSE [349x352] -8.04,...,-7.95 [y]\n# band    1   6     NA    NA                      NULL    \n# curvilinear grid\n\n이제 곡선형 그리드가 생성되는 것을 볼 수 있으며, 이는 새로운 CRS에 의거해 모든 그리드 셀의 좌표가 재계산되므로 더 이상 규칙 그리드로 존재할 수 없음을 의미한다. 이러한 데이터를 플로팅하면 속도가 극단적으로 느린데, 각 그리드 셀에 대해 작은 폴리곤이 우선적으로 계산되고 그 후에 플로팅되기 때문이다. 이것의 이점은 정보가 손실되지 않는다는 것으로 투영 이후에도 그리드 셀의 값은 동일하게 유지된다.\n규칙 그리드를 투입하여 새로운 CRS에서도 규칙 그리드를 산출하려면 워프(warp) 오퍼레이션을 적용해야 한다. 즉, 새로운 위치에 그리드를 재생성하고 새로운 그리드 셀에 값을 할당하는 특정한 규칙을 사용해야 한다. 이러한 규칙에 가장 가까운 값을 사용하거나 어떤 형태의 보간법을 사용하는 것이 포함될 수 있다. 이 오퍼레이션은 정보의 손실이 발생하며 불가역적이다.\n워프를 수행하는 가장 좋은 방법은 타깃 그리드를 stars 객체로 지정하는 것이다. 타깃 CRS만 지정할 경우, 문제에 전혀 적합하지 않은 기본 옵션이 선택될 수 있다. 타깃 CRS만 사용하는 예시 워크플로우는 다음과 같다.\n\nread_stars(tif) |&gt;\n    st_warp(crs = st_crs('OGC:CRS84')) |&gt;\n    st_dimensions()\n#      from  to offset     delta refsys x/y\n# x       1 350  -34.9  0.000259 WGS 84 [x]\n# y       1 352  -7.95 -0.000259 WGS 84 [y]\n# band    1   6     NA        NA     NA\n\n이는 상당한 근사 래스터를 생성하지만, 변환도 상대적으로 작다. 소스 래스터와 정확히 동일한 행과 열을 갖는 타깃 래스터를 먼저 생성하려는 워크플로우의 경우 다음과 같이 하면 된다.\n\nr &lt;- read_stars(tif)\ngrd &lt;- st_bbox(r) |&gt;\n        st_as_sfc() |&gt;\n        st_transform('OGC:CRS84') |&gt;\n        st_bbox() |&gt;\n        st_as_stars(nx = dim(r)[\"x\"], ny = dim(r)[\"y\"])\nst_warp(r, grd)\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\n# L7_ETMs.tif     1      54     69 68.9      86  255 6180\n# dimension(s):\n#      from  to offset     delta refsys x/y\n# x       1 349  -34.9   0.00026 WGS 84 [x]\n# y       1 352  -7.95 -0.000259 WGS 84 [y]\n# band    1   6     NA        NA     NA\n\n여기서 \\(x\\)와 \\(y\\)의 방향의 그리드 해상도가 조금 달라진 점을 확인할 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#연습문제",
    "href": "07.html#연습문제",
    "title": "7  sf와 stars",
    "section": "\n7.9 연습문제",
    "text": "7.9 연습문제\nR을 사용하여 다음 연습문제를 해결하시오.\n\nnc 카운티 중 LINESTRING(-84 35, -78 35)와 교차하는 카운티의 이름을 찾아보라. 이를 위해 [를 사용하고, 대안으로 st_join 함수를 사용하라.\nsf_use_s2(FALSE)를 설정한 후에 이 작업을 반복하고, 차이를 계산하라(힌트: setdiff를 사용). 차이가 나타나는 카운티는 색상 ’#88000088’로 채색하라.\n두 지점 사이의 직선과 대권을 하나의 플롯에 그려보라. 현재 사용 중인 투영법에서는 R은 직선을 항상 직선으로 그린다는 점을 명심하라. st_segmentize 함수를 사용하여 직선 상이나 타원 좌표의 대원(큰 원) 상에 포인트를 추가하라.\nNDVI(정규화 차이 식생 지수)는 (NIR-R)/(NIR+R)로 계산되며, 여기서 NIR은 근적외선 밴드, R은 빨간색 밴드이다. L7_ETMs.tif 파일을 객체 x에 읽고, split(x, \"band\")를 사용하여 밴드 차원을 속성으로 분리하라. 그런 다음 NIR(밴드 4)과 R(밴드 3) 속성을 직접 사용하는 표현식을 사용하여 이 객체에 NDVI 속성을 추가하라.\nL7_ETMs.tif 이미지에 대해 밴드 차원을 축소하여 NDVI를 계산하라. 이를 위해 st_apply 함수와 ndvi = function(x) { (x[4]-x[3])/(x[4]+x[3]) } 함수를 사용하라. 결과를 플로팅하고, 결과를 GeoTIFF 형식으로 저장하라.\nL7_ETMs.tif에서 읽은 stars 객체를 st_transform 함수를 사용하여 OGC:CRS84로 변환하라. 객체를 출력하라. 이것이 규칙 그리드인가? 첫 번째 밴드를 axes=TRUE 및 border=NA 아규먼트를 사용하여 플로팅하고, 왜 이렇게 시간이 오래 걸리는지 설명하라.\nL7_ETMs.tif 객체를 st_warp 함수를 사용하여 OGC:CRS84로 변환하고, 결과 객체를 axes=TRUE로 플로팅하라. 왜 st_transform 함수에 비해 플롯이 훨씬 더 빨리 생성되는지 설명하라.\n래스터 L7_ETMs의 벡터 재현을 사용하여 POINT(293716 9113692)를 중심으로 반지름 75m인 원형 영역과의 인터센션을 플로팅하고, 이 원의 면적-가중 평균 픽셀 값을 계산하라. 벡터 데이터를 사용하여 애그리게이트한 값과 래스터 데이터를 사용하여 애그리게이트한 값을 (디폴트인 exact=FALSE 및 exact=TRUE 사용) 비교하라. 차이점을 설명하라.\n\n\n\n\n그림 7.1: sf 객체의 구조\n그림 7.2: 노스케롤라이나의 첫 7개의 카운티\n그림 7.3: 오렌지 카운티(오렌지색), 반경 50km 내의 카운티(검은색), 오랜지 카운티 주변의 버퍼(갈색), 나머지 카운티(회색)\n그림 7.4: largest = TRUE 아규먼트를 적용한 st_join 함수의 예: 아래쪽 그림의 폴리곤과 가장 넓은 면적이 겹치는 위쪽 그림의 폴리곤 라벨이 아래쪽 폴리곤에 할당되어 있다.\n그림 7.5: 인터섹션의 결과는 측지선 혹은 대권호를 사용하느냐(왼쪽) 데카르트 좌표계를 사용하느냐에 따라 달라진다.\n그림 7.6: Landsat 7 (band 1) 이미지의 원형 중심부\n그림 7.7: 트레이닝 데이터로 사용되는 무작위 샘플 포인트: 빨간색은 해양부이고 노란색을 육지부이다.\n그림 7.8: 육지부/수부 구분을 위한 선형 판별 분류기로 그림 7.7의 트레이닝 데이터에 기반한 결과임.\n30m 해상도의 Landsat 6개 밴드를 90m로 다운샘플한 결과, 브라질의 올린다\n그림 7.9: 컬러 합성의 두 가지 예\n그림 7.10: 시간과 스테이션별로 계산된 PM10 값에 대한 시공간 다이어그램\n그림 7.11: 관측 스테이션별 PM10 평균값\n그림 7.12: 임의의 6일에 대한 지역 평균 PM10\n그림 7.13: 단일 스테이션에 대한 지역 평균 PM10의 시계열\n그림 7.14: 영국 브리스톨의 102개 구역 현황(33번 구역(E02003043)이 빨간색으로 표시되어 있음)\n그림 7.15: 33번 존에 대한 OD 데이터를 추출한 후 교통수단별로 지도화하였다.\n그림 7.16: 출발지별 총 통근(왼쪽) 또는 목적지별 총 통근(오른쪽)\n그림 7.17: 출발지별 총 통근 밀도(왼쪽) 또는 목적지별 총 통근 밀도(오른쪽)\n그림 7.18: st_as_stars 함수를 활용한 백터 지오메트리의 래스터화\n그림 7.19: 노스캐롤라이나 카운티 경계를 래스터로 전환하기",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#stars-패키지",
    "href": "07.html#stars-패키지",
    "title": "7  sf와 stars",
    "section": "\n7.4 stars 패키지",
    "text": "7.4 stars 패키지\nsp 패키지가 래스터 데이터에 대한 지원이라는 측면에서 정체되어 있는 동안, raster 패키지(Hijmans 2023a)가 지난 10여년 동안 래스터 분석을 위한 강력하고 유연하며 확장 가능한 패키지로서 지배적인 위치를 공고히 하였다. raster 패키지(및 그 후속인 terra 패키지(Hijmans 2023b))는 2D 규칙 래스터 또는 래스터 레이어 집합(“래스터 스택”)이라는 래스터 데이터 모델에 기반하고 있다. 이는 세상이 수많은 레이어로 구성되어 있고 개별 레이어는 특정한 주제를 반영하고 있다는 고전적인 정적 “GIS 뷰”와 일치한다. 그러나 오늘날의 많은 데이터는 동적이며, 시계열 래스터 또는 시계열 래스터 스택으로 제공된다. 기존의 래스터 스택은 이러한 동적 특성을 제대로 반영하지 못하며, 사용자늘 어떤 레이어가 무엇을 나타내는지를 기록하고 있어야만 한다.\n또한, raster 패키지와 그 후속인 terra 패키지는 데이터 크기가 로컬 저장소(컴퓨터의 하드 드라이브)보다 크지 않을 때에만 훌륭한 전산 처리 능력을 발휘한다. 그러나 최근 데이터셋, 예를 들어 위성 이미지, 기후 모델 또는 기상 예보 데이터는 로컬 저장소의 용량으로는 더 이상 감당하기 어려운 수준에 도달했다(9장 참조). spacetime 패키지(Pebesma 2012, 2022)는 벡터 지오메트리 또는 래스터 그리드 셀의 시계열 분석을 어느 정도 다룰 수 있다. 하지만 더 높은 차원의 어레이나 메모리가 감당하기 어려운 정도의 크기를 가진 데이터셋은 여전히 다루기 어렵다.\n여기서 우리는 래스터 및 벡터 데이터 큐브 분석을 위한 패키지로 stars를 소개한다. 이 패키지는 다음과 같은 기능을 제공한다.\n\n동적(시간 변화) 래스터 스택을 재현할 수 있다.\n로컬 디스크의 크기에 한정되지 않는 확장 가능성을 목표로 한다.\nGDAL 라이브러리의 래스터 기능과 강력한 통합을 제공한다.\n규칙 그리드 외에도 회전, 전단, 직선, 곡선 래스터를 처리할 수 있다(그림 1.6 참조).\nsf 패키지와의 긴밀한 통합을 제공한다.\n비래스터(non-raster) 공간 차원을 가진 어레이 데이터(벡터 데이터 큐브)를 처리할 수 있다.\n타이디버스 디자인 원리를 따른다.\n\n벡터 데이터 큐브에는 심플 피처의 시계열이나 출발지-목적지 매트릭스(그것의 시계열 포함)와 같은 공간 그래프 데이터가 포함된다. 공간적 벡터 및 래스터 데이터 큐브의 개념은 6장에서 설명되었다. 불규칙 시공간 관측치는 sftime 패키지(Teickner, Pebesma, and Graeler 2022)에서 제공하는 sftime 객체로 재현될 수 있으며, 이는 시간 열을 추가하는 방식으로 sf 객체를 확장한 것이다(13.3절 참조).\n\n7.4.1 래스터 데이터의 읽기와 쓰기\n래스터 데이터는 일반적으로 파일을 불러온다. 우리는 브라질의 올린다 시에 대한 30m 해상도의 Landsat 7 데이터셋(밴드 1-5 및 7)을 사용한다. 패키지 stars에서 규칙 비회전 그리드에 대한 예제 GeoTIFF 파일을 읽을 수 있다.\n\ntif &lt;- system.file(\"tif/L7_ETMs.tif\", package = \"stars\")\nlibrary(stars)\n# Loading required package: abind\n(r &lt;- read_stars(tif))\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     1      54     69 68.9      86  255\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\n\n여기서 우리는 오프셋, 셀 크기, 좌표참조계, 및 차원을 확인할 수 있다. 차원 테이블은 각 차원에 대해 다음과 같은 필드를 포함한다.\n\nfrom: 시작 인덱스 값\nto: 종료 인덱스 값\noffset: 첫 번째 픽셀의 시작(모서리)에서의 차원 값\ndelta: 셀 크기로 음의 delta 값은 디멘션 값이 감소할수록 필셀 인덱스 값이 증가한다는 것을 의미\nrefsys: 참조계\npoint: 셀 값이 포인트 서포트인지, 셀 서포트인지를 명시하는 논리 값\nx/y: 디멘션이 래스터의 x- 축과 관련되는지 y-축과 관련되는지를 나타내는 값\n\n여기에는 사용되지 않기 때문에 숨겨진 또 다른 필드인 values가 있다. 정규, 회전, 또는 전단 그리드와 같은 규칙적으로 이산화된 차원(예: 시간)의 경우, 오프셋과 델타는 NA가 아니다. 반면 불규칙한 경우에는 오프셋과 델타가 NA이며, values 속성은 다음 중 하나를 포함한다.\n\n값 또는 구간의 시퀀스: 직선 공간 래스터 또는 불규칙 시간 차원의 경우\n공간 차원과 연결된 지오메트리: 벡터 데이트 큐브의 경우\n각 래스터 셀에 대한 좌표값이 포함된 매트릭스: 곡선 래스터의 경우\n차원 값과 연결된 밴드 이름 또는 레이블: 이산 디멘션의 경우\n\nstars 클래스의 객체 r은 길이가 1인 간단한 리스트로 구성되어 있으며, 3차원 어레이를 포함한다.\n\nlength(r)\n# [1] 1\nclass(r[[1]])\n# [1] \"array\"\ndim(r[[1]])\n#    x    y band \n#  349  352    6\n\n또한, 이 객체는 어레이 차원이 무엇을 나타내는지 알기 위해 필요한 모든 메타데이터를 포함한 디멘션 테이블을 속성으로 가지고 있다. 이는 다음을 통해 얻어진다.\n\nst_dimensions(r)\n\n어레이의 공간적 범위에 대한 정보를 다음과 같이 얻을 수 있다.\n\nst_bbox(r)\n#    xmin    ymin    xmax    ymax \n#  288776 9110729  298723 9120761\n\nwrite_stars 함수를 통해 래스터 데이터를 로컬 디스크에 저장할 수 있다.\n\ntf &lt;- tempfile(fileext = \".tif\")\nwrite_stars(r, tf)\n\n파일 확장자를 통해 데이터 형식(이 경우, GeoTIFF)이 지정된다. 단순 피처와 마찬가지로 읽기 및 쓰기 작업은 GDAL 라이브러리를 사용하며, 래스터 데이터에 사용할 수 있는 드라이버 목록은 다음을 통해 확인할 수 있다.\n\nst_drivers(\"raster\")\n\n\n7.4.2 stars 데이터 큐브로부터 일부분 골라내기\n데이터 큐브는 [ 연산자를 사용하거나 타이디버스 동사를 사용하여 부분 집합을 만들 수 있다. 첫 번째 옵션인 [를 사용하는 방식은 다음의 아규먼트를 쉼표의 구분과 함께 순서대로 지정하는 것이다.\n\n속성(이름, 인덱스, 또는 논리 벡터)\n차원\n\n예를 들어, r[1:2, 101:200,, 5:10]는 r에서 속성 1-2를 선택하고, 디멘션 1에 대해 인덱스 101-200, 차원 3에 대해 인덱스 5-10을 선택함을 의미한다. 차원 2를 통한 선택은 이루어지지 않는다. 속성의 경우, 속성 이름, 인덱스 또는 논리 벡터를 사용할 수 있다. 차원의 경우에는 논리 벡터가 지원되지 않는다. 불연속 범위 선택은 규칙 시퀀스일 때만 지원된다. 기본적으로 drop은 FALSE로 설정되어 있으며, TRUE로 설정하면 단일 값을 가진 차원은 모두 제거된다.\n\nr[,1:100, seq(1, 250, 5), 4] |&gt; dim()\n#    x    y band \n#  100   50    1\nr[,1:100, seq(1, 250, 5), 4, drop = TRUE] |&gt; dim()\n#   x   y \n# 100  50\n\n특정 범위의 차원 값을 선택하기 위해 filter 함수를 사용할 수 있는데, 이는 dplyr 패키지를 우선적으로 로드해야 한다.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nfilter(r, x &gt; 289000, x &lt; 290000)\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     5      51     63 64.3      75  242\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1  35  289004  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6       1     1                NA    NA\n\n이는 차원의 오프셋을 변경한다. 특정 큐브 슬라이스는 slice 함수를 사용하여 얻을 수 있다.\n\nslice(r, band, 3)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif    21      49     63 64.4      77  255\n# dimension(s):\n#   from  to  offset delta            refsys point x/y\n# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n\n이는 단일 차원 band를 제거한다. mutate 함수는 stars 객체에서 기존 어레이를 기반으로 새로운 어레이를 추가하는 데 사용되며, transmute는 여기에 덧붙여 기존 어레이를 제거한다.\n\n7.4.3 잘라내기\n부분 집합을 생성하는 또 다른 방법에 sf, sfc 또는 bbox 클래스의 공간 객체를 사용하는 방법이 있다.\n\nb &lt;- st_bbox(r) |&gt;\n    st_as_sfc() |&gt;\n    st_centroid() |&gt;\n    st_buffer(units::set_units(500, m))\nr[b]\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\n# L7_ETMs.tif    22      54     66 67.7    78.2  174 2184\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x     157 193  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y     159 194 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\n\n예를 들어, 해당 지역에 대한 직경 500m의 원형 중심부를 추출할 수 있는데, 그림 7.6에는 첫 번째 밴드에 적용한 결과가 나타나 있다.\n\n\n\n\n\n그림 7.6: Landsat 7 (band 1) 이미지의 원형 중심부\n\n\n원형 공간 객체의 외부에 존재하는 픽셀에는 NA 값이 할당되는 것을 볼 수 있다. 이 원형 객체는 여전히 r의 offset과 delta 값에 대한 차원 인덱스를 가지고 있다. 다음과 같은 방식으로 offset 값을 재설정할 수 있다.\n\nr[b] |&gt; st_normalize() |&gt; st_dimensions()\n#      from to  offset delta            refsys point x/y\n# x       1 37  293222  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 36 9116258 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1  6      NA    NA                NA    NA\n\n기본적으로, 결과 래스터는 선택 객체의 범위로 잘린다. 입력 객체와 동일한 차원을 가진 객체는 다음과 같은 방식으로 얻을 수 있다.\n\nr[b, crop = FALSE]\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's\n# L7_ETMs.tif    22      54     66 67.7    78.2  174 731280\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\n\nstars 객체의 잘라내기는 st_crop 함수를 사용하여 직접 수행할 수도 있다.\n\nst_crop(r, b)\n\n\n7.4.4 stars 객체의 차원재부여 및 결합\nstars 패키지는 다양한 어레이 조작을 수행하기 위해 패키지 abind (Plate and Heiberger 2016)를 사용한다. 한 예로 어레이를 순열하여 전치하는 aperm 함수이다.\n\naperm(r, c(3, 1, 2))\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     1      54     69 68.9      86  255\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# band    1   6      NA    NA                NA    NA    \n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n\nstars 객체에 대한 메서드가 제공되며, 결과 객체의 차원 순서를 순열한다.\n속성과 차원을 교환할 수 있으며, 이는 split과 merge를 사용하여 수행된다.\n\n(rs &lt;- split(r))\n# stars object with 2 dimensions and 6 attributes\n# attribute(s):\n#     Min. 1st Qu. Median Mean 3rd Qu. Max.\n# X1    47      67     78 79.1      89  255\n# X2    32      55     66 67.6      79  255\n# X3    21      49     63 64.4      77  255\n# X4     9      52     63 59.2      75  255\n# X5     1      63     89 83.2     112  255\n# X6     1      32     60 60.0      88  255\n# dimension(s):\n#   from  to  offset delta            refsys point x/y\n# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\nmerge(rs, name = \"band\") |&gt; setNames(\"L7_ETMs\")\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#          Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs     1      54     69 68.9      86  255\n# dimension(s):\n#      from  to  offset delta            refsys point    values x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE      NULL [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE      NULL [y]\n# band    1   6      NA    NA                NA    NA X1,...,X6\n\nsplit 함수는 밴드 차원을 2차원 어레이의 여섯 개 속성에 분배하며, merge 함수는 거꾸로 수행한다. st_redimension 함수는 단일 어레이 차원을 두 개의 새로운 차원으로 분할하는 것과 같은 보다 일반적인 작업에 사용된다.\n\nst_redimension(r, c(x = 349, y = 352, b1 = 3, b2 = 2))\n# stars object with 4 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     1      54     69 68.9      86  255\n# dimension(s):\n#    from  to  offset delta            refsys point x/y\n# x     1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y     1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# b1    1   3      NA    NA                NA    NA    \n# b2    1   2      NA    NA                NA    NA\n\n동일한 차원을 가진 여러 개의 stars 객체는 c를 사용하여 결합할 수 있다. 결합된 어레이는 추가적인 속성으로 취급하는 것이 디폴트 설정이지만, along 아규먼트를 지정하면 어레이를 새로운 차선을 따라 병합할 수도 있다.\n\nc(r, r, along = \"new_dim\")\n# stars object with 4 dimensions and 1 attribute\n# attribute(s), summary of first 1e+05 cells:\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif    47      65     76 77.3      87  255\n# dimension(s):\n#         from  to  offset delta            refsys point x/y\n# x          1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y          1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band       1   6      NA    NA                NA    NA    \n# new_dim    1   2      NA    NA                NA    NA\n\n이의 사용 예시는 7.5.2절에서 설명된다.\n\n7.4.5 포인트 샘플 추출하기, 애그리게이팅하기\n래스터 데이터 큐브 분석의 매우 일반적인 사용 사례는 특정 위치에서 값을 추출하거나 특정 지오메트리에 대해 집계값을 계산하는 것이다. st_extract 함수는 포인트 값을 추출한다. 우리는 r 객체의 바운딩 박스 내의 몇 개의 무작위로 샘플링 포인트에 대해 이 오퍼레이션을 수행할 것이다.\n\nset.seed(115517)\npts &lt;- st_bbox(r) |&gt; st_as_sfc() |&gt; st_sample(20)\n(e &lt;- st_extract(r, pts))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif    12    41.8     63   61    80.5  145\n# dimension(s):\n#          from to            refsys point\n# geometry    1 20 SIRGAS 2000 / ...  TRUE\n# band        1  6                NA    NA\n#                                           values\n# geometry POINT (293002 ...,...,POINT (290941 ...\n# band                                        NULL\n\n이것은 20개의 포인트와 6개의 밴드를 가진 벡터 데이터 큐브를 생성한다(시드를 설정하게 되면, 반복 실행에서 동일한 샘플의 사용이 보장된다. 따라서 포인트의 무작위 생성을 재실행하고자 하는 경우는 시드를 설정해서는 안된다).\n데이터 큐브에서 정보를 추출하는 또 다른 방법은 집계값을 산출하는 것이다. 이를 수행하는 한 가지 방법은 공간 폴리곤 또는 라인에 의거해 값을 공간적으로 집계하는 것이다(6.4절 참조). 예를 들어, 그림 1.4(d)에 표시된 세 개의 원 각각에 대해 여섯 개 밴드의 최대 픽셀 값을 계산할 수 있다.\n\ncircles &lt;- st_sample(st_as_sfc(st_bbox(r)), 3) |&gt;\n    st_buffer(500)\naggregate(r, circles, max)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif    73    94.2    117  121     142  205\n# dimension(s):\n#          from to            refsys point\n# geometry    1  3 SIRGAS 2000 / ... FALSE\n# band        1  6                NA    NA\n#                                           values\n# geometry POLYGON ((2913...,...,POLYGON ((2921...\n# band                                        NULL\n\n이는 세 개의 지오메트리와 여섯 개의 밴드를 가진 (벡터) 데이터 큐브를 생성한다. 시간 차원에 대한 집계값의 산출은 aggregate 함수의 두 번째 아규먼트로 시간 변수를 설정하여 수행된다. 시간 변수에 다음과 같은 것이 있을 수 있다.\n\n시간 간격의 시작을 나타내는 타임 스탬프의 집합\nmake_intervals 함수로 정의된 시간 간격 집합\n“주”, “5일” 또는 “년”과 같은 시간 기간\n\n7.4.6 예측 모델\nR에서의 일반적인 모델 예측 워크플로우는 다음과 같다.\n\n응답 변수와 예측 변수(공변량)가 포함된 data.frame의 사용\ndata.frame을 기반으로 모델 객체를 생성\n모델 객체와 대상 예측 변수 값이 포함된 data.frame을 사용하여 predict를 호출\n\nstars 패키지는 stars 객체에 대한 predict 메서드를 제공하며, 이는 본질적으로 위의 마지막 단계를 수행하는데, data.frame을 생성하고, predict 메서드를 호출한 후, 예측 값으로 stars 객체를 재구성한다.\n이 과정을 설명하기 위해 Landsat 데이터셋에 위에서 추출한 샘플 포인트를 적용해 육지를 바다에서 분리하는 간단한 이진 클래스 예제를 사용할 것이다. 결과는 그림 7.7에 나타나 있다.\n\n\n\n\n\n그림 7.7: 트레이닝 데이터로 사용되는 무작위 샘플 포인트: 빨간색은 해양부이고 노란색을 육지부이다.\n\n\n이 그림에서 포인트 8, 14, 15, 18 및 19는 수부에 위치하고 있으며, 나머지는 육지부에 있다는 것을 “육안”으로 확인할 수 있다. 선형 판별(“최대 우도”) 분류기를 사용하여, 우리는 그림 7.8에 나타난 모델 예측 결과를 얻을 수 있다.\n\nrs &lt;- split(r)\ntrn &lt;- st_extract(rs, pts)\ntrn$cls &lt;- rep(\"land\", 20)\ntrn$cls[c(8, 14, 15, 18, 19)] &lt;- \"water\"\nmodel &lt;- MASS::lda(cls ~ ., st_drop_geometry(trn))\npr &lt;- predict(rs, model)\n\n여기서 우리는 MASS:: 접두사를 사용하여 MASS 패키지를 로드하지 않았으며, 이는 dplyr의 select 함수를 가리는 것을 방지하기 위함이다. split 단계는 밴드 차원을 속성으로 변환하여 예측 변수로 투입하기 위해 필요한 단계이다.\n\n\n\n\n\n그림 7.8: 육지부/수부 구분을 위한 선형 판별 분류기로 그림 7.7의 트레이닝 데이터에 기반한 결과임.\n\n\n우리는 또한 그림 7.8에 플로팅된 레이어가 클래스 레이블을 가진 범주형 변수임을 알 수 있다.\n\n7.4.7 래스터 데이터 플로팅\n\n\n30m 해상도의 Landsat 6개 밴드를 90m로 다운샘플한 결과, 브라질의 올린다\n\n베이스 플롯 함수를 stars 객체에 적용할 수 있는데, plot(r)로 생성된 플롯은 그림 7.9에 나타나 있다. 기본 색상 스케일은 회색 톤을 사용하며, 모든 밴드의 데이터 분위수에 맞춰 명암 대비가 조정된다(“히스토그램 평활화”)(역자주: 히스토그램 평활화는 데이터의 분토를 재조정하여 시각적으로 더 유용하고 세부 사항을 더 잘 볼 수 있게 하는 기법을 말한다. 예를 들어, 어두운 이미지에서는 어두운 영역의 픽셀 값이 많이 몰려 있는데, 히스토그램 평활화를 적용하면 이 픽셀 값의 범위를 더 넓은 범위로 확장(stretch)시켜 이미지를 밝고 명확하게 보이도록 할 수 있다.) breaks = \"equal\"로 설정하면 급폭이 동일하게 설정되는 등간격 분류법이 적용되며, 계급 단절값을 임의로 지정할 수도 있다. 그런데 더 익숙한 플로팅 방식은 그림 7.10에 나타난 RGB 또는 폴스 컬러 합성일 것이다.\n\n\n\n\n\n그림 7.9: 컬러 합성의 두 가지 예\n\n\n보다 자세한 사항은 8장에서 다루어진다.\n\n7.4.8 래스터 데이터 분석하기\nstars 객체의 개별 엘리먼트에 대해서는, 수리 함수의 적용이 어레이에 직접적으로 이루어진다. 이는 사용자가 함수를 호출하여 표현식(expression)을 생성하는 것이 가능하다는 것을 의미한다.\n\nlog(r)\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     0    3.99   4.23 4.12    4.45 5.54\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\nr + 2 * log(r)\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     1      62   77.5 77.1    94.9  266\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\n\n혹은 특정 값들을 마스킹 처리할 수도 있다.\n\nr2 &lt;- r\nr2[r &lt; 50] &lt;- NA\nr2\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's\n# L7_ETMs.tif    50      64     75   79      90  255 149170\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\n\n혹은 마스킹을 해제할 수도 있다.\n\nr2[is.na(r2)] &lt;- 0\nr2\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     0      54     69   63      86  255\n# dimension(s):\n#      from  to  offset delta            refsys point x/y\n# x       1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y       1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n# band    1   6      NA    NA                NA    NA\n\nstars 객체의 개별 차원에 대해서는, 선택된 어레이 차원에 함수를 적용하는 것이 가능하며, 이는 apply 함수가 어레이에 대해 수행하는 방식과 유사하다(6.3.3절). 예를 들어, 각 픽셀에 대해 6개 밴드 값의 평균을 계산할 수 있다.\n\nst_apply(r, c(\"x\", \"y\"), mean)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.\n# mean  25.5    53.3   68.3 68.9      82  255\n# dimension(s):\n#   from  to  offset delta            refsys point x/y\n# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n\n더 유의미한 함수로는 예를 들어 NDVI(Normalized Difference Vegetation Index, 정규화 식생 지수 )를 계산하는 것이 있다.\n\nndvi &lt;- function(b1, b2, b3, b4, b5, b6) (b4 - b3)/(b4 + b3)\nst_apply(r, c(\"x\", \"y\"), ndvi)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#         Min. 1st Qu.  Median    Mean 3rd Qu.  Max.\n# ndvi  -0.753  -0.203 -0.0687 -0.0643   0.187 0.587\n# dimension(s):\n#   from  to  offset delta            refsys point x/y\n# x    1 349  288776  28.5 SIRGAS 2000 / ... FALSE [x]\n# y    1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE [y]\n\n혹은, 다음과 같이 정의할 수도 있다.\n\nndvi2 &lt;- function(x) (x[4]-x[3])/(x[4]+x[3])\n\n밴드 수가 많을 경우 이러한 방식은 더 편리하지만, 각 픽셀에 대해 호출해야 하므로 위에서 정의한 ndvi 함수보다 훨씬 느리다. 반면 ndvi 함수는 모든 픽셀이나 큰 픽셀 덩어리에 대해 한 번 호출할 수 있다. 전체 이미지에 대해 각 밴드의 평균은 다음과 같이 계산된다.\n\nst_apply(r, c(\"band\"), mean) |&gt; as.data.frame()\n#   band mean\n# 1    1 79.1\n# 2    2 67.6\n# 3    3 64.4\n# 4    4 59.2\n# 5    5 83.2\n# 6    6 60.0\n\n결과는 data.frame의 형태로 막바로 출력해 볼 수 있을 만큼 작다. 이 두 가지 예에서는 전체 디멘션이 사라진다. 그러나 그렇지 않은 경우도 종종 발생한다(6.3.2절). 예를 들어, 각 밴드에 대해 세 개의 사분위수를 계산할 수 있다.\n\nst_apply(r, c(\"band\"), quantile, c(.25, .5, .75))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif    32    60.8   66.5 69.8    78.8  112\n# dimension(s):\n#          from to        values\n# quantile    1  3 25%, 50%, 75%\n# band        1  6          NULL\n\n이렇게 하면 세 개의 값으로 이루어진 새로운 차원인 quantile이 생성된다. 또는 각 픽셀에 대해 여섯 개의 밴드 값에 대한 세 개의 사분위수를 다음과 같은 방식으로 얻을 수도 있다.\n\nst_apply(r, c(\"x\", \"y\"), quantile, c(.25, .5, .75))\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#              Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs.tif     4      55   69.2 67.2    81.2  255\n# dimension(s):\n#          from  to  offset delta            refsys point\n# quantile    1   3      NA    NA                NA    NA\n# x           1 349  288776  28.5 SIRGAS 2000 / ... FALSE\n# y           1 352 9120761 -28.5 SIRGAS 2000 / ... FALSE\n#                 values x/y\n# quantile 25%, 50%, 75%    \n# x                 NULL [x]\n# y                 NULL [y]\n\n\n7.4.9 곡선 래스터\n비규칙 래스터가 발생하는 여러 가지 이유가 있다(그림 1.6). 우선, 데이터가 지구의 형태를 그대로 반영하고 있을 때, 규칙 래스터는 곡면인 지구의 표면에 맞지 않는다. 다른 이유에는 다음과 같은 것들이 있다.\n\n규칙 래스터 데이터를 다른 좌표참조계로 전환하거나 변환할 경우, 리샘플링, 즉 워핑(7.8절)을 하지 않으면 곡선 형태가 된다. 그런데 워핑은 항상 데이터 손실을 초래하며, 이는 가역적이지 않다.\n관측이 비규칙 래스터를 초래할 수 있다. 품질이 낮은 위성 영상의 경우, 위성의 진행 방향에서는 규칙 래스터가 되지만(\\(x\\) 또는 \\(y\\)와 정렬되지 않음), 그와 수직인 방향에서는 직각(rectilinear) 래스터가 된다(예: 센서가 시야각을 일정한 간격으로 분할하여 관측을 수행하는 경우).\n\n7.4.10 GDAL 유틸리티\nGDAL 라이브러리는 일반적으로 데이터 변환 및 처리를 위한 여러 실행 가능한 바이너리, 즉 GDAL 명령줄 유틸리티와 함께 제공된다. 이러한 유틸리티 중 여러 개(파이썬으로 작성된 것을 제외한 모든 유틸리티)는 “GDAL Algorithms C API”를 통해 GDAL 라이브러리의 C 함수로도 사용 가능하다. GDAL 라이브러리와 연동되어 있는 sf와 같은 R 패키지가 이러한 C API 알고리즘을 사용한다면, 사용자는 R 패키지 외에 추가로 GDAL 바이너리 명령줄 유틸리티를 설치할 필요가 없다는 의미이다.\nsf 패키지는 gdal_utils 함수를 통해 이러한 C API 알고리즘을 호출할 수 있으며, 첫 번째 인수는 gdal 접두사를 제거한 해당 유틸리티의 이름이다.\n\ninfo: GDAL(래스터) 데이터셋에 대한 정보를 출력한다.\nwarp: 래스터를 새로운 래스터로 변환한다(CRS의 전환 포함).\nrasterize: 벡터 데이터셋을 래스터화한다.\ntranslate: 래스터 파일을 다른 형식으로 변환한다.\nvectortranslate: 벡터 파일을 다른 형식으로 변환한다(ogr2ogr에 해당).\nbuildvrt: 가상 래스터 타일(여러 파일의 결합을 통해 생성된 단일 래스터)을 생성한다.\ndemprocessing: DEM(digital data model, 디지털고도모델)에 대한 다양한 프로세싱을 수행한다.\nnearblack: 거의 검정색/흰색 경계를 검정색으로 변환한다.\ngrid: 흩어진 데이터로부터 규칙 그리드를 생성한다.\nmdiminfo: 다차원 어레이에 대한 정보를 출력한다.\nmdimtranslate: 다차원 어레이를 다른 형식으로 변환한다.\n\n이러한 유틸리티는 기본적으로 파일에서 작동하며, sf 또는 stars 객체에 직접적으로 작용하지는 않는다. 그러나 stars_proxy 객체는 본질적으로 파일에 대한 포인터이며, 다른 객체들도 파일로 기록될 수 있다. 이러한 유틸리티 중 몇몇은 (항상 혹은 선택적으로) st_mosaic, st_warp, 또는 st_write와 같은 함수를 통해 사용된다. R의 gdalUtilities (O’Brien 2022) 패키지는 sf::gdal_utils에 덧붙여 사용자 편의성을 위한 래퍼 함수를 제공하는데, 함수의 아규먼트 이름이 바이너리 유틸리티의 명령줄 아규먼트와 정확히 일치한다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#래스터-투-벡터와-벡터-투-래스터",
    "href": "07.html#래스터-투-벡터와-벡터-투-래스터",
    "title": "7  sf와 stars",
    "section": "\n7.6 래스터-투-벡터와 벡터-투-래스터",
    "text": "7.6 래스터-투-벡터와 벡터-투-래스터\n\n7.6.1 벡터-투-래스터",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#타원-좌표",
    "href": "07.html#타원-좌표",
    "title": "7  sf와 stars",
    "section": "\n7.3 타원 좌표",
    "text": "7.3 타원 좌표\n비투영 데이터는 경위도로 표현된 타원체 좌표를 가진다. 4.1절에서 설명된 대로, 포인트간 “직선”은 최단 곡선 경로(“측지선”)이다. 기본적으로 sf 패키지는 s2geometry 라이브러리의 기하학적 연산을 사용하며, 이는 s2 패키지를 통해 이루어진다(Dunnington, Pebesma, and Rubak 2023). 예를 들어, 아래의 지점은 특정 폴리곤 내부에 존재한다(그림 7.5의 왼쪽 그림: 정사 도법).\n\n\"POINT(50 50.1)\" |&gt; st_as_sfc(crs = \"OGC:CRS84\") -&gt; pt\n\n\n\"POLYGON((40 40, 60 40, 60 50, 40 50, 40 40))\" |&gt;\n  st_as_sfc(crs = \"OGC:CRS84\") -&gt; pol\nst_intersects(pt, pol)\n# Sparse geometry binary predicate list of length 1, where the\n# predicate was `intersects'\n#  1: 1\n\n\n\n\n\n\n그림 7.5: 인터섹션의 결과는 측지선 혹은 대권호를 사용하느냐(왼쪽) 데카르트 좌표계를 사용하느냐에 따라 달라진다.\n\n\nsf 패키지가 타원체 좌표를 마치 데카르트 좌표처럼 사용하도록 하려면, s2 사용을 비활성화하면 된다.\n\nold &lt;- sf_use_s2(FALSE)\n# Spherical geometry (s2) switched off\nst_intersects(pol, pt)\n# although coordinates are longitude/latitude, st_intersects assumes\n# that they are planar\n# Sparse geometry binary predicate list of length 1, where the\n# predicate was `intersects'\n#  1: (empty)\nsf_use_s2(old) # restore\n# Spherical geometry (s2) switched on\n\n이렇게 하면, 그림 7.5의 오른쪽 그림(정거원통 도법)처럼, 엠프티 인터섹션이 리턴된다. 타원체 좌표를 평면 좌표로 취급한다는 점이 경고 메시지에 명시되어 있다.\n성능이나 레거시 구현과의 호환성 이유로 s2 사용을 비활성화할 수 있다. 데카르트 기하학을 위한 GEOS 라이브러리와 구체 기하학을 위한 s2geometry 라이브러리(그림 1.7)는 서로 다른 동기로 개발되었으며, sf를 통해 사용될 때 그 방식에서 몇 가지 차이가 있다.\n\n특정 오퍼레이션에서 속도차가 크게 날 수 있다.\n특정 함수는 오로지 특정 라이브러리에만 존재한다(예를 들어 st_relate 함수는 GEOS 라이브러리에만 존재)\n변환자(transformer)를 사용할 때, GEOS는 외부 폴리곤 링을 시계 방향으로 노드로 반환하며, 이를 반시계 방향으로 되돌리기 위해 st_sfc(..., check_ring_dir = TRUE)를 사용한다. 반면, s2geometry는 외부 폴리곤 링을 반시계 방향으로 반환한다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#벡터-데이터-큐브의-예제",
    "href": "07.html#벡터-데이터-큐브의-예제",
    "title": "7  sf와 stars",
    "section": "\n7.5 벡터 데이터 큐브의 예제",
    "text": "7.5 벡터 데이터 큐브의 예제\n\n7.5.1 예제: 대기질 시계열 데이터에 대한 애그리게이션 실행\n유럽 대기질 데이터를 사례로 벡터 데이터 큐브에 대한 애그리게이션 작업을 설명한다. 동일한 데이터가 Gräler, Pebesma, Heuvelink (2016)에서 사용되었으며, 12장과 13장에서도 사용될 예정이다. 독일의 농촌 지역 관측소의 1998~2009년 데이터로부터 일평균 \\(\\text{PM}_{10}\\) 값을 계산하였다.\nair 데이터 매트릭스, 날짜 벡터인 dates, 그리고 SpatialPoints 객체인 stations을 결합해 stars 객체를 생성할 수 있다.\n\nload(\"data/air.rda\") # this loads several datasets in .GlobalEnv\ndim(air)\n# space  time \n#    70  4383\nstations |&gt;\n    st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) |&gt;\n    st_geometry() -&gt; st\nd &lt;- st_dimensions(station = st, time = dates)\n(aq &lt;- st_as_stars(list(PM10 = air), dimensions = d))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.   NA's\n# PM10     0    9.92   14.8 17.7      22  274 157659\n# dimension(s):\n#         from   to     offset  delta refsys point\n# station    1   70         NA     NA WGS 84  TRUE\n# time       1 4383 1998-01-01 1 days   Date FALSE\n#                                          values\n# station POINT (9.59 53.7),...,POINT (9.45 49.2)\n# time                                       NULL\n\n그림 7.11에서 시간 시계열이 상당히 길지만, 큰 결측값 간격도 있다는 것을 알 수 있다. 그림 7.12는 평균 \\(\\text{PM}_{10}\\) 값과 함께 측정소의 공간 분포를 보여준다.\n\n\n\n\n\n그림 7.10: 시간과 스테이션별로 계산된 PM10 값에 대한 시공간 다이어그램\n\n\n\n\n\n\n\n그림 7.11: 관측 스테이션별 PM10 평균값\n\n\n간단한 실습 차원에서, 측정 스테이션별 시간 시계열 데이터를 지역 평균으로 집계할 수 있다. 이를 위해 stars 객체에 대한 aggregate 메소드를 사용한다.\n\n(a &lt;- aggregate(aq, de_nuts1, mean, na.rm = TRUE))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\n# PM10  1.08    10.9   15.3 17.9    21.8  172 25679\n# dimension(s):\n#      from   to     offset  delta refsys point\n# geom    1   16         NA     NA WGS 84 FALSE\n# time    1 4383 1998-01-01 1 days   Date FALSE\n#                                       values\n# geom MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# time                                    NULL\n\n그리고, 아래의 코드를 통해 임의로 선택한 여섯 개의 날짜에 대한 지도를 보여줄 수 있다(그림 7.13).\n\nlibrary(tidyverse)\na |&gt; filter(time &gt;= \"2008-01-01\", time &lt; \"2008-01-07\") |&gt; \n    plot(key.pos = 4)\n\n\n\n\n\n\n그림 7.12: 임의의 6일에 대한 지역 평균 PM10\n\n\n또한 다음의 코드를 이용해 단일 주에 대한 평균 값의 시계열 플롯을 생성할 수 있다(그림 7.14).\n\nlibrary(xts) |&gt; suppressPackageStartupMessages()\nplot(as.xts(a)[,4], main = de_nuts1$NAME_1[4])\n\n\n\n\n\n\n그림 7.13: 단일 스테이션에 대한 지역 평균 PM10의 시계열\n\n\n\n7.5.2 예제: 브리스톨 출발지-도착지 데이터 큐브\n이 예제에 사용된 데이터는 Lovelace, Nowosad, Muenchow (2019)에서 가져온 것으로, 출발지-목적지(OD) 매트릭스이다. 구체적으로 A 지역에서 B 지역으로 이동하는 사람의 수를 교통 수단별로 나타낸 것이다. 102개의 지역에 대한 피처 지오메트리는 sf 객체인 bristol_zones에 포함되어 있다.\n\n\n\n\n\n그림 7.14: 영국 브리스톨의 102개 구역 현황(33번 구역(E02003043)이 빨간색으로 표시되어 있음)\n\n\nbristol_od 테이블에 데이터가 저장되어 있는데, OD 쌍(이동량이 0인 경우는 제외)가 레코드로, 서로 다른 교통수단이 변수로 들어가 있다.\n\nhead(bristol_od)\n# # A tibble: 6 × 7\n#   o         d           all bicycle  foot car_driver train\n#   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n# 1 E02002985 E02002985   209       5   127         59     0\n# 2 E02002985 E02002987   121       7    35         62     0\n# 3 E02002985 E02003036    32       2     1         10     1\n# 4 E02002985 E02003043   141       1     2         56    17\n# 5 E02002985 E02003049    56       2     4         36     0\n# 6 E02002985 E02003054    42       4     0         21     0\n\n제외된 무이동 OD 쌍의 갯수는 모든 OD 조합의 수에서 데이터에 포함된 OD 쌍의 갯수를 빼면 구할 수 있다.\n\nnrow(bristol_zones)^2 - nrow(bristol_od) \n# [1] 7494\n\n우리는 출발지, 목적지, 교통 수단을 차원으로 가지는 3차원 벡터 데이터 큐브를 형성할 것이다. 이를 위해 먼저 pivot_longer를 사용하여 bristol_od 테이블을 정리하여 출발지(o), 목적지(d), 교통 수단(mode), 및 수(count)라는 변수를 갖도록 한다.\n\n# create O-D-mode array:\nbristol_tidy &lt;- bristol_od |&gt; \n    select(-all) |&gt; \n    pivot_longer(3:6, names_to = \"mode\", values_to = \"n\")\nhead(bristol_tidy)\n# # A tibble: 6 × 4\n#   o         d         mode           n\n#   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;\n# 1 E02002985 E02002985 bicycle        5\n# 2 E02002985 E02002985 foot         127\n# 3 E02002985 E02002985 car_driver    59\n# 4 E02002985 E02002985 train          0\n# 5 E02002985 E02002987 bicycle        7\n# 6 E02002985 E02002987 foot          35\n\n그리고 나서 0으로 채워진 3차원 어레이 a를 생성한다.\n\nod &lt;- bristol_tidy |&gt; pull(\"o\") |&gt; unique()\nnod &lt;- length(od)\nmode &lt;- bristol_tidy |&gt; pull(\"mode\") |&gt; unique()\nnmode = length(mode)\na = array(0L,  c(nod, nod, nmode), \n    dimnames = list(o = od, d = od, mode = mode))\ndim(a)\n# [1] 102 102   4\n\n해당 어레이의 세 차원에 구역 이름(o, d)과 교통 수단 이름(mode)이 부여된 것을 확인할 수 있다. 이렇게 함으로써 bristol_tidy의 각 행은 해당 어레이의 한 단위(엔트리)에 해당하게 된다. bristol_tidy 테이블에 있는 인덱스(o, d 및 mode)와 값(n)을 이용해 해당 어레이(a)의 비제로 부분을 채울 수 있다.\n\na[as.matrix(bristol_tidy[c(\"o\", \"d\", \"mode\")])] &lt;- \n        bristol_tidy$n\n\nbristol_zones의 구역과 bristol_tidy의 구역 이름 간에 순서 불일치가 발생할 수 있기 때문에 다음의 조치를 취한다.\n\norder &lt;- match(od, bristol_zones$geo_code)\nzones &lt;- st_geometry(bristol_zones)[order]\n\n순서가 이미 올바른 경우도 있지만, 이러한 가정을 배제한 채 위의 코드를 실행하는 것이 좋다. 다음으로 존과 교통수단을 이용해 stars 디멘션 객체를 생성한다.\n\nlibrary(stars)\n(d &lt;- st_dimensions(o = zones, d = zones, mode = mode))\n#      from  to refsys point                                  values\n# o       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# d       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# mode    1   4     NA FALSE                       bicycle,...,train\n\na와 d로부터 최종적으로 stars 객체를 생성한다.\n\n(odm &lt;- st_as_stars(list(N = a), dimensions = d))\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#    Min. 1st Qu. Median Mean 3rd Qu. Max.\n# N     0       0      0  4.8       0 1296\n# dimension(s):\n#      from  to refsys point                                  values\n# o       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# d       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# mode    1   4     NA FALSE                       bicycle,...,train\n\n이 3차원 어레이로부터 단일 슬라이스를 추출할 수 있다. 예를 들어 구역 33에 대한 데이터를 odm[,,33]을 통해 추출한 후 플롯을 그릴 수 있다(그림 7.16).\n\nplot(adrop(odm[,,33]) + 1, logz = TRUE)\n\n\n\n\n\n\n그림 7.15: 33번 존에 대한 OD 데이터를 추출한 후 교통수단별로 지도화하였다.\n\n\n이렇게 하여 서브셋을 생성하면, 첫 번째 아규먼트가 비어 있으므로 모든 속성(여기서는 하나만 존재함: N)을 선택하고, 두 번째 아규먼트가 비어 있어 모든 출발지를 선택하며, 세 번째 아규먼트로 목적지 구역 33을 선택하고, 네 번째 아규먼트는 비어 있어 모든 교통 수단을 선택하게 된다.\n우리가 이 특정 구역을 목적지로 선택한 이유는 해당 구역이 가장 많은 여행자를 가지고 있기 때문이다. 이는 목적지별로 모든 출발지와 여행 수단을 합산하여 확인할 수 있다.\n\nd &lt;- st_apply(odm, 2, sum)\nwhich.max(d[[1]])\n# [1] 33\n\n다른 애그리게이션도 실행할 수 있다. 예를 들어 OD(102 x 102)의 총통행량을 다음과 같이 구할 수 있다.\n\nst_apply(odm, 1:2, sum)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#      Min. 1st Qu. Median Mean 3rd Qu. Max.\n# sum     0       0      0 19.2      19 1434\n# dimension(s):\n#   from  to refsys point                                  values\n# o    1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# d    1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n\n교통 수단별로 출발지 총계를 구할 수 있다.\n\nst_apply(odm, c(1,3), sum)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#      Min. 1st Qu. Median Mean 3rd Qu. Max.\n# sum     1    57.5    214  490     771 2903\n# dimension(s):\n#      from  to refsys point                                  values\n# o       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# mode    1   4     NA FALSE                       bicycle,...,train\n\n교통 수단별로 도착지 총계를 구할 수 있다.\n\nst_apply(odm, c(2,3), sum)\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#      Min. 1st Qu. Median Mean 3rd Qu.  Max.\n# sum     0      13    104  490     408 12948\n# dimension(s):\n#      from  to refsys point                                  values\n# d       1 102 WGS 84 FALSE MULTIPOLYGON (...,...,MULTIPOLYGON (...\n# mode    1   4     NA FALSE                       bicycle,...,train\n\n모드별로 합산된 출발지 총계를 구할 수 있다.\n\no &lt;- st_apply(odm, 1, sum)\n\n모드별로 합산된 도착지 총계를 구할 수 있다.\n\nd &lt;- st_apply(odm, 2, sum)\n\no와 d를 결합한 후 함께 플롯할 수 있다(그림 7.17).\n\nx &lt;- (c(o, d, along = list(od = c(\"origin\", \"destination\"))))\nplot(x, logz = TRUE)\n\n\n\n\n\n\n그림 7.16: 출발지별 총 통근(왼쪽) 또는 목적지별 총 통근(오른쪽)\n\n\n이 지도가 현상의 본질을 호도할 수 있다는 우려가 있을 수 있다. 왜냐하면 실질적인 값의 크기(컬러) 뿐만 아니라 구역의 면적 역시 시각적으로 느끼는 양의 크기에 영향을 주기 때문이다. 이러한 점을 감안하여 밀도값(카운트/\\(\\text{km}^2\\))을 계산하여 나타낼 수 있다(그림 7.18)(역자주: 지도학적 원칙으로 보자면, 카운트를 코로플레스 맵으로 나타내는 것은 적절하지 않다. 따라서 보다 좋은 방법은 카운트를 도형표현도로 나타내는 것이다).\n\nlibrary(units)\na &lt;- set_units(st_area(st_as_sf(o)), km^2)\no$sum_km &lt;- o$sum / a\nd$sum_km &lt;- d$sum / a\nod &lt;- c(o[\"sum_km\"], d[\"sum_km\"], along = \n        list(od = c(\"origin\", \"destination\")))\nplot(od, logz = TRUE)\n\n\n\n\n\n\n그림 7.17: 출발지별 총 통근 밀도(왼쪽) 또는 목적지별 총 통근 밀도(오른쪽)\n\n\n카운트를 정규화하는 또 다른 방법은 값을 면적이 아닌 인구수로 나누는 것이다.\n\n7.5.3 타이디 어레이 데이터\nWickham(2014)의 타이디 데이터 논문은 3차원 데이터를 어레이 데이터 형식보다는 각 행이 (지역, 클래스, 연도, 값)으로 구성된 긴(비정규화된) 테이블 형식으로 처리되는 것이 더 좋다고 제안한다. 이는 가능하기만 하다면 늘 좋은 방법이다. 그러나 이 옵션이 불가능한 경우가 있는데, 기본 처리 및 저장의 목적에서 그러하다. 그 이유는 다음과 같다.\n\n많은 어레이 데이터는 처음부터 어레이 데이터로 수집되거나 생성된다. 예를 들어, 원격탐사를 통해 수집된 데이터 혹은 기후 모델을 통해 생성된 데이터\n어레이 형식을 긴 테이블 형태로 전환하는 것이 그 역보다 훨씬 쉽다.\n긴 테이블 형식의 데이터가 훨씬 더 많은 메모리를 요구한다. 왜냐하면 \\(n_i\\)가 디멘션 \\(i\\)의 기수(크기)일 때, 디멘션 값이 차지하는 메모리 공간은 \\(O(\\sum{n_i})\\)가 아니라 \\(O(\\prod{n_i})\\)로 주어지기 때문이다.\n결측값이 있는 셀이 삭제되면, 긴 테이블 형식은 어레이 형식에 내재된 인덱싱을 상실하게 된다.\n\n이 주장을 극단적으로 표현하자면, 모든 이미지, 비디오 및 음성 데이터가 어레이 형식으로 저장된다고 가정해 보자. 실제로 이를 긴 테이블 형식으로 저장해야 한다고 주장하는 사람은 거의 없을 것이다. 그럼에도 불구하고 tsibble(Wang et al. 2022)과 같은 R 패키지는 긴 테이블 형식을 취하고 있는데, 동일한 시간 스텝을 가진 다수의 공간적 피처에 대해 순서를 매기는 것은 매우 모호한 작업임에도 불구하고 어쨋던 인덱싱을 해야한다는 문제점이 있을 수 있다. 이러한 문제는 stars에서 제공하는 어레이 형식을 사용함으로써 자동으로 해결된다. 물론 조밀한 어레이를 사용해야한다는 대가를 치루는 것이기도 하다.\nstars 패키지는 어레이 집합을 처리하는 문제에 있어서는 타이디 데이터 원칙(tidy manifesto)을 따르려 하며, 특히 하나 이상의 차원이 공간 및/또는 시간을 참조하는 경우에 대해서는 특별히 더 그러하다.\n\n7.5.4 벡터 데이터 큐브를 위한 파일 포멧\n정규 테이블 형식(긴 테이블 형식을 포함)은 하나의 대안이지만 사용하기에는 불편하다. 위의 출발지-목적지 데이터 예제와 13장에서 다를 내용은 테이블 형식에서 벡터 데이터 큐브를 재구성하는 것이 매우 복잡하다는 점을 잘 보여준다. NetCDF나 Zarr와 같은 어레이 형식은 어레이 데이터를 저장하기 위해 설계되었다. 그러나 이러한 형식은 모든 데이터 구조에 사용할 수 있으며, 일단 작성된 파일은 재사용하기 어려운 위험이 있다. 포인트, (멀티)라인스트링 또는 (멀티)폴리곤으로 구성된 단일 지오메트리 디멘션을 가진 벡터 큐브의 경우, CF 규칙(Eaton et al. 2022)은 이러한 지오메트리를 인코딩하는 방법을 설명한다. stars::read_mdim과 stars::write_mdim은 이러한 규칙을 따르는 벡터 데이터 큐브를 읽고 쓸 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "07.html#래스터-벡터-전환과-벡터-래스터-전환",
    "href": "07.html#래스터-벡터-전환과-벡터-래스터-전환",
    "title": "7  sf와 stars",
    "section": "\n7.6 래스터-벡터 전환과 벡터-래스터 전환",
    "text": "7.6 래스터-벡터 전환과 벡터-래스터 전환\n1.3절에서 래스터-벡터 변환과 벡터-래스터 변환에 대한 몇 가지 예제를 이미 다루었다. 이 절에서는 코드와 예제를 추가하고자 한다.\n\n7.6.1 벡터-래스터 전환\nst_as_stars 함수는 객체를 stars 객체로 변환하는 메소드로로 설계되었다. 그러나 모든 stars 객체가 래스터 객체인 것은 아니며, sf 객체에 이 메소들 적용하면 지오메트리를 공간적(벡터) 디멘션으로 하고 속성을 속성 디멘션으로 가지는 벡터 데이터 큐브가 생성된다. 피처 지오메트리(sfc) 객체가 주어지면, st_as_stars 함수는 이를 래스터한다(섹션 7.8과 그림 7.19).\n\nfile &lt;- system.file(\"gpkg/nc.gpkg\", package=\"sf\")\nread_sf(file) |&gt; \n    st_geometry() |&gt;\n    st_as_stars() |&gt;\n    plot(key.pos = 4)\n\n\n\n\n\n\n그림 7.18: st_as_stars 함수를 활용한 백터 지오메트리의 래스터화\n\n\nst_as_stars 함수는 셀 크기, 셀 수 및/또는 범위를 제어하는 파라미터를 설정할 수 있다. 반환되는 셀 값은 지오메트리 밖에 중심점이 있는 셀의 경우는 0이고, 지오메트리 내부 또는 경계에 중심점이 있는 셀의 경우는 1이다. 기존 피처를 래스터화하는 것은 st_rasterize 함수를 사용하여 수행되며, 이는 그림 1.5에서도 볼 수 있다.\n\nlibrary(dplyr)\nread_sf(file) |&gt;\n    mutate(name = as.factor(NAME)) |&gt;\n    select(SID74, SID79, name) |&gt;\n    st_rasterize()\n# stars object with 2 dimensions and 3 attributes\n# attribute(s):\n#      SID74           SID79            name       \n#  Min.   : 0      Min.   : 0      Sampson :  655  \n#  1st Qu.: 3      1st Qu.: 3      Columbus:  648  \n#  Median : 5      Median : 6      Robeson :  648  \n#  Mean   : 8      Mean   :10      Bladen  :  604  \n#  3rd Qu.:10      3rd Qu.:13      Wake    :  590  \n#  Max.   :44      Max.   :57      (Other) :30952  \n#  NA's   :30904   NA's   :30904   NA's    :30904  \n# dimension(s):\n#   from  to offset   delta refsys point x/y\n# x    1 461  -84.3  0.0192  NAD27 FALSE [x]\n# y    1 141   36.6 -0.0192  NAD27 FALSE [y]\n\n라인과 포인트 지오메트리고 이와 유사하게 래스터화할 수 있다(그림 7.20).\n\nread_sf(file) |&gt;\n    st_cast(\"MULTILINESTRING\") |&gt;\n    select(CNTY_ID) |&gt;\n    st_rasterize() |&gt;\n    plot(key.pos = 4)\n\n\n\n\n\n\n그림 7.19: 노스캐롤라이나 카운티 경계를 래스터로 전환하기",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>sf와 stars</span>"
    ]
  },
  {
    "objectID": "05.html#애그리게이션과-서머라이즈",
    "href": "05.html#애그리게이션과-서머라이즈",
    "title": "5  속성과 서포트",
    "section": "\n5.2 애그리게이션과 서머라이즈",
    "text": "5.2 애그리게이션과 서머라이즈\n테이블 레코드의 합형은 다음의 두 간계를 통해 이루어진다.\n\n그룹 프리디케이트에 기반해 레코드를 분류하기\n합형 함수를 적용해 그룹별로 단일한 요약 속성값을 계산하기\n\nSQL에서 합형 과정은 다음의 예시처럼 이루어진다.\nSELECT GroupID, SUM(population) FROM table GROUP BY GroupID;\n여기서 합형 함수는 SUM이고 그룹 프리디케이트는 GroupID이다.\nR 패키지인 dplyr은 이를 수행하기 위해 두 단계를 사용한다. 함수 group_by는 레코드의 그룹 멤버십을 지정하고, summarise는 각 그룹에 대한 데이터 요약(예: 합계 또는 평균)을 계산한다. 베이스 R의 aggregate 함수는 테이블, 그룹화 조건, 및 집계 함수를 아규먼트로 받아 두 가지 작업을 단일 함수로 해결한다.\n노스캐롤라이나 카운티의 예는 그림 5.1에 나타나 있다. 타원 좌표 POINT(-79, 35.5)를 기준으로 사분면을 설정하고 카운티의 센트로이드가 어느 사분면에 위치하느냐에 따라 카운티를 그룹화하고, 각 그룹별로 질병 사례 수를 합산했다. 그 결과, 그룹별로 통합된 지오메트리가 생성되었음을 알 수 있다(3.2.6절 참조). 이러한 그룹별 합형은 필수적인데, 만일 카운티 지오메트리를 단순히 한데 묶어 MULTIPOLYGON을 생성했다면 수 많은 중복 경계가 생겨나 유효하지 않은 지오메트리가 생성되었을 것이기 때문이다(3.1.2절 참조).\n\n\n\n\n\n그림 5.1: SID74가 네 개의 지역별로 합산되었다.\n\n\n결합된 카운티 폴리곤을 지도로 나타내는 것은 기술적으로 아무런 문제가 없지만, 그룹 합계가 그룹화된 카운티에 관련된 것이 아니라 개별 카운티와 관련된 것이라는 잘못된 암시를 줄 수 있다. 이러한 방식의 합형의 특징은 각 레코드가 하나의 그룹에만 할당된다는 점이다. 이렇게 하면 그룹별 합계의 총합이 그룹화 이전 데이터의 총합과 동일하다는 장점이 있다. 즉, 정량적인 변수의 경우, 정보가 손실되거나 추가되는 일이 없다. 새로 형성된 기오메트리는 원 레코드의 지오메트리를 그룹에 의거해 유니온한 결과이다.\n\n\n\n\n\n그림 5.2: 노스케롤라이나 카운티 상의 타깃 블\n\n\n지오메트리의 결합 없이 그룹별 합산값을 산출할 필요가 있을 수 있다. 이 경우, 우리는 공간적 프리디케이트를 사용하는데, 하나의 레코드가 여러개의 그룹과 관련될 수 있다. 그림 5.2의 직사각형을 타깃 에어리어로 하여 직사각형별로 교차하는 카운티의 유병자를 합산하게 되면 전체 합계는 훨씬 더 큰 값을 갖게 될 것이다.\n#   sid74_sum_counties sid74_sum_rectangles \n#                  667                 2621\n반대로 contains 또는 covers와 같은 다른 프리디케이트를 사용하면 훨씬 더 적은 값이 산출된다. 왜냐하면 많은 카운티가 직사각형 속에 완전히 포함되지 않기 때문이다. 그러나 이러한 결과가 좋을 수 있는 상황도 충분히 존재할 수 있다.\n\nPOINT 지오메트리를 폴리곤에 의거해 합형하고자 하는 경우. 이 때 모든 포인트는 해당 포인트를 완전 포함하는 폴리곤에 할당된다. 만일 경계 상에 위치하게 되면 양쪽 폴리곤 모두에 할당된다(DE-9IM-기반 GEOG 라이브러리가 이러한 방식을 취한다. s2geometry 라이브러리는 “반-개방” 폴리곤을 지정할 수 있게 해주는데, 폴리곤의 중첩만 없다면, 반드시 하나의 폴리곤에 포인트를 할당해준다.\n매우 작은 폴리곤이나 래스터 픽셀을 더 큰 에어리어로 합역하는 경우. 예를 들어 노스케롤라이나에 대한 30m 해상도의 고도 데이터를 카운티별로 평균내는 경우가 해당될 수 있는데 다중 대응으로 인한 데이터 오류는 무시할 만하다.\n다대다 대응에 최대면적대응이 적용된 경우(그림 7.4 참조)\n\n보다 작은 에어리어를 보다 큰 에어리어로 합역하는 보다 포괄적인 접근 방법은 면적-가중 인터폴레이션(area-weighted interpolation)을 적용하는 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "08.html#sec-every",
    "href": "08.html#sec-every",
    "title": "8  공간데이터의 플로팅",
    "section": "",
    "text": "그림 8.1: 국가 경계: 왼쪽은 경위도를 xy 좌표로 선형 변환한 것이고(플라트 카레 도법), 오른쪽은 무한 거리에서 지구를 바라본 것 같은 방식으로 나타낸 것(정사 도법)이다.\n\n\n\n\n\n\n\n\n\n\n# [1] 51.14\n\n\n\n\n\n\n그림 8.2: 등장방형 도법이 적용된 독일. 왼쪽 지도의 단위는 도이고 정거원통 도법이 적용된 오른쪽 지도의 단위는 미터이다.\n\n\n\n8.1.1 데이터에 맞는 투영법 고르기\n안타깝게도 여기에는 만병통치약이 없다. 모든 지점에서 모든 방향으로 축척이 동일하게 유지되는 투영법은 없다. 오직 지구본만이 이 속성을 보유한다. 널리 사용되고 있는 투영법들은 다음 중 하나를 보존하려고 한다:\n\n면적: 정적 도법\n형태: 정형 도법(예: 메르카토르 도법)(역자주: 형태가 유지되기 위해서는 각도가 유지되어야 하기 때문에 정각 도법이라고도 부른다.)\n거리의 일부 속성 (등장방형 도법은 모든 지점에 경선 방향으로 정거성을 보존하고, 정거방위 도법은 투영 원점에서 모든 방향으로 거리를 보존한다.)\n\n또는 어떤 도법은 주로 두 개 속성의 절충점을 찾으려고 한다(역자주: 주로 면적과 형태를 절충하는데, 이런 도법을 절충 도법이라 부르고 대표적인 것에 로빈슨 도법과 빈켈 트리펠 도법이 있다). 투영 패러미터는 지도의 중앙과 가장자리에 어떤 지역이 위치하는지, 어떤 지역이 위쪽에 있고 어떤 지역이 아래쪽에 있는지, 그리고 어떤 지역이 가장 크게 확대되는지를 결정한다. 이러한 모든 선택이 합리적으로 이루어지도록 도와주는 가이드라인이 있기는 하지만, 절대적인 규준은 존재할 수 없기 때문에, 어떤 맥락에서는 정치적 결단과 유사할 수도 있다.\n다양한 투영법을 적용하고 결과를 비교해보는 것은 재밌기도 하고 교육적이기도 하다. 그러나 지도를 그리는 주된 목적이 투영법의 다양성에 대한 흥미 충족 및 지식 획득이 아니라면, 잘 알려져 있는 투영법 혹은 최소한 덜 생소한 투영법을 선택함으로써, 어떤 투영법을 선택할 것인가와 관련된 논의에 천착하기 보다는 선택된 투영법을 어떻게 적용할 것인가와 관련된 논의로 진전해 나가는 것이 더 바람직할 수 있다. 그러나 세계 지도를 위한 투영법으로 무엇인 좋은가에 대한 질문에는 어느 정도 합의된 대답이 존재한다. 거의 모든 경우에 있어, 정적 도법이 플라트 카레(Plate Carrée)(역자주: 등장방형 도법 혹은 적도를 표준위선으로 설정한 정거원통도법의 또 다른 이름이다.)나 웹 메르카토르 도법보다 선호된다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#포인트-라인-폴리곤-그리드-셀의-플로팅",
    "href": "08.html#포인트-라인-폴리곤-그리드-셀의-플로팅",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.2 포인트, 라인, 폴리곤, 그리드 셀의 플로팅",
    "text": "8.2 포인트, 라인, 폴리곤, 그리드 셀의 플로팅\n지도는 통계 데이터를 플로팅하는 특별한 형식으로 볼 수 있기 때문에, 플로팅의 일반적인 규칙이 지도에도 그대로 적용된다. 그렇지만 지도-특수적 문제는 존재하며, 여기에는 다음과 같은 것들이 있다.\n\n매우 작은 폴리곤은 경우, 플로팅하면 사라질 수 있다.\n데이터에 따라 지도 심볼이 서로 겹칠 수 있어서 어떤 심볼은 부분적으로만 보일 수 있다. 투명도를 조정하면 겹친 심볼을 식별하는 데 도움이 될 수 있다.\n포인트 피처나 포인트 심볼을 플로팅하는 경우, 포인트들이 쉽게 겹치고 다른 포인트 뒤에 완전히 가려질 수 있다. 커널 밀도 지도(11장)가 더 유용할 수 있다.\n라인 피처나 라인 심볼을 플로팅하는 경우, 라인에 부여된 색이 잘 분간되지 않을 수 있으며, 라인 너비와 상관없이 겹칠 수 있다.\n\n\n8.2.1 컬러\n컬러 심볼이 적용된 폴리곤을 플로팅하는 경우, 폴리곤 경계를 나타낼지 아니면 생략할지를 선택할 수 있다. 경계가 너무 눈에 띄면, 회색 톤이나 폴리곤 컬러와 충돌이 적은 다른 색상을 경계에 적용할 수 있다. 경계를 완전히 생략해 버리면, (거의) 동일한 컬러를 가진 폴리곤들을 시각적으로 구별할 수 없게 된다. 컬러가 서로 다른 토지 피복 유형을 표현한 것이라면, 경계의 생략이 큰 문제가 되지는 않는다. 그러나 컬러가 집계값(예를 들어 인구수)의 크기를 표현한 것이라면 지도 오독의 문제를 발생시킬 수 있다(역자주: 인구 1,000명 정도를 가진 폴리곤이 연접해 있을 때, 경계를 없애 버리면 마친 훨씬 넓은 지역의 인구가 여전히 1,000명인 것처럼 보여질 수 있다). 특히 인구 수와 같은 공간적으로 외연적인 속성의 경우, 이는 엄청난 오독의 가능성을 야기할 수 있다. 사실은, 공간적으로 외연적인 속성의 경우는 경계를 없애지 않는다 하더라도 폴리곤 내부를 컬러로 채우는 형태의 지도는 적절하지 않다. 왜냐하면 컬러가 폴리곤이 보유한 속성의 크기 뿐만 아니라 폴리곤의 면적도 함께 나타내기 때문이다(역자주: 이런 이유로 공간적으로 외연적인 속성은 코로플레스 맵이 아니라 도형표현도로 나타내는 것이 지도학적 합리성에 부합하는 것이다. 그러나 불행하게도 총합이나 총빈도를 코로플레스 맵으로 나타낸 지도가 인터넷에 넘쳐나고 있다.).\n컬러의 단절이 없는 연속형 컬러 스킴은 연속형 공간 현상(역자주: 어디에나 존재하는 속성으로 예를 들어 기온)을 표현하는데 빈번히 사용되고 있는데, 지도학적 실용성보다는 시각적 매력도가 우선시되는 경우가 많다.\n\n지도 상의 특정 컬러와 범례 상의 특정 값을 일치시키는 것은 인간의 시각 능력을 고려할 때 큰 실용성이 없다(역자주: 연속형 컬러 스킴을 적용한다는 것은 미세한 컬러의 차이에 의거해 미세한 값의 차이를 분간하라는 것인데, 효과적인 정보 전달이라는 측면에서 큰 지도학적 실효성이 없다).\n컬러의 범위와 값의 범위가 비선형적으로 연결되는 경우가 많기 때문에, 값의 상대적인 차이를 분간하기 어렵게 만든다.\n\n값의 식별보다는 공간적 현상의 연속성의 재현이 더 중요한 경우에 한하여 연속형 컬러 스킴의 적용이 정당성을 획득할 수 있다. 대표적인 예가 고해상도 디지털 지형 모델을 채색을 통해 시각화하는 경우이다. 좋은 컬러 스킴과 팔레트는 hcl.colors 또는 palette.colors 함수에서 찾을 수 있으며, RColorBrewer(Neuwirth 2022), viridis(Garnier 2021), 또는 colorspace(Ihaka et al. 2023; Zeileis et al. 2020)와 같은 패키지에서도 찾아볼 수 있다.\n\n8.2.2 컬러 단절값: classInt\n\n연속적인 공간적 속성을 제한된 컬로(또는 기호)를 사용해 플로팅하려고 하면, 데이터를 몇 개의 계급으로 구분하여야 한다. R 패키지인 classInt (Bivand 2022)는 이를 수행할 수 있는 여러 방법을 제공한다. 디폴트는 “등개수분류법(quantile)”이다.\n\nlibrary(classInt)\n# set.seed(1) if needed ?\nr &lt;- rnorm(100)\n(cI &lt;- classIntervals(r))\n# style: quantile\n#   one of 1.49e+10 possible partitions of this variable into 8 classes\n#   [-2.29,-1.27)  [-1.27,-0.698) [-0.698,-0.426) [-0.426,-0.147) \n#              13              12              13              12 \n#  [-0.147,0.129)    [0.129,0.47)     [0.47,1.06)      [1.06,2.1] \n#              12              13              12              13\ncI$brks\n# [1] -2.290 -1.272 -0.698 -0.426 -0.147  0.129  0.470  1.059  2.105\n\n이 함수의 n 아규먼트를 통해 계급의 수를 설정할 수 있고, style 아규먼트를 통해 서로다른 계급구분 방식을 선택할 수 있다. 사용가능한 옵션에 “fixed”, “sd”, “equal”, “pretty”, “quantile”, “kmeans”, “hclust”, “bclust”, “fisher”, 또는 “jenks”가 있다. n이 지정되었다 하더라도 “pretty”를 선택하면 무효화될 수 있고, n이 제공되지 않으면 nclass.Sturges가 사용된다. 자동으로 n을 선택할 수 있는 두 가지 다른 방법도 있다. 관측값의 수가 3000개를 초과하는 경우, “fisher”와 “jenks”의 경우 10% 샘플이 사용되어 계급을 생성한다.\n\n8.2.3 그래티큘 및 관련 요소\n그래티큘은 일정한 위도 또는 경도를 따라 지도상에 그으진 선의 네트워크이다. 그림 1.1에서는 회색으로 그려져 있고, 그림 1.2에서는 흰색으로 그려져 있다. 그래티큘은 기본적으로 위치에 대한 참조물로서 지도에 그려진다. 그림 1.1의 첫 번째 지도에서는 플로팅된 지역이 북위 35도, 서경 80도 근처에 있음을 읽을 수 있다. 투영 좌표에 기반한 그래티큘은 모든 선이 직선으로 나타나고 좌표값이 특정 지점으로부터의 거리를 나타내므로 경위도 그래티큘에 비해 쓰임새가 크지 않다(역자주: 통상적으로 투영 좌표에 기반한 격자망은 그래티큘이라 부르지 않고 그리드(grid)라고 부른다). 그래도 독도자가 이러한 그래티큘에 익숙하고 좌표값의 단위가 주어져 있다면, 크기나 거리를 해석하는데 도움을 줄 수 있을 것이다. 그래티큘의 형태는 사용된 투영법의 특성을 반영한다. 따라서 그래트큘을 통해 투영법에 대한 정보를 얻을 수 있다. 등장방형 도법이나 메르카토르 도법은 수직선 및 수평선을 가지며, 원추 도법은 직선이지만 간격이 넓어지는 경선(meridian)을 가지며, 많은 정적 도법에서 경선은 곡선으로 나타난다(역자주: 이것은 지나친 일반화이다. 세계 전체를 나타내는 타원형 형태의 정적 도법(예를 들어: 에케르트 IV 도법)에서 경선이 곡선으로 표현되긴 하지만, 원통 도법(정축의 경우)에서는 경위선이 모두 직선으로 나타난다).\n그림 8.1과 대부분의 다른 지도들에서, 실제적인 참조물 구실을 하는 것은 그래티큘이라기 보다는 주 경계, 국가 경계, 해안선, 강, 도로, 철도 등과 같은 지리적 사상들이다. 이러한 요소들이 지도상에 적절히 배치된다면 그래티큘은 생략하는 것이 좋다. 그래티큘이 생략되면 일반적인 플롯의 중요 구성요소인 축, 눈금, 레이블이 사라지므로, 실질적인 지도 데이터로 채울 수 있는 많은 플로팅 공간이 남겨지게 된다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#베이스-plot",
    "href": "08.html#베이스-plot",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.3 베이스 plot\n",
    "text": "8.3 베이스 plot\n\nsf 및 stars 객체에 적용되는 plot 메서드는 유용한 데이터 탐색용 플롯을 빠르고 간편하게 만들 수 있게 해준다. 더 높은 품질과 더 높은 사용자 자율성을 원한다면, ggplot2(Wickham et al. 2022), tmap(Tennekes 2022, 2018) 또는 mapsf(Giraud 2022)와 같은 패키지를 활용하면 된다.\nplot 메서드의 디폴트는 주어진 “모든 것”을 플로팅한다는 것이다. 이는 다음을 의미한다.\n\n지오메트리만 주어지면(sfc), 색상 없이 지오메트리만 플로팅된다.\n지오메트리와 속성이 함께 주어지면, 속성 값에 따라 지오메트리에 컬러가 부여된다. factor 또는 logical 속성에는 질적인 컬러 스킴이 적용되고, 그 외에는 연속적 컬러 스킴이 적용되며 컬러에 대한 범례가 추가된다.\n여러 속성이 주어지면, 여러 개의 지도가 플로팅된다. 색상 할당이 각 하위 지도별로 이루어지기 때문에 지도마다 다른 컬러 스킴이 적용된다. 디폴트로 범례는 생략된다.\n여러 속성을 가진 stars 객체의 경우, 첫 번째 속성만 플로팅되며, 3차원 래스터 큐브의 경우, 세 차원 상의 모든 슬라이스가 하위 플롯으로 플로팅된다.\n\n\n8.3.1 플롯에 범례 첨가하기\nstars 및 sf 객체의 plot 메서드는 플롯 영역의 한쪽에 컬러 범례를 나타낼 수 있다(그림 1.1). base::plot 함수는 이를 위해 플롯 영역을 두 개로 나누고 두 개의 플롯을 생성한다. 당연히 하나는 지도이고, 다른 하나는 범례이다. plot 함수는 디폴트로 그래픽 장치를 초기화하는데(layout(matrix(1)) 이는 이후에 생성되는 플롯이 장치가 둘로 나누어지는 것에 의해 방해받지 않도록 하려는 것이다. 하지만, 이것은 만들어진 플롯에 그래픽 요소를 추가하는 것을 불가능하게 한다. 색상 범례가 있는 기존 플롯에 추가하려면 plot 명령에서 reset = FALSE를 사용하여 장치 초기화를 방지하고, 이후 plot 호출에서는 add = TRUE를 사용해야 한다. 그림 8.3에 예시가 나타나 있다.\n\nlibrary(sf)\nnc &lt;- read_sf(system.file(\"gpkg/nc.gpkg\", package = \"sf\"))\nplot(nc[\"BIR74\"], reset = FALSE, key.pos = 4)\nplot(st_buffer(nc[1,1], units::set_units(10, km)), col = 'NA', \n     border = 'red', lwd = 2, add = TRUE)\n\n\n\n\n\n\n그림 8.3: 범례가 있는 베이스 플롯에 주석 달기\n\n\n단일한 stars 레이어가 표시되는 경우, stars 플롯에 주석을 추가하는 것은 동일한 방식으로 이루어진다. 여러 큐브 슬라이스가 있는 stars 패싯 플롯에 주석을 추가하려면, “후크(hook)” 함수를 추가하면 되는데, 이 후크 함수는 모든 슬라이스에서 개별적으로 호출되어야 한다. 이는 다음과 같이 수행할 수 있으며 결과가 그림 8.4에 나타나 있다.\n\nlibrary(stars)\n# Loading required package: abind\nsystem.file(\"tif/L7_ETMs.tif\", package = \"stars\") |&gt;\n    read_stars() -&gt; r\nst_bbox(r) |&gt; st_as_sfc() |&gt; st_sample(5) |&gt; \n    st_buffer(300) -&gt; circ\nhook &lt;- function() { \n    plot(circ, col = NA, border = 'yellow', add = TRUE)\n}\nplot(r, hook = hook, key.pos = 4)\n# downsample set to 1\n\n\n\n\n\n\n그림 8.4: 다중 슬라이스를 가진 stars 플롯에 주석 달기\n\n\n후크 함수는 패싯 파라미터, 패싯 레이블 및 바운딩 박스에 접근할 수 있다.\n베이스 plot 메서드는 화면 장치의 해상도에 접근할 수 있다. 따라서 stars 및 stars_proxy 객체에 대해 고밀도 래스터는 다운샘플링하여 가용 장치에 적합한 수준의 밀도로만 픽셀을 플로팅한다.\n\n8.3.2 베이스 플롯의 투영법\n베이스 plot 메서드는 타원체 좌표를 가진 데이터의 경우 등장방형 도법을 이용해 데이터를 플로팅하는데(그림 8.2), 표준 위선의 파라미터 값으로 경계 상자의 중간 위도를 디폴트로 사용한다. 이 파라미터 값을 제어하려면, 플로팅 전에 다른 파라미터 값을 가진 등장방형 도법을 적용하거나, 파라미터 asp를 직접 설정함으로써 디폴트를 해제하면 된다(asp=1은 플라트 카레 도법(그림 8.1 왼쪽)의 지도를 생성하게 된다). 기존 플롯에 차후의 플롯을 중첩하는 것이 의미가 있으려면, 후속 플롯에 동일한 CRS가 적용되어 있어야 한다. 베이스 plot 메서드는 동일 CRS의 여부를 체크하지 않는다.\n\n8.3.3 컬러와 컬러 단절값\n베이스 plot에서, nbreaks 아규먼트는 컬러 단절값의 수를 설정하는 데 사용되며, breaks 아규먼트는 실제 컬러 단절값을 포함한 수치 벡터를 설정하거나 classInt::classIntervals의 style 아규먼트에 대한 스타일 값을 지정하는데 사용된다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#ggplot2-패키지로-지도-그리기",
    "href": "08.html#ggplot2-패키지로-지도-그리기",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.4 ggplot2 패키지로 지도 그리기",
    "text": "8.4 ggplot2 패키지로 지도 그리기\nggplot2 패키지(Wickham 외, 2022; Wickham, 2016)는 더 복잡하고 보기 좋은 그래프를 만들 수 있다. 이 패키지에는 sf의 개발과 함께 발전된 geom_sf라는 지오메트리 객체가 있으며, 아름다운 지도를 만드는 데 도움을 준다. 이에 대한 소개는 Moreno와 Basille(2018)에서 찾을 수 있다. 첫 번째 예시는 그림 1.2에 나와 있으며, 이 플롯에 사용된 코드는 다음과 같다.\n\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nnc.32119 &lt;- st_transform(nc, 32119) \nyear_labels &lt;- \n    c(\"SID74\" = \"1974 - 1978\", \"SID79\" = \"1979 - 1984\")\nnc.32119 |&gt; select(SID74, SID79) |&gt; \n    pivot_longer(starts_with(\"SID\")) -&gt; nc_longer\n\n\nggplot() + geom_sf(data = nc_longer, aes(fill = value), linewidth = 0.4) + \n  facet_wrap(~ name, ncol = 1, \n             labeller = labeller(name = year_labels)) +\n  scale_y_continuous(breaks = 34:36) +\n  scale_fill_gradientn(colours = sf.colors(20)) +\n  theme(panel.grid.major = element_line(colour = \"white\"))\n\n코드를 살펴보면, 패싯(facet) 형태의 플롯팅을 위해 사전에 두 개의 속성을 스택(pivot_longer) 했다는 것을 알 수 있다. 이것이 “타이디” 데이터의 핵심 개념이며, sf 객체에 대한 pivot_longer 메서드는 지오메트리 열도 자동으로 스택한다.\nggplot2는 그래픽 객체를 먼저 생성한 후 플롯팅하기 때문에, 모든 요소의 CRS를 제어할 수 있으며, 이후의 모든 객체를 첫 번째 객체의 CRS로 변환하거나 전환한다. 또한, 회색 배경 위의 얇은 흰색 선(디폴트)으로 그래피큘을 나타내며, 특정한 데이텀(디폴트는 WGS84)를 사용한다. geom_sf는 다른 geom과 결합할 수 있으며, 이를 통해 플롯에 주석을 추가하는 등의 작업을 할 수 있다.\nstars 패키지의 경우, geom_stars가 존재하기는 하지만 책을 쓰고 있는 현 시점을 기준으로 말하자만 활용성이 다소 제한적인 상태에 있다. geom_stars는 지도 레이아웃과 벡터 데이터 큐브에 대해서는 geom_sf를 사용하며, 규칙 래스터에 대해서는 geom_raster를, 직교 래스터에 대해서는 geom_rect를 추가적으로 사용한다. 사용자가 다운샘플링 비율을 지정하면 다운샘플링을 수행하지만, 화면 크기에 접근하여 자동으로 다운샘플링 비율을 선택하는 기능은 없다. 그러나 이 정도 기능만으로도 충분할 수 있으며, 예를 들어 그림 8.5는 다음 명령어로 생성되었다.\n\nlibrary(ggplot2)\nlibrary(stars)\nr &lt;- read_stars(system.file(\"tif/L7_ETMs.tif\", package = \"stars\"))\nggplot() + geom_stars(data = r) +\n        facet_wrap(~band) + coord_equal() +\n        theme_void() +\n        scale_x_discrete(expand = c(0,0)) + \n        scale_y_discrete(expand = c(0,0)) +\n        scale_fill_viridis_c()\n\n\n\n\n\n\n그림 8.5: ggplot2와 geom_stars로 제작된 단순 패싯 래스터 플롯\n\n\n더 정교한 ggplot2 기반의 stars 객체 플롯은 ggspatial 패키지(Dunnington, 2022)를 사용하여 제작할 수 있다. 보다 고품질의 지도를 만드는 옵션에 tmap 패키지가 있다. 이를 이용하면 ggplot2와 호환되지는 않지만 형식적으로 ggplot2과 유사한 스타일의 지도를 생성할 수 있다(8.5절).",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#tmap-패키지로-지도-그리기",
    "href": "08.html#tmap-패키지로-지도-그리기",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.5 tmap 패키지로 지도 그리기",
    "text": "8.5 tmap 패키지로 지도 그리기\ntmap 패키지(Tennekes, 2022, 2018)는 R에서 공간데이터를 플로팅하는 신선한 접근을 시도한다. 이 패키지는 grid 패키지를 기반으로 그래픽 객체를 먼저 구성한 후 출력하며, 지도 요소를 + 기호로 연결하는 방식에서 ggplot2와 유사하지만, 그 외에는 ggplot2와 완전히 독립적이고 호환되지 않는다. 이 패키지는 매우 전문적인 지도를 만들 수 있는 다양한 옵션을 제공하며, 많은 디폴트 설정도 신중하게 선택되었다. 두 개의 유사한 속성을 가진 지도를 한꺼번에 만들 수 있는데, tm_polygons 함수에 두 속성을 동시에 지정하면 된다.\n\nlibrary(tmap)\nsystem.file(\"gpkg/nc.gpkg\", package = \"sf\") |&gt;\n    read_sf() |&gt; st_transform('EPSG:32119') -&gt; nc.32119\ntm_shape(nc.32119) + \n    tm_polygons(c(\"SID74\", \"SID79\"), title = \"SIDS\") +\n    tm_layout(legend.outside = TRUE, \n              panel.labels = c(\"1974-78\", \"1979-84\")) +\n    tm_facets(free.scales=FALSE)\n\n\n\n\n\n\n그림 8.6: tmap: tm_polygon() 함수에 두 개의 속성을 동시에 지정하여 플로팅하기\n\n\n또는, pivot_longer로 얻은 긴 테이블 형태의 데이터를 + tm_polygons(\"SID\") + tm_facets(by = \"name\")를 적용하면 동일한 지도를 생성할 수 있다.\ntmap 패키지는 또한 stars 객체를 지원하며, 아래에 예시가 그림 8.7에 나타나 있다.\n\ntm_shape(r) + tm_raster()\n\n\n\n\n\n\n그림 8.7: tmap을 활용하여 제작된 단순한 래스터 플롯\n\n\ntmap 패키지를 활용해 제작된 더 많은 사례 지도가 14~16장에 제시되어 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#인터렉티브-지도-leaflet-mapview-tmap",
    "href": "08.html#인터렉티브-지도-leaflet-mapview-tmap",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.6 인터렉티브 지도: leaflet, mapview, tmap",
    "text": "8.6 인터렉티브 지도: leaflet, mapview, tmap\n그림 1.3에 나타나 있는 것과 같은 인터렉티브 지도는 R 패키지인 leaflet, mapview 또는 tmap을 사용하여 생성할 수 있다. mapview 패키지는 leaflet 패키지가 제공하는 기본 기능에 여러 기능을 추가하는데, 맵 범례, 피처 클릭 팝업 창의 조정, 래스터 데이터 지원, FlatGeobuf 파일 형식의 대용량 피처 세트를 위한 축척조정형(scalable) 맵, 그리고 줌 및 팬 작업에 동기화하여 반응하는 패싯 맵과 같은 기능들이다. tmap 패키지는 다음을 제공하는 옵션이 있다.\ntmap 패키지는 두 가지 모드를 제공하는 데, 다음과 같이 “view” 지정을 하면 모든 tmap 명령이 상호작용형 html/leaflet 위젯에 적용된다.\n\ntmap_mode(\"view\")\n\n그런데 “plot” 지정을 하면, 모든 산출물이 원래대로 R의 (정적인) 그래픽 장치로 보내진다.\n\ntmap_mode(\"plot\")",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#연습문제",
    "href": "08.html#연습문제",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.7 연습문제",
    "text": "8.7 연습문제\n\n인도네시아와 캐나다에 대해 등장방형(equirectangular) 도법, 정사(orthographic) 도법, 그리고 람베르트 정적원추(Lambert azimuthal equal area) 도법이 적용된 지도 플롯을 생성하라. 각 투영법에 대해 해당 국가에 적절한 투영 파라미터를 선택하라.\n그림 8.3의 플롯을 ggplot2 패키지와 tmap 패키지를 각각 사용하여 재생성하라.\n그림 8.7의 플롯을 viridis 색상 램프를 사용하여 재성성하라.\ntmap의 “view” (상호작용) 모드를 사용하여 그림 8.7을 인터랙티브 플롯으로 재생성하고 어떤 상호작용이 가능한지 탐색하라. 또한 + tm_facets(as.layers=TRUE)를 추가한 후, 레이어를 켜고 끄는 것을 해보라. 투명도 값을 0.5로 설정해 보라.\n\n\n\n\n그림 8.1: 국가 경계: 왼쪽은 경위도를 xy 좌표로 선형 변환한 것이고(플라트 카레 도법), 오른쪽은 무한 거리에서 지구를 바라본 것 같은 방식으로 나타낸 것(정사 도법)이다.\n그림 8.2: 등장방형 도법이 적용된 독일. 왼쪽 지도의 단위는 도이고 정거원통 도법이 적용된 오른쪽 지도의 단위는 미터이다.\n그림 8.3: 범례가 있는 베이스 플롯에 주석 달기\n그림 8.4: 다중 슬라이스를 가진 stars 플롯에 주석 달기\n그림 8.5: ggplot2와 geom_stars로 제작된 단순 패싯 래스터 플롯\n그림 8.6: tmap: tm_polygon() 함수에 두 개의 속성을 동시에 지정하여 플로팅하기\n그림 8.7: tmap을 활용하여 제작된 단순한 래스터 플롯",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "09.html",
    "href": "09.html",
    "title": "9  대용량 데이터와 클라우드 네이티브",
    "section": "",
    "text": "9.1 벡터 데이터: sf",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>대용량 데이터와 클라우드 네이티브</span>"
    ]
  },
  {
    "objectID": "09.html#벡터-데이터-sf",
    "href": "09.html#벡터-데이터-sf",
    "title": "9  대용량 데이터와 클라우드 네이티브",
    "section": "",
    "text": "9.1.1 로컬 디스크로부터 불러오기\nst_read 함수는 GDAL을 사용하여 디스크에서 벡터 데이터를 읽은 후, 해당 데이터를 작업 메모리에 유지한다. 파일이 너무 커서 작업 메모리에 모두 로드할 수 없을 경우, 파일의 일부만 읽는 여러 가지 옵션이 존재한다. 첫 번째 방법은 wkt_filter 아규먼트에 지오메트리 정보를 포함한 WKT 텍스트 문자열을 설정하는 것이다. 이 경우, 해당 지오메트리와 교차하는 타깃 파일의 지오메트리 정보만 반환된다. 아래에 사례가 있다.\n\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\nfile &lt;- system.file(\"gpkg/nc.gpkg\", package = \"sf\")\nc(xmin = -82,ymin = 36, xmax = -80, ymax = 37) |&gt;\n    st_bbox() |&gt; st_as_sfc() |&gt; st_as_text() -&gt; bb\nread_sf(file, wkt_filter = bb) |&gt; nrow() # out of 100\n# Re-reading with feature count reset from 17 to 16\n# [1] 16\n\n여기에서는 st_read 대신 read_sf가 사용되었는데, 출력을 억제하기 위해서이다.\n두 번째 옵션은 st_read의 query 아규먼트를 사용하는 것으로, 이는 “OGR SQL”로 작성된 어떤 쿼리도 다 가능하다. 예를 들어, 특정 레이어에서 피처를 선택하거나 필드를 제한하는데 사용될 수 있다. 아래에 사례가 있다.\n\nq &lt;- \"select BIR74,SID74,geom from 'nc.gpkg' where BIR74 &gt; 1500\"\nread_sf(file, query = q) |&gt; nrow()\n# [1] 61\n\nnc.gpkg는 레이어 이름이며, 이는 st_layers를 사용하여 파일에서 확인할 수 있다. 레코드의 시퀀스는 LIMIT과 OFFSET을 사용하여 읽을 수 있으며, 51-60번째 레코드를 읽으려면 다음과 같이 한다.\n\nq &lt;- \"select BIR74,SID74,geom from 'nc.gpkg' LIMIT 10 OFFSET 50\"\nread_sf(file, query = q) |&gt; nrow()\n# [1] 10\n\n추가적인 쿼리 옵션으로는 지오메트리 유형 또는 폴리곤 면적을 기준으로 선택하는 것이 있다. 쿼리되는 데이터셋이 공간 데이터베이스인 경우, 해당 쿼리는 GDAL이 해석하지 않고 데이터베이스로 전달된다. 이는 더 강력한 기능을 사용할 수 있음을 의미한다. 자세한 정보는 GDAL 문서의 “OGR SQL 방언(dialect)” 부분에서 확인할 수 있다.\n대용량 파일이나 디렉터리가 압축되어 있는 경우, /vsizip(Zip 파일), /vsigzip(Gzip 파일), 또는 /vsitar(Tar 파일) 접두사를 파일 경로 앞에 붙여 압축을 풀지 않고도 파일을 읽을 수 있다. 압축 파일의 종류에 따라 접두어를 쓰고, 그 다음에 zip 파일의 경로를 쓰고, 그 다음에 압축 파일 내 해당 파일의 이름을 쓰면 된다. 이런 방식으로 파일을 읽으면 컴퓨팅 자원을 더 많이 소모할 수 있다.\n\n9.1.2 데이터베이스로부터 불러오기, dbplyr\nGDAL은 여러 공간 데이터베이스를 지원하며, 앞서 언급한 바와 같이 query 아규먼트에 포함된 SQL 문을 데이터베이스에 전달하지만, DBI R 데이터베이스 드라이버를 사용하여 공간 데이터베이스에 직접 읽고 쓰는 것이 유리한 경우도 있다. 이러한 예시는 다음과 같다.\n\npg &lt;- DBI::dbConnect(\n    RPostgres::Postgres(),\n    host = Sys.getenv(\"DB_HOST\"),\n    user = Sys.getenv(\"DB_USERNAME\"),\n    dbname = \"postgis\")\nread_sf(pg, query = \n        \"select BIR74,wkb_geometry from nc limit 3\") |&gt; nrow()\n# [1] 3\n\n여기에서, 데이터베이스 호스트와 사용자 이름은 환경 변수에서 가져오고, 데이터베이스 이름은 postgis이다.\n공간 쿼리는 보통 아래와 같은 모습이다.\n\nq &lt;- \"SELECT BIR74,wkb_geometry FROM nc WHERE \\\nST_Intersects(wkb_geometry, 'SRID=4267;POINT (-81.50 36.43)');\"\nread_sf(pg, query = q) |&gt; nrow()\n# [1] 1\n\n여기서, 인터섹션 연산은 데이터베이스 내에서 수행되며, 공간 인덱스가 존재할 경우 이를 사용한다. 데이터베이스 백엔드를 사용하여 dplyr을 활용할 때도 동일한 메커니즘이 작동한다.\n\nlibrary(dplyr, warn.conflicts = FALSE)\nnc_db &lt;- tbl(pg, \"nc\")\n\ndplyr 문법 속에서 공간 쿼리가 작성될 수 있으며, 해당 쿼리는 데이터베이스로 전달된다.\n\nnc_db |&gt; \n     filter(ST_Intersects(wkb_geometry, \n                        'SRID=4267;POINT (-81.50 36.43)')) |&gt;\n     collect()\n# # A tibble: 1 × 16\n#   ogc_fid  area perimeter cnty_ cnty_id name  fips  fipsno cress_id\n#     &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;    &lt;int&gt;\n# 1       1 0.114      1.44  1825    1825 Ashe  37009  37009        5\n# # ℹ 7 more variables: bir74 &lt;dbl&gt;, sid74 &lt;dbl&gt;, nwbir74 &lt;dbl&gt;,\n# #   bir79 &lt;dbl&gt;, sid79 &lt;dbl&gt;, nwbir79 &lt;dbl&gt;,\n# #   wkb_geometry &lt;pq_gmtry&gt;\nnc_db |&gt; filter(ST_Area(wkb_geometry) &gt; 0.1) |&gt; head(3)\n# # Source:   SQL [3 x 16]\n# # Database: postgres  [edzer@localhost:5432/postgis]\n#   ogc_fid  area perimeter cnty_ cnty_id name   fips  fipsno cress_id\n#     &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;    &lt;int&gt;\n# 1       1 0.114      1.44  1825    1825 Ashe   37009  37009        5\n# 2       3 0.143      1.63  1828    1828 Surry  37171  37171       86\n# 3       5 0.153      2.21  1832    1832 North… 37131  37131       66\n# # ℹ 7 more variables: bir74 &lt;dbl&gt;, sid74 &lt;dbl&gt;, nwbir74 &lt;dbl&gt;,\n# #   bir79 &lt;dbl&gt;, sid79 &lt;dbl&gt;, nwbir79 &lt;dbl&gt;,\n# #   wkb_geometry &lt;pq_gmtry&gt;\n\n(참고로, PostGIS의 ST_Area 함수는 nc의 AREA 필드와 동일한 면적을 계산하는데, 사실 아무런 의미가 없는 값이다. 왜냐하면 경위도 좌표를 마치 투영 좌표로 취급하여 계산한 면적이기 때문이다.)\n\n9.1.3 온라인 리소스 혹은 웹 서비스로부터 불러오기\nGDAL 드라이버는 URL이 https://로 시작하는 온라인 리소스에서 읽는 것을 지원하며, 이때 URL 앞에 /vsicurl/을 붙인다. 특정 클라우드에 특화된 유사한 드라이버도 여러 가지가 있으며, Amazon S3의 경우 /vsis3/, Google Cloud Storage의 경우 /vsigs/, Azure의 경우 /vsiaz/, Alibaba Cloud의 경우 /vsioss/, OpenStack Swift Object Storage의 경우 /vsiswift/를 사용한다. /vsicurl/을 사용하는 예시는 9.3.2절에 있다.\n위의 접두사와 /vsizip/를 결합하면 압축된 온라인 리소스에서 파일을 읽을 수 있다. 파일 형식에 따라 다르겠지만, 보통 이런 방식으로 정보를 읽으면 파일 전체를 읽어야 하거나 심지어 여러 번 읽어야 할 수 있으며, 항상 리소스를 처리하는 가장 효율적인 방법이 아닐 수도 있다. 클라우드 네이티브 포맷은 HTTP 리퀘스트에 효과적으로 작동하도록 최적화되어 있다.\n\n9.1.4 API, OpenStreetMap\n지리공간 데이터를 위한 웹 서비스는 사용자의 요청에 따라 데이터를 실시간으로 생성하고 이를 API를 통해 접근할 수 있게 해준다. 예를 들어, OpenStreetMap의 데이터는 GDAL 벡터 드라이버와 같은 것을 통해 일괄 다운로드하여 로컬에서 활용하는 것이 가능하다. 그러나 사용자는 보통 일부 데이터만을 얻고자 하거나 소규모 쿼리에 데이터를 사용하고자 한다. OpenStreetMap 데이터를 쿼리하는 여러 R 패키지가 존재한다.\n\nOpenStreetMap 패키지(Fellows와 Jan Peter Stotz의 JMapViewer 라이브러리, 2019)는 데이터를 래스터 타일로 다운로드하며, 보통 다른 피처를 플로팅하는 배경 또는 참조로 사용된다.\nosmdata 패키지(Mark Padgham 외, 2017)는 sf 또는 sp 형식의 포인트, 라인 또는 폴리곤으로 벡터 데이터를 다운로드한다.\nosmar 패키지(CRAN 아카이브에서 다운로드 가능)는 벡터 데이터를 반환하지만, 도로 요소가 어떻게 연결되어 있는지를 포함한 네트워크 토폴로지(igraph 객체 형태)도 제공하며, 최단 경로를 계산하는 함수도 포함되어 있다.\n\n올바르게 구성된 API 호출이 URL의 형태로 주어지면, 세세한 옵션 설정이 가능한 GDAL OSM 드라이버(st_read 함수에서 사용 가능)가 “.osm” 파일(xml)을 읽고 다음과 같은 다섯 개의 레이어가 포함된 데이터 세트를 반환한다. 중요 태그를 가진 points, 면적이 없는 “way” 피처를 가진 lines, “relation” 피처를 가진 multilinestrings, “relation” 피처를 가진 miltipolygons, 그리고 other_relations. 다음은 매우 작은 영역에 대한 단순한 OpenStreetMap에 대한 쿼리의 사례를 보여준다.\n\ndownload.file(paste0(\"https://openstreetmap.org/api/0.6/map?\",\n       \"bbox=7.595,51.969,7.598,51.970\"),\n    \"data/ms.osm\", method = \"auto\")\n\n다운로드된 파일로부터 lines 레이어를 읽어 첫 번째 속성을 아래와 같이 플롯할 수 있다(그림 9.1).\n\no &lt;- read_sf(\"data/ms.osm\", \"lines\")\np &lt;- read_sf(\"data/ms.osm\", \"multipolygons\")\nst_bbox(c(xmin = 7.595, ymin = 51.969, \n          xmax = 7.598, ymax = 51.970), crs = 'OGC:CRS84') |&gt;\n    st_as_sfc() |&gt;\n    plot(axes = TRUE, lwd = 2, lty = 2, cex.axis = .5)\nplot(o[,1], lwd = 2, add = TRUE)\nplot(st_geometry(p), border = NA, col = '#88888888', add = TRUE)\n\n\n\n\n\n\n그림 9.1: OpenStreetMap 벡터 데이터\n\n\nOverpass API는 OpenStreetMap 데이터에 대해 더 일반적이고 강력한 쿼리 기능을 제공한다.\n\n9.1.5 GeoParquet와 GeoArrow\n클라우드 네이티브 분석에 특화된 두 가지 포맷은 Apache 프로젝트인 Parquet와 Arrow에서 파생되었다. 두 형식 모두 테이블 데이터에 대한 컬럼 지향 스토리지를 제공하는데, 대부분의 다른 데이터베이스가 취하고 있는 레코드 지향 스토리지에 비해 많은 레코드에서 단일 필드를 읽어내는 속도가 빠르다. 두 형식의 Geo 확장에는 다음이 포함된다.\n\n지오메트리 컬럼을 저장하는 방법으로, WKB(well-known binary) 또는 WKT(well-known text)로 저장할 수 있으며, 서브 지오메트리가 미리 인덱스된 보다 효율적인 형식으로 저장할 수도 있다.\nCRS의 저장\n\n이 책을 쓰고 있는 시점 기준으로, 두 포맷 모두 활발히 개발 중이며, GDAL 버전 3.5부터는 이들을 읽거나 생성하기 위한 드라이버가 제공된다. 두 포맷 모두 압축 저장을 지원한다. 차이점은 (Geo)Parquet가 퍼시스턴트 스토리지(역자주: 데이터를 장기적으로 훼손없이 저장하는 방식)에 더 중점을 두고 있는 반면, (Geo)Arrow는 빠른 접근과 빠른 계산에 더 중점을 두고 있다는 것이다. 예를 들어, Arrow는 인메모리 포맷(역자주: 데이터를 주기억장치에 저장하여 처리하는 방식)과 온디스크 포맷(역자주: 데이터를 저장 매체에 저장하는 방식) 모두로 사용할 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>대용량 데이터와 클라우드 네이티브</span>"
    ]
  },
  {
    "objectID": "09.html#래스터-데이터-stars",
    "href": "09.html#래스터-데이터-stars",
    "title": "9  대용량 데이터와 클라우드 네이티브",
    "section": "\n9.2 래스터 데이터: stars\n",
    "text": "9.2 래스터 데이터: stars\n\n래스터 데이터셋을 다룰 때 발생하는 가장 일반적인 문제는 파일의 용량이 너무 크다는 점 뿐만 아니라(단일 Sentinel-2 타일은 약 1GB), 관심 있는 지역과 기간에 대한 데이터를 얻기 위해서는 수천 또는 수백만 개의 이러한 파일이 필요하다는 점이다. 2022년, Sentinel 위성 운영 프로그램인 Copernicus는 매일 160TB의 이미지 데이터를 산출했다. 이는 데이터를 로컬 디스크에 다운로드하고, 메모리에 로드한 다음, 분석하는 전통적인 R 사용 패턴은 더 이상 작동하지 않을 것임을 의미한다.\nGoogle Earth Engine (Gorelick et al. 2017), Sentinel Hub, 또는 openEO.cloud와 같은 클라우드 기반 지구 관측 프로세싱 플랫폼은 이러한 점을 인식하고 사용자가 페타바이트 범위의 데이터셋을 쉽게 다루고 상호작용할 수 있도록 해준다. 이러한 플랫폼은 다음과 같은 특성을 공유한다.\n\n계산은 가능한 한 늦게 수행된다(지연 평가)\n사용자가 요청한 데이터만 계산되고 반환되며, 그 이상은 하지 않는다.\n중간 결과를 저장하지 않고 즉석(on-the-fly) 계산을 선호한다.\n유용한 결과를 가진 지도가 신속하게 생성되고 표시되어 인터렉티브 모델 개발을 가능하게 한다.\n\n이것은 데이터베이스 및 클라우드 기반 분석 환경에 대한 dbplyr 인터페이스와 유사하지만, 우리가 무엇을 신속하게 보고자하는가에서 차이가 난다. dbplyr의 지연 테이블에서는 처음 n개의 레코드를 빨리 보고 싶어 하지만, 여기서는 결과에 대한 빠른 개요를 보고 싶어한다. 그것도 전체 지역 또는 일부 지역에 대한 지도 형식의 개요를 보고 싶어한다. 이를 위해 해상도는 손해본다(원본(관측) 해상도가 아닌 화면 해상도로 디스플레이 된다).\n예를 들어, 화면에서 미국의 결과를 “보고자” 할 때 1000 x 1000 픽셀의 해상도가 필요하다면, 이만큼의 픽셀에 대한 결과만 계산하면 된다. 이는 대략 3000m x 3000m 그리드 셀로 구성된 데이터에 해당한다. Sentinel-2 데이터의 경우 해상도가 10m이므로, 300배로 다운샘플링하여 3km x 3km 해상도로 작업할 수 있다. 이 경우, 기본 10m x 10m 해상도로 작업할 때와 비교하여 처리, 저장 및 네트워크 요구 사항이 \\(300^2\\approx10^5\\)배 줄어든다. 언급된 플랫폼에서는 지도를 확대하면 더 세밀한 해상도와 더 작은 범위에서 추가 계산이 촉발된다.\n이러한 원리에 따른 간단한 최적화 중 하나는 stars 객체의 플롯 방법이 작동하는 방식이다. 대용량 래스터를 플로팅할 경우, 플롯하기 전에 어레이를 다운샘플링하여 시간을 대폭 절약한다. 다운샘플링 정도는 플로팅 영역의 크기와 플로팅 해상도(픽셀 밀도)에 의거해 결정된다. PDF와 같은 벡터 장치의 경우, R은 플롯 해상도를 75 dpi로 설정하며, 이는 픽셀당 0.3mm에 해당한다. 플롯을 확대하면 이 사실이 드러날 수 있지만, 확대된 장치에 다시 플롯하면 목표 밀도로 플롯이 생성된다. geom_stars의 경우, 사용자가 downsample 비율을 지정해야 하는데, 이는 ggplot2의 해당 함수를 통해 장치 크기를 설정할 수 있는 방법이 없기 때문이다.\n\n9.2.1 stars 프록시 객체\n작업 메모리에 맞추기 어려울 만큼 큰 데이터셋을 처리하기 위해 stars는 stars_proxy 객체를 제공한다. 어떻게 사용하는지를 보여주기 위해, 대용량 데이터셋(총 약 1GB)을 포함한 R 데이터 패키지인 starsdata 패키지를 사용할 것이다. 이는 다음과 같이 설치할 수 있다.\n\noptions(timeout = 600) # or larger in case of slow network\ninstall.packages(\"starsdata\", \n  repos = \"http://cran.uni-muenster.de/pebesma/\", type = \"source\")\n\n다음과 같이 starsdata 패키지에서 Sentinel-2 이미지를 “불러올” 수 있다.\n\nlibrary(stars) |&gt; suppressPackageStartupMessages()\nf &lt;- paste0(\"sentinel/S2A_MSIL1C_20180220T105051_N0206\",\n           \"_R051_T32ULE_20180221T134037.zip\")\ngranule &lt;- system.file(file = f, package = \"starsdata\")\nfile.size(granule)\n# [1] 7.69e+08\nbase_name &lt;- strsplit(basename(granule), \".zip\")[[1]]\ns2 &lt;- paste0(\"SENTINEL2_L1C:/vsizip/\", granule, \"/\", base_name, \n    \".SAFE/MTD_MSIL1C.xml:10m:EPSG_32632\")\n(p &lt;- read_stars(s2, proxy = TRUE))\n# stars_proxy object with 1 attribute in 1 file(s):\n# $EPSG_32632\n# [1] \"[...]/MTD_MSIL1C.xml:10m:EPSG_32632\"\n# \n# dimension(s):\n#      from    to offset delta            refsys    values x/y\n# x       1 10980  3e+05    10 WGS 84 / UTM z...      NULL [x]\n# y       1 10980  6e+06   -10 WGS 84 / UTM z...      NULL [y]\n# band    1     4     NA    NA                NA B4,...,B8\nobject.size(p)\n# 12576 bytes\n\n이 과정에서 실제로는 픽셀 값을 전혀 불러오지 않으며, 데이터셋에 대한 참조를 유지하고 디멘션 테이블을 채울 뿐이다. (복잡한 s2 이름을 통해 .zip 파일 내의 115개 파일 중 무엇이 올바른 파일인지를 GDAL이 찾을 수 있도록 한다.)\n프록시 객체의 아이디어에 기반해 다음과 같은 표현식을 생성할 수 있다.\n\np2 &lt;- p * 2\n\n하지만 이 경우 계산은 미루어진다. 실제로 데이터가 필요할 때만 p * 2가 평가된다. 데이터가 필요할 때는 다음과 같다.\n\n데이터를 플롯할 때\nwrite_stars를 사용하여 객체를 디스크에 쓸 때\nst_as_stars를 사용하여 객체를 명시적으로 메모리에 불러올 때\n\n전체 객체를 담기에 메모리가 부족한 경우, plot과 write_stars는 이를 처리하기 위해 서로 다른 전략을 선택한다.\n\nplot은 모든 픽셀이 아닌 화면에 표시될 수 있는 픽셀만 다운샘플링하여 가져온다.\nwrite_stars는 데이터를 청크 단위로 읽고 처리한 후, 기록한다.\n\n\n\n\n\n\n그림 9.2: Sentinel-2의 10m 밴드를 다운샘플링한 경우\n\n\n고밀도 공간 이미지에 대해서는 다운샘플링과 청크 처리가 구현되지만, 고밀도 시계열이나 기타 고밀도 차원에 대해서는 구현되지 않는다. 예를 들어, 그림 9.2에 표시된 plot(p)의 출력은 각 밴드에서 사용할 수 있는 10,980 x 10,980 픽셀이 아닌, 플롯 장치에서 볼 수 있는 픽셀만 가져온다. 적용된 다운샘플링 비율은 다음과 같이 구할 수 있다.\n# [1] 19\n숫자가 의미하는 바는 원본 이미지의 19 x 19 서브 이미지마다 단 하나의 픽셀만 읽고 플롯되었다는 것이다.\n\n9.2.2 프록시 객체에 대한 오퍼레이션\nstars_proxy 객체를 위해 여러 전용 메소드가 제공된다.\n\nmethods(class = \"stars_proxy\")\n#  [1] [               [[&lt;-            [&lt;-             adrop          \n#  [5] aggregate       aperm           as.data.frame   c              \n#  [9] coerce          dim             droplevels      filter         \n# [13] hist            image           initialize      is.na          \n# [17] Math            merge           mutate          Ops            \n# [21] plot            predict         print           pull           \n# [25] rename          select          show            slice          \n# [29] slotsFromS3     split           st_apply        st_as_sf       \n# [33] st_as_stars     st_crop         st_dimensions&lt;- st_downsample  \n# [37] st_mosaic       st_normalize    st_redimension  st_sample      \n# [41] st_set_bbox     transmute       write_stars    \n# see '?methods' for accessing help and source code\n\n우리는 이미 plot과 print의 작동은 살펴보았고 dim은 차원 메타데이터 테이블에서 차원을 읽어온다.\n실제로 데이터를 가져오는 세 가지 메소드는 st_as_stars, plot, 그리고 write_stars이다. st_as_stars는 실제 데이터를 stars 객체로 읽어오며, 이때 downsample 아규먼트가 다운샘플링 비율을 제어한다. plot도 이 작업을 수행하며, 장치 해상도에 적합한 다운샘플링 값을 선택하고 객체를 플롯한다. write_stars는 stars_proxy 객체를 디스크에 기록한다.\nstars_proxy 객체를 위한 다른 모든 메소드는 래스터 데이터에 실질적으로 작용하는 것을 아니고, 객체에 연결된 작업 목록에 오퍼레이션을 추가하지만 한다. 실제 래스터 데이터가 불어와지면, 예를 들어 plot 또는 st_as_stars가 호출되면, 그 때 이 목록의 명령이 실행된다.\nst_crop는 읽힐 래스터의 범위(영역)를 제한한다. c는 stars_proxy 객체를 결합한다. 역시 실제 데이터를 결합하는 것은 아니다. adrop은 빈 차원을 제거하고, aperm은 차원 순서를 변경한다.\nwrite_stars는 입력을 청크 단위로 읽고 처리한다. 이 메소드는 사용자가 공간 청크의 크기를 제어할 수 있도록 해주는 chunk_size 아규먼트를 가진다.\n\n9.2.3 원격 래스터 리소스\n“클라우드 최적화 GeoTIFF”(COG)와 같은 포맷은 효율성과 자원 친화성을 염두에 두고 설계되었다. 예를 들어, 메타데이터만 읽거나 (전체 이미지를 낮은 해상도로 표시한) 오버뷰만 읽거나 /vsixxx/ 메커니즘을 사용하여 특정 공간 영역만을 읽는 데 유용하다(9.1.3절 참조). COG는 GDAL의 GeoTIFF 드라이버를 사용하여 생성할 수 있으며, write_stars 호출에서 적절한 데이터셋 생성 옵션을 설정하면 된다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>대용량 데이터와 클라우드 네이티브</span>"
    ]
  },
  {
    "objectID": "09.html#대용량-데이터-큐브",
    "href": "09.html#대용량-데이터-큐브",
    "title": "9  대용량 데이터와 클라우드 네이티브",
    "section": "\n9.3 대용량 데이터 큐브",
    "text": "9.3 대용량 데이터 큐브\n어떤 단계에서는 다운로드가 더 이상 실행 불가능할 정도로 큰 데이터셋을 분석해야 할 필요가 있다. 로컬 저장소가 충분하더라도 네트워크 대역폭이 제한적일 수 있다. 예를 들어, Landsat 및 Copernicus(Sentinel-x)의 위성 이미지 아카이브나, 1950년부터의 전 세계 대기, 육지 표면, 해양 파도를 모델링한 ERA5(기후 재분석 모델)와 같은 모델 재분석(reanalysis)이 있다(Hersbach et al. 2020). 이러한 경우, 해당 데이터가 제공되는 클라우드의 가상 머신에 접근하거나, 사용자가 가상 머신과 스토리지에 대해 걱정하지 않고 계산을 수행할 수 있도록 해주는 시스템을 사용하는 것이 가장 유용할 수 있다. 두 가지 옵션에 대해 논의할 것이다.\n\n9.3.1 검색과 처리\n클라우드의 가상 머신에서 작업할 때, 첫 번째 작업은 일반적으로 작업할 자산(파일)을 찾는 것이다. 파일 목록을 얻고, 그런 다음 다음과 같은 파일 이름을 파싱하는 것이 매력적으로 보인다.\nS2A_MSIL1C_20180220T105051_N0206_R051_T32ULE_20180221T134037.zip\n파싱은 획득 날짜와 공간 타일 코드 정보를 가지고 있는 메타데이터에 대해 이루어진다. 그러나 이러한 파일 목록을 얻는 것은 일반적으로 전산 부담이 매우 크며, 타일 수가 수백만 개에 달할 경우 결과를 처리하는 것도 마찬가지로 부담이 된다.\n이 문제에 대한 한가지 해결책은 카탈로그를 사용하는 것이다. 최근 개발되고 점점 더 많이 배포되는 STAC(Spatiotemporal Asset Catalogue의 약자)는 바운딩 박스, 날짜, 밴드, 구름 커버리지와 같은 속성으로 이미지 컬렉션을 쿼리하는 데 사용할 수 있는 API를 제공한다. R 패키지인 rstac(Simoes, Carvalho, Brazil Data Cube Team 2023)는 쿼리를 생성하고 반환된 정보를 관리하기 위한 R 인터페이스를 제공한다.\n결과 파일을 처리하는 과정에는 서로 다른 CRS(예: 여러 UTM 존)을 가진 이미지로부터 더 낮은 공간 및/또는 시간 해상도의 데이터 큐브를 생성하는 것이 포함될 수 있다. 이러한 이미지 컬렉션에서 규칙 데이터 큐브를 생성할 수 있는 R 패키지로 gdalcubes(Appel 2023; Appel and Pebesma 2019)가 있으며, STAC(Appel, Pebesma, Mohr 2021)를 직접 사용하여 이미지를 식별한다.\n\n9.3.2 클라우드 네이티브 스토리지: Zarr\nCOG가 래스터 이미지에 대한 클라우드 네이티브 스토리지를 제공하는 반면, Zarr은 대용량 다차원 어레이의 클라우드 네이티브 스토리지 포맷이다. Zarr은 NetCDF의 후속 포맷으로 볼 수 있으며, 기후 및 예측 커뮤니티에서 유사한 관례를 따르는 것으로 보인다(Eaton et al. 2022). Zarr “파일”은 실제로 데이터의 압축 청크를 포함하는 하위 디렉토리가 있는 디렉토리이다. 압축 알고리즘과 청크 전략은 특정 하위 큐브를 읽거나 쓰는 속도에 영향을 미칠 수 있다.\nstars::read_mdim 함수를 통해 전체 데이터 큐브를 읽을 수도 있지만, 옵션을 통해 하위 큐브를 읽을 수도 있다. 옵션은 각 차원별로 오프셋, 픽셀 수 및 낮은 해상도로 차원을 읽기 위한 스텝 사이즈 등을 지정할 수 있다(Pebesma 2022). 이와 유사하게, stars::write_mdim 함수를 통해 다차원 어레이를 다양한 포맷으로 쓸 수 있는데, Zarr 또는 NetCDF 파일, 또는 GDAL C++ 다차원 배열 API를 지원하는 다른 포맷이 가능하다.\n원격(클라우드 기반) Zarr 파일을 읽기 위해서는 URL 앞에 형식 및 접근 프로토콜에 대한 지시자를 추가해야 한다.\ndsn = paste0('ZARR:\"/vsicurl/https://ncsa.osn.xsede.org',\n       '/Pangeo/pangeo-forge/gpcp-feedstock/gpcp.zarr\"')\n그 후, 다음을 통해 첫 10개의 시간 스텝을 읽을 수 있다.\n\nlibrary(stars)\nbounds = c(longitude = \"lon_bounds\", latitude = \"lat_bounds\")\n(r = read_mdim(dsn, bounds = bounds, count = c(NA, NA, 10)))\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#               Min. 1st Qu. Median Mean 3rd Qu. Max.\n# precip [mm/d]    0       0      0 2.25     1.6  109\n# dimension(s):\n#           from  to     offset  delta refsys x/y\n# longitude    1 360          0      1     NA [x]\n# latitude     1 180        -90      1     NA [y]\n# time         1  10 1996-10-01 1 days   Date\nst_bbox(r)\n# xmin ymin xmax ymax \n#    0  -90  360   90\n\n이 예에서\n\ncount의 NA 값은 해당 차원에 대해 사용 가능한 모든 값을 가져오도록 한다는 것을 의미한다.\n여기서 bounds 변수는 데이터 소스가 더 최근의 CF (1.10) 규칙을 따르지 않았기 때문에 명시적인 지정이 필요했으며, bounds를 무시하면 [\\(-90,90\\)] 위도 범위를 벗어나는 바운딩 박스를 가진 래스터가 생성될 수도 있다.\n\n9.3.3 데이터 API: GEE, openEO\n클라우드에 존재하는 가상 머신에 대한 관리 및 프로그래밍 없이 이미지에 직접 접근할 수 있는 플랫폼으로는 GEE(구글 어스 엔진), openEO, 기후 데이터 스토어가 있다.\n구글 어스 엔진(GEE)은 대용량의 지구 관측 데이터와 모델링 제품에 사용자가 접근할 수 있게 해주는 클라우드 플랫폼이다(Gorelick et al. 2017). 이 플랫폼은 6.3절에서 설명된 데이터 큐브 작업을 포함한 강력한 분석 기능을 제공한다. GEE는 JavaScript와 Python 언어를 위한 인터페이스를 제공한다. GEE의 코드는 오픈소스가 아니며, Python이나 R과 같은 언어를 통한 사용자 정의 함수의 추가가 불가능하다. R 패키지인 rgee(Aybar 2022)는 GEE에 대한 R 클라이언트 인터페이스를 제공한다.\n온전히 오픈소스 소프트웨어로만 구축된 클라우드 기반 데이터 큐브 처리 플랫폼이 등장하고 있으며, 그 중 몇몇은 openEO API(Schramm et al. 2021)를 사용하고 있다. 이 API는 Python 또는 R로 작성된 사용자 정의 함수(UDF)를 허용하며, 이러한 함수는 API를 통해 전달되어 픽셀 수준에서 실행된다. 예를 들어, 사용자 정의 리듀서를 사용하여 차원을 애그리게이트하거나 축소할 수 있다. R의 UDF는 처리할 데이터 청크를 stars 객체로 표현하며, Python에서는 xarray 객체가 사용된다.\n기타 플랫폼으로는 Copernicus 기후 데이터 스토리지(Raoult et al. 2017)나 대기 데이터 스토리지가 있으며, 이들 플랫폼을 통해 ERA5를 포함한 ECMWF의 대기 및 기후 데이터를 처리할 수 있다. 두 데이터 스토리지에 대한 인터페이스를 제공하는 R 패키지는 ecmwfr(Hufkens 2023)이다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>대용량 데이터와 클라우드 네이티브</span>"
    ]
  },
  {
    "objectID": "09.html#연습문제",
    "href": "09.html#연습문제",
    "title": "9  대용량 데이터와 클라우드 네이티브",
    "section": "\n9.4 연습문제",
    "text": "9.4 연습문제\n다음 연습문제를 R을 사용하여 해결하시오.\n\nS2 이미지(위의 경우)에 대해 st_get_dimension_values()를 사용하여 밴드의 순서를 확인하고, 각 스펙트럴 밴드/색상이 무엇인지 알아보라.\nS2 이미지에 대해 st_apply함수와 적절한 ndvi 함수를 사용하여 NDVI를 계산하라. 결과를 화면에 플롯한 후, 결과를 GeoTIFF로 저장하라. 플로팅과 쓰기의 실행 시간 차이에 대해 설명하라.\nS2 이미지를 RGB 합성하여 플롯하라. 먼저 plot()의 rgb 아규먼트를 사용하고, 그 다음 st_rgb() 함수를 사용하라.\nS2의 바운딩 박스에서 무작위로 다섯 개의 점을 선택하고, 이 점에서 밴드 값을 추출하라. 반환된 객체를 sf 객체로 변환하라.\nPOINT(390000 5940000) 중심으로 반경 10km 원에서 aggregate를 사용하여 S2 이미지의 평균 픽셀 값을 계산하라. 이미지를 30배 다운샘플링한 결과와 원래 해상도에서의 결과를 비교하라. 두 결과 간의 상대적 차이를 계산하라.\n다운샘플링된 S2 이미지에서 hist를 사용하여 히스토그램을 계산하라. 각 밴드에 대해서도 동일한 작업을 수행하라. ggplot2를 사용하여 네 개의 히스토그램을 모두 포함하는 단일 플롯을 만들어라.\nst_crop 함수를 사용하여 S2 이미지를 10km 원이 포함하는 영역으로 자른 다음 결과를 플롯하라. 아규먼트 crop = FALSE를 설정했을 때의 어떤 변화가 있는지 살펴보라.\n다운샘플링된 이미지를 사용하여 네 개의 밴드에서 모든 픽셀 값이 1000보다 큰지의 여부를 나타내는 논리 레이어를 계산하라. 네 개의 밴드에 대해 래스터 대수 표현식을 사용하거나 st_apply 함수를 사용하라.\n\n\n\n\n그림 9.1: OpenStreetMap 벡터 데이터\n그림 9.2: Sentinel-2의 10m 밴드를 다운샘플링한 경우",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>대용량 데이터와 클라우드 네이티브</span>"
    ]
  },
  {
    "objectID": "part_3.html",
    "href": "part_3.html",
    "title": "공간통계분석과 공간모델링",
    "section": "",
    "text": "이 책의 첫 번째 파트와 두 번째 파트에서는 ’공간데이터 모델’과 관련된 많은 개념에 대해 알아보았다. 다음의 주제들이 다루어졌다.\n\n실제 현상과 숫자의 관계(2장)\n다양한 공간에서 좌표가 정의되는 방식(2장과 4장)\n단순 피처 지오메트리(3장), 두 점 사이의 직선을 이용해 라인스트링과 폴리곤을 정의하는 방법\n지오메트리 유형의 집합(3.1절)\n서포트 및 피처 속성과 지오메트리의 관련 방식(5장)\n단순 테셀레이션이 시공간 체적(볼륨)을 설명하는 방식(6장)\n이 개념들을 데이터사이언스 소프트웨어로 적용하는 방법(7장)\n\n이 책의 세 번째이자 가장 분량이 많은 이 파트에서는 공간데이터의 통계적 모델링을 다룬다. 과학으로서 통계학은 관측값의 변동성을 기술하고 이해하며, 미래 관측값을 예측하는 데 중점을 둔다. 관측값은 보통 다음과 같이 모델링된다.\n\\[\n\\text{관측값}=\\text{설명된 부분}+\\text{잔여 부분}\n\\]\n여기서 “잔여 부분”은 측정 오차를 포함한 예측 변수로 설명되지 않는 변동성을 의미할 뿐만 아니라 낮은 모델 적합도 또는 모델 오지정(missification)이 야기한 변동성을 의미한다. 공간데이터의 경우, 다음과 같이 항이 하나 더 추가된다.\n\\[\n\\text{관측값}=\\text{설명된 부분}+\\text{매끄러운 부분}+\\text{잔여 부분}\n\\]\n여기서 “매끄러운 부분”은 외부 예측 변수로는 설명되지 않지만, 명확하게 “매끄러운” 공간 패턴을 보여주는 변동성을 의미하며, “잔차”는 이러한 패턴을 나타내지 않는 “거친” 변동성을 의미한다. 이러한 “매끄러운” 항은 예를 들어 좌표상의 기본 함수(스플라인, 스무더)로 모델링하거나, 공간적 상관성을 띠는 랜덤 항으로 모델링할 수 있다.\n10장에서는 공간데이터에 대한 통계적 모델링을 소개한다. 이를 통해 후속 장을 준비하는 동시에, 후속 장에서는 자세히 다루지 않는 여러 사항을 다룬다. 또한 이 장은 첫번째 파트에서 다룬 개념들, 특히 5장에서 다룬 ‘서포트’ 개념과의 연결을 시도한다.\n공간 데이터의 통계적 모델링에 대한 상세한 내용 뿐만 아니라 전산 소프트웨어의 사용 방법에 대한 세세한 내용까지를 단 한 권의 책에 모두 담는 일은 애당초 불가능하다. 예를 들어, spatstat 책(Baddeley, Rubak, and Turner, 2015)은 오직 공간 포인트 패턴 데이터와 R에 대한 내용만을 다루는데도 분량이 약 850페이지에 달한다. 이 세 번째 파트에서는 ‘고전적인’ 공간통계학적 주제 세 가지에 집중한다: 포인트 패턴 분석(11장), 지구통계학적 데이터(12장, 13장), 그리고 래티스(지역) 데이터(14-17장). 내용 중간중간에 통계 방법론 및 R 실행과 관련된 참고 사항을 가능한 많이 제시하도록 노력할 것이다.",
    "crumbs": [
      "공간통계분석과 공간모델링"
    ]
  },
  {
    "objectID": "10.html",
    "href": "10.html",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "",
    "text": "10.1 비공간적 회귀분석과 머신러닝 모델을 통한 지도화\n회귀 모델이나 기타 머신러닝(ML) 모델은 비공간 문제에서 새로운 관측값을 예측하는 데 사용되는 방식과 동일하게 공간 및 시공간 데이터에도 적용할 수 있다.\nsf 클래스 객체는 그 자체가 data.frame 객체이므로 특별한 처리가 필요하지 않다. 예측 결과를 지도에 표현하려면, 예측된 값을 sf 객체에 추가해야 하며, 1장에서 불러온 nc 데이터셋을 사용해 다음과 같이 할 수 있다.\nnc |&gt; mutate(SID = SID74/BIR74, NWB = NWBIR74/BIR74) -&gt; nc1\nlm(SID ~ NWB, nc1) |&gt;\n  predict(nc1, interval = \"prediction\") -&gt; pr\nbind_cols(nc, pr) |&gt; names()\n#  [1] \"AREA\"      \"PERIMETER\" \"CNTY_\"     \"CNTY_ID\"   \"NAME\"     \n#  [6] \"FIPS\"      \"FIPSNO\"    \"CRESS_ID\"  \"BIR74\"     \"SID74\"    \n# [11] \"NWBIR74\"   \"BIR79\"     \"SID79\"     \"NWBIR79\"   \"geom\"     \n# [16] \"fit\"       \"lwr\"       \"upr\"\n여기에서 우리는 다음의 사항을 알 수 있다.\n많은 회귀 및 머신러닝 유형 문제들이 동일한 구조를 공유하기 때문에, caret (Kuhn 2022) 또는 tidymodels (Kuhn and Wickham 2022)와 같은 패키지는 광범위한 모델 대안에 대한 자동 평가 및 비교를 가능하게 하며, 다양한 모델 평가 기준과 교차 검증(cross-validation) 전략을 제공한다. 이러한 교차 검증 접근법은 기본적으로 독립 관측 가정에 기반한다. 그런데 공간데이터와 관련하여서는 이것이 반드시 합리적인 가정이라고 전제하기 어려운 경우가 상당히 많다. 이는 공간적 자기상관(Ploton et al. 2020) 때문이거나 표본 데이터에서의 강한 공간 클러스터링(Meyer and Pebesma 2022) 때문이거나, 둘 다 때문이다. 여러 R 패키지는 이러한 단순한 교차 검증을 대체하기 위한 방법을 제공하는데, 여기에는 spatialsample (Silge and Mahoney 2023), CAST (Meyer, Milà, and Ludwig 2023), mlr3spatial (Becker and Schratz 2022), 그리고 mlr3spatiotempcv (Schratz and Becker 2022)가 포함된다.\n다양한 이유로 표본의 강한 공간 클러스터링이 나타날 수 있다. 하나는 서로 다른 데이터베이스를 결합하여 하나의 표본 데이터를 구성하는 경우이다. 이는 각 데이터베이스는 서로 다른 샘플링 밀도를 가지고 있기 때문인데, 보통 글로벌 데이터셋에서 나타난다(Meyer and Pebesma 2022). 또 다른 강한 클러스터링의 예는, 토지 피복 클래스를 샘플링하기 위해 폴리곤을 디지타이징하고 이들 폴리곤 내에서 위성 이미지의 픽셀 해상도로 포인트를 샘플링할 때 발생한다.\n공간적 자기상관은 모델의 “잔여 부분”에서 나타날 수 있는데, 공간 좌표 또는 공간 좌표의 함수들을 예측 변수로 추가 투입하면 감소시킬 수 있다. 그러나 이는 인터폴레이션에서 지나치게 낙관적인 예측의 위험성을 수반하며, (교차) 검증 및 모델 평가에서도 동일한 문제를 야기한다. 이와 관련된 내용은 10.5절에서 더 논의된다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "10.html#비공간적-회귀분석과-머신러닝-모델을-통한-지도화",
    "href": "10.html#비공간적-회귀분석과-머신러닝-모델을-통한-지도화",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "",
    "text": "추정: 일련의 관측값에 대해, 해당 관측값에 대응하는 예측 변수 값을 사용하여 회귀 또는 머신러닝 모델을 적합시킨다(머신러닝 용어로는 이 단계를 “훈련”이라고도 함).\n예측: 새로운 상황에 대해 알려진 예측 변수 값을 적합된 모델과 결합하여 관측 변수 값을 예측하며, 가능하다면 예측 오차 또는 예측 구간도 함께 제시한다.\n\n\n\n\n\nlm 함수는 선형 모델을 추정하며 sf 객체에 직접 적용할 수 있다.\n모델의 결과가 predict 모델에 투입되는데, 이 모델은 nc와 마찬가지로 sf 객체인 nc1에 대한 예측값을 생성한다.\npredict는 세 개의 열을 생성하는데, fit은 예측값을, lwr과 upr은 95% 예측 구간을 나타낸다.\n이 세 열은 bind_cols 함수를 사용하여 최종 객체에 추가되었다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "10.html#서포트와-통계적-모델링",
    "href": "10.html#서포트와-통계적-모델링",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "\n10.2 서포트와 통계적 모델링",
    "text": "10.2 서포트와 통계적 모델링\n데이터의 서포트(1.6절; 5장) 개념은 공간 데이터의 통계 분석에서 중요한 역할을 한다. 에어리어 데이터에 대한 기법(14-17장)은 에어리어 서포트를 가진 데이터, 즉 에어리어들의 집합이 지역 전체를 포괄하는 데이터를 위한 것이다.\n공간적으로 외연적인 변수를 코로플레스맵으로 나타내는 것은(1.1 그림과 같이) 상당히 위험한 선택일 수 있다. 왜냐하면 정보가 폴리곤 크기와 관련되면서 컬러로 표현된 속성값이 해당 폴리곤의 전역에서 나타나는 것처럼 보여질 수 있다. 해결하는 방법은 공간적으로 외연적인 변수를 공간적으로 내포적인 변수로 전환하는 것인데, 예를 들어 인구 수와 같은 변수의 경우 폴리곤 면적으로 나누어 인구 밀도를 산출하고 그것을 지도로 나타내는 것이다. 그럼 1.1에 나타나 있는 연도별 발병자 수와 같은 보건 데이터의 경우는, 폴리곤 면적으로 나누어 공간적 밀도를 계산하기보다는 관측값을 해당 폴리곤의 인구 수로 나누어 확률이나 발병률로 변환하는 것이 일반적이다. 이 경우, 여전히 폴리곤 면적과 연관되지만, 해당 변수의 서포트는 인구 총수와 관련되어 있다. 이러한 총수는 후속 모델링, 예를 들어 CAR 유형 모델(16장)에서 사용되는 (포아송) 변동성을 알려주는 데 중요한 역할을 한다.\n11장은 원칙적으로 포인트 서포트 관측개체를 다루지만, 그렇다고 해서 관측개체가 면적이 전혀 없는 0차원인 것은 아니라는 점을 인식해야 한다. 예를 들어 나무 줄기 “포인트들”의 경우 나무 지름보다 작은 거리에서는 또 다른 포인트가 나타날 수가 없다. 또한, 포인트 패턴 분석에서 포인트는 관측 창 개념에 의거해 측정된 것으로, 해당 관측 창은 완벽한 포인터 데이터셋을 구성해야 한다(즉 관측 창 외부에는 포인트가 없다). 관측 창 개념은 많은 분석 도구에 영향을 미친다. 만약 포인트가 라인 네트워크 상에서 관측된다면, 관측 창은 관측된 라인의 집합으로 구성되며, 포인트 간 거리는 해당 네트워크 상에서의 거리로 측정된다.\n지구통계학적 데이터(12장 및 13장)는 일반적으로 포인트 서포트 관측값에 기반하여 연구 대상 지역 내 비관측 지점의 값을 예측하거나(공간적 인터폴레이션), 세부 지역에 대한 평균값을 예측한다(블록 크리깅; 12.5절). 관측값이 포인트 값이 아니라 구역 전체의 집계값일 수도 있다(Skøien et al. 2014). 원격탐사 데이터에서 픽셀 값은 보통 픽셀 전체에 대한 집계값이다. 이 경우 구름으로 인한 이미지의 결함을 인접한 공간 및 시간의 픽셀로부터 메우는 것이 중요한 도전 과제이다(Militino et al. 2019).\n서로 다른 공간 지원을 가진 데이터를 결합할 때, 모든 데이터를 가장 높은 해상도를 가진 데이터에 “맞추는” 경우가 종종 발생한다. 예를 들어 행정구역 폴리곤과 래스터 레이어를 결합하는 경우, 래스터 레이어의 개별 픽셀 위치에서 폴리곤의 속성 값을 단순 추출하고, 이렇게 생성된 “관측값”을 가지고 분석을 진행해나가는 방식이다. 당연히 이러한 방식으로 생성된 “데이터”를 분석하면 비합리적인 결과를 초래할 위험성이 훨씬 커진다. 불확실성에 대처하기 위해 시뮬레이션을 사용할 수 있는 적절한 다운샘플링 전략이 더 나은 대안이 될 것이다. 초보 사용자가 주어진 소프트웨어를 경각심 없이 사용하는 상황은 매우 우려스럽다. 왜냐하면 어떤 소프트웨어는 구역과 관련된 속성값의 서포트 개념을 잘 다루지 못하거나, 나이브한 다운샘플링에 대한 경고를 보여주지 않기 때문이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "10.html#예측-모델에서의-시간",
    "href": "10.html#예측-모델에서의-시간",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "\n10.3 예측 모델에서의 시간",
    "text": "10.3 예측 모델에서의 시간\nSchabenberger와 Gotway (2005)는, 많은 시공간 데이터에 대한 통계 분석이 시간 차원을 축소(삭감)한 후 해당 문제를 공간적으로 다루거나(시간 먼저, 공간 나중) 공간 차원을 축소한 후 문제를 시간적으로 다루는(공간 먼저, 시간 나중) 방식으로 진행된다는 점을 오래 전에 지적한 바 있다. 첫 번째 접근 방식의 예는 12장에서 제시되는데, 1년 동안의 시간 단위 측정값 데이터셋(13장에서 자세히 설명됨)을 먼저 측정소의 평균 값으로 축소한 후(시간 먼저), 이 평균 값을 공간적으로 인터폴레이션하는(공간 나중) 과정을 보여준다.\n원격탐사 분야의 예시는 다음과 같다.\n\nSimoes et al. (2021)은 지도 학습 기법과 시계열 딥 러닝을 사용하여 픽셀 시계열을 토지 이용 시퀀스로 분할한 후(시간 먼저), 결과로 생성된 맵 시퀀스를 평활화하여 독특한 필셀이 보여주는 불가능한 전환을 제거(공간 나중)한다.\nVerbesselt et al. (2010)은 픽셀 시계열에서 급변점을 찾기 위해 (비지도) 구조적 변화 알고리즘을 사용하고(시간 먼저), 이러한 급변점을 이후에 산림 파괴의 맥락에서 해석한다.\n\n원격탐사 분야에서 공간 먼저, 시간 나중 접근 방식의 예시는 단일 레이어(scene) 또는 단일 시즌에 속하는 레이어들을 우선 분류한 후, 분류된 레이어의 시간 순서를 비교하여 토지 이용이나 토지 피복의 다년간 변화를 평가하는 경우이다. Brown et al. (2022)가 그 예이다. 공간과 시간을 함께 고려하는 예시로는 13장에서 다루는 시공간 인터폴레이션(spatiotemporal interpolation)과 Lu et al. (2016)이 원격탐사 맥락에서 제시한 연구가 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "10.html#디자인-기반-추정과-모델-기반-추정",
    "href": "10.html#디자인-기반-추정과-모델-기반-추정",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "\n10.4 디자인-기반 추정과 모델-기반 추정",
    "text": "10.4 디자인-기반 추정과 모델-기반 추정\n통계적 추론은 샘플 데이터를 통해 모집단에 대한 파라미터(모수)를 추정하는 행위를 의미한다. 위치 \\(s\\)에서 측정된 속성값을 \\(z\\)라고 하면 변수는 \\(z(s)\\)로 주어지고, 우리는 샘플 데이터 \\(z(s_1),...,z(s_n)\\)에서 도메인 \\(D\\)의 면적 \\(|D|\\)에 대한 |\\(z(s)\\)의 평균값을 추정하는 것에 관심이 있다고 하자.\n\\[\nz(s)=\\frac{1}{|D|}\\int_{u\\in D}z(u)du\n\\]\n이 때 우리 앞에는 모델-기반 접근법(model-based)과 디자인-기반 접근법(design-based)이라는 두 가지 가능성이 놓여 있다. 모델-기반 접근법은 \\(z(s)\\)를 초모집단 \\(Z(s)\\)의 실현으로 간주하며(확률 변수를 나타내기 위해 대문자를 사용함), 예를 들어 다음과 같은 공간 변동성을 설명하는 모델을 가정할 수 있다.\n\\[\nZ(s)=m+e(s),\\quad \\text{E}(e(s))=0, \\quad \\text{Cov}(e(s))=\\Sigma(\\theta)\n\\]\n여기서 \\(m\\)은 고정(constant) 평균이고 \\(e(s)\\)는 평균이 0이고 공분산 행렬이 \\(\\Sigma(\\theta)\\)인 잔차를 의미한다. 이는 공분산 함수 \\(\\Sigma(\\theta)\\)를 선택하고 \\(z(s)\\)로부터 그 매개변수 \\(\\theta\\)를 추정한 다음, 블록 크리깅 예측값 \\(\\hat{Z}(D)\\)를 계산해야 한다(12.5절). 이 접근법은 \\(z(s)\\)가 공간적으로 어떻게 샘플링되었는지에 대한 가정을 하지 않지만, 물론 공분산 함수를 선택하고 그 파라미터를 추정할 수 있어야 한다. 추론은 가정된 모델의 유효성에 따라 달라진다.\n디자인-기반 접근법(De Gruijter and Ter Braak 1990; Brus 2021a; Breidt, Opsomer 등 2017)은 초모집단 모델이 아니라 위치에서의 무작위성을 가정한다. 따라서 이 접근법은 무작위 샘플링을 사용할 때만 정당화된다. 샘플 데이터는 반드시 확률 샘플링을 통해 획득되어야 하는데, \\(z(s)\\)의 모든 요소가 샘플에 포함될 (양수) 확률이 수학적으로 규정되어 있는 특정한 종류의 공간적 무작위 샘플링이 사용되어야 한다. 무작위 프로세스는 샘플링 프로세스이다. 즉, \\(z(s_1)\\)은 무작위 과정 \\(z(S_1)\\)의 실현으로 무작위 샘플링을 반복하여 얻은 첫 번째 관측치이다. 디자인-기반 추정량은 이러한 포함 확률만 있으면 평균 값을 표준 오차와 함께 추정할 수 있다. 이는 예를 들어 단순 무작위 샘플이 주어졌을 때, 비가중 샘플 평균이 그대로 모집단 평균을 추정하는 데 사용되며, 모델 파라미터를 적합시킬 필요가 없다.\n이제 질문은 \\(s_1\\)과 \\(s_1\\)가 가까이 있을 때 \\(z(s_1)\\)과 \\(z(s_2)\\)가 서로 상관될 것으로 기대할 수 있는지 여부이다. \\(z(s_1)\\)과 \\(z(s_2)\\)가 단지 두 개의 숫자에 불과할 때는 이 질문이 성립하지 않는다. 상관성을 논하기 위해서는 확률 변수와 같은 일종의 프레임워크가 필요한데, 이 상황을 재현할 수 있는 두 세트의 숫자를 만들어 내야한다. 여기서의 오해는, Brus (2021a)가 설명한 바와 같이, 두 세트의 숫자가 항상 공간적으로 상관되어 있다고 생각하는 것이다. 그러나 이는 \\(Z(s_1)\\)과 \\(Z(s_2)\\)가 강한 상관성을 가지는 모델을 전제한 경우에만 성립한다(“모델-의존”). 특정 무작위 샘플(실현)에서 \\(z(s_1)\\)과 \\(z(s_2)\\)는 공간적으로 가까울 수 있지만, 반복적 무작위 샘플링을 통한 확률 변수 \\(z(S_1)\\)과 \\(z(S_2)\\)는 공간적으로 가깝지 않고, 디자인에 독립적이다. 이 두 상황은 서로 모순 없이 공존할 수 있으며, 어떤 추론 틀을 선택하느냐에 달린 문제일 뿐이다.\n디자인-기반 프레임워크를 선택할지 모델-기반 프레임워크를 선택할지는 연구 목적과 데이터 수집 과정에 따라 달라진다. 모델-기반 프레임워크는 다음과 같은 경우에 가장 적합하다.\n\n개별 위치에 대한 예측이 필요하거나, 샘플링하기에는 너무 좁은 지역에 대한 예측이 필요한 경우\n해당 데이터가 무작위 샘플링 방식으로 수집되지 않은 경우(즉, 샘플 포함 확률이 알려져 있지 않거나 특정 지역이나 시간대에 대해 포함 확률이 0인 경우)\n\n디자인-기반 접근법은 다음과 같은 경우에 가장 적합하다.\n\n관측값이 공간 무작위 샘플링 과정을 통해 수집된 경우\n전체 샘플 지역(또는 하위 지역)에 대한 집계 속성이 필요한 경우\n규제나 법적 목적 등을 위해 모델의 오지정 문제에 민감하지 않은 추정치가 필요한 경우\n\n샘플링 절차를 계획해야 하는 경우(De Gruijter et al. 2006), 공간 무작위 샘플링 방식을 고려하는 것은 매우 바람직한데, 이는 두 가지 추론 프레임워크를 모두 활용할 가능성을 열어주기 때문이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "10.html#좌표값을-활용한-예측-모델",
    "href": "10.html#좌표값을-활용한-예측-모델",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "\n10.5 좌표값을 활용한 예측 모델",
    "text": "10.5 좌표값을 활용한 예측 모델\n데이터사이언스 프로젝트를 수행할 때, 좌표값을 예측 변수(또는 피처, 공변량) 중 하나로 간주하고 다른 변수와 동일한 방식으로 취급하는 경우가 있다. 그런데, 여기에는 몇 가지 위험 요소가 도사리고 있다.\n예측 변수를 다룰 때와 마찬가지로, 원점 이동이나 단위(스케일) 변화에 민감하지 않은 예측 방법을 선택하는 것이 좋다. 2차원 문제를 가정할 때, 예측 모델은 \\(x\\)-축과 \\(y\\)-축 또는 위도와 경도 축의 임의 회전에 민감해서는 안 된다. 투영된 2차원(데카르트) 좌표의 경우, 예를 들어 \\((x+y)^n\\)과 같은 \\(n\\)차 다항식을 사용해 이러한 특성을 보장할 수 있으며, 이는 \\((x)^n+(y)^n\\) 형태 대신 사용된다. 2차 다항식의 경우 \\(xy\\)항을 포함시켜 타원형 경향면이 반드시 \\(x\\)-축이나 \\(y\\)-축에 정렬될 필요가 없도록 한다. 스플라인 요소를 포함하는 GAM 모델의 경우에도 상호작용을 허용하지 않는 독립적 스플라인 \\(s(x)\\)와 \\(s(y)\\) 대신, 2차원에서의 스플라인 \\(s(x,y)\\)를 사용한다. 이러한 ’규칙’에 당연히 예외가 있을 수 있는데, 예를 들어 연간 총 태양 에너지 유입을 설명하기 위해 순전히 위도의 효과만 필요한 경우이다.\n데이터가 넓은 지역에 걸쳐 있는 경우, 타원 좌표와 투영 좌표를 사용하는 것의 차이가 당연히 커지기 때문에 둘 중 어느 좌표를 선택하느냐가 예측 모델링의 결과에 큰 영향을 미칠 수 있다. 매우 넓은 범위나 전 지구적 모델의 경우, 위도와 경도 좌표를 활용한 다항식이나 스플라인은 경도의 순환 특성과 극지점에서의 좌표 특이성을 무시하기 때문에 잘 작동하지 않는다. 이때, 구면 조화 함수(spherical harmonics)를 다항식에 대한 대체 함수나 스플라인 기저 함수로 활용할 수 있는데, 이는 구면 위에서 연속성을 가지며 공간 주파수가 높아질수록 더 세밀한 변화를 표현할 수 있는 함수이다.\n많은 경우, 표본이 수집된 공간 좌표는 예측이 이루어질 공간도 정의하게 되기 때문에, 좌표 변수는 다른 예측 변수와는 선명하게 구별되는 특성을 가진다. 대부분의 간단한 예측 접근법, 특히 많은 머신러닝 기법은 표본 데이터를 독립적이라고 가정한다. 표본이 공간 대상 지역에서 공간 무작위 샘플링(표본추출)에 의해 수집된 경우, 디자인-기반 모델의 맥락에서는 이 가정이 정당화될 수 있다(Brus 2021b). 그러나 디자인-기반 접근에서는 좌표 공간을 우리가 무작위화의 대상 변수로 간주하기 때문에 새롭게 무작위로 선택된 위치에 대한 예측이 가능하지만 고정된 위치에 대한 예측은 불가능하다. 즉, 표본이 수집된 지역의 평균 값을 구할 수는 있지만, 해당 지역에 대한 공간적 인터폴레이션 값을 구할 수는 없다. 고정된 위치에 대한 예측이 필요하거나 데이터가 공간 무작위 표본추출로 수집되지 않은 경우, 모델-기반 접근(Chapter 12에서 설명)과 더불어 잔차의 공간 및/또는 시간적 자기상관을 가정하는 방법을 고려해야만 한다.\n일반적인 경우는 샘플 데이터가 기회적으로 수집되고(“찾을 수 있는 것 모두”), 이후 가중치를 부여하지 않은 채 예측 프레임워크에서 사용되는 경우이다. 이로 인해 결과 모델은 과대표집된 영역(예측 변수 공간 및/또는 공간 좌표 공간)으로 편향될 수 있으며, 단순한(무작위) 교차 검증 통계가 공간 예측의 성능 척도로 사용될 때 지나치게 낙관적인 결과가 도출될 수 있다 (Meyer and Pebesma 2021, 2022; Mila et al. 2022). 공간적 교차 검증(spatial cross-validation)과 같은 적응형 교차 검증 측도가 예측 성능에 대한 유관성 높은 평가값을 얻는 데 도움이 될 수 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "10.html#연습문제",
    "href": "10.html#연습문제",
    "title": "10  공간데이터의 통계적 모델링",
    "section": "\n10.6 연습문제",
    "text": "10.6 연습문제\nR을 활용하여 다음의 연습문제를 해결하라.\n\n10.1절의 lm 예제를 참고하여 랜덤 포레스트 모델을 사용해 SID 값을 예측하고(예: randomForest 패키지 사용), 랜덤 포레스트 예측값을 관측값과 함께 플로팅하되 \\(x=y\\) 선도 함께 표시하시오.\nnc 데이터셋에서 1,000개의 포인트를 무작위로 샘플링하여 새로운 데이터셋을 만들고, 이 데이터셋에 10.1절의 선형 회귀 모델을 다시 실행한다. 적합된 모델의 summary를 살펴보라. 특히 추정 계수, 표준 오차, 잔차 표준 오차를 주목하라. 원 모델과 비교했을 때 무엇이 달라졌는가?\n7.4.6절의 수역-육지 분류를 lda 대신 class::knn을 사용하여 k=5의 값을 설정하여 다시 수행하고, 예측값을 lda의 예측값과 비교하라.\nnc 데이터셋을 사용하는 선형 모델과 이전 연습문제의 knn 예제에 대해 1차 및 2차 공간 좌표 변수를 추가한 다항 선형 모델을 실행하고 결과를 비교하라. 이를 위해 st_centroid를 사용하여 폴리곤의 중심점을 얻고, st_coordinates를 사용하여 x 및 y 좌표를 행렬 형태로 추출하라.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>공간데이터의 통계적 모델링</span>"
    ]
  },
  {
    "objectID": "11.html",
    "href": "11.html",
    "title": "11  포인트 패턴 분석",
    "section": "",
    "text": "11.1 관측 윈도우\n포인트 패턴을 관측 윈도우를 가진다. 다음의 코드를 통해 무작위 포인트 패턴을 생성한다.\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\nn &lt;- 30\nset.seed(13531) # remove this to create another random sequence\nxy &lt;- data.frame(x = runif(n), y = runif(n)) |&gt; \n    st_as_sf(coords = c(\"x\", \"y\"))\n이 포인트들은 \\([0,1]\\times[1,0]\\) 영역 내에 고르게 분포하고 있는데, 완전히 공간적으로 무작위로 분포하고 표현할 수도 있다. 그런데 영역의 크기가 확대되면 고르게 분포하고 있다는 말을 하기 어려워 진다. 예를 들어 아래의 코드로 두 개의 정사각형 영역(w1과 w2)을 생성한다(그림 11.1).\nw1 &lt;- st_bbox(c(xmin = 0, ymin = 0, xmax = 1, ymax = 1)) |&gt; \n        st_as_sfc() \nw2 &lt;- st_sfc(st_point(c(1, 0.5))) |&gt; st_buffer(1.2)\nspatstat 패키지는 포인트 패턴을 ppp 클라스의 객체로 저장한다. 모든 ppp 객체는 포인트 위치 정보와 관측 윈도우(owin 클라스의 객체)를 가진다. 다음과 같이 포인트로부터 ppp 객체로 생성할 수 있다.\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\nas.ppp(xy)\n# Planar point pattern: 30 points\n# window: rectangle = [0.009, 0.999] x [0.103, 0.996] units\n여기서 윈도우가 지정되지 않으면 포인트들의 바운딩 박스가 관측 윈도우로 사용됨을 볼 수 있다. 데이터셋의 첫 번째 피처로 폴리곤 지오메트리를 추가하면, 해당 폴리곤이 관측 윈도우로 사용된다.\n(pp1 &lt;- c(w1, st_geometry(xy)) |&gt; as.ppp())\n# Planar point pattern: 30 points\n# window: polygonal boundary\n# enclosing rectangle: [0, 1] x [0, 1] units\nc1 &lt;- st_buffer(st_centroid(w2), 1.2)\n(pp2 &lt;- c(c1, st_geometry(xy)) |&gt; as.ppp())\n# Planar point pattern: 30 points\n# window: polygonal boundary\n# enclosing rectangle: [-0.2, 2.2] x [-0.7, 1.7] units\n포인트 패턴의 등질성(homogeneity)(역자주: 기대 밀도가 어는 지점에서나 동일한가의 여부)을 검정하기 위해 적절한 방격 레이아웃(그림 11.2에는 3 \\(\\times\\) 3 레이아웃이 나타나 있다)를 사용하여 방격 빈도(quadrat count)(방격별 포인트 수)를 구할 수 있다.\npar(mfrow = c(1, 2), mar = rep(0, 4))\nq1 &lt;- quadratcount(pp1, nx=3, ny=3)\nq2 &lt;- quadratcount(pp2, nx=3, ny=3)\nplot(q1, main = \"\")\nplot(xy, add = TRUE)\nplot(q2, main = \"\")\nplot(xy, add = TRUE)\n이 방격 빈도 정보를 활용해 다음과 같이 \\(\\chi^2\\) 검정을 수행한다.\nquadrat.test(pp1, nx=3, ny=3)\n# Warning: Some expected counts are small; chi^2 approximation may be\n# inaccurate\n# \n#   Chi-squared test of CSR using quadrat counts\n# \n# data:  pp1\n# X2 = 8, df = 8, p-value = 0.9\n# alternative hypothesis: two.sided\n# \n# Quadrats: 9 tiles (irregular windows)\nquadrat.test(pp2, nx=3, ny=3)\n# Warning: Some expected counts are small; chi^2 approximation may be\n# inaccurate\n# \n#   Chi-squared test of CSR using quadrat counts\n# \n# data:  pp2\n# X2 = 43, df = 8, p-value = 2e-06\n# alternative hypothesis: two.sided\n# \n# Quadrats: 9 tiles (irregular windows)\n이는 두 번째 사례가 CSR(완전공간무작위성) 패턴이 아님을 나타낸다. 경고 메시지에서 언급된 것처럼 기대 빈도 수가 너무 적기 때문에 유의 확률(p-값)을 매우 신중하게 해석해야 한다.\ndensity 함수를 통해 커널 밀도를 계산할 수 있으며 커널의 형태와 탐색반경에 조정할 수 있다. 탐색반경 파라미터인 sigma는 bw.diggle 함수의 교차 검증을 통해 지정되며, 그림 11.3에 생성된 밀도면이 나타나 있다.\nden1 &lt;- density(pp1, sigma = bw.diggle)\nden2 &lt;- density(pp2, sigma = bw.diggle)\n이러한 방식으로 생성된 밀도 맵은 명백히 래스터 이미지이며, 이를 stars 객체로 전환할 수 있다.\nlibrary(stars)\n# Loading required package: abind\ns1 &lt;- st_as_stars(den1)\n(s2 &lt;- st_as_stars(den2))\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#        Min.  1st Qu. Median Mean 3rd Qu. Max. NA's\n# v  6.28e-15 0.000153  0.304 6.77    13.1 42.7 3492\n# dimension(s):\n#   from  to offset   delta x/y\n# x    1 128   -0.2  0.0187 [x]\n# y    1 128    1.7 -0.0187 [y]\n밀도면 하부 체적(역자주: 각 셀별로 면적과 밀도값을 곱하여 셀 체적을 구하고 모든 셀에 대한 이 체적값을 합한 값을 의미한다)을 계산하면 샘플 크기(30)와 유사해진다는 것을 다음의 코드를 통해 확인할 수 있다.\ns1$a &lt;- st_area(s1) |&gt; suppressMessages()\ns2$a &lt;- st_area(s2) |&gt; suppressMessages()\nwith(s1, sum(v * a, na.rm = TRUE))\n# [1] 29\nwith(s2, sum(v * a, na.rm = TRUE))\n# [1] 30.7\n여기에 밀도면을 외부 변수의 함수로 나타내는 모델링을 적용하면 좀 더 흥미로운 결과를 얻을 수 있다. 예를 들어, pp2의 밀도를 푸아송 포인트 패턴 프로세스으로 모델링하고자 한다고 가정해 보자(즉, 포인트 간에 상호작용이 없음을 가정). 여기서 밀도 강조는 “클러스터” 중심으로부터의 거리의 함수이며, 이 거리값은 stars 객체에 포함되어 있다.\npt &lt;- st_sfc(st_point(c(0.5, 0.5)))\nst_as_sf(s2, as_points = TRUE, na.rm = FALSE) |&gt;\n  st_distance(pt) -&gt; s2$dist\n그런 다음 ppm을 사용하여 밀도를 모델링할 수 있으며, 포인트 패턴 객체의 이름이 formula의 왼쪽에 사용된다.\n(m &lt;- ppm(pp2 ~ dist, data = list(dist = as.im(s2[\"dist\"]))))\n# Nonstationary Poisson process\n# Fitted to point pattern dataset 'pp2'\n# \n# Log intensity:  ~dist\n# \n# Fitted trend coefficients:\n# (Intercept)        dist \n#        4.54       -4.24 \n# \n#             Estimate  S.E. CI95.lo CI95.hi Ztest  Zval\n# (Intercept)     4.54 0.341    3.87    5.21   *** 13.32\n# dist           -4.24 0.700   -5.62   -2.87   *** -6.06\n반환된 객체는 ppm 클래스이며, 이를 플롯할 수 있다. 그림 11.4는 예측 밀도면을 보여준다. 예측 표준 오차도 플롯할 수 있다.\n모델에는 예측 메소드도 있어, 이를 통해 im 객체를 반환하며, 이 객체는 다음과 같이 stars 객체로 전환될 수 있다.\npredict(m, covariates = list(dist = as.im(s2[\"dist\"]))) |&gt;\n    st_as_stars()\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#      Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\n# v  0.0698   0.529   2.13 6.62     7.3 89.7 3492\n# dimension(s):\n#   from  to offset   delta x/y\n# x    1 128   -0.2  0.0187 [x]\n# y    1 128    1.7 -0.0188 [y]",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#crs",
    "href": "11.html#crs",
    "title": "11  포인트 패턴 분석",
    "section": "\n11.2 CRS",
    "text": "11.2 CRS\nspatstat 패키지의 모든 루틴은 데카르트 좌표계를 가진 2차원 데이터를 위해 설계되어 있다. 타원 좌표계를 가진 객체를 전환하려고 하면 오류가 발생한다.\n\nsystem.file(\"gpkg/nc.gpkg\", package = \"sf\") |&gt; \n    read_sf() |&gt;\n    st_geometry() |&gt;\n    st_centroid() |&gt;\n    as.ppp()\n# Error: Only projected coordinates may be converted to spatstat\n# class objects\n\nspatstat 패키지의 데이터 구조로 전환되고 나면, 처음 사용했던 CSR이 손실된다. 이를 sf 또는 stars 객체로 되돌리기 위해서는 st_set_crs를 사용하면 된다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#속성이-있는-포인트-패턴-선형-네트워크-상의-포인트",
    "href": "11.html#속성이-있는-포인트-패턴-선형-네트워크-상의-포인트",
    "title": "11  포인트 패턴 분석",
    "section": "\n11.3 속성이 있는 포인트 패턴, 선형 네트워크 상의 포인트",
    "text": "11.3 속성이 있는 포인트 패턴, 선형 네트워크 상의 포인트",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#공간-샘플링과-포인트-프로세스를-시뮬레이션하기",
    "href": "11.html#공간-샘플링과-포인트-프로세스를-시뮬레이션하기",
    "title": "11  포인트 패턴 분석",
    "section": "\n11.4 공간 샘플링과 포인트 프로세스를 시뮬레이션하기",
    "text": "11.4 공간 샘플링과 포인트 프로세스를 시뮬레이션하기\nsf 패키지에는 MULTIPOINT, 선형 또는 폴리곤 지오메트리에서 포인트를 샘플링하는 st_sample 메소드가 포함되어 있으며, 다양한 공간 샘플링 전략을 사용한다. 이 메소드는 기본적으로 “random”, “hexagonal”, “Fibonacci”(11.5절), 및 “regular” 옵션을 지원하는데, 여기서 “regular”는 정사각형 격자에서 샘플링하는 것을 의미하고 “hexagonal”은 본질적으로 삼각형 격자를 제공한다. “random” 유형만 요청된 포인트의 수를 정확히 반환하고, 다른 유형에서는 근사값만을 반환한다.\nst_sample 함수는 spatstat 패키지의 포인트 프로세스 시뮬레이션 함수와도 인터페이스를 제공하는데, 샘플링 유형에 대해 다른 값을 선택하는 경우가 해당된다. 예를 들어, type = Thomas로 설정하면 spatstat 함수 rThomas가 호출된다(그림 11.5).\n\nkappa &lt;- 30 / st_area(w2) # intensity\nth &lt;- st_sample(w2, kappa = kappa, mu = 3, scale = 0.05, \n    type = \"Thomas\")\nnrow(th)\n# [1] 90\n\n\n\n\n\n\n그림 11.5: mu =3, scale = 0.05로 설정한 Thomas 프로세스\n\n\n?rThomas를 실행하며 파라미터 kappa, mu, 및 scale의 의미에 대한 자세한 설명을 얻을 수 있다. 포인트 프로세스 시뮬레이션을 수행할 때는 샘플 크기가 아닌 강도가 주어진다. 이 방법으로 얻어진 관측 윈도우 내의 샘플 크기는 하나의 확률 변수가 된다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#구체-상의-포인트를-시뮬레이션하기",
    "href": "11.html#구체-상의-포인트를-시뮬레이션하기",
    "title": "11  포인트 패턴 분석",
    "section": "\n11.5 구체 상의 포인트를 시뮬레이션하기",
    "text": "11.5 구체 상의 포인트를 시뮬레이션하기\nsf에서 기본적으로 지원하는 또 다른 공간 무작위 샘플링 유형은 구면에서의 무작위 포인트 시뮬레이션이다. 그림 11.6에 한 예시가 나타나 있으며, 포인트들이 모두 해양에만 존재한다. 구면에 규칙적 포인트 패턴을 시뮬레이션 하려면 st_sample 함수에서 아규먼트로 type = \"Fibonacci\"로 지정하면 된다(González 2010).\n\n\n\n\n\n그림 11.6: 구체의 해양부에 한정된 샘플 포인트: 무작위 패턴(왼쪽)과 규칙 패턴(오른쪽)이 정사 도법의 지도 상에 나타나 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#연습문제",
    "href": "11.html#연습문제",
    "title": "11  포인트 패턴 분석",
    "section": "\n11.6 연습문제",
    "text": "11.6 연습문제\n\nspatstat 패키지에서 plot(longleaf)로 얻은 플롯과 동일한 것을 ggplot2 패키지의 geom_sf() 함수와 sf::plot()을 사용하여 생성하라.\n12장에서 사용된 NO\\(_2\\) 데이터의 샘플 위치를 적절한 관측 윈도우와 함께 ppp 객체로 전환하라.\nNO\\(_2\\) 데이터셋을 가지고 밀도를 계산하고 밀도면을 플롯하라. 밀도면을 stars 객체로 전환하고, 표면 하부 체적을 계산하라.\n\n\n\n\n그림 11.1: 관찰 윈도우(회색)에 따라 동일한 포인트 패턴이 공간적으로 완전히 무작위로 나타날 수도 있고(왼쪽), 군집을 이루고 있는 것으로 나타날 수도 있다(오른쪽).\n그림 11.2: 두 포인트 패턴의 3 X 3 방격 빈도\n그림 11.3: 두 포인트 패턴에 대한 커널 밀도면\n그림 11.4: ppm 모델에 의거한 예측 밀도면\n그림 11.5: mu =3, scale = 0.05로 설정한 Thomas 프로세스\n그림 11.6: 구체의 해양부에 한정된 샘플 포인트: 무작위 패턴(왼쪽)과 규칙 패턴(오른쪽)이 정사 도법의 지도 상에 나타나 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#관측-윈도우",
    "href": "11.html#관측-윈도우",
    "title": "11  포인트 패턴 분석",
    "section": "",
    "text": "그림 11.1: 관찰 윈도우(회색)에 따라 동일한 포인트 패턴이 공간적으로 완전히 무작위로 나타날 수도 있고(왼쪽), 군집을 이루고 있는 것으로 나타날 수도 있다(오른쪽).\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 11.2: 두 포인트 패턴의 3 X 3 방격 빈도\n\n\n\n\n\n\n\n\n\n\n\n\n그림 11.3: 두 포인트 패턴에 대한 커널 밀도면\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 11.4: ppm 모델에 의거한 예측 밀도면",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "11.html#마크-포인트-패턴-선형-네트워크-상의-포인트",
    "href": "11.html#마크-포인트-패턴-선형-네트워크-상의-포인트",
    "title": "11  포인트 패턴 분석",
    "section": "\n11.3 마크 포인트 패턴, 선형 네트워크 상의 포인트",
    "text": "11.3 마크 포인트 패턴, 선형 네트워크 상의 포인트\nspatstat 패키지에서는 몇 가지 추가 데이터 유형을 서로 전환할 수 있다. 마크(marked) 포인트 패턴은 각 포인트에 대해 범주형 레이블 또는 숫자 레이블을 가진 포인트 패턴이다. spatstat 패키지에 포함되어 있는 마크 포인트 패턴으로 longleaf 소나무 데이터셋이 있는데, 이 데이터셋에는 가슴 높이에서의 나무 직경이 숫자 마크로 포함되어 있다.\n\nlongleaf\n# Marked planar point pattern: 584 points\n# marks are numeric, of storage type  'double'\n# window: rectangle = [0, 200] x [0, 200] metres\nll &lt;- st_as_sf(longleaf)\nprint(ll, n = 3)\n# Simple feature collection with 585 features and 2 fields\n# Geometry type: GEOMETRY\n# Dimension:     XY\n# Bounding box:  xmin: 0 ymin: 0 xmax: 200 ymax: 200\n# CRS:           NA\n# First 3 features:\n#    spatstat.geom..marks.x.  label                           geom\n# NA                      NA window POLYGON ((0 0, 200 0, 200 2...\n# 1                     32.9  point                POINT (200 8.8)\n# 2                     53.5  point                 POINT (199 10)\n\n값은 다음과 같이 ppp객체로 다시 전환할 수 있다.\n\nas.ppp(ll)\n# Warning in as.ppp.sf(ll): only first attribute column is used for\n# marks\n# Marked planar point pattern: 584 points\n# marks are numeric, of storage type  'double'\n# window: polygonal boundary\n# enclosing rectangle: [0, 200] x [0, 200] units\n\nspatstat 패키지의 psp 클래스의 선분은 LINESTRING 지오메트리를 가진 sf 피처로 전환 및 재전환이 가능한데, 관측 윈도우를 가진 POLYGON 피처 하나를 우선적으로 포함하게 된다.\n\nprint(st_as_sf(copper$SouthLines), n = 5)\n# Simple feature collection with 91 features and 1 field\n# Geometry type: GEOMETRY\n# Dimension:     XY\n# Bounding box:  xmin: -0.335 ymin: 0.19 xmax: 35 ymax: 158\n# CRS:           NA\n# First 5 features:\n#     label                           geom\n# 1  window POLYGON ((-0.335 0.19, 35 0...\n# 2 segment LINESTRING (3.36 0.19, 10.4...\n# 3 segment LINESTRING (12.5 0.263, 11....\n# 4 segment LINESTRING (11.2 0.197, -0....\n# 5 segment LINESTRING (6.35 12.8, 16.5...\n\n마지막으로, 선형 네트워크상의 포인트 패턴은 spatstat 패키지에서 lpp 객체로 표현되는데 다음과 같이 sf 객체로 전환할 수 있다.\n\nprint(st_as_sf(chicago), n = 5)\n# Simple feature collection with 620 features and 4 fields\n# Geometry type: GEOMETRY\n# Dimension:     XY\n# Bounding box:  xmin: 0.389 ymin: 153 xmax: 1280 ymax: 1280\n# CRS:           NA\n# First 5 features:\n#     label seg tp marks                           geom\n# 1  window  NA NA  &lt;NA&gt; POLYGON ((0.389 153, 1282 1...\n# 2 segment  NA NA  &lt;NA&gt; LINESTRING (0.389 1254, 110...\n# 3 segment  NA NA  &lt;NA&gt; LINESTRING (110 1252, 111 1...\n# 4 segment  NA NA  &lt;NA&gt; LINESTRING (110 1252, 198 1...\n# 5 segment  NA NA  &lt;NA&gt; LINESTRING (198 1277, 198 1...\n\n여기서는 첫 다섯 개 피처만 나타나 있어 금방 알아챌 수는 없지만, label 변수를 통해 알 수 있듯이 포인트들도 이 객체에 포함되어 있다.\n\ntable(st_as_sf(chicago)$label)\n# \n#   point segment  window \n#     116     503       1\n\n네트워크의 구조에 대한 정보(역자주: 네트워크 연결성에 대한 위상 정보), 즉 LINESTRING 지오메트리가 어떻게 연결되어 있는지는 sf 객체에 포함되어 있지 않다. 이런 측면에서 sfnetworks 패키지(van der Meer et al. 2022)는 좋은 대안일 수 있는데, 네트워크 위상 정보를 다룰 수 있을 뿐만 아니라 OpenStreetMaps에서 가져온 네트워크 데이터를 spatstat 패키지로 전달할 수도 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>포인트 패턴 분석</span>"
    ]
  },
  {
    "objectID": "12.html",
    "href": "12.html",
    "title": "12  공간적 인터폴레이션",
    "section": "",
    "text": "12.1 첫 번째 데이터셋\ngstat 패키지에 포함되어 있는 평균 NO₂ 데이터셋을 읽어 들인다. 이것은 13장에서 준비된다.\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nno2 &lt;- read_csv(system.file(\"external/no2.csv\", \n    package = \"gstat\"), show_col_types = FALSE)\n이 데이터셋에 UTM 투영을 적용하여 sf 객체로 전환한다.\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\ncrs &lt;- st_crs(\"EPSG:32632\")\nst_as_sf(no2, crs = \"OGC:CRS84\", coords = \n    c(\"station_longitude_deg\", \"station_latitude_deg\")) |&gt;\n    st_transform(crs) -&gt; no2.sf\n그리고 나서, 국가 행정 경계를 불러 들이고, ggplot 패키지를 이용해 지도를 그린다(그림 12.1)\nread_sf(\"data/de_nuts1.gpkg\") |&gt; st_transform(crs) -&gt; de\n이 데이터를 바탕으로 공간적 인터폴레이션을 수행하려면 먼저 인터폴레이션을 할 위치를 결정해야 한다. 이는 보통 연구 대상 지역 전체를 덮는 규칙적 그리드를 사용하여 수행된다. 객체 de의 국가 윤곽에 맞추어 독일 전역을 커버하는 10 km × 10 km의 규칙적 그리드를 생성한다.\nlibrary(stars) |&gt; suppressPackageStartupMessages()\nst_bbox(de) |&gt;\n  st_as_stars(dx = 10000) |&gt;\n  st_crop(de) -&gt; grd\ngrd\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#         Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\n# values     0       0      0    0       0    0 2076\n# dimension(s):\n#   from to  offset  delta            refsys x/y\n# x    1 65  280741  10000 WGS 84 / UTM z... [x]\n# y    1 87 6101239 -10000 WGS 84 / UTM z... [y]\n그리드 셀의 크기를 너무 세밀하게 하지 않은 것은 플롯 상에서 눈으로 확인해 보려는 의도이다.\n가장 간단한 공간적 인터폴레이션 기법은 역거리 가중법(inverse distance weighted)일 것이다. 인터폴레이션이 적용되는 지점으로부터의 거리의 역비례에 따라 가중치를 부여하여 가중 평균을 산출하는 기법이다.\n\\[\n\\hat{z}(s_0)=\\frac{\\sum^n_{i=1} w_iz(s_i)}{\\sum^n_{i=1}w_i}\n\\]\n여기서 \\(w_i=|s_0-s_i|^{-p}\\)으로 주어진다. 역거리를 위한 지수(\\(p\\))는 보통 2가 사용되는데, 교차 검증을 통해 최적화할 수도 있다. gstat 패키지의 idw 함수를 활용하면 역거리 가중 인터폴레이션을 수행할 수 있다.\nlibrary(gstat)\ni &lt;- idw(NO2~1, no2.sf, grd)\n# [inverse distance weighted interpolation]\n결과는 그림 12.2에 나타나 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#샘플-베리오그램",
    "href": "12.html#샘플-베리오그램",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.2 샘플 베리오그램",
    "text": "12.2 샘플 베리오그램\n지구통계학적 방법을 사용하여 공간 예측을 수행하려면 먼저 평균과 공간적 자기상관을 위한 모델을 수립해야 한다. 가장 단순한 모델은 \\(Z(s)=m+e(s)\\)로 주어질 수 있는데, 평균은 알려지지 않은 고정값 \\(m\\)이고 공간적 자기상관은 \\(\\gamma (h)=0.5E(Z(s)-Z(s+h))^2\\)의 형태로 주어지는 베리오그램(variogram)을 통해 모델화된다. 유한 분산 \\(C(0)\\)를 가진 프로세스의 경우는 \\(\\gamma (h)=C(0)-C(h)\\)가 성립하는데, 이는 베리오그램이 코베리오그램(covariogram) 또는 공분산 함수(covariance function)와 관련되어 있음을 보여준다.\n샘플 베리오그램은 거리 인터벌 \\(h_i=[h_{i,0},h_{i,1}]\\)별 \\(\\gamma(h)\\)에 대한 추정값을 계산함으로써 획득된다.\n\\[\n\\hat{\\gamma}(h_i)=\\frac{1}{2N(h_i)}\\sum^{N(h_i)}_{j=1}(z(s_i)-z(s_i+h'))^2,\\quad h_{i,0}\\le h' \\lt h_{i,1}\n\\]\n여기에서 \\(N(h_i)\\)는 거리 구간 \\(h_i\\)에 해당하는 모든 샘플 쌍의 개수를 의미한다(역자주: 샘플 쌍의 거리가 해당 거리 구간 내에 포함되는 모든 샘플 쌍의 개수). gstat 패키지의 variogram 함수를 통해 샘플 베리오그램을 계산할 수 있다.\n\nv &lt;- variogram(NO2~1, no2.sf)\n\n그림 12.3은 베리오그램의 결과를 플롯으로 나타낸 것이다.\n\n\n\n\n\n그림 12.3: 샘플 베리오그램 플롯\n\n\nvariogram 함수는 내장된 디폴트 값을 최대 거리(cutoff: 경계 상자의 대각선 길이의 삼분의 일)와 (상수) 구간 너비(width: cutoff를 15로 나눈 값)에 적용하는데. 디폴트 값은 다음을 통해 변경할 수 있다.\n\nv0 &lt;- variogram(NO2~1, no2.sf, cutoff = 100000, width = 10000)\n\n새로운 값의 결과는 그림 12.4에 나타나 있다.\n\n\n\n\n\n그림 12.4: 디폴트 값을 조정해 생성된 샘플 베리오그램\n\n\n공식 NO₂ ~ 1은 데이터 파일(NO₂)에서 관심 변수를 선택하고 평균 모델을 지정하는 데 사용된다. 여기서 ~1은 절편만 있는(알려지지 않은 고정 평균) 모델을 지정한다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#베리오그램-모델-적합",
    "href": "12.html#베리오그램-모델-적합",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.3 베리오그램 모델 적합",
    "text": "12.3 베리오그램 모델 적합\n공간 예측을 진행하기 위해서는 위에서 도출한 거리 구간별 추정값이 아니라 이론적으로 모든 거리 \\(h\\)에 적용될 수 있는 베리오그램 모델 \\(\\gamma(h)\\)가 필요하다. 위의 구간별 추정값을 하나의 직선으로 연결하거나 구간별 추정값을 해당 구간에 대한 고정값이라고 가정하게 되면 문제가 발생한다. 즉, 이것은 비양수 정의 공분산 행렬(non-positive definite covariance matrices)을 갖는 통계 모델을 전제하는 것이 되고, 이것을 예측에 사용하는 것은 불가능한다.\n이를 피하기 위해 우리는 파라메트릭 모델 \\(\\gamma (h)\\)를 적합하여 추정값 \\(\\hat{\\gamma} (h)\\)를 구한다. 여기서 \\(\\hat{\\gamma} (h)\\)는 \\(\\gamma (h)\\)를 추정하는 데 관여한 모든 \\(h'\\) 값의 평균값으로 설정한다. 예를 들어, 다음과 같은 지수 베리오그램 모델을 적합할 수 있다.\n\nv.m &lt;- fit.variogram(v, vgm(1, \"Exp\", 50000, 1))\n\n결과는 그림 12.5에 나타나 있다.\n\n\n\n\n\n그림 12.5: 샘플 베리오그램(가운데가 비어 있는 점) 상에 가중 최소 제곱법(실선) 및 최대 우도 추정법(점선)을 사용하여 적합한 모델이 표시되어 있다.\n\n\n라인의 적합에 다음을 최소화하는 가중 최소 제곱법이 적용되었다.\n\\[\n\\sum^n_{i=1}w_i(\\gamma (h_i)-\\hat{\\gamma}(h_i))^2,\n\\]\n여기에서 가중치의 디폴트값은 \\(N(h_i)/h^2\\)으로 주어진다. fit.method 아규먼트를 통해 다른 가중치 옵션을 선택할 수 있다.\n가중 최소 제곱법 적합의 대안으로 최대 우도(ML) 또는 제한 최대 우도(parameter estimation) 모수 추정법을 사용할 수 있으며(Kitanidis and Lane 1985), 이 사례에서는 그림 12.5에서 점선으로 나타난 것처럼 비교적 유사한 적합 모델이 도출되었다. ML 유형 접근법의 장점은 방정식 12.1에서 거리 구간 \\(h_i\\)나 방정식 12.2에서 가중치 \\(w_i\\)를 선택할 필요가 없다는 것이다. 단점으로는 데이터가 다변량 정규 분포를 보인다는 강한 가정에 기반하고 있고, 더 큰 데이터셋의 경우 관측 수만큼의 선형 시스템을 반복적으로 풀어야 한다는 점 등이 있다. Heaton et al. (2018)은 대규모 데이터셋에 모델을 적합하는 데 특화된 접근법을 비교한다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#크리깅-인터폴레이션",
    "href": "12.html#크리깅-인터폴레이션",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.4 크리깅 인터폴레이션",
    "text": "12.4 크리깅 인터폴레이션\n일반적으로 인터폴레이션은 연구 대상 지역을 덮는 규칙적인 그리드 상의 지점들을 대상으로 이루어진다. 먼저 해당 지역을 커버하면서 그 외부는 NA로 채워진 래스터(stars 객체)를 생성한다.\n크리깅은 연구 대상 지역 내의 임의의 지점 \\(Z(s_0)\\)에 대한 속성값을 예측한다. gstat 패키지의 krige 함수를 통해 NO₂를 크리깅할 수 있으며, 이때 경향면 모델, 데이터, 예측 그리드, 베리오그램 모델을 아규먼트로 전달한다(그림 12.6).\n\nk &lt;- krige(NO2~1, no2.sf, grd, v.m)\n# [using ordinary kriging]\n\n\nggplot() + geom_stars(data = k, aes(fill = var1.pred, x = x, y = y)) + \n    xlab(NULL) + ylab(NULL) +\n    geom_sf(data = st_cast(de, \"MULTILINESTRING\")) + \n    geom_sf(data = no2.sf) +\n    coord_sf(lims_method = \"geometry_bbox\")\n\n\n\n\n\n\n그림 12.6: 독일 NO\\(_2\\) 농도에 대한 크리깅의 결과",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#에어리어-평균-블록-크리깅",
    "href": "12.html#에어리어-평균-블록-크리깅",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.5 에어리어 평균: 블록 크리깅",
    "text": "12.5 에어리어 평균: 블록 크리깅\n에어리어 평균을 계산하는 방법은 여러 가지가 있다. 가장 간단한 방법은 대상 폴리곤 내부에 포함된 포인트 샘플의 평균을 취하는 것이다.\n\na &lt;- aggregate(no2.sf[\"NO2\"], by = de, FUN = mean)\n\n더 복잡한 방법으로는 블록 크리깅(block kriging, Journel and Huijbregts 1978)이 있는데, 타깃 지역의 평균값을 추정하기 위해 모든 데이터를 활용한다. krige 함수에서 newdata 인수에 타깃 지역(폴리곤)을 전달하여 이를 수행한다.\n\nb &lt;- krige(NO2~1, no2.sf, de, v.m)\n# [using ordinary kriging]\n\n두 지도를 하나의 객체로 병합하여 단일 플롯을 생성한다(그림 12.7).\n\nb$sample &lt;- a$NO2\nb$kriging &lt;- b$var1.pred\n\n\nb |&gt; select(sample, kriging) |&gt; \n        pivot_longer(1:2, names_to = \"var\", values_to = \"NO2\") -&gt; b2\nb2$var &lt;- factor(b2$var, levels = c(\"sample\", \"kriging\"))\nggplot() + geom_sf(data = b2, mapping = aes(fill = NO2)) + facet_wrap(~var) +\n     scale_fill_gradientn(colors = sf.colors(20))\n\n\n\n\n\n\n그림 12.7: 단순 평균계산(왼쪽)과 블록 크리깅(오른쪽)을 통해 계산된 NO\\(_2\\) 농도의 집계값\n\n\n패턴은 유사하지만, 단순 평균계산을 통한 샘플 평균이 블록 크리깅의 값보다 변동성이 더 크다는 것을 알 수 있다. 이는 크리깅의 평활화 효과 때문일 수 있는데, 집계 영역 외부의 데이터 포인트에도 가중치가 부여되기 때문이다.\n표준 오차에 대한 대략적인 추정치는 \\(\\sqrt{(\\sigma^2 /n)}\\)를 통해 얻을 수 있다.\n\nSE &lt;- function(x) sqrt(var(x)/length(x))\na &lt;- aggregate(no2.sf[\"NO2\"], de, SE)\n\n샘플이 공간적으로 무작위 표본 추출을 통해 얻어진 경우, 디자인-기반 추론(10.4절)에서 실제 추정치가 이와 같았을 것이다. 블록 크리깅 분산은 모델-기반 추정치로, 크리깅의 부산물로 계산된다. 그림 12.8에서 두 값을 비교해 보면, 단순 평균계산 접근법이 블록 크리깅에 비해 구역 평균의 예측 오차가 더 큰 변동성을 보일 뿐만 아니라 값도 더 크다는 것을 확인할 수 있다.\n\n\n\n\n\n그림 12.8: 단순 평균계산법(왼쪽)과 블록 크리깅(오른쪽)을 통해 획득된 평균 NO\\(_2\\) 농도의 표준 오차",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#조건적-시뮬레이션",
    "href": "12.html#조건적-시뮬레이션",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.6 조건적 시뮬레이션",
    "text": "12.6 조건적 시뮬레이션\n필드 \\(Z(s)\\)의 조건부 평균이 아닌 하나 혹은 여러개의 조건부 실현이 필요할 경우, 조건부 시뮬레이션을 활용할 수 있다. 조건부 실현이 필요한 경우는 비선형 함수인 \\(g(\\cdot)\\)을 통해 \\(Z(s)\\)의 구역 평균 값, 즉 \\(g(Z(s))\\)를 추정해야 하는 상황이 해당된다. 간단한 예로는 \\(Z(s)\\)가 특정 임계값을 초과하는 지역이 존재하는 경우이다.\ngstat 패키지의 기본 접근 방식은 이를 위해 순차 시뮬레이션 알고리즘을 사용하는 것이다. 이 알고리즘은 예측이 이루어지는 위치들을 무작위로 순회하며 각 위치에서 다음과 같은 작업을 수행한다.\n\n크리깅 예측을 수행한다.\n크리깅 분산과 동일한 평균과 분산을 가진 정규 분포에서 난수를 생성한다.\n이 값을 조건부 데이터셋에 추가한다.\n새로운 무작위 시뮬레이션 위치를 찾는다.\n\n이것을 모든 위치에 반복 수행한다.\ngstat 패키지의 krige 함수가 이를 수행하며 nsim 아규먼트는 양수로 설정된다.\n\nset.seed(13341)\n(s &lt;- krige(NO2~1, no2.sf, grd, v.m, nmax = 30, nsim = 6))\n# drawing 6 GLS realisations of beta...\n# [using conditional Gaussian simulation]\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\n# var1  -5.7    6.12   8.68 8.88    11.5 23.9 12456\n# dimension(s):\n#        from to  offset  delta            refsys        values x/y\n# x         1 65  280741  10000 WGS 84 / UTM z...          NULL [x]\n# y         1 87 6101239 -10000 WGS 84 / UTM z...          NULL [y]\n# sample    1  6      NA     NA                NA sim1,...,sim6\n\nset.seed()를 설정한 것은 시뮬레이션 결과가 달라지지 않도록 하기 위해서이다.\nnmax 아규먼트의 설정을 통해 크리깅 추정 시 포함할 최근접 이웃의 (최대) 개수를 제한하는 것이 필요하다. 왜냐하면 단계가 진해되면서 데이터셋이 계속 증가하기 때문에 계산 시간이 길어지고 메모리 요구량이 커지기 때문이다. 조건부 시뮬레이션의 결과가 그림 12.9에 나타나 있다.\n\n\n\n\n\n그림 12.9: NO2에 대한 6가지의 조건부 시뮬레이션 결과\n\n\ngstat 패키지에는 최근 조건부 시뮬레이션의 대체 기법이 추가되었으며, 원형 임베딩(circular embedding) 기법을 구현한 krigeSimCE(Davies와 Bryant, 2013)와 터닝 밴드(turning band) 기법을 구현한 krigeSTSimTB(Schlather, 2011)가 있다. 이러한 기법들은 대규모 데이터셋이나 시공간 데이터셋의 조건부 시뮬레이션에 유용하다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#경향면-모델",
    "href": "12.html#경향면-모델",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.7 경향면 모델",
    "text": "12.7 경향면 모델\n이 장에서 사용된 크리깅과 조건부 시뮬레이션은 모든 공간 변동성이 공간 공분산 모델로 특징지어지는 무작위 과정이라고 가정한다. 만약 타깃 변수와 의미 있게 상관된 다른 변수가 있는 경우, 이러한 변수를 경향면을 위한 선형 회귀 모델에 사용할 수 있다.\n\\[\nZ(s)=\\sum^p_{j=0} \\beta_jX_j(s)+e(s)\n\\]\n여기서 \\(X_0(s)=1\\), \\(\\beta_0\\)는 절편, \\(\\beta_j\\)는 변수에 대한 회귀계수이다. 변수를 추가하면 보통 잔차 \\(e(s)\\)의 공간적 자기상관과 분산이 모두 감소하여, 더 정확한 예측과 유사한 조건부 시뮬레이션 결과를 얻을 수 있다. NO\\(_2\\)의 변동에 대해 인구 밀도 변수를 사용하는 예를 살펴볼 것이다.\n\n12.7.1 인구 밀도 그리드\n대기의 NO\\(_2\\)에 대한 예측 변수로 인구 밀도를 사용한다. NO\\(_2\\)는 주로 교통에 의해 발생하며, 교통은 인구 밀도가 높은 지역에서 더 집중된다. 인구 밀도는 2011년 인구 조사에서 얻어진 데이터로, 100m × 100m 그리드 셀당 거주자 수가 CSV 파일에 포함되어 있다. 우리는 이 데이터를 타깃 그리드 셀에 맞춰 합산함으로써 새로운 집계 데이터를 생성할 수 있다.\n\nv &lt;- vroom::vroom(\"aq/pop/Zensus_Bevoelkerung_100m-Gitter.csv\")\nv |&gt; filter(Einwohner &gt; 0) |&gt; \n    select(-Gitter_ID_100m) |&gt;\n    st_as_sf(coords = c(\"x_mp_100m\", \"y_mp_100m\"), crs = 3035) |&gt;\n    st_transform(st_crs(grd)) -&gt; b\na &lt;- aggregate(b, st_as_sf(grd, na.rm = FALSE), sum)\n\n위의 코드를 통해 집계된 타깃 그리드 셀의 인구 수가 a에 저장된다. 인구 밀도를 구하기 위해서는 각 셀의 면적이 필요한데, 국경에 걸쳐 있는 그리드 셀의 경우 면적이 10km × 10km보다 작을 것이다.\n\ngrd$ID &lt;- 1:prod(dim(grd)) # to identify grid cells\nii &lt;- st_intersects(grd[\"ID\"],\n  st_cast(st_union(de), \"MULTILINESTRING\"), as_points = FALSE)\ngrd_sf &lt;- st_as_sf(grd[\"ID\"], na.rm = FALSE)[lengths(ii) &gt; 0,]\nst_agr(grd_sf) = \"identity\"\niii &lt;- st_intersection(grd_sf, st_union(de))\ngrd$area &lt;- st_area(grd)[[1]] + \n    units::set_units(grd$values, m^2)\ngrd$area[iii$ID] &lt;- st_area(iii)\n\n위의 두 단계 과정, 즉 먼저 국경에 걸쳐 있는 셀을 찾고 그 후에 면적을 계산하는 과정을 거치지 말고, 모든 셀에 바로 st_intersection 함수를 적용하는 방법도 있겠지만 이는 오퍼레이션 시간이 긴 단점이 있다. 인구 수와 면적을 통해 인구 밀도를 계산하고(그림 12.10), 총계가 맞는지 확인해 본다.\n\ngrd$pop_dens &lt;- a$Einwohner / grd$area\nsum(grd$pop_dens * grd$area, na.rm = TRUE) # verify\n# 80323301 [1]\nsum(b$Einwohner)\n# [1] 80324282\n\n두 값의 일치도가 상당히 높다는 것을 알 수 있다. st_interpolate_aw 함수를 사용했다면 정확히 일치하는 결과를 얻었을 것이다.\n\n\n\n\n\n그림 12.10: 100 m X 100 m 그리드 셀별 인구 밀도 값\n\n\n인구 수를 인구 밀도로 전환하기 위해서는 해당 인구 수를 100m × 100m 격자 셀의 수로 나누어야 한다.\n모니터링 네트워크 스테이션에서 인구 밀도 값을 얻기 위해 st_extract 함수를 사용한다.\n\ngrd |&gt;\n  select(\"pop_dens\") |&gt;\n  st_extract(no2.sf) |&gt;\n  pull(\"pop_dens\") |&gt; \n  mutate(no2.sf, pop_dens = _) -&gt; no2.sf\n\n그런 다음 모니터링 스테이션 위치에서 NO\\(_2\\)와 인구 밀도 간의 선형 관계를 조사할 수 있다.\n\nsummary(lm(NO2~sqrt(pop_dens), no2.sf))\n# \n# Call:\n# lm(formula = NO2 ~ sqrt(pop_dens), data = no2.sf)\n# \n# Residuals:\n#    Min     1Q Median     3Q    Max \n# -7.990 -2.052 -0.505  1.610  8.095 \n# \n# Coefficients:\n#                Estimate Std. Error t value Pr(&gt;|t|)    \n# (Intercept)       4.537      0.685    6.62  5.5e-09 ***\n# sqrt(pop_dens)  326.154     49.366    6.61  5.8e-09 ***\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# \n# Residual standard error: 3.13 on 72 degrees of freedom\n# Multiple R-squared:  0.377,   Adjusted R-squared:  0.369 \n# F-statistic: 43.7 on 1 and 72 DF,  p-value: 5.82e-09\n\n해당 선형 관계는 그림 12.11의 산점도에 나타나 있다.\n\n\n\n\n\n그림 12.11: 농촌 지역 대기질 관측소의 2017년 연평균 NO\\(_2\\) 농도와 인구 밀도의 산점도\n\n\n이 새로운 모델에서의 예측을 수행하기 위해서는 먼저 잔차 베리오그램을 모델링해야 한다(그림 12.12).\n\nno2.sf &lt;- no2.sf[!is.na(no2.sf$pop_dens),]\nvr &lt;- variogram(NO2~sqrt(pop_dens), no2.sf)\nvr.m &lt;- fit.variogram(vr, vgm(1, \"Exp\", 50000, 1))\n\n\n\n\n\n\n그림 12.12: 인구 밀도 경향성을 제거하고 남은 잔차에 대한 베리오그램\n\n\n그리고 나서 아래의 코드로 크리깅 예측이 이루어진다. 여기서, 중요한 것은 예측 위치에 대해서도 pop_dens 값이 계산되어 새로이 생성되는 객체인 grd 속에 포함되다는 점이다. 예측 결과는 12.13에 나타나 있다.\n\nkr &lt;- krige(NO2 ~ sqrt(pop_dens), no2.sf, \n            grd[\"pop_dens\"], vr.m)\n# [using universal kriging]\n\n\n\n\n\n\n그림 12.13: 인구 밀도를 경향성 변수로 사용한 크리깅의 NO\\(_2\\) 농도 예측값\n\n\n(오디네리) 크리깅과 비교할 때 몇 가지 뚜렷한 차이를 볼 수 있다. 인구 밀도를 경향면으로 사용한 크리깅의 결과 지도는 측정 스테이션의 극단적인 값이 아니라 인구 밀도의 극단적인 값을 따르는 경향이 있으며, 값의 범위도 오디네리 크리깅의 범위 보다 넓다. 그러나 “농촌 배경”의 범주에 속하는 측정 스테이션만 사용되어 인구 밀도가 전체적으로 낮은 특성이 있다는 점에서 해석에 신중을 기할 필요가 있다. 그림 12.11의 산점도의 x-축을 보면 측정 스테이션의 인구 밀도 값이 인구 밀도 지도에 나타나 있는 값의 범위에 비해 훨씬 제한적이라는 사실을 알 수 있으며, 따라서 오른쪽 지도는 그림 12.11에 나타난 관계를 강하게 인터폴레이션한 결과이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#연습문제",
    "href": "12.html#연습문제",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.8 연습문제",
    "text": "12.8 연습문제\n\n그림 12.13과 같은 플롯을 생성하되, 왼쪽에 그림 12.2의 역거리 인터폴레이션 맵을 추가하라.\nIDW와 크리깅, 그리고 IDW와 잔차 크리깅 간의 관계를 나타내는 산점도를 생성하라.\n그리드 셀을 중심으로 하는 블록 평균을 예측하기 위해 블록 크리깅을 수행하되, krige() 함수의 block 아규먼트를 통해 블록 크기가 10km(그리드 셀 크기), 50km, 200km인 블록 크리깅을 수행하라. 이 세 가지 블록 크기에 대한 추정치의 결과 맵을 포인트 크리깅으로 얻은 맵과 비교하고, 관련된 모든 크리깅 표준 오차에 대해서도 동일하게 수행하라.\n위에서 얻은 잔차 크리깅 결과를 기반으로, 크리깅 오차가 정규 분포를 따른다고 가정할 때 95% 신뢰 구간의 하한선과 상한선 맵을 계산하고, 이를 단일(결합) 범례가 있는 플롯에 표시하라.\n크리깅 오차에 대한 정규 분포 가정 하에서, NO\\(_2\\)의 포인트 값이 15 ppm을 초과할 확률 값을 계산하고 그것을 지도로 표현하라.\n\n\n\n\n그림 12.1: 독일의 농촌 지역 관측소들에 높은 평균 NO\\(_2\\) 값이 집중해 있다.\n그림 12.2: 독일 NO\\(_2\\) 집중도에 대한 역거리 가중 인터폴레이션의 결과\n그림 12.3: 샘플 베리오그램 플롯\n그림 12.4: 디폴트 값을 조정해 생성된 샘플 베리오그램\n그림 12.5: 샘플 베리오그램(가운데가 비어 있는 점) 상에 가중 최소 제곱법(실선) 및 최대 우도 추정법(점선)을 사용하여 적합한 모델이 표시되어 있다.\n그림 12.6: 독일 NO\\(_2\\) 농도에 대한 크리깅의 결과\n그림 12.7: 단순 평균계산(왼쪽)과 블록 크리깅(오른쪽)을 통해 계산된 NO\\(_2\\) 농도의 집계값\n그림 12.8: 단순 평균계산법(왼쪽)과 블록 크리깅(오른쪽)을 통해 획득된 평균 NO\\(_2\\) 농도의 표준 오차\n그림 12.9: NO\\(_2\\) 농도에 대한 6가지의 조건부 시뮬레이션 결과\n그림 12.10: 100 m X 100 m 그리드 셀별 인구 밀도 값\n그림 12.11: 농촌 지역 대기질 관측소의 2017년 연평균 NO\\(_2\\) 농도와 인구 밀도의 산점도\n그림 12.12: 인구 밀도 경향성을 제거하고 남은 잔차에 대한 베리오그램\n그림 12.13: 인구 밀도를 경향성 변수로 사용한 크리깅의 NO\\(_2\\) 농도 예측값",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "13.html",
    "href": "13.html",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "",
    "text": "13.1 대기질 데이터셋 준비\n여기서 사용할 데이터셋은 유럽 환경청(EEA)에서 얻은 대기 질 데이터셋이다. 유럽 회원국들은 이 기관에 대기 질 측정 결과를 보고한다. 이른바 검증된 데이터는 회원국에 의해 품질이 관리되며, 연단위로 보고된다. 이 데이터는 정책 준수 평가와 (대응) 조치의 기초가 된다.\nEEA의 대기 질 전자 보고(e-reporting) 웹사이트를 통해 유럽 회원국들이 보고한 데이터에 접근할 수 있다. 우리는 기본 측정 데이터인 시간별(시계열) 데이터를 다운로드하기로 결정했다. 웹 양식을 통해 우리의 데이터 선택 규준이 손쉽게 HTTP GET 요청으로 변환된다. 독일(CountryCode=DE)의 2017년(Year_from, Year_to)의 모든 검증된(Source=E1a) \\(NO_2\\)(Pollutant=8) 데이터를 선택하는 URL이 생성되었다. 이 URL은 여러개의 CSV 파일과 연결된 URL 정보가 들어있는 텍스트 파일을 반환한다. 개별 CSV 파일에는 개별 측정 측정 스테이션에 대해 전 기간에 대한 시간별 측정값이 들어 있다. 파일을 다운로드하고 dos2unix 명령줄 유틸리티를 활용하여 인코딩 변환하였다.\n다음으로, 스테이션 메타데이터가 포함된 단일 파일을 제외하고 나머지 모든 파일을 리스트 형태로 읽어들인다.\nfiles &lt;- list.files(\"aq\", pattern = \"*.csv\", full.names = TRUE)\nfiles &lt;- setdiff(files, \"aq/AirBase_v8_stations.csv\") # metadata file\nr &lt;- lapply(files, function(f) read.csv(f))\n그런 다음 시간 변수를 POSIXct 변수로 변환하고, 다음과 같이 시간 순서로 정렬한다.\nSys.setenv(TZ = \"UTC\") # don't use local time zone\nr &lt;- lapply(r, function(f) {\n        f$t = as.POSIXct(f$DatetimeBegin) \n        f[order(f$t), ] \n    }\n)\n이 데이터셋에서 시간별 데이터가 없는 작은 하위 데이터셋을 제거한다.\nr &lt;- r[sapply(r, nrow) &gt; 1000]\nnames(r) &lt;- sapply(r,\n               function(f) unique(f$AirQualityStationEoICode))\nlength(r) == length(unique(names(r)))\n# [1] TRUE\n그런 다음 xts 패키지의 cbind 함수를 사용하여 모든 파일을 병합하여 시간을 기준으로 매칭 레코드를 결합한다.\nlibrary(xts) |&gt; suppressPackageStartupMessages()\nr &lt;- lapply(r, function(f) xts(f$Concentration, f$t))\naq &lt;- do.call(cbind, r)\n이 데이터셋에 추가적인 선택을 실행하였는데, 측정된 시간별 값이 75%가 유효한 스테이션을 선택하는 것이다. 즉, 25% 이상의 결측 시간별 값을 가진 스테이션은 제외한다. mean(is.na(x)) 함수가 벡터 x에서 결측 값의 비율을 계산해 주기 때문에, 이 함수를 열(스테이션)에 적용하면 된다.\nsel &lt;- apply(aq, 2, function(x) mean(is.na(x)) &lt; 0.25)\naqsel &lt;- aq[, sel]\n다음으로, 스테이션 메타데이터를 읽어 들이고, 독일(“DE”)의 농촌 배경 스테이션에 해당하는 내용만을 골라낸다.\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nread.csv(\"aq/AirBase_v8_stations.csv\", sep = \"\\t\") |&gt;\n    as_tibble() |&gt; \n    filter(country_iso_code == \"DE\",\n           station_type_of_area == \"rural\",\n           type_of_station == \"Background\") -&gt; a2\n포함되어 있던 좌표값을 이용해, (정적) 스테이션 메타데이터를 가진 sf 객체를 생성한다.\nlibrary(sf) |&gt; suppressPackageStartupMessages()\na2.sf &lt;- st_as_sf(a2, crs = 'OGC:CRS84',\n  coords = c(\"station_longitude_deg\", \"station_latitude_deg\"))\n이제 위에서 정리한 대기 질 측정 데이터에서 농촌 배경 유형의 스테이션에 해당 되는 것만을 골라내야 하는데, 스테이션의 코드 정보는 메타데이터를 정리한 a2에 저장되어 있었다.\nsel &lt;- colnames(aqsel) %in% a2$station_european_code\naqsel &lt;- aqsel[, sel]\ndim(aqsel)\n# [1] 8760   74\n스테이션별로 평균을 계산하고 그것을 스테이션 위치 객체와 조인한다.\ntb &lt;- tibble(NO2 = apply(aqsel, 2, mean, na.rm = TRUE), \n            station_european_code = colnames(aqsel))\ncrs &lt;- st_crs('EPSG:32632')\nright_join(a2.sf, tb) |&gt; st_transform(crs) -&gt; no2.sf \nread_sf(\"data/de_nuts1.gpkg\") |&gt; st_transform(crs) -&gt; de\n그림 12.1에는 이렇게 계산된 스테이션별 평균 NO\\(_2\\) 농도와 국가 경계가 나타나 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "13.html#다변량-지구통계학",
    "href": "13.html#다변량-지구통계학",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "\n13.2 다변량 지구통계학",
    "text": "13.2 다변량 지구통계학\n다변량 지구통계학은 여러 변수를 결합하여 모델링, 예측 및 시뮬레이션하는 것을 의미한다. 이것을 수식으로 표현하면 다음과 같다.\n\\[\nZ_1(s)=X_i\\beta_i+e_1(s)\n\\]\n\\[\n...\n\\]\n\\[\nZ_n(s)=X_n\\beta_n+e_n(s)\n\\]\n이러한 모델을 위해서는 각 변수별로 관측치, 경향면 모델, 베리오그램이 필요할 뿐만 아니라 각 변수쌍별로 잔차의 교차-베리오그램이 필요하다. 교차-베리오그램은 \\(e_i(s)\\)와 \\(e_j(s+h)\\) 간의 공분산을 나타낸다. 이 교차-공분산이 0이 아니라면, \\(e_j(s+h)\\)의 정보는 \\(e_i(s)\\)를 예측(또는 시뮬레이션)하는 데 도움이 될 수 있다. 이는 특히 \\(Z_j(s)\\)가 \\(Z_i(s)\\) 보다 더 조밀하게 샘플링된 경우에 그러하다. 이러한 방식의 예측과 시뮬레이션을 코크리깅(cokriging) 및 코시뮬레이션(cosimulation)이라고 부른다. 데모 스크립트를 실행하면 gstat 패키지를 사용한 예제를 살펴볼 수 있다.\n\nlibrary(gstat)\ndemo(cokriging)\ndemo(cosimulation)\n\n좀 더 자세한 사항은 Bivand, Pebesma, & Gómez-Rubio(2013)를 참고하라.\n다양한 변수가 동일한 위치에서 관측되는 경우, 예를 들어 다양한 대기 질 변수가 스테이션에서 함께 측정되는 경우, 코크리깅(cokriging)을 사용하는 통계적 이익이 미미한 것으로 드러나는 경우가 있다. 그러나 진정한 다변량 모델링을 원한다면 코크리깅을 수행하는 것이 맞다. 코크리깅을 통해 예측 벡터 \\(\\hat{Z}(s_0)=(\\hat{Z}_1(s_0),...,\\hat{Z}_n(s_0))\\)를 얻을 뿐만 아니라 예측 오차의 전체 공분산 행렬도 얻을 수 있다(Ver Hoef and Cressie 1993). 이 예측 오차 공분산 행렬을 이용하면, \\(\\hat{Z}(s_0)\\)의 어떠한 선형 조합, 예를 들어 \\(\\hat{Z}_2(s_0)-\\hat{Z}_1(s_0)\\)에 대한 표준 오차를 얻을 수 있다.\n베리오그램 및 교차-베리오그램을 자동으로 계산하고 적합할 수 있지만, 변수의 수가 많아질수록 다변량 지구통계 모델링은 관리하기 어려워진다. 필요한 베리오그램 및 교차-베리오그램의 수가 \\(n(n+1)/2\\)로 늘어나기 때문이다.\n여러 변수라는 의미가 동일한 변수에 대한 여러 시점의 변수를 의미하는 경우라도 다변량(코크리깅) 예측 접근 방식을 사용할 수 있다. 하지만 이 경우 두 시점 사이의 특정 시점에 대해 인터폴레이션 하는 것은 불가능하다. 이런 경우, 혹은 여러 시간 인스턴스에서 관측된 데이터를 처리해야 하는 경우, \\(Z(s,t)\\)처럼 연속적인 시공간 결합 함수를 통해 변동성을 모델링할 수 있다. 다음 절에서 이를 다룰 것이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "13.html#시공간-지구통계학",
    "href": "13.html#시공간-지구통계학",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "\n13.3 시공간 지구통계학",
    "text": "13.3 시공간 지구통계학\n시공간 지구통계 프로세스는 시공간의 모든 위치에서 변수 값이 존재한다는 전제에 기반한다. 이것을 \\(Z(s,t)\\)로 나타낼 수 있고, 여기서 \\(s\\)와 \\(t\\)는 시공간 상에서 연속적으로 정의되는 인덱스이다. 관측치 \\(Z(s_i,t_j)\\)와 베리오그램(공변동) 모델 \\(\\gamma(s,t)\\)가 주어지면, 표준 가우시안 프로세스 이론을 활용해 임의의 시공간 위치 \\((s_0,t_0)\\)의 속성값 \\(Z(s_0,t_0)\\)를 예측할 수 있다.\n최근에 시공간 지구통계 데이터의 처리 및 모델링에 관한 현대적인 접근을 다룬 몇 권의 책이 출간되었다. 예를 들어 Wikle, Zammit-Mangion, & Cressie(2019)와 Blangiardo & Cameletti(2015)가 있다. 여기서는 Gräler, Pebesma, & Heuvelink(2016)를 참고하고, 이전 장에서 사용한 데이터셋을 활용한 간단한 예제를 제시할 것이다.\n\n13.3.1 시공간 베리오그램 모델\n이 장의 서두에서 NO\\(_2\\)의 시공간 매트릭스 데이터를 aq 객체에 저장했고, 이것으로부터 완전한 레코드를 보유한 농촌 배경 관측소만을 선택해 aqsel 객체로 만들었다. 최종 74개 관측소의 공간 위치를 다음과 같이 선택할 수 있다.\n\nsfc &lt;- st_geometry(a2.sf)[match(colnames(aqsel),\n                           a2.sf$station_european_code)] |&gt;\n  st_transform(crs)\n\n그리고 나서 마침내 시간과 스테이션을 디멘션으로 가지는 stars 벡터 큐브를 구축한다.\n\nlibrary(stars)\n# Loading required package: abind\nst_as_stars(NO2 = as.matrix(aqsel)) |&gt;\n    st_set_dimensions(names = c(\"time\", \"station\")) |&gt;\n    st_set_dimensions(\"time\", index(aqsel)) |&gt;\n    st_set_dimensions(\"station\", sfc) -&gt; no2.st\nno2.st\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#      Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\n# NO2  -8.1    3.02   5.66 8.39    10.4  197 16134\n# dimension(s):\n#         from   to         offset   delta            refsys point\n# time       1 8760 2017-01-01 UTC 1 hours           POSIXct    NA\n# station    1   74             NA      NA WGS 84 / UTM z...  TRUE\n#                                          values\n# time                                       NULL\n# station POINT (439814 ...,...,POINT (456668 ...\n\n이 데이터를 바탕으로 다음과 같이 시공간 베리오그램을 구성한다.\n\nlibrary(gstat)\n\n\nv.st &lt;- variogramST(NO2~1, no2.st[,1:(24*31)], tlags = 0:48, \n    cores = getOption(\"mc.cores\", 2))\n\n결과는 그림 13.1에 나타나 있다.\n\n\n\n\n\n그림 13.1: 2017년 독일의 농촌 배경 스테이션의 시간별 NO\\(_2\\) 농도에 대한 시공간 샘플 베리오그램으로 오른쪽의 컬러는 시간 지체를 나타내며(노란색이 더 늦은 시간을 나타냄) 거리의 단위는 미터이다.\n\n\n이 샘플 베리오그램에 대해 특정한 베리오그램 모델을 적합할 수 있다. 여기에서는 비교적 유연한 모델인 곱-합(product-sum) 모델(Gräler, Pebesma, 및 Heuvelink 2016)을 적용하고자 하는데, 다음과 같이 적합된다.\n\n# product-sum\nprodSumModel &lt;- vgmST(\"productSum\",\n    space = vgm(150, \"Exp\", 200000, 0),\n    time = vgm(20, \"Sph\", 6, 0),\n    k = 2)\n#v.st$dist = v.st$dist / 1000\nStAni &lt;- estiStAni(v.st, c(0,200000))\n(fitProdSumModel &lt;- fit.StVariogram(v.st, prodSumModel,\n    fit.method = 7, stAni = StAni, method = \"L-BFGS-B\",\n    control = list(parscale = c(1,100000,1,1,0.1,1,10)),\n    lower = rep(0.0001, 7)))\n# space component: \n#   model    psill range\n# 1   Nug   0.0166     0\n# 2   Exp 152.7046 83590\n# time component: \n#   model   psill range\n# 1   Nug  0.0001  0.00\n# 2   Sph 25.5736  5.77\n# k: 0.00397635996859073\n\n그림 13.2에 결과가 나타나 있으며, 와이어 프레임으로도 플롯할 수 있다(그림 13.3). 이 모델의 적합은 선택된 파라미터에 다소 민감한데, 사용 가능한 관측 네트워크 관측소의 수가 상대적으로 적은 수(74개)이기 때문일 수 있다.\n\n\n\n\n\n그림 13.2: 샘플 베리오그램에 적합된 곱-합 모델\n\n\n\n\n\n\n\n그림 13.3: 적합된 시공간 베리오그램 모델에 대한 와이어 프레임 플롯\n\n\n시공간 베리오그램을 적합하는 전략과 대체 모델에 대해서는 Gräler, Pebesma, & Heuvelink(2016)을 참고할 수 있다.\n이 적합 모델과 주어진 관측치를 바탕으로, 우리는 시공간의 임의의 위치에 대한 크리깅 또는 시뮬레이션을 수행할 수 있다. 예를 들어, 누락된 시계열 값을 추정(또는 시뮬레이션)하는데 사용할 수 있다. 이런 경우는 흔히 발생하며, 이에 대한 대처로서 12.4절에서는 관측치의 최대 25%를 배제한 시계열 평균을 계산한 바 있다. 보다 더 합리적인 옵션은, 해당 결측치를 (시공간적) 이웃의 관측치에 기반한 추정값 혹은 시뮬레이션한 값으로 대체한 후 연간 평균 값을 계산하는 것이다.\n보다 일반적인 관점에서 임의의 시공간 위치에서 추정을 수행하는 것이 가능하며, 이러한 과정을 특정 위치에서 시계열 값을 예측하는 것과 공간 슬라이스를 예측하는 것을 통해 설명할 것이다(Gräler, Pebesma, and Heuvelink 2016). 이를 위해 두 개의 공간 지점을 무작위로 선택하고 그 두 지점에 대한 모든 시간 인스턴스를 가진 stars 객체를 생성한다.\n\nset.seed(1331)\npt &lt;- st_sample(de, 2)\nt &lt;- st_get_dimension_values(no2.st, 1)\nst_as_stars(list(pts = matrix(1, length(t), length(pt)))) |&gt;\n    st_set_dimensions(names = c(\"time\", \"station\")) |&gt;\n    st_set_dimensions(\"time\", t) |&gt;\n    st_set_dimensions(\"station\", pt) -&gt; new_pt\n\n그리고 krigeST 함수를 사용하여 이 두 지점에서의 시공간 예측값을 얻는다.\n\nno2.st &lt;- st_transform(no2.st, crs)\nnew_ts &lt;- krigeST(NO2~1, data = no2.st[\"NO2\"], newdata = new_pt,\n         nmax = 50, stAni = StAni, modelList = fitProdSumModel,\n         progress = FALSE)\n\n결과는 그림 13.4에 나타나 있다.\n\n\n\n\n\n그림 13.4: 선택된 두 지점에 대한 시공간 예측의 시계열 플롯\n\n\n또한, 2017년 한 해 동안 일정한 시간 간격으로 생성된 일련의 래스터 지도들에 대한 시공간 예측을 생성할 수 있으며, 이는 다음과 같이 수행된다.\n\nst_bbox(de) |&gt;\n  st_as_stars(dx = 10000) |&gt;\n  st_crop(de) -&gt; grd\nd &lt;- dim(grd)\nt4 &lt;- t[(1:4 - 0.5) * (3*24*30)]\nst_as_stars(pts = array(1, c(d[1], d[2], time = length(t4)))) |&gt;\n    st_set_dimensions(\"time\", t4) |&gt;\n    st_set_dimensions(\"x\", st_get_dimension_values(grd, \"x\")) |&gt;\n    st_set_dimensions(\"y\", st_get_dimension_values(grd, \"y\")) |&gt;\n    st_set_crs(crs) -&gt; grd.st\n\n그리고 예측은 다음과 같이 수행된다.\n\nnew_int &lt;- krigeST(NO2~1, data = no2.st[\"NO2\"], newdata = grd.st,\n         nmax = 200, stAni = StAni, modelList = fitProdSumModel,\n         progress = FALSE)\nnames(new_int)[2] = \"NO2\"\n\n결과는 그림 13.5에 나타나 있다.\n\n\n\n\n\n그림 13.5: 네 개의 시점에 대해 수행된 시공간 예측의 결과\n\n\n여기서는 nmax 아규먼트의 값을 크게 설정할 필요가 있었는데, 이는 이산적인 이웃의 선택에서 시간과 공간을 모두 고려해야 하고 이로 인해 발생할 수 있는 시각적 왜곡(날카로운 경계)을 줄이기 위한 조치이다.\n\n13.3.2 불규칙 시공간 데이터\n관측 지점이 계속해서 변화하거나 고정된 관측 지점이라 하더라도 시간 프레임이 일관성이 없는 경우, stars 객체(벡터 데이터 큐브)는 이러한 데이터를 잘 다루지 못한다. 이러한 불규칙 시공간 관측치는 sftime 패키지(Teickner, Pebesma, and Graeler 2022)에서 제공하는 sftime 객체로 표현할 수 있다. sftime 객체는 기본적으로 sf 객체인데, 지정된 시간 컬럼을 가지고 있다. 이 사용 예시는 gstat 패키지에서 제공되는 demo(sftime)에서 찾을 수 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "13.html#연습문제",
    "href": "13.html#연습문제",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "\n13.4 연습문제",
    "text": "13.4 연습문제\n\n섹션 13.1에서 “관측 스테이션이 최소 75%의 완전한 데이터를 가져야 한다”는 기준을 적용할 때, 스테이션의 몇 %가 제거되는가?\nno2.st의 시간당 시계열 데이터에서 aggregate 함수를 사용하여 일별 평균 농도를 계산하고, 이에 대한 시공간 베리오그램을 계산하시오. 이를 시간별 베리오그램과 비교하시오.\n그림 13.5에 표시된 날짜의 일별 평균 값에 대한 시공간 인터폴레이션을 수행하고 그 결과를 비교하시오.\n13.2절에서 소개된 데모 스크립트의 예를 따라, 그림 13.5에 표시된 네 날의 일별 평균 스테이션 데이터를 사용하여 코크리깅을 수행하시오.\n시공간 크리깅에 대한 위의 접근법이 가지는 차별점은 무엇인가?\n\n\n\n\n그림 13.1: 2017년 독일의 농촌 배경 스테이션의 시간별 NO\\(_2\\) 농도에 대한 시공간 샘플 베리오그램으로 오른쪽의 컬러는 시간 지체를 나타내며(노란색이 더 늦은 시간을 나타냄) 거리의 단위는 미터이다.\n그림 13.2: 샘플 베리오그램에 적합된 곱-합 모델\n그림 13.3: 적합된 시공간 베리오그램 모델에 대한 와이어 프레임 플롯\n그림 13.4: 선택된 두 지점에 대한 시공간 예측의 시계열 플롯\n그림 13.5: 네 개의 시점에 대해 수행된 시공간 예측의 결과",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "12.html#첫-번째-데이터셋",
    "href": "12.html#첫-번째-데이터셋",
    "title": "12  공간적 인터폴레이션",
    "section": "",
    "text": "그림 12.1: 독일의 농촌 지역 관측소들에 높은 평균 NO\\(_2\\) 값이 집중해 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 12.2: 독일 NO\\(_2\\) 집중도에 대한 역거리 가중 인터폴레이션의 결과",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "12.html#조건부-시뮬레이션",
    "href": "12.html#조건부-시뮬레이션",
    "title": "12  공간적 인터폴레이션",
    "section": "\n12.6 조건부 시뮬레이션",
    "text": "12.6 조건부 시뮬레이션\n필드 \\(Z(s)\\)의 조건부 평균이 아닌 하나 혹은 여러개의 조건부 실현이 필요할 경우, 조건부 시뮬레이션을 활용할 수 있다. 조건부 실현이 필요한 경우는 비선형 함수인 \\(g(\\cdot)\\)을 통해 \\(Z(s)\\)의 구역 평균 값, 즉 \\(g(Z(s))\\)를 추정해야 하는 상황이 해당된다. 간단한 예로는 \\(Z(s)\\)가 특정 임계값을 초과하는 지역이 존재하는 경우이다.\ngstat 패키지의 기본 접근 방식은 이를 위해 순차 시뮬레이션 알고리즘을 사용하는 것이다. 이 알고리즘은 예측이 이루어지는 위치들을 무작위로 순회하며 각 위치에서 다음과 같은 작업을 수행한다.\n\n크리깅 예측을 수행한다.\n크리깅 분산과 동일한 평균과 분산을 가진 정규 분포에서 난수를 생성한다.\n이 값을 조건부 데이터셋에 추가한다.\n새로운 무작위 시뮬레이션 위치를 찾는다.\n\n이것을 모든 위치에 반복 수행한다.\ngstat 패키지의 krige 함수가 이를 수행하며 nsim 아규먼트는 양수로 설정된다.\n\nset.seed(13341)\n(s &lt;- krige(NO2~1, no2.sf, grd, v.m, nmax = 30, nsim = 6))\n# drawing 6 GLS realisations of beta...\n# [using conditional Gaussian simulation]\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#       Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\n# var1  -5.7    6.12   8.68 8.88    11.5 23.9 12456\n# dimension(s):\n#        from to  offset  delta            refsys        values x/y\n# x         1 65  280741  10000 WGS 84 / UTM z...          NULL [x]\n# y         1 87 6101239 -10000 WGS 84 / UTM z...          NULL [y]\n# sample    1  6      NA     NA                NA sim1,...,sim6\n\nset.seed()를 설정한 것은 시뮬레이션 결과가 달라지지 않도록 하기 위해서이다.\nnmax 아규먼트의 설정을 통해 크리깅 추정 시 포함할 최근접 이웃의 (최대) 개수를 제한하는 것이 필요하다. 왜냐하면 단계가 진해되면서 데이터셋이 계속 증가하기 때문에 계산 시간이 길어지고 메모리 요구량이 커지기 때문이다. 조건부 시뮬레이션의 결과가 그림 12.9에 나타나 있다.\n\n\n\n\n\n그림 12.9: NO\\(_2\\) 농도에 대한 6가지의 조건부 시뮬레이션 결과\n\n\ngstat 패키지에는 최근 조건부 시뮬레이션의 대체 기법이 추가되었으며, 원형 임베딩(circular embedding) 기법을 구현한 krigeSimCE(Davies와 Bryant, 2013)와 터닝 밴드(turning band) 기법을 구현한 krigeSTSimTB(Schlather, 2011)가 있다. 이러한 기법들은 대규모 데이터셋이나 시공간 데이터셋의 조건부 시뮬레이션에 유용하다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>공간적 인터폴레이션</span>"
    ]
  },
  {
    "objectID": "14.html",
    "href": "14.html",
    "title": "14  근접성과 에어리어 데이터",
    "section": "",
    "text": "14.1 근접성의 재현: spdep 패키지의 경우\n공간적 자기상관을 그래프 상의 이웃들의 관계를 통해 다루는 접근의 경우, 해당 그래프는 주어진 것이고, 그 그래프를 연구자가 선택한 것으로 간주한다. 이것은 지구통계학적 접근과는 다른 것인데, 연구자는 경험적 베리오그램의 거리를 어떻게 나눌 것인지, 어떤 함수를 적용할 것인지, 베리오그램 적합을 어떻게 수행할 것인지를 모두 선택한다. 두 접근법 모두 사전 선택을 포함하지만, 기저의 상관성을 재현하는 방식에서는 서로 다른 것이다(Wall 2004). 그래프에 기반한 이웃 규정 방식을 보다 넓은 맥락에서 설명하는 시도도 존재한다(Bavaud, 1998).\n이웃 관계를 나타내는 객체를 생성할 때 이웃이 없는 구역단위의 존재는 문제를 야기한다(Bivand and Portnov 2004). 섬이나 강으로 분리된 구역단위가 이러한 비이웃 구역단위일 수 있는데, 구역단위에 에어리어 스포터가 적용되어 있고 공유 경계와 같은 위상 관계가 사용되는 경우이다. 예를 들어, mgcv::gam과 같은 모델 적합 함수에서 mrf(마르코프 랜덤 필드) 항을 사용할 때, 방향이 없는 필요하지만, 그래프가 분리된 하위 그래프들로 구성되는 경우 에러가 발생한다.\n이러한 무이웃 문제는 포인트 간의 거리로 이웃을 규정하는 경우에도 발생할 수 있는데, 거리 임계값이 최근린 이웃 거리보다 작은 경우가 여기에 해당된다. 공유 경계에 기반한 연접성 규정은 비투영 경위도 좌표를 사용하더라도 영향을 받지 않지만, 모든 포인트 기반 접근법은 어쨌든 거리를 사용하며, 적절한 방식으로 거리를 계산할 필요가 있다.\nspdep 패키지는 이웃을 규정하는 nb 클래스를 제공한다. nb 클래스는 관측개체의 수를 길이로 갖는 리스트로 정수 벡터를 구성 요소로 갖는다. 이웃이 없는 경우는 0L이 단일 요소로 포함된 정수 벡터로 인코딩된다. 이웃이 있는 경우는 1L:n 범위 내의 값이 포함된 정수 벡터로 인코딩되는데, 그 값들은 이웃으로 규정된 관측개체의 인덱스값이다. 이것은 소위 행-기반 희소 재현(row-oriented sparse representation) 방식이다. spdep 패키지는 nb 객체를 생성하는 다양한 방법을 제공하며, 이 표현과 생성 함수는 다른 패키지에서도 널리 사용된다.\nspdep 패키지는 nb 클래스(무방향 혹은 유방향 그래프)를 통해 listw 객체를 구성한다. listw 객체는 세 가지 구성 요소를 갖는 리스트로, nb 객체, 가중치 리스트, 그리고 가중치 계산 방식을 나타내는 단일 요소 문자 벡터가 포함된다. 사회과학에서 가장 흔히 사용되는 방법은 행 표준화를 통해 가중치를 계산하는 것인데, 개별 관측개체의 한 이웃의 가중치는 해당 관측개체의 이웃의 수(즉 카드널리티)의 역수(즉, 1/card(nb)[i])로 변환된다.\n이 장에서는 2015년 폴란드 대통령 선거 데이터를 사용하는데, 지역 전체가 2,495개의 지방자치단체와 바르샤바 구역으로 구성되어 있다(그림 14.1 참조). 이 지도는 tmap 패키지(8.5절)를 활용해 그려진 것으로 지방자치단체 유형이 표시되어 있다. 구역단위는 sf 객체이며, 투표소 단위의 결과를 구역단위로 집계한 데이터이다.\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\ndata(pol_pres15, package = \"spDataLarge\")\npol_pres15 |&gt;\n    subset(select = c(TERYT, name, types)) |&gt;\n    head()\n# Simple feature collection with 6 features and 3 fields\n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 235000 ymin: 367000 xmax: 281000 ymax: 413000\n# Projected CRS: ETRS89 / Poland CS92\n#    TERYT                name       types\n# 1 020101         BOLESŁAWIEC       Urban\n# 2 020102         BOLESŁAWIEC       Rural\n# 3 020103            GROMADKA       Rural\n# 4 020104        NOWOGRODZIEC Urban/rural\n# 5 020105          OSIECZNICA       Rural\n# 6 020106 WARTA BOLESŁAWIECKA       Rural\n#                         geometry\n# 1 MULTIPOLYGON (((261089 3855...\n# 2 MULTIPOLYGON (((254150 3837...\n# 3 MULTIPOLYGON (((275346 3846...\n# 4 MULTIPOLYGON (((251770 3770...\n# 5 MULTIPOLYGON (((263424 4060...\n# 6 MULTIPOLYGON (((267031 3870...\nlibrary(tmap, warn.conflicts = FALSE)\n# Breaking News: tmap 3.x is retiring. Please test v4, e.g. with\n# remotes::install_github('r-tmap/tmap')\ntm_shape(pol_pres15) + tm_fill(\"types\")\nsf 객체의 위상 구조의 유효성을 검토한다.\nif (!all(st_is_valid(pol_pres15)))\n        pol_pres15 &lt;- st_make_valid(pol_pres15)\n2002년 초부터 2019년 4월까지, spdep는 이웃 및 공간 가중치 객체를 생성하고 처리하는 함수, 공간적 자기상관을 검정하는 함수, 모델 적합과 관련된 함수 등을 포함하고 있었다. 모델 적합과 관련된 함수는 spatialreg로 분리되었으며, 이후 장에서 다룰 예정이다. 현재 spdep(Bivand 2022)는 sf 클래스와 sp 클래스 객체 모두를 지원한다.\nlibrary(spdep) |&gt; suppressPackageStartupMessages()",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#이웃의-규정-연접성-기반",
    "href": "14.html#이웃의-규정-연접성-기반",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.2 이웃의 규정: 연접성 기반",
    "text": "14.2 이웃의 규정: 연접성 기반\nspdep 패키지의 poly2nb 함수는 pl 아규먼트를 통해 투입된 객체에서 폴리곤 경계를 구성하고 있는 경계 포인트들을 이용한다. 투입 객체는 일반적으로 \"POLYGON\" 또는 \"MULTIPOLYGON\" 지오메트리를 가진 \"sf\" 또는 \"sfc\" 객체이다. 각 관측개체에 대해, 최소한 하나의 포인트(디폴트 퀸 방식, queen=TRUE) 또는 최소 두 개의 포인트(루크 방식, queen=FALSE)가 snap 거리 내에 또 다른 포인트(역자주: 연접 폴리곤의 경계 포인트)를 가지는지를 확인한다. 거리 계산은 투영법에 관계없이 원 길이 단위에 기반한 평면 거리로 이루어진다. 필요한 수의 충분히 가까운 점을 찾으면, 검색이 중단된다.\n\nargs(poly2nb)\n\n#  function (pl, row.names = NULL, snap = sqrt(.Machine$double.eps),\n#    queen = TRUE, useC = TRUE, foundInBox = NULL)\nspdep 패키지 1.1-7부터, poly2nb 함수는 후보 이웃을 찾고 foundInBox를 내부적으로 채우기 위해 sf 패키지의 GEOS 인터페이스를 사용한다. 이 경우, sf 패키지를 통한 GEOS의 공간 인덱싱(STRtree 쿼리 사용)이 기본값으로 설정된다.\n\npol_pres15 |&gt; poly2nb(queen = TRUE) -&gt; nb_q\n\nprint 메서드는 이웃 객체의 요약 구조를 표시한다.\n\nnb_q\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14242 \n# Percentage nonzero weights: 0.229 \n# Average number of links: 5.71\n\nsf 패키지 버전 1.0-0부터는 구체 지오메트리를 위해 기본적으로 s2 패키지(Dunnington, Pebesma, and Rubak 2023)가 사용된다. 이는 poly2nb 함수에서 사용되는 st_intersects 함수가 계산을 s2::s2_intersects_matrix로 전달하기 때문이다(4장 참조). spdep 패키지 버전 1.1-9부터는 sf_use_s2()가 TRUE일 경우 구체 인터섹션을 사용하여 후보 이웃을 찾는다. GEOS와 마찬가지로, s2 라이브러리는 빠른 공간 인덱싱을 사용한다.\n\nold_use_s2 &lt;- sf_use_s2()\n\n\nsf_use_s2(TRUE)\n\n\n(pol_pres15 |&gt; st_transform(\"OGC:CRS84\") -&gt; pol_pres15_ll) |&gt; \n    poly2nb(queen = TRUE) -&gt; nb_q_s2\n\n예시의 경우, 구면 교차와 평면 교차가 동일한 인접 이웃을 생성한다. 두 경우 모두 투입 지오메트리의 유효성이 담보되어야 한다.\n\nall.equal(nb_q, nb_q_s2, check.attributes=FALSE)\n# [1] TRUE\n\nnb 객체는 대칭적인 이웃 관계인 \\(i\\)에서 \\(j\\), \\(j\\)에서\\(i\\)를 모두 기록하는데, 이는 nb 객체가 비대칭적인 관계도 허용하기 때문이다. 그러나 객체 생성에는 이러한 중복이 큰 의미는 없다.\n대부분의 spdep 패키지 함수는 이웃 객체를 생성할 때 row.names 아규먼트를 사용하며, 이 값은 region.id 속성으로 저장된다. 만약 row.names 아규먼트가 지정되지 않으면, 첫 번째 아규먼트의 row.names()에서 가져온다. region.id 속성은 nb 객체가 원 데이터와 동일한 순서로 정리되어 있는지를 확인하는 데 사용된다. nb 객체의 일부만 추출할 경우 인덱스는 1:length(subsetted_nb) 범위 내의 값으로 재설정되지만, region.id 속성 값을 통해 원본 객체와 정확한 연결 정보를 확인할 수 있다. 이는 17.4절에서 간략하게 논의될 공간적 회귀 모델의 샘플 외 예측에서 사용된다.\nn.comp.nb 함수를 사용하여 이 비방향 그래프의 연결성을 확인할 수도 있다. 일부 모델 추정 기법은 비연결 그래프를 지원하지 않지만, 비연결 그래프가 야기할 가능한 문제를 인지하고 있는 것은 중요하다(Freni-Sterrantino, Ventrucci, and Rue 2018).\n\n(nb_q |&gt; n.comp.nb())$nc\n# [1] 1\n\n이 접근법은 이웃 객체를 그래프처럼 취급하고 해당 그래프에 대해 그래프 분석을 수행하는 것과 동일하다(Csardi and Nepusz 2006; Nepusz 2022). 먼저 이웃 객체를 이진 희소 행렬로 변환한 후 그래프 분석을 수행한다(Bates, Maechler, and Jagan 2022).\n\nlibrary(Matrix, warn.conflicts = FALSE)\nlibrary(spatialreg, warn.conflicts = FALSE)\nnb_q |&gt; \n    nb2listw(style = \"B\") |&gt; \n    as(\"CsparseMatrix\") -&gt; smat\nlibrary(igraph, warn.conflicts = FALSE)\n(smat |&gt; graph.adjacency() -&gt; g1) |&gt; \n    count_components()\n# [1] 1\n\n다른 소프트웨어와의 호환성을 위해 이웃 객체를 GAL 형식으로 내보내고 가져올 수 있다. 이를 위해 write.nb.gal함수와 read.gal 함수가 사용된다.\n\ntf &lt;- tempfile(fileext = \".gal\")\nwrite.nb.gal(nb_q, tf)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#이웃의-규정-그리프-기반",
    "href": "14.html#이웃의-규정-그리프-기반",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.3 이웃의 규정: 그리프 기반",
    "text": "14.3 이웃의 규정: 그리프 기반",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#이웃의-규정-거리-기반",
    "href": "14.html#이웃의-규정-거리-기반",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.4 이웃의 규정: 거리 기반",
    "text": "14.4 이웃의 규정: 거리 기반\n거리 기반 이웃은 dnearneigh를 사용하여 생성할 수 있다. bounds 아규먼트를 통해 거리 구간을 설정할 수 있는데, d1과 d2는 각각 거리의 하한값과 상한값이다. 경위도 좌표계가 사용되고, 좌표 객체 x가 주어지고, longlat=TRUE로 설정된 경우, WGS84 기준 타원체를 가정하여 킬로미터 단위의 대권 거리를 계산한다. use_s2=TRUE(기본값)로 설정되면 구체를 상정한 거리 계산을 한다(4장 참조). dwithin이 FALSE이고 s2 버전이 1.0.7보다 크면 s2_closest_edges가 사용될 수 있으며, dwithin이 TRUE이고 use_s2=TRUE이면 s2_dwithin_matrix가 사용된다. 이 두 방법 모두 빠른 구형 공간 인덱싱을 사용하긴 하지만, s2_closest_edges의 경우는 최소 및 최대 경계를 지정하기 때문에 dnearneigh의 R 코드에서 한 번의 실행만으로 충분하다.\ndbscan 패키지(Hahsler and Piekenbrock 2022)에 새로운 아규먼트를 추가함으로써 2차원 또는 3차원에서 평면 공간 인덱싱을 사용하여 이웃을 찾는 기능이 보강되었고 대칭성 을 확인하는 절차가 필요없게 되었다. 또한, 구면 기하학적 거리 측정을 사용하는 세 가지 아규먼트도 추가되었다.\n\\(k\\)-최근린 이웃을 위한 knearneigh 함수는 knn 객체를 반환하며, knn2nb를 사용해 nb 객체로 전환된다. 이 함수는 구면 거리도 사용할 수 있는데, 평면 거리와는 다른 최근린 이웃이 산출될 수 있기 때문이다. \\(k\\)는 작은 숫자여야 한다. 투영 좌표의 경우 dbscan 패키지를 사용하여 최근접 이웃을 더 효율적으로 계산한다. 이렇게 생성된 nb 객체는 대개 대칭적이지 않으므로, knn2nb는 대칭성을 강제할 수 있는 sym 아규먼트를 제공한다. 대칭성을 강제하면 모든 단위가 최소 \\(k\\)개의 이웃을 가지게 되지만, 모든 단위가 정확히 \\(k\\)개의 이웃을 갖는 것은 아니다. sf_use_s2()가 TRUE인 경우, 입력 객체가 \"sf\" 또는 \"sfc\" 클래스일 때 knearneigh는 빠른 구형 공간 인덱싱을 사용한다.\nnbdists 함수는 투영 좌표의 경우 좌표 단위로 이웃 관계 엣지의 길이를 반환하고, 그렇지 않으면 킬로미터 단위로 반환한다. 거리 밴드의 상한을 설정하려면 먼저 첫 번째 최근린 이웃 거리의 최대값을 찾아야 하며, 이때 반환된 객체의 리스트 구조를 제거하기 위해 unlist를 사용할 수 있다. sf_use_s2()가 TRUE인 경우, nbdists는 입력 객체가 \"sf\" 또는 \"sfc\" 클래스일 때 빠른 구형 거리 계산을 사용한다.\n\ncoords |&gt; \n    knearneigh(k = 1) |&gt; \n    knn2nb() |&gt; \n    nbdists(coords) |&gt; \n    unlist() |&gt; \n    summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     247    6663    8538    8275   10124   17979\n\n여기서 첫 번째 최근린 이웃 거리의 최대값은 약 18km로, 이를 상한선으로 사용하면 모든 단위가 최소한 하나의 이웃을 가지게 된다.\n\ncoords |&gt; dnearneigh(0, 18000) -&gt; nb_d18\n\n사례에서 보는 것처럼 관측개체의 수가 그리 많지 않은 경우에는 공간 인덱싱을 사용해도 실행 시간에서 큰 이점을 얻지 못한다.\n\ncoords |&gt; dnearneigh(0, 18000, use_kd_tree = FALSE) -&gt; nb_d18a\n\n그리고 산출 객체도 동일하다.\n\nall.equal(nb_d18, nb_d18a, check.attributes = FALSE)\n# [1] TRUE\n\n\nnb_d18\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 20358 \n# Percentage nonzero weights: 0.327 \n# Average number of links: 8.16\n\n그런데 이웃이 없는 관측값은 없지만(이들은 nb 객체의 print 메소드에서 보고됨), 그래프는 완전 연결 상태가 아니다. 왜냐하면 한 쌍의 관측개체가 서로의 유일한 이웃이기 때문이다.\n\n(nb_d18 |&gt; n.comp.nb() -&gt; n_comp)$nc\n# [1] 2\n\n\ntable(n_comp$comp.id)\n# \n#    1    2 \n# 2493    2\n\n임계값에 300m를 추가하면 비이웃 관측단위가 없는 이웃 객체가 생성되고, 모든 관측단위는 그래프를 통해 다른 모든 관측단위에 도달할 수 있게 된다.\n\n(coords |&gt; dnearneigh(0, 18300) -&gt; nb_d183)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 21086 \n# Percentage nonzero weights: 0.339 \n# Average number of links: 8.45\n\n\n(nb_d183 |&gt; n.comp.nb())$nc\n# [1] 1\n\n거리 기반 이웃의 한 특징은 면적이 작은 단위들이 밀집된 지역일수록 더 많은 이웃을 갖는다는 것이다(예를 들어, 바르샤바 구역은 평균적으로 훨씬 작지만, 이 거리 기준으로 약 30개의 이웃을 가진다). 많은 이웃을 갖는 것은 이웃 관계를 더 많은 이웃을 통해 부드럽게 만든다.\n나중에 사용할 수 있도록, 16km의 임계값을 사용하여 비이웃 단위가 포함된 이웃 객체도 생성한다.\n\n(coords |&gt; dnearneigh(0, 16000) -&gt; nb_d16)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 15850 \n# Percentage nonzero weights: 0.255 \n# Average number of links: 6.35 \n# 7 regions with no links:\n# 569 1371 1522 2374 2385 2473 2474\n\n\\(k\\)-최근린 이웃을 사용하여 이웃의 수를 직접적으로 제어할 수 있으며, 이때 비대칭 이웃을 허용할 수도 있다.\n\n((coords |&gt; knearneigh(k = 6) -&gt; knn_k6) |&gt; knn2nb() -&gt; nb_k6)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14970 \n# Percentage nonzero weights: 0.24 \n# Average number of links: 6 \n# Non-symmetric neighbours list\n\n또는 대칭성을 강제할 수도 있다.\n\n(knn_k6 |&gt; knn2nb(sym = TRUE) -&gt; nb_k6s)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 16810 \n# Percentage nonzero weights: 0.27 \n# Average number of links: 6.74\n\n여기서 \\(k\\)의 크기는 완전 연결성을 보장하기에 충분하지만, 그래프가 반드시 평면성을 가지는 것은 아니다. 엣지가 노드가 아닌 다른 위치에서 교차하기 때문이다. 이는 연접성 기반 이웃이나 그래프 기반 이웃에서는 발생하지 않는 상황이다.\n\n(nb_k6s |&gt; n.comp.nb())$nc\n# [1] 1\n\n구체 상의 포인트들인 경우(4장에서 참조), st_centroid의 출력은 달라지므로, 포인트들을 역 투영하는 대신 역 투영된 폴리곤 지오메트리에서 경위도 좌표로 포인트들을 추출한다.\n\nold_use_s2 &lt;- sf_use_s2()\n\n\nsf_use_s2(TRUE)\n\n\npol_pres15_ll |&gt; \n    st_geometry() |&gt; \n    st_centroid(of_largest_polygon = TRUE) -&gt; coords_ll\n\n구면 좌표의 경우, 거리 경계는 킬로미터 단위로 표시된다.\n\n(coords_ll |&gt; dnearneigh(0, 18.3, use_s2 = TRUE, \n                         dwithin = TRUE) -&gt; nb_d183_ll)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 21140 \n# Percentage nonzero weights: 0.34 \n# Average number of links: 8.47\n\n이 이웃들은 예상대로 구면 18.3 km 이웃들과 다르다.\n\nisTRUE(all.equal(nb_d183, nb_d183_ll, check.attributes = FALSE))\n# [1] FALSE\n\ns2가 더 빠른 거리 이웃 인덱싱을 제공할 수 있다면, 디폴트로 s2_closest_edges가 경위도 좌표에 대해 사용된다.\n\n(coords_ll |&gt; dnearneigh(0, 18.3) -&gt; nb_d183_llce)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 21140 \n# Percentage nonzero weights: 0.34 \n# Average number of links: 8.47\n\n이 경우에는 두 s2 기반 이웃 객체가 동일하다.\n\nisTRUE(all.equal(nb_d183_llce, nb_d183_ll,\n                 check.attributes = FALSE))\n# [1] TRUE\n\ns2에서 빠른 구형 공간 인덱싱을 사용하여 \\(k\\)개의 최근린 이웃을 찾는다.\n\n(coords_ll |&gt; knearneigh(k = 6) |&gt; knn2nb() -&gt; nb_k6_ll)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14970 \n# Percentage nonzero weights: 0.24 \n# Average number of links: 6 \n# Non-symmetric neighbours list\n\n이 이웃들은 예상대로 평면 k=6 최근접 이웃과 다르지만, 전통적인 브루트포스(brute-force) 타원체 거리와도 약간 다를 것이다.\n\nisTRUE(all.equal(nb_k6, nb_k6_ll, check.attributes = FALSE))\n# [1] FALSE\n\nnbdists 함수 역시 구면 상의 거리를 계산하기 위해 s2를 사용하는데, \"sf\" 또는 \"sfc\" 투입 객체가 경위도 좌표값을 가지는 경우에 그러하다(반환된 거리는 킬로미터 단위로 표시).\n\nnb_q |&gt; nbdists(coords_ll) |&gt; unlist() |&gt; summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     0.2     9.8    12.2    12.6    15.1    33.0\n\n평면 좌표가 사용될 때와 구형 혹은 타원체 지오메트리가 사용할 때, 동일한 가중치 객체인 경우에도 계산되는 거리 값이 약간 다르다(평면 지오메트리의 경우 포인트의 단위로 거리가 반환되고, 타원체 및 구형 지오메트리의 경우 킬로미터 단위로 거리가 반환된다).\n\nnb_q |&gt; nbdists(coords) |&gt; unlist() |&gt; summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     247    9822   12173   12651   15117   33102\n\n\nsf_use_s2(old_use_s2)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#가중치-부여",
    "href": "14.html#가중치-부여",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.5 가중치 부여",
    "text": "14.5 가중치 부여\n이웃 객체를 기반으로 가중치 객체를 지정한다. 여기에 몇 가지 선택이 이루어져야 한다. nb2listw 함수는 nb 객체에 기반하여 listw 가중치 객체를 생성한다. 가중치 객체는 가중치 벡터 리스트와 스타일 선택값으로 구성된다. 비이웃 관측개체의 처리가 중요한 사안인데 zero.policy 아규먼트가 이를 담당한다. 디폴트는 FALSE로 설정되어 있으며, 이는 비이웃 관측개체의 존재가 오류를 발생시킨다는 것을 의미한다. 관측개체가 이웃을 가지지 않으면 공간지체값(spatially lagged values)을 사용할 수 없기 때문이다. 보통 비관측개체의 경우 공간지체값으로 제로가 부여되는데, 이는 제로 값의 가중치 벡터와 데이터 벡터의 교차곱과 같기 때문에 zero.policy라는 이름이 붙여졌다.\n\nargs(nb2listw)\n\n#  function (neighbours, glist = NULL, style = \"W\", zero.policy =\n#    NULL)\n우리는 스타일 선택을 변경했을 때의 결과를 보여주기 위해 아래에서 도우미 함수 spweights.constants를 사용할 것이다. 이 함수는 listw 객체에 대한 상수 값들을 반환한다. 여기서 \\(n\\)은 관측개체의 수이고, n1부터 n3은 \\(n-1,...,\\) nn은 \\(n^2\\)이며, \\(S_0\\), \\(S_1\\), \\(S_2\\)는 상수이다. \\(S_0\\)는 가중치의 합이다. 상수에 대한 자세한 논의는 Bivand와 Wong (2018)를 참고하면 된다.\n\nargs(spweights.constants)\n\n#  function (listw, zero.policy = NULL, adjust.n = TRUE)\n\"B\" 바이너리 스타일은 이웃 관계에 대해 단위 값(1)을 부여하며, 이웃의 규정을 위한 경계가 존재하는 가장자리 구역단위에 비해 더 많은 이웃을 가질 수 있는 내부 구역에 더 높은 가중치를 부여한다.\n\n(nb_q |&gt; \n    nb2listw(style = \"B\") -&gt; lw_q_B) |&gt; \n    spweights.constants() |&gt; \n    data.frame() |&gt; \n    subset(select = c(n, S0, S1, S2))\n#      n    S0    S1     S2\n# 1 2495 14242 28484 357280\n\n\"W\" 행표준화 스타일은 연구 지역의 가장자리에 위치하여 반드시 더 적은 수의 이웃을 가질 수 밖에 없는 구역단위에 더 높은 가중치를 부여한다. 행표준화 스타일은 먼저 각 이웃 관계에 대해 단위 값을 가중치로 부여한 후, 이 가중치를 각 구역단위의 가중치 합으로 나눈다. 비이웃 구역단위에서는 0을 0으로 나누게 되므로 “부정(not-a-number)”의 결과가 발생하게 된다. 물론 zero.policy를 TRUE로 설정한 경우에는 문제가 없다. 행표준화 스타일에서는 \\(S_0\\)는 \\(n\\)과 같아진다.\n\n(nb_q |&gt; \n        nb2listw(style = \"W\") -&gt; lw_q_W) |&gt; \n    spweights.constants() |&gt; \n    data.frame() |&gt; \n    subset(select = c(n, S0, S1, S2))\n#      n   S0  S1    S2\n# 1 2495 2495 958 10406\n\n역거리 가중치는 많은 애플리케이션에서 사용된다. 밀집된 역거리 행렬이 사용되는 경우 많은 역거리가 거의 0에 가깝고, 특히 공간 프로세스 행렬 자체가 밀집되어 있는 경우 실제적인 의미는 미약하다. 역거리 가중치는 보통의 다음의 절차를 통해 생성된다. 우선 엣지의 길이를 산출하고, 단위를 바꾸고(예시의 경우 미터에서 킬로미터로 변환)어 가중치가 너무 크거나 작지 않도록 하고, 그 값을 역수로 바꾼 후, nb2listw의 glist 인자를 통해 전달한다.\n\nnb_d183 |&gt; \n    nbdists(coords) |&gt; \n    lapply(function(x) 1/(x/1000)) -&gt; gwts\n(nb_d183 |&gt; nb2listw(glist=gwts, style=\"B\") -&gt; lw_d183_idw_B) |&gt; \n    spweights.constants() |&gt; \n    data.frame() |&gt; \n    subset(select=c(n, S0, S1, S2))\n#      n   S0  S1   S2\n# 1 2495 1841 534 7265\n\n비이웃 단위의 경우 디폴트로 가중치 객체가 생성되지 않는다. 이를 통해 분석가가 이후 과정을 결정할 수 있게 한다.\n\ntry(nb_d16 |&gt; nb2listw(style=\"B\") -&gt; lw_d16_B)\n# Error in nb2listw(nb_d16, style = \"B\") : Empty neighbour sets found\n\nnb와 listw 객체와 관련된 많은 함수에서는 zero.policy 아규먼트를 활용할 수 있다.\n\nnb_d16 |&gt; \n    nb2listw(style=\"B\", zero.policy=TRUE) |&gt; \n    spweights.constants(zero.policy=TRUE) |&gt; \n    data.frame() |&gt; \n    subset(select=c(n, S0, S1, S2))\n#      n    S0    S1     S2\n# 1 2488 15850 31700 506480\n\nspweights.constants 함수의 adjust.n 아규먼트는 디폴트로 TRUE로 설정되어 있어, 비이웃 관측개체 수를 차감하기 때문에 \\(n\\)이 작아지며, 통계적 추론에 영향을 미칠 수 있다. 원래 \\(n\\)은 아규먼트를 다르게 지정하면 알 수 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#고차-이웃의-규정",
    "href": "14.html#고차-이웃의-규정",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.6 고차 이웃의 규정",
    "text": "14.6 고차 이웃의 규정\n앞에서 살펴본 것처럼 퀸 인접성 기반 이웃 객체의 특성은 다음과 같다.\n\nnb_q\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14242 \n# Percentage nonzero weights: 0.229 \n# Average number of links: 5.71\n\n\\(i\\)가 \\(j\\)의 이웃이고, \\(j\\)가 \\(k\\)의 이웃인 경우, 즉 이웃 그래프에서 두 단계를 거쳐 \\(i\\)에서 \\(k\\)까지의 이웃을 나타내는 객체를 만들고자 한다면, nblag를 사용할 수 있다. 이 함수는 자동으로 \\(i\\) 에서 \\(i\\)로 가는 자기 이웃을 제거한다.\n\n(nb_q |&gt; nblag(2) -&gt; nb_q2)[[2]]\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 32930 \n# Percentage nonzero weights: 0.529 \n# Average number of links: 13.2\n\nnblag_cumul 함수는 주어진 모든 차원의 이웃 목록을 누적한다.\n\nnblag_cumul(nb_q2)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 47172 \n# Percentage nonzero weights: 0.758 \n# Average number of links: 18.9\n\nunion.nb 집합 연산은 두 개의 객체를 받아들이며, 여기서는 동일한 결과를 생성한다.\n\nunion.nb(nb_q2[[2]], nb_q2[[1]])\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 47172 \n# Percentage nonzero weights: 0.758 \n# Average number of links: 18.9\n\n앞에서 이웃 객체를 그래프 재현으로 전환하였는데, 해당 그래프 객체를 이용하면 그래프를 탐색하는 데 몇 단계가 필요한지에 대한 정보를 얻을 수 있다.\n\ndiameter(g1)\n# [1] 52\n\n각 관측개체에서 그래프를 통해 가장 짧은 경로로 도달하는 데 필요한 단계 수를 계산하여 \\(n \\times n\\) 크기의 sps 행렬을 생성한다. 이를 통해 동일한 최대 값을 얻을 수 있다.\n\ng1 |&gt; shortest.paths() -&gt; sps\n(sps |&gt; apply(2, max) -&gt; spmax) |&gt; max()\n# [1] 52\n\n최대 값을 가진 지방자치단체는 Lutowiska로, 남동부의 말단부에 위치해 우크라이나와 국경을 맞대고 있다.\n\nmr &lt;- which.max(spmax)\npol_pres15$name0[mr]\n# [1] \"Lutowiska\"\n\n그림 14.3은 연접성 기반 이웃과 거리 기반 이웃이 매우 유사하다는 점을 잘 보여준다. 어떤 경우에는 거리 기반 이웃 방법이 선호된다. 왜냐하면 모든 관측개체가 다른 모든 관측개체와 관련된다는 점을 명확히 보여주기 때문이다. 그러나 공간적 자기상관 및 공간 회귀 모델을 위한 검정은 공간적 프로세스 모델의 역(inverse)을 사용하고, 이것은 회귀계수의 벡터와 공간가중행렬의 곱을 여러번 더한 합이므로, 결국 모든 관측개체와 다른 모든 관측개체 간의 관계가 이러한 과정 속에 포함될 수 밖에 없다. 희소 연접 이웃 객체를 사용하면 이러한 복잡한 관계를 명시적으로 만들 필요 없이 풍부한 의존성 구조를 표현할 수 있다.\n\n\n\n\n\n그림 14.2: Lutowiska에 이르는 최단 경로 수와 Lutowiska까지의 거리의 관련성. 왼쪽은 Lutowiska에 이르는 최단 경로 수를 나타낸 지도이고, 오른쪽은 Lutowiska에 이르는 최단 경로 수와 Lutowiska까지의 거리의 관계를 나타낸 그래프이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#연습문제",
    "href": "14.html#연습문제",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.7 연습문제",
    "text": "14.7 연습문제\n\n어떤 종류의 지오메트리 스포트가 이웃 객체를 생성하는 함수에 적합한가?\n이웃 객체를 생성하는 함수 중 어떤 것이 평면 재현에만 적합한가?\n체스판에서 queen 연접성 대신 rook 연접성을 선택하면 어떤 차이가 발생하는가?\n이웃 집합의 카디널리티(이웃 수)와 행표준화 가중치 사이에는 어떤 관계가 있으며, 이것이 어떻게 엣지 효과(edge effect) 분석을 가능하게 하는가? 연습문제 3에서 만든 체스판을 사용하고, rook와 queen 이웃 각각에 대해 설명하라.\n\n\n\n\n그림 14.1: 폴란드 구역단위 유형(2015년)\n삼각망 이웃(오렌지색과 검은색)과 영향권 이웃(검은색)의 비교. 군데군데 구멍이 형성되어 있는데, 모두 도시 구역이 농촌 구역으로 완전히 둘러싸여 있는 경우(그림 14.1 참조)에 해당한다.\n그림 14.2: Lutowiska에 이르는 최단 경로 수와 Lutowiska까지의 거리의 관련성. 왼쪽은 Lutowiska에 이르는 최단 경로 수를 나타낸 지도이고, 오른쪽은 Lutowiska에 이르는 최단 경로 수와 Lutowiska까지의 거리의 관계를 나타낸 그래프이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#근접성의-재현-spdep-패키지의-경우",
    "href": "14.html#근접성의-재현-spdep-패키지의-경우",
    "title": "14  근접성과 에어리어 데이터",
    "section": "",
    "text": "그림 14.1: 폴란드 구역단위 유형(2015년)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#이웃의-규정-그래프-기반",
    "href": "14.html#이웃의-규정-그래프-기반",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.3 이웃의 규정: 그래프 기반",
    "text": "14.3 이웃의 규정: 그래프 기반\n구역단위가 적합한 재현이지만 평면 상의 포인트로 관찰된 경우, 연접성은 그래프 기반 이웃을 사용하여 근사할 수 있다. 이 경우, 평면은 폴리곤 테셀레이션(역자주: 티센폴리곤과 같은 것)으로 분할되는데, 각 폴리곤 내의 모든 지점은 해당 포인트를 가장 가까운 포인트로 갖는다. 가장 간단한 형태는 삼각망 형성(triangulation)을 사용하는 것인데, 여기서는 deldir 패키지의 deldir 함수를 사용한다. 이 함수는 \\(i\\)와 \\(j\\) 식별자를 반환하므로, 세로(긴) 형식으로 listw 객체를 구성하는 것이 용이하다. 이는 S-Plus SpatialStats 모듈에서 사용되었던 방식이고, nb 객체(가로 형식)를 구성하기 위해 내부적으로 sn2listw 함수에서 사용되는 방식이기도 하다. GEOS와 같은 다른 대안들은 이웃의 식별을 위한 충분한 정보를 반환하지 못한다.\n이러한 함수들이 리턴한 결과는 graph2nb 함수를 통해 nb 객체로 전환된다. 이 때 sym 아규먼트를 사용하여 이웃 관계의 대칭성을 규정할 수 있다. 그래프 기반 방식을 적용하기 위해 폴리곤의 센트로이드(다중폴리곤의 경우 가장 큰 폴리곤의 센트로이드)를 포인트 재현으로 활용한다. 물론 인구 가중 센트로이드를 구할 수 있다면 더 좋다.\n\npol_pres15 |&gt; \n    st_geometry() |&gt; \n    st_centroid(of_largest_polygon = TRUE) -&gt; coords \n(coords |&gt; tri2nb() -&gt; nb_tri)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14930 \n# Percentage nonzero weights: 0.24 \n# Average number of links: 5.98\n\n평균 이웃수의 측면에서 보면 퀸 방식의 경계 연접성과 유사한 결과가 나왔다. 그러나 nbdists() 함수를 사용하여 엣지 길이의 분포를 살펴보면, 상위 4분위 수는 약 15km 정도이지만 최대값은 거의 300km에 달한다는 것을 알 수 있다. 이는 전체 지역을 포괄하는 컨벡스 헐의 한쪽 면의 길이에 버금가는 것이다. 최소 거리 역시 중요하다. 왜냐하면 많은 도시 구역의 센트로이드가 주변 농촌 구역의 센트로이드와 매우 근접해 있기 때문이다.\n\nnb_tri |&gt; \n    nbdists(coords) |&gt; \n    unlist() |&gt; \n    summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     247    9847   12151   13485   14994  296974\n\n삼각망에 의거한 이웃 규정도 연결 그래프(역자주: 그래프 상의 모든 지점이 직간접적으로 연결되어 있는 그래프)를 생성한다.\n\n(nb_tri |&gt; n.comp.nb())$nc\n# [1] 1\n\n그래프 기반 접근법에는 soi.graph, relativeneigh, gabrielneigh와 같은 것들이 있다. 여기서는 soi.graph만 살펴본다.\nsoi.graph 함수에서 soi는 영향권(sphere of influence)의 약자이다. 이 함수는 삼각망 이웃에서 비정상적으로 긴 엣지로 표현된 이웃 관계는 제거함으로써 실질적인 의미를 가진 이웃 관계만 남긴다. 이러한 비정상적으로 긴 엣지는 컨벡트 헐의 가장 자리에서 흔히 나타나는 것이다(Avis and Horton, 1985).\n\n(nb_tri |&gt; \n        soi.graph(coords) |&gt; \n        graph2nb() -&gt; nb_soi)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 12792 \n# Percentage nonzero weights: 0.205 \n# Average number of links: 5.13\n\n그러나 삼각망에 의거한 이웃 관계의 일부를 해체하면, 연결 그래프로서의 전체적인 성격은 사라지게 된다.\n\n(nb_soi |&gt; n.comp.nb() -&gt; n_comp)$nc\n# [1] 16\n\n이 알고리즘은 비정상적으로 긴 엣지를 제거하도록 설계되었지만, 농촌 구역들이 하나의 도시 구역을 완전히 둘러싸고 있는 경우 매우 가까운 도시-농촌 쌍의 엣지도 잘못 삭제될 수 있다. 이러한 결과로 15개의 도시-농촌 쌍이 메인 그래프로부터 분리되는 결과가 초래된 것이다.\n\ntable(n_comp$comp.id)\n# \n#    1    2    3    4    5    6    7    8    9   10   11   12   13 \n# 2465    2    2    2    2    2    2    2    2    2    2    2    2 \n#   14   15   16 \n#    2    2    2\n\n컨벡스 헐에서 가장 긴 엣지들이 제거되었지만, 연결되지 않은 이웃 쌍들이 나타나면서 “구멍”이 생겼다. nb_tri와 nb_soi의 차이는 그림 14.2에서 주황색으로 표시되었다.\n\n\n삼각망 이웃(오렌지색과 검은색)과 영향권 이웃(검은색)의 비교. 군데군데 구멍이 형성되어 있는데, 모두 도시 구역이 농촌 구역으로 완전히 둘러싸여 있는 경우(그림 14.1 참조)에 해당한다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "15.html",
    "href": "15.html",
    "title": "15  공간적 자기상관 측도",
    "section": "",
    "text": "15.1 측도와 프로세스 오지정\nTobler(1970)가 말한 지리학의 제1법칙, 즉 “모든 것은 다른 모든 것과 연관되어 있다. 그러나 가까이 있는 것은 멀리 떨어져 있는 것보다 더 많이 연관되어 있다”가 만고의 진리인 것으로 취급되어서는 안된다. 이는 지나치게 단순화된 개념으로 다른 잠재적 문제들, 즉 개체화(entitation)의 문제(역자주: 사용된 공간단위가 해당 공간적 현상을 분석하기에 적당한 것인가와 관련된 문제로 소위 ’공간단위 임의성의 문제(MAUP, modifiable areal unit problem)’와 관련된 것이다), 스포트의 문제, 기타 오지정(misspecification)의 문제(역자주: 통계 모델에서 해당 현상을 설명하기에 적절하지 않은 방식으로 변수 설정이 이루어진 경우를 통칭하는 용어인데, 주로 주요 변수의 누락이 야기하는 문제를 지적한다)를 덮어 버릴 수 있다. 관측 단위의 크기가 기저의 공간 프로세스의 스케일에 부합하는가? 주어진 관측 단위 하에서 표출된 관심 변수의 공간적 패턴이 다른 변수의 공간적 패턴으로 설명될 수 있는가?\n토블러(Tobler, 1970)의 논문은 올슨(Olsson, 1970)의 논문과 함께 Economic Geography의 특별호에 실렸다. 하지만 올슨은 공간적 자기상관이 공간적 현상에 필연적으로 내재되어 있는 것이 아니라, 부적절한 개체화, 누락된 변수, 그리고/또는 부적절하게 설정된 함수 관계에 의해 발생하는 경우가 더 많다는 점을 간파했다. Olsson의 핵심 인용구는 228쪽에 있다.\n“제1법칙”으로서의 지위는 존 스노(John Snow)가 콜레라의 원인이 수인성이라는 것을 지도로부터 유도해냈다는 믿음과 매우 유사하다. 이는 GIS를 홍보하는 좋은 방법일 수 있지만, 부정확한 것이다. Snow는 Soho를 방문하기 전에 이미 강력한 작업 가설을 가지고 있었고, 그 지도는 Broad Street 펌프가 차단된 후 그의 가설이 맞다는 것을 문서화하기 위해 작성된 것이었다(Brody et al. 2000).\n불행히도 공간적 자기상관 측도는 우리가 데이터를 모델링하는 과정에서 저지른 다른 오지정 오류를 반영한다(Schabenberger and Gotway 2005; McMillen 2003). 참고로, 모런 통계량은 다음과 같이 주어진다(Cliff and Ord 1981, 17).\n\\[\nI=\\frac {n\\sum_{(2)}w_{ij} z_i z_j}{S_0\\sum^n_{i=1}z^2_i}\n\\]\n여기서 \\(z_i=x_i-\\bar{x}\\), \\(x_i\\)는 해당 변수의 \\(n\\)개의 관측값 중 하나, \\(\\bar{x}=\\sum^n_{i=1}x_i/n\\), \\(\\sum_{(2)}=\\sum^n_{i=1}\\sum^n_{j=1}(i\\neq j)\\), \\(w_{ij}\\)는 공간적 가중치, \\(S_0=\\sum_{(2)}w_{ij}\\)이다. 먼저 우리는 무작위 확률 변수에 대해 공간적 자기상관을 검토하고자 하는데, 정규성 가정(아규먼트를 randomisation=FALSE로 지정) 하에서 모런 검정을 행한다. 검정통계량은 \\(Z(I)=\\frac{I-E(I)}{\\sqrt{Var(I)}}\\)로, 산출된 z-값을 \\(E(I)\\)와 \\(Var(I)\\)를 가진 정규분포와 대조한다. 아래는 무작위 확률 변수에 공간적 자기상관이 존재하지 않는다는 검정 결과이다.\nlibrary(spdep) |&gt; suppressPackageStartupMessages()\nlibrary(parallel)\nglance_htest &lt;- function(ht) c(ht$estimate, \n    \"Std deviate\" = unname(ht$statistic), \n    \"p.value\" = unname(ht$p.value))\nset.seed(1)\n(pol_pres15 |&gt; \n    nrow() |&gt; \n    rnorm() -&gt; x) |&gt; \n    moran.test(lw_q_B, randomisation = FALSE,\n               alternative = \"two.sided\") |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#         -0.004772         -0.000401          0.000140 \n#       Std deviate           p.value \n#         -0.369320          0.711889\n그런데 약간의 공간적 경향성을 가진 가상의 변수를 생성하고 그것을 또 다른 변수로 간주하는 대신 원 무작위 변수와 합산했다고 하자. 이 상태에서 동일한 검정을 적용하면 이번에는 강한 공간적 자기상관이 나타나게 된다. 공간적 경향성을 가진 변수를 모델에 포함시키지 않았다는 측면에서 변수 누락의 문제가 있는 것인데 그것이 공간적 자기상관의 문제로 전이된 것이다.\nbeta &lt;- 0.0015\ncoords |&gt; \n    st_coordinates() |&gt; \n    subset(select = 1, drop = TRUE) |&gt; \n    (function(x) x/1000)() -&gt; t\n(x + beta * t -&gt; x_t) |&gt; \n    moran.test(lw_q_B, randomisation = FALSE,\n               alternative = \"two.sided\") |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#          0.043403         -0.000401          0.000140 \n#       Std deviate           p.value \n#          3.701491          0.000214\n공간적 경향성을 가진 변수를 선형 모델에 독립적인 변수로 투입하면, 잔차에서 공간적 자기상관이 사라진 것을 확인할 수 있다.\nlm(x_t ~ t) |&gt; \n    lm.morantest(lw_q_B, alternative = \"two.sided\") |&gt; \n    glance_htest()\n# Observed Moran I      Expectation         Variance      Std deviate \n#        -0.004777        -0.000789         0.000140        -0.337306 \n#          p.value \n#         0.735886\n다양한 공간적 자기상관 측도가 다양한 R 패키지에서 이용가능하다. 그 중에서 spdep 패키지(Bivand 2022b)가 핵심적 역할을 담당하며, 패키지간 차이는 주로 실행 디자인과 관련되어 있다(Bivand and Wong 2018). spdep 패키지를 통해 회귀 잔차에 대한 전역적 및 국지적 모런 검정을 행할 수 있으며, 다른 패키지와 달리 정확(exact) 및 안장점 근사법(Tiefelsdorf 2002; Bivand, Müller, and Reder 2009)을 제공한다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#측도와-프로세스-오지정",
    "href": "15.html#측도와-프로세스-오지정",
    "title": "15  공간적 자기상관 측도",
    "section": "",
    "text": "이러한 자기상관의 존재는 Tobler(1970)의 “모든 것은 다른 모든 것과 연관되어 있다. 그러나 가까이 있는 것은 멀리 떨어져 있는 것보다 더 많이 연관되어 있다”는 주장에 동의하고 싶어지게 만든다. 그러나 한편으로 이러한 자기상관이 체계적인 오지정 오류를 감추는 것처럼 보인다는 사실은 이 주장을 ’지리학의 제1법칙’으로 격상시키는 것이 우선은 성급하다는 점을 시사한다. 최악의 경우, 이 주장은 사후 오류(post hoc fallacy)(단순한 우연을 인과 관계로 잘못 해석하는 오류)의 공간적 변형에 불과한 것일 수 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#전역적-측도",
    "href": "15.html#전역적-측도",
    "title": "15  공간적 자기상관 측도",
    "section": "\n15.2 전역적 측도",
    "text": "15.2 전역적 측도\n\n15.2.1 범주 데이터를 위한 조인-카운트 통계량\n먼저 조인-카운트(join-count) 통계량을 살펴본다. 여기서 joincount.test 함수는 \"factor\" 값 벡터 fx와 listw 객체를 입력받고, stats 패키지에서 정의된 htest(가설 검정) 객체들의 리스트를 반환한다. 반환되는 htest 객체는 fx 아규먼트의 각 수준에 대해 하나씩 생성된다. 관찰된 카운트는 동일한 범주 수준을 가진 이웃쌍의 수로, 이를 동일 색상 조인(same-colour joins)이라고 한다.\n\nargs(joincount.test)\n\n#  function (fx, listw, zero.policy = NULL, alternative = \"greater\",\n#    sampling = \"nonfree\", spChk = NULL, adjust.n = TRUE)\n이 함수는 가설 검정을 위한 alternative 아규먼트와 통계량의 분산을 구성하는 기준을 나타내는 sampling 아규먼트를 입력받는다. 기본값인 \"nonfree\"는 개념적으로 분석적 순열(analytical permutation)과 동일한 것이다. spChk 아규먼트는 이전 버전과의 호환성을 위해 유지된다. 참고로, 앞에서 살펴본 지방자치단체 및 바르샤바 데이터에 대한 범주 유형별 카운트는 다음과 같다.\n\n(pol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = types, drop = TRUE) -&gt; Types) |&gt; \n    table()\n# \n#          Rural          Urban    Urban/rural Warsaw Borough \n#           1563            303            611             18\n\n네 개의 범주 유형, 즉 네 개의 수준이 있으므로, htest 객체 리스트를 재배열하여 추정된 결과를 나타내는 행렬을 생성한다. 관찰된 동일-컬러 조인 카운트는 입력된 범주 수준의 카운트를 기반으로 한 기대값과 함께 표로 정리된다. 예를 들어 바르샤바 구역 간에는 결합이 거의 없을 것으로 예상된다. 이는 구역의 수가 매우 적기 때문이다. 분산 계산은 선택된 listw 객체의 기본 상수와 입력 범주 수준의 카운트를 사용하여 수행된다. z-값은 관찰된 조인 카운트와 기대값의 차이를 분산의 제곱근으로 나누어 얻어진다.\n조인-카운트 검정은 컬러 멀티-컬러 조인 카운트 상황으로의 확장을 위해 수정되었다(Upton and Fingleton 1985). spdep에서 joincount.multi 함수로 구현되었는데 비자유 샘플링(non-free sampling)을 기반으로 표를 반환하며, p-값은 보고하지 않는다.\n\nTypes |&gt; joincount.multi(listw = lw_q_B)\n#                               Joincount Expected Variance z-value\n# Rural:Rural                    3087.000 2793.920 1126.534    8.73\n# Urban:Urban                     110.000  104.719   93.299    0.55\n# Urban/rural:Urban/rural         656.000  426.526  331.759   12.60\n# Warsaw Borough:Warsaw Borough    41.000    0.350    0.347   68.96\n# Urban:Rural                     668.000 1083.941  708.209  -15.63\n# Urban/rural:Rural              2359.000 2185.769 1267.131    4.87\n# Urban/rural:Urban               171.000  423.729  352.190  -13.47\n# Warsaw Borough:Rural             12.000   64.393   46.460   -7.69\n# Warsaw Borough:Urban              9.000   12.483   11.758   -1.02\n# Warsaw Borough:Urban/rural        8.000   25.172   22.354   -3.63\n# Jtot                           3227.000 3795.486 1496.398  -14.70\n\n바이너리 가중치를 적용하는 상항에서는 조인-카운트의 합에 해당 조인에 대한 가중치를 곱한 값도 여전히 정수로 나타난다. 만약 행표준화 가중치를 적용하게 되면, 가중치가 대부분 1보다 작은 분수가 되기 때문에 카운트, 기대값, 분산은 달라진다. 그러나 최종적인 z-값에는 큰 변화가 없다.\n그러나 역거리 기반의 listw 객체를 사용하면 z-값이 크게 변한다. 이는 가까운 센트로이드에 상대적으로 강한 가중치가 부여되기 때문이다.\n\nTypes |&gt; joincount.multi(listw = lw_d183_idw_B)\n#                               Joincount Expected Variance z-value\n# Rural:Rural                    3.46e+02 3.61e+02 4.93e+01   -2.10\n# Urban:Urban                    2.90e+01 1.35e+01 2.23e+00   10.39\n# Urban/rural:Urban/rural        4.65e+01 5.51e+01 9.61e+00   -2.79\n# Warsaw Borough:Warsaw Borough  1.68e+01 4.53e-02 6.61e-03  206.38\n# Urban:Rural                    2.02e+02 1.40e+02 2.36e+01   12.73\n# Urban/rural:Rural              2.25e+02 2.83e+02 3.59e+01   -9.59\n# Urban/rural:Urban              3.65e+01 5.48e+01 8.86e+00   -6.14\n# Warsaw Borough:Rural           5.65e+00 8.33e+00 1.73e+00   -2.04\n# Warsaw Borough:Urban           9.18e+00 1.61e+00 2.54e-01   15.01\n# Warsaw Borough:Urban/rural     3.27e+00 3.25e+00 5.52e-01    0.02\n# Jtot                           4.82e+02 4.91e+02 4.16e+01   -1.38\n\n\n15.2.2 모런 통계량\nspdep 패키지에서 모런 통계량은 moran.test 함수로 구현되어 있다. 이 함수는 joincount.test 함수와 유사한 아규먼트를 가지지만, 샘플링 대신 랜덤화(randomisation)를 사용하여 측정의 분산을 계산한다. 또한 수치 값 대신 순위를 사용할 수도 있다(Cliff and Ord 1981, 46). 일부 오래된 소프트웨어에서는 분산 항목의 마지막 구성 요소가 생략된채 나타나는데, drop.EI2 아규먼트는 그것을 재현해준다.\n\nargs(moran.test)\n\n#  function (x, listw, randomisation = TRUE, zero.policy = NULL,\n#    alternative = \"greater\", rank = FALSE, na.action = na.fail,\n#    spChk = NULL, adjust.n = TRUE, drop.EI2 = FALSE)\nrandomisation 아규먼트의 디폴트는 TRUE인데, FALSE를 지정하게 되면 정규성 가정 하에서의 검정을 수행하게 된다. 아래의 사례를 통해, 단일 변수에 정규성 가정을 적용한 검정 결과와 절편만이 포함된 회귀 모델의 잔차에 대한 랜덤화 가정 하에서의 검정 결과가 동일하게 나타난다는 점을 알게 될 것이다. 해당 변수는 2015년 폴란드 대통령 선거의 투표율이다. randomisation의 철자는 Cliff와 Ord (1973)의 방식에 따른 것이다.\n\npol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = I_turnout, drop = TRUE) -&gt; I_turnout\n\n\nI_turnout |&gt; moran.test(listw = lw_q_B, randomisation = FALSE) |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#          0.691434         -0.000401          0.000140 \n#       Std deviate           p.value \n#         58.461349          0.000000\n\nlm.morantest 함수는 resfun 아규먼트도 가지고 있는데, 이를 통해 검정을 위한 잔차를 추출하는 함수를 설정할 수 있으며, 종속 변수의 다른 중요한 특징을 모델화할 수 있게 해준다(Cliff and Ord 1981, 203). 단일 변수에 대한 표준 테스트와 비교하기 위해 여기서는 절편만 포함된 회귀 모델을 사용하였으며, 그 결과가 동일함을 확인할 수 있다.\n\nlm(I_turnout ~ 1, pol_pres15) |&gt; \n    lm.morantest(listw = lw_q_B) |&gt; \n    glance_htest()\n# Observed Moran I      Expectation         Variance      Std deviate \n#         0.691434        -0.000401         0.000140        58.461349 \n#          p.value \n#         0.000000\n\n정규성과 랜덤화 가정 하에서의 검정 간 차이는 변수의 첨도가 정상 범위를 벗어나는 경우 추가 항목이 더해진다는 점이다. 이때 사용되는 척도는 고전적인 첨도 측정법이다. 디폴트인 랜덤화 가정 하에서는 결과가 크게 변화하지는 않는다.\n\n(I_turnout |&gt; \n    moran.test(listw = lw_q_B) -&gt; mtr) |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#          0.691434         -0.000401          0.000140 \n#       Std deviate           p.value \n#         58.459835          0.000000\n\n1970년대 초반부터 몬테카를로(Monte Carlo) 검정, 즉 호프(Hope) 유형의 검정 혹은 순열 부트스트랩으로 알려진 검정 절차에 대한 관심이 제기되었다. 기본적으로 moran.mc 함수는 \"htest\" 객체를 반환하지만, 내부적으로는 boot::boot을 사용하기 때문에 return_boot=TRUE로 설정하면 \"boot\" 객체를 반환할 수도 있다. 또한 시뮬레이션 횟수는 nsim으로 지정하는데, 이는 관측값들이 무작위로 섞이는 횟수를 나타낸다.\n\nset.seed(1)\nI_turnout |&gt; \n    moran.mc(listw = lw_q_B, nsim = 999, \n             return_boot = TRUE) -&gt; mmc\n\n부트스트랩 순열은 각 무작위 순열의 결과를 보존하며, 통계량의 관측값(여기서는 모런 통계값)과 랜덤화 시뮬레이션의 평균값(\\(E(I)\\)와 동일한 역할)의 차이, 그리고 램덤화 시뮬레이션의 표준 편차를 보고한다.\n몬테카를로 시뮬레이션의 분산과 랜덤화 가정 하의 분석적 분산을 비교하면 보통 큰 차이가 없으며, 이는 몬테카를로 검정의 무용론을 주장할 근거가 된다.\n\nc(\"Permutation bootstrap\" = var(mmc$t), \n  \"Analytical randomisation\" = unname(mtr$estimate[3]))\n#    Permutation bootstrap Analytical randomisation \n#                 0.000144                 0.000140\n\n기어리의 전역적 통계량(Geary’s \\(C\\))는 moran.test 함수와 거의 동일한 아규먼트 구조를 따라 geary.test 함수로 구현되어 있다. 게티스-오드(Getis-Ord \\(G\\)) 테스트는 추가적인 아규먼트를 가지는데, 이는 Bivand와 Wong (2018)이 지적한 바처럼, 초기 통계량의 변종이 이후에 나타났고 주로 거리 기반 이웃 규정에서는 생성되는 무이웃 관측개체를 다루는 방식에서의 차이를 반영해야 하기 때문이다. Getis와 Ord(1992)의 194 페이지를 보면, \\(G^*\\)의 경우, \\(G\\)와는 달리 \\(i \\neq j\\) 합산 제약이 완화되어 \\(i\\)가 자기 자신을 이웃으로 포함할 수 있다(따라서 모든 관측개체가 적어도 하나의 이웃을 가지므로 무이웃 문제도 해결된다).\n마지막으로, 경험적 베이즈 모런 통계량은 비율 데이터에서 공간적 자기상관을 평가할 때 분모를 고려할 수 있게 해준다(Assunção and Reis 1999). 지금까지 우리는 공간단위별로 유효 투표수와 투표권을 가진 인구수의 비율을 고려했으나, EBImoran.mc 함수를 사용하면 투표권을 가진 인구수가 적은 공간단위에서의 극단적인 비율값이 가지는 통계적 불확실성을 반영할 수 있게 된다. 그러나 결과에는 큰 영향이 없다.\n지금까지 다룬 전역적 공간적 자기상관 통계량은 이웃 그래프에 기반한 공간 가중치를 활용한 측도들이다. 이러한 측도들을 매우 정교한 통계적 툴이라고 부르기는 어려울 것 같다. 왜냐하면 결과의 해석이 해당 변수에 대한 평균 모델을 어떻게 설정하느냐에 크게 의존하기 때문이다. 만약 평균 모델이 절편만을 가진 모델이라면, 전역적 통계량은 공간적 자기상관 뿐만 아니라 다른 모든 종류의 오지정 문제에 동시에 반응하게 된다(역자주: 공간적 자기상관 통계량이 측정하고 검정하는 것 속에는 다른 오지정 문제가 포함될 수 있기 때문에, 공간적 자기상관 통계량을 정교한 측도라고 평가할 수 없다는 의미이다). 공간단위의 선정과 관련된 개체화의 문제가 일반적으로는 오지정 문제의 핵심적인 원인이 된다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#국지적-측도",
    "href": "15.html#국지적-측도",
    "title": "15  공간적 자기상관 측도",
    "section": "\n15.3 국지적 측도",
    "text": "15.3 국지적 측도\n전역적 측도의 한계를 극복하기 위한 노력의 일환으로, 1990년대 초반부터 국지적 공간연관성 지표들이 등장하기 시작했다(Anselin 1995; Getis and Ord 1992, 1996).\n또한, 모런 플롯을 통해 관심 변수와 관심 변수의 공간 지연값(spatially lagged values) 간의 관련성을 시각화할 수 있게 되었다. 일반적으로 행 표준화 가중치를 사용하면 축을 보다 더 직접적으로 비교할 수 있게 된다(Anselin 1996). moran.plot 함수는 또한 영향력 측정 객체(influence measures object)를 반환하는데, 전역적 모런 통계값을 나타내는 직선의 기울기에 상대적으로 큰 영향을 미치는 관측개체를 표시할 수 있게 해준다. 그림 15.1에서 높은 영향력을 미치는 관측개체가 상당히 많다는 점을 확인할 수 있다. 이러한 관측값과 공간지연 관측값의 쌍이 집합적으로 글로벌 측도를 구성하지만, 세부적으로도 탐색할 수 있다. 모런 플롯에서, 왼쪽 하단 사분면에는 낮은 값-낮은 값(low-low) 쌍이, 오른쪽 상단 사분면에는 높은 값-높은 값(high-high) 쌍이, 왼쪽 상단 사분면과 오른쪽 하단 사분면에는 낮은 값-높은 값(low-high) 및 높은 값-낮은 값(high-low) 쌍이 나타난다. 앞의 두 개의 사분면에 비해 상대적으로 적은 수가 포함되어 있다. moran.plot 함수에서 사분면은 변수값와 공간지연값의 평균을 기준으로 나뉘지만, 해당 값을 표준화한 경우라면 0을 기준으로 나뉘기도 한다.\n\n\n\n\n\n그림 15.1: 투표율에 대한 모런 플롯으로 행 표준화된 가중치가 사용되었다.\n\n\n반환된 객체에서 회귀 영향 측정값(hat influence measure)을 추출하여 지도를 그리면(그림 15.2) 경계부에 위치한 공간단위들이 높은 값을 나타내는 것을 볼 수 있다(아마도 행표준화 공간가중치행렬을 적용했기 때문일 수도 있음)(역자주: 경계부의 공간단위는 상대적으로 적은 수의 이웃을 가지며, 행 표준화가 적용되었을 때 상대적으로 높은 가중치를 부여받게 된다.). 대도시 혹은 그 주변 지역에서도 높은 값을 관찰할 수 있다.\n\nlibrary(tmap)\n# Breaking News: tmap 3.x is retiring. Please test v4, e.g. with\n# remotes::install_github('r-tmap/tmap')\npol_pres15$hat_value &lt;- infl_W$hat\ntm_shape(pol_pres15) + tm_fill(\"hat_value\")\n\n\n\n\n\n\n그림 15.2: 모런 회귀 영향 측도값의 분포로 행 표준화 행렬을 적용함.\n\n\n\n15.3.1 국지적 모런 통계량\nBivand와 Wong(2018)은 국지적 모런 통계량(Moran’s \\(I_i\\))​과 국지적 게티스-오드 통계량(Getis-Ord \\(G_i\\))​와 같은 국지적 지표 사용에 영향을 미치는 문제들을 다루었다. 일부 문제는 국지적 지표 계산에 영향을 미치며, 다른 문제는 해당 값의 통계적 추론에 영향을 미친다. \\(n\\)개의 관측단위에 대해 \\(n\\)개의 통계값이 산출되기 때문에, 다중 비교(multiple comparison) 문제를 해결할 필요가 있다. Caldas de Castro와 Singer(2006)는 전형적인 데이터셋과 시뮬레이션 실험을 바탕으로, 확률 값에 대한 오발견율(FDR, false discovery rate) 조정이 무조정의 결과보다 흥미로운 클러스터를 더 잘 보여줄 것이라고 결론지었다. 이를 바탕으로, Anselin(2019)은 FDR 조정을 재정의된 “유의성” 기준치(Benjamin et al., 2018)와 결합하는 방식을 제안했다. 예를 들어, 기존의 0.1, 0.05, 0.01 대신 0.01, 0.005, 0.001을 사용하는 방식이다. 또한 유의적(significant) 대신 흥미로운(interesting)이라는 용어를 사용할 것을 권고하였다. 이러한 논의는 Bivand(2022a)에서 더 자세히 다루어진다. 전역적 통계량과 마찬가지로, 오지정 문제는 여전히 혼란의 원인이 되며, 전역적 공간적 자기상관이 존재하는 상황에서 국지적 공간적 자기상관을 해석하는 것은 여전히 도전 과제이다(Ord and Getis 2001; Tiefelsdorf 2002; Bivand, Müller, and Reder 2009).\n\nargs(localmoran)\n\n#  function (x, listw, zero.policy = NULL, na.action = na.fail,\n#    conditional = TRUE, alternative = \"two.sided\", mlvar = TRUE,\n#    spChk = NULL, adjust.x = FALSE)\nBivand와 Wong(2018)는 국지적 모런 통계량의 표준 편차에 대해 분석적 공식에 기반한 방식과 조건부 순열(permutation)에 기반한 방식을 비교한 바 있다. 이에 대해 Sauer et al.(2021)은 그러한 비교가 오해에 기반하고 있음을 명확히 보여주었다. Sokal, Oden, 그리고 Thomson(1998)은 총괄(total) 순열과 조건부 순열에 기반한 국지적 모런 통계량의 표준 편차 공식을 제시한 바 있는데, Bivand와 Wong(2018)에서 사용된 분석 공식은 이전의 관행에 기반하여 총괄 순열만 사용하며, 따라서 시뮬레이션 조건부 순열과 일치하지 않는다. 적시에 제안된 풀 리퀘스트 덕분에, 이제 localmoran 함수는 Sokal, Oden, 그리고 Thomson(1998)의 부록에 수록되어 있는 대안적 공식을 사용한 conditional 논리 아규먼트(디폴트는 TRUE)를 포함한다. localmoran 함수의 mlvar와 adjust.x 아규먼트가 필요한 이유는 Bivand와 Wong(2018)에 나타나 있으며, 다른 패키지의 결과와 비교할 수 있게 해준다. \"two.sided\" 확률 값을 디포트로 설정하여 다음과 같은 결과를 얻을 수 있다.\n\nI_turnout |&gt; \n    localmoran(listw = lw_q_W) -&gt; locm\n\n국지적 모런 통계량을 합산한 후 공간 가중치의 합으로 나누면 전역적 모런 통계량과 같아지며, 국지적 수준에서의 양 혹은 음의 공간적 자기상관의 존재를 확인할 수 있다.\n\nall.equal(sum(locm[,1])/Szero(lw_q_W), \n          unname(moran.test(I_turnout, lw_q_W)$estimate[1]))\n# [1] TRUE\n\nstats::p.adjust를 사용하여 다중 비교를 조정한 결과, 조정을 적용하지 않을 경우 2,495개의 국지적 지표 중 15% 이상이 p-value &lt; 0.005를 가지는 것으로 나타났다. 그러나 전체 오류율(FWER, family-wise error rate)(역자주: 다중 가설 검정에서 최소한 하나의 개별 검정에서 제1종 오류가 발생할 확률을 의미하는데, 예를 들어 전체 오류률을 0.05로 하는 경우 개별 검정에서의 오류률은 반드시 0.05보다 적은 값이어야 함.)을 제어하기 위해 Bonferroni 조정을 사용할 경우 이는 1.5%로 감소한다. 두 가지 다른 옵션을 통한 조정도 가능한데, \"fdr\"은 Benjamini와 Hochberg(1995)의 허위 발견율(FDR) 조정 방법으로 약 6%를 나타내고, \"BY\"는 Benjamini와 Yekutieli(2001)의 또 다른 FDR 조정 방법으로 약 2.5%를 보였다.\n\npva &lt;- function(pv) cbind(\"none\" = pv, \n    \"FDR\" = p.adjust(pv, \"fdr\"), \"BY\" = p.adjust(pv, \"BY\"),\n    \"Bonferroni\" = p.adjust(pv, \"bonferroni\"))\nlocm |&gt; \n    subset(select = \"Pr(z != E(Ii))\", drop = TRUE) |&gt; \n    pva() -&gt; pvsp\nf &lt;- function(x) sum(x &lt; 0.005)\napply(pvsp, 2, f)\n#       none        FDR         BY Bonferroni \n#        385        149         64         38\n\n전역적 측도에서는 분석적 방법을 대체할 수 있는 추론 방식으로 부트스트랩 순열을 사용할 수 있다. 그런데 분석적 분산 도출 방식과 순열 방식 모두 모든 관측값을 뒤섞는 것에 기반하고 있다. 국지적 측도에서는 조건부 순열이 사용되어야 하며, 이는 관측개체 \\(i\\)의 값을 고정한채로 나머지 \\(n-1\\)개의 값을 무작위로 샘플링하여 해당 이웃의 값을 결정하는 방식이다. 조건부 순열은 localmoran_perm 함수로 제공되며, 여러 컴퓨팅 노드가 있는 경우 병렬 샘플링이 가능하고, 각 컴퓨팅 노드에서 난수 생성기의 시드를 설정할 수도 있다. nsim 아규먼트로 시뮬레이션 수를 설정할 수 있는데, 시뮬레이션된 값 중 관측된 모런 통계값의 순위에 기반한 확률값 추정치의 정밀도를 결정한다.\n\nlibrary(parallel)\ninvisible(spdep::set.coresOption(max(detectCores()-1L, 1L)))\nI_turnout |&gt; \n    localmoran_perm(listw = lw_q_W, nsim = 9999, \n                    iseed = 1) -&gt; locm_p\n\n그 결과, 다중 비교 조정이 없는 경우 15% 이상의 관측값이 양측 p값이 0.005 미만으로 나타났고, Bonferroni 조정을 적용했을 때는 약 1.5%가 p값이 0.005 미만이었다. 여기서 p값은 순열 샘플의 표준 편차와 정규 분포를 사용하여 계산된 것이다.\n\nlocm_p |&gt; \n    subset(select = \"Pr(z != E(Ii))\", drop = TRUE) |&gt; \n    pva() -&gt; pvsp\napply(pvsp, 2, f)\n#       none        FDR         BY Bonferroni \n#        380        148         64         39\n\n해당 변수가 반드시 정규 분포를 따른다고 가정할 수 없으므로, 모든 시뮬레이션 값 중에 관측값의 순위를 결정하고 그것에 기반하여 균등 분포에서의 확률 값을 계산하는 방식으로 p값을 구할 수도 있다.\n\nlocm_p |&gt; \n    subset(select = \"Pr(z != E(Ii)) Sim\", drop = TRUE) |&gt; \n    pva() -&gt; pvsp\napply(pvsp, 2, f)\n#       none        FDR         BY Bonferroni \n#        391        127          0          0\n\n위의 결과는 \"BY\"와 본페로니 방식을 적용할 경우 9999개의 샘플의 경우에는 흥미로운 위치가 없다는 점을 말하고 있다. 하지만 샘플 수를 999999로 증가시킨다면 흥미로운 위치가 발견될 수 있다. FDR 조정과 흥미로운 컷오프 0.005를 적용하면 약 5%의 위치가 흥미로운 위치로 나타난다.\n\npol_pres15$locm_pv &lt;- p.adjust(locm[, \"Pr(z != E(Ii))\"], \"fdr\")\npol_pres15$locm_std_pv &lt;- p.adjust(locm_p[, \"Pr(z != E(Ii))\"], \n                                   \"fdr\")\npol_pres15$locm_p_pv &lt;- p.adjust(locm_p[, \"Pr(z != E(Ii)) Sim\"],\n                                 \"fdr\")\n\n\n\n\n\n\n그림 15.3: 국지적 모런 통계량의 FDR 유의확률 값. 왼쪽 상단 패널에는 분석적 조건부 유의확률이, 오른쪽 상단 패널에는 순열 표준 편차를 활용한 조건부 유의확률이, 왼쪽 하단 패널에는 순열 순위 조건부 유의확률이 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n\n\nFDR 조정과 흥미로운 위치 컷오프 0.005를 적용하여 진행한 결과, 그림 15.3에서 볼 수 있듯이 분석적 조건부 접근법, 순열 샘플링에서 샘플된 값들의 적률(moments)을 사용하는 접근법, 순열 샘플 내에서 관측 값의 순위를 사용하는 접근법 모두 비슷한 지도 패턴을 보여준다. 이는 입력 변수의 분포가 정규 분포에 매우 가깝기 때문에 발생한 것이다.\n국지적 모런 통계치를 제시할 때는 종종 “핫스팟” 맵이 사용된다. 국지적 모런 통계값은 입력 변수의 값이 낮든 높든 강한 양의 자기상관을 보이기만 하면 높은 값을 가지므로, 유사한 값을 가지는 이웃들의 “클러스터”가 어디에서 발생하는지를 낮은 값의 클러스터와 높은 값의 클러스터를 구분하여 보여주는 것이 어렵다. 이를 해결하기 위해 모런 플롯을 사용할 수 있는데, 변수값과 공간 지체값의 평균을 기준으로 범주형 사분면 변수를 생성한다. 그런 다음, 기준 확률 값과 조정 과정에 의거해 모런 통계값이 “흥미로운” 값으로 간주되지 않으면 해당 개체의 사분면 범주값은 NA로 설정된다. 아래의 사례에서는 FDR 조정된 조건부 분석 확률 값이 사용되었는데(그림 15.3, 왼쪽 상단 패널), 53개의 관측치가 “Low-Low” 클러스터에, 96개의 관측치는 “High-High” 클러스터에 속한다. 이는 표준 편차 기반의 순열 p-값(그림 15.3, 오른쪽 상단 패널)에서도 비슷하지만, 순위 기반의 순열 p-값은 “High-High” 클러스터의 수가 줄고 “Low-Low” 클러스터의 군집 수가 증가한다(그림 15.3, 왼쪽 하단 패널).\n\nquadr &lt;- attr(locm, \"quadr\")$mean\na &lt;- table(addNA(quadr))\nlocm |&gt; hotspot(Prname=\"Pr(z != E(Ii))\", cutoff = 0.005, \n                droplevels=FALSE) -&gt; pol_pres15$hs_an_q\nlocm_p |&gt; hotspot(Prname=\"Pr(z != E(Ii))\", cutoff = 0.005, \n                  droplevels=FALSE) -&gt; pol_pres15$hs_ac_q \nlocm_p |&gt; hotspot(Prname=\"Pr(z != E(Ii)) Sim\", cutoff = 0.005,\n                  droplevels = FALSE) -&gt; pol_pres15$hs_cp_q\nb &lt;- table(addNA(pol_pres15$hs_an_q))\nc &lt;- table(addNA(pol_pres15$hs_ac_q))\nd &lt;- table(addNA(pol_pres15$hs_cp_q))\nt(rbind(\"Moran plot quadrants\" = a, \"Analytical cond.\" = b, \n  \"Permutation std. cond.\" = c, \"Permutation rank cond.\" = d))\n#           Moran plot quadrants Analytical cond.\n# Low-Low                   1040               53\n# High-Low                   264                0\n# Low-High                   213                0\n# High-High                  978               96\n# &lt;NA&gt;                         0             2346\n#           Permutation std. cond. Permutation rank cond.\n# Low-Low                       53                     56\n# High-Low                       0                      0\n# Low-High                       0                      0\n# High-High                     95                     71\n# &lt;NA&gt;                        2347                   2368\n\n\npol_pres15$hs_an_q &lt;- droplevels(pol_pres15$hs_an_q)\npol_pres15$hs_ac_q &lt;- droplevels(pol_pres15$hs_ac_q)\npol_pres15$hs_cp_q &lt;- droplevels(pol_pres15$hs_cp_q)\n\n\n\n\n\n\n그림 15.4: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(유의수준은 0.005). 왼쪽 상단 패널에는 분석적 조건부 유의확률이, 오른쪽 상단 패널에는 순열 표준 편차를 활용한 조건부 유의확률이, 왼쪽 하단 패널에는 순열 순위 조건부 유의확률이 적용된 경우가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n\n\nFigure 15.4는 세 가지 접근 방식인 분석적 조건부 표준 편차, 순열 기반 표준 편차, 순위 기반 확률 값에 대해 \\(\\alpha=0.005\\) 확률 값 컷오프를 선택한 경우 FDR 조정된 흥미로운 클러스터들 사이에 거의 차이가 없음을 보여준다. “High-High” 클러스터의 핵심부는 대도시 지역이다.\nTiefelsdorf (2002)는 국지적 모런 통계량의 표준 편차 계산을 위한 표준 접근 방식에 수치적 추정치를 추가해야 한다고 주장하며, 안장점 근사를 통해 이 목표를 달성하는 것이 계산적으로 효율적인 방법임을 보여준다. localmoran.sad 함수는 첫 번째 아규먼트로 적합된 선형 모델을 받으므로, 우선 기본 모델(절편만 있는 모델)을 적합시켜야 한다. 그런데 유권자 수가 구역별로 매우 상이하므로 그것의 효과를 통제하기 위해 결국 가중 선형 모델을 적합시킨다.\n\nlm(I_turnout ~ 1) -&gt; lm_null\n\n안장점 근사 방식은 조건부 순열만큼 계산이 많이 소요된다. 많은 샘플에 대해 단일한 측정값을 계산하는 대신, 각 국지적 근사에 대해 상당한 수치 계산이 필요하기 때문이다.\n\nlm_null |&gt; localmoran.sad(nb = nb_q, style = \"W\",\n                                  alternative = \"two.sided\") |&gt;\n        summary() -&gt; locm_sad_null\n\n안장점 근사법의 주요 장점은 단순히 수치 변수를 사용하는 대신, 적합된 선형 모델을 사용하여 잔차를 분석한다는 점이다. 절편만 있는 모델을 사용하면 결과는 국지적 모런 통계량과 유사하지만, 관찰값에 가중치를 부여할 수 있다. 여기서는 투표권이 있는 사람의 수를 기준으로 가중치를 부여하며, 이를 통해 작은 단위의 관찰값은 낮은 가중치를 받게 된다.\n\nlm(I_turnout ~ 1, weights = pol_pres15$I_entitled_to_vote) -&gt;\n        lm_null_weights\nlm_null_weights |&gt;\n            localmoran.sad(nb = nb_q, style = \"W\",\n                           alternative = \"two.sided\") |&gt;\n        summary() -&gt; locm_sad_null_weights\n\n다음으로, 농촌, 도시 및 기타 유형의 관찰 단위를 구분하는 범주형 변수를 추가한다.\n\nlm(I_turnout ~ Types, weights=pol_pres15$I_entitled_to_vote) -&gt;\n        lm_types\nlm_types |&gt; localmoran.sad(nb = nb_q, style = \"W\",\n                                  alternative = \"two.sided\") |&gt;\n        summary() -&gt; locm_sad_types\n\n\nlocm_sad_null |&gt; hotspot(Prname=\"Pr. (Sad)\",\n                     cutoff=0.005) -&gt; pol_pres15$locm_sad0\nlocm_sad_null_weights |&gt; hotspot(Prname=\"Pr. (Sad)\",\n                     cutoff = 0.005) -&gt; pol_pres15$locm_sad1\nlocm_sad_types |&gt; hotspot(Prname=\"Pr. (Sad)\",\n                     cutoff = 0.005) -&gt; pol_pres15$locm_sad2\n\n\n\n\n\n\n그림 15.5: 국지적 모런 통계량의 FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 상단 패널에는 순열 표준 편차를 활용한 조건부 유의확률이, 오른쪽 상단 패널에는 기본(절편만 있는) 모델의 안장점 근사에 근거한 유의확률이 , 왼쪽 하단 패널에는 가중 기본(절편만 있는) 모델의 안장점 근사에 근거한 유의확률이, 오른쪽 하단 패널에는 가중 유형 모델의 안장점 근사에 근거한 유의확률이 적용된 경우가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n\n\n\nrbind(null = append(table(addNA(pol_pres15$locm_sad0)),\n                    c(\"Low-High\" = 0), 1),\n      weighted = append(table(addNA(pol_pres15$locm_sad1)),\n                        c(\"Low-High\" = 0), 1),\n      type_weighted = append(table(addNA(pol_pres15$locm_sad2)),\n                        c(\"Low-High\" = 0), 1))\n#               Low-Low Low-High High-High &lt;NA&gt;\n# null               19        0        55 2421\n# weighted            9        0        52 2434\n# type_weighted      13        0        81 2401\n\n그림 15.5의 왼쪽 상단 패널에는 비교의 목적으로 순열 순위 기반 클러스터가 제시되어 있다. 안장점 근사법은 더 풍부한 평균 모델을 사용할 수 있게 해주고, \\(i\\)에서의 회귀 잔차 값을 그 이웃들의 값과 연결시킨다는 의미에서 본질적으로 국지적인 근사법이기 때문에, 안정접 근사법에 기반한 나머지 세 개의 패널은 제법 다른 패턴을 보여주고 있다. 절편만 있는 (기본) 모델은 표준적 결과와 매우 유사하지만, 유권자 수에 따른 가중치 부여로 말미암아 대부분의 “Low-Low” 클러스터가 제거된 모습을 보인다. 범주형 유형 변수를 추가하면 도시의 “High-High” 클러스터가 강화되지만, 바르샤바 구역들은 흥미로운 군집 핵으로서 제외된다. 높은 투표율을 보인 바르샤바의 중앙 구역들은 마찬가지로 높은 투표율을 보이는 다른 구역들에 의해 둘러싸여 있는데, 이것은 공간적 자기상관에 기인한 것이 아니라 모두 대도시 구역들로 이루어졌기 때문이다. 또한, 전역적 공간 프로세스가 통합된 경우 안장점 근사법을 사용할 수 있는데, 이는 표준 접근 방식에서의 전역 및 지역 공간 자가 상관의 결합을 제거한다.\n같은 결과를 정확 접근법을 사용하여 달성할 수도 있지만, 수치 적분이 실패할 수 있어 표준 편차의 정확한 추정값 대신 NaN을 반환하는 경우가 있을 수 있으므로 더 많은 조정이 필요할 수 있다(Bivand, Müller, and Reder 2009).\n\nlm_types |&gt; localmoran.exact(nb = nb_q, style = \"W\", \n    alternative = \"two.sided\", useTP=TRUE, truncErr=1e-8) |&gt; \n    as.data.frame() -&gt; locm_ex_types\n\n\nlocm_ex_types |&gt; hotspot(Prname = \"Pr. (exact)\",\n                         cutoff = 0.005) -&gt; pol_pres15$locm_ex\n\n\n\n\n\n\n그림 15.6: 국지적 모런 통계량의 FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 패널에는 가중 유형 모델의 안장점 근사에 근거한 유의확률이, 오른편 패널에는 가중 유형 정확 접근법에 의거한 유의확률 의 결과가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n\n\n그림 15.6에서 볼 수 있듯이, 정확 방법과 안장점 근사 방법은 동일한 회귀 잔차, 다중 비교 조정 방법, 그리고 기준값 수준을 적용했을 때 거의 동일한 클러스터 분류 결과를 산출한다. 아래에 나타나 있는 것처럼, 둘 사이의 불일치는 정확 방법이 4개의 부가적인 관측개체를 흥미로운 케이스로 탐지한다는 것이다.\n\ntable(Saddlepoint = addNA(pol_pres15$locm_sad2),\n      exact = addNA(pol_pres15$locm_ex))\n#            exact\n# Saddlepoint Low-Low High-High &lt;NA&gt;\n#   Low-Low        13         0    0\n#   High-High       0        81    0\n#   &lt;NA&gt;            2         2 2397\n\n\n15.3.2 국지적 게티스-오드 통계량\n국지적 게티스-오드 측도(Getis-Ord \\(G_i\\))(Getis and Ord 1992, 1996)는 표준 편차값으로 주어진다. include.self 아규먼트를 통해 이웃 객체에 자신을 포함하도록 설정하면 \\(G^*_i\\) 측도값을 계산할 수도 있다. return_internals=TRUE를 설정하면 관측값, 대값, 그리고 그에 대한 분석적 분산값이 반환된다.\n\nI_turnout |&gt; \n        localG(lw_q_W, return_internals = TRUE) -&gt; locG\n\n순열에 기반한 가설검정도 가능하다.\n\nI_turnout |&gt; \n        localG_perm(lw_q_W, nsim = 9999, iseed = 1) -&gt; locG_p\n\n분석적 표준편차에 기반한 유의확률, 순열-기반 표준편차에 기반한 유의확률(첫 번째 두 열과 행), 순열 순위-기반 유의확률간의 상관관계는 매우 강하다.\n\ncor(cbind(localG=attr(locG, \"internals\")[, \"Pr(z != E(Gi))\"], \n    attr(locG_p, \"internals\")[, c(\"Pr(z != E(Gi))\", \n                                  \"Pr(z != E(Gi)) Sim\")]))\n#                    localG Pr(z != E(Gi)) Pr(z != E(Gi)) Sim\n# localG                  1              1                  1\n# Pr(z != E(Gi))          1              1                  1\n# Pr(z != E(Gi)) Sim      1              1                  1\n\n\n15.3.3 국지적 기어리 통계량\nAnselin(2019)은 Anselin(1995)를 확장한 내용으로, Josiah Parry의 기여(풀 리퀘스트: https://github.com/r-spatial/spdep/pull/66) 덕분에 최근 spdep에 추가되었다. \\(I_i\\)와 \\(G_i\\)에 사용된 조건부 순열 프레임워크가 국지적 기어리 통계량(\\(C_i\\))에도 적용된다.\n\nI_turnout |&gt; \n        localC_perm(lw_q_W, nsim=9999, iseed=1) -&gt; locC_p\n\n순열 표준편차 기반 유의확률과 순위-기반 유의확률값은 \\(G_i\\)에 비해 상관관계가 그리 높지 않은데, 이는 부분적으로 \\(C_i\\)에서는 값들의 유사성을 값들의 곱이 아닌 값들 간의 차이 함수로 표현하는데, 공간적 자기상관에 대한 이러한 개념화의 차이가 반영된 것으로 해석된다.\n\ncor(attr(locC_p, \"pseudo-p\")[, c(\"Pr(z != E(Ci))\",\n                                 \"Pr(z != E(Ci)) Sim\")])\n#                    Pr(z != E(Ci)) Pr(z != E(Ci)) Sim\n# Pr(z != E(Ci))              1.000              0.966\n# Pr(z != E(Ci)) Sim          0.966              1.000\n\n\nlocC_p |&gt; hotspot(Prname = \"Pr(z != E(Ci)) Sim\",\n                  cutoff = 0.005) -&gt; pol_pres15$hs_C\nlocG_p |&gt; hotspot(Prname = \"Pr(z != E(Gi)) Sim\",\n                  cutoff = 0.005) -&gt; pol_pres15$hs_G\n\n\n\n\n\n\n그림 15.7: FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 패널에는 국지적 모런 통계량에 의한 공간 클러스터, 가운데 패널에는 국지적 게티스-오드 통계량에 의한 공간 클러스터, 오른편 패널에는 국지적 기어리 통계량에 의한 공간 클러스터가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n\n\n그림 15.7은 동일한 변수(투표율)와 동일한 공간 가중치를 사용하여 \\(I_i\\), \\(G_i\\), \\(C_i\\)를 통해 흥미로운 클러스터 핵심부를 식별한 결과가 매우 유사함을 보여준다. 통계적 추론을 위해 순위-기반 순열 FDR 조정 확률값을 사용했고 \\(\\alpha=0.005\\) 기준값이 적용되었다. 대부분의 경우, \"High-High\" 클러스터 핵심은 도시 지역이며, \"Low-Low\" 클러스터의 핵심은 북부의 인구 밀도가 낮은 농촌 지역과 남부 국경 근처의 독일 소수 민족 지역이다. 세 가지 측도는 클러스터 핵심을 명명하는 데 약간 다른 전략을 사용한다. \\(I_i\\)는 모런 산점도 플롯의 사분면을 사용하고, \\(G_i\\)는 입력 변수의 평균을 기준으로 \"Low\"와 \"High\"로 나눈다(이는 \\(I_i\\) 튜플의 첫 번째 요소와 동일). \\(C_i\\)는 입력 변수의 평균값 기준으로 하지만 공간 지체값에 대해서는 0을 기준으로 나눈다. 이전과 마찬가지로 해당 케이스를 갖지 않는 클러스터 범주는 제외된다.\n비교를 위해, 다변량 \\(C_i\\)로 넘어가기 전에 두 번째(최종) 라운드 투표율에 대한 단변량 \\(C_i\\)를 살펴보자. 1차 투표에서 상위 두 후보 간의 결선 투표는 1차 투표에서 명확한 선호를 보이지 않았던 일부 유권자를 동원할 가능성이 있지만, 1차 투표에서 탈락한 후보에게 강한 충성심을 가졌던 일부 유권자들의 참여를 저해할 가능성도 있다.\n\npol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = II_turnout) |&gt; \n        localC_perm(lw_q_W, nsim=9999, iseed=1) -&gt; locC_p_II\n\n\nlocC_p_II |&gt; hotspot(Prname = \"Pr(z != E(Ci)) Sim\",\n                     cutoff = 0.005) -&gt; pol_pres15$hs_C_II\n\n다변량 \\(C_i\\)(Anselin 2019)는 단변량 \\(C_i\\)의 합을 변수 개수로 나눈 값으로 계산되지만, 순열은 고정되어 변수 간 상관관계가 변하지 않도록 한다.\n\npol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = c(I_turnout, II_turnout)) |&gt;\n        localC_perm(lw_q_W, nsim=9999, iseed=1) -&gt; locMvC_p\n\n다변량 \\(C_i\\)가 단변량 \\(C_i\\)의 평균값임을 다음과 같이 확인해 볼 수 있다.\n\nall.equal(locMvC_p, (locC_p+locC_p_II)/2,\n          check.attributes = FALSE)\n# [1] TRUE\n\n\nlocMvC_p |&gt; hotspot(Prname = \"Pr(z != E(Ci)) Sim\",\n                    cutoff = 0.005) -&gt; pol_pres15$hs_MvC\n\n\n\n\n\n\n그림 15.8: FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 패널에는 첫 번째 라운드 투표율에 대한 공간 클러스터, 가운데 패널에는 두 번째 라운드 투표율에 대한 공간 클러스터, 오른편 패널에는 두 라운드 모두의 투표율에 대한 공간 클러스터가 나타나 있다. 행 표준화 이웃이 적용되었다.\n\n\n그림 15.8은 다변량 측도가 개별 단변량 측도에서 흥미로운 케이스로 확인된 관측개체들을 기본적으로 결합하고 있음을 보여준다. 이를 세분화하기 위해 1차 및 2차 라운드 단변량 측도값을 결합하고, 이를 다변량 측정값과 대조하여 표로 정리할 수 있다.\n\ntable(droplevels(interaction(addNA(pol_pres15$hs_C),\n                             addNA(pol_pres15$hs_C_II), sep=\":\")), \n      addNA(pol_pres15$hs_MvC))\n#                      \n#                       Positive &lt;NA&gt;\n#   High-High:High-High       81    0\n#   NA:High-High              41   27\n#   Low-Low:Low-Low           25    0\n#   NA:Low-Low                43   11\n#   NA:Other Positive          1    0\n#   NA:Negative                0    1\n#   High-High:NA              15    0\n#   Low-Low:NA                11    3\n#   NA:NA                     36 2200\n\n다변량 \\(C_i\\)에서는 흥미로운 케이스로 나타난 관측개체들 중 47개는 단변량 \\(C_i\\) 어디에서도 흥미로운 케이스로 나타나지 않은 것이다(FDR, 기준값 0.005). 1차 및 2차 라운드에서 모두 흥미로운 것으로 나타난 관측값은 거의 모두 다변량에서도 흥미로운 것으로 간주되지만, 두 라운드 중 하나에서만 흥미로운 것으로 나타난 관측값의 경우는 보다 혼재된 결과가 도출되었다.\n\n15.3.4 rgeoda 패키지\nrgeoda(Li and Anselin 2022) 패키지는 Geoda의 R 래퍼 패키지로, spdep 패키지와 유사한 기능을 제공함으로써 에어리어 데이터에서의 공간적 자기상관을 탐색할 수 있게 해준다. 활성 객체는 컴파일된 작업 공간의 메모리 주소를 참조하는 포인터로 관리된다. 즉 모든 오퍼레이션이 컴파일된 코드를 통해 실행되기 때문에(GeoDa와 동일한 방식) rgeoda 패키지는 빠른 성능을 자랑한다. 그러나 수정이나 기능 확장이 필요할 때는 유연성이 떨어진다.\n\nlibrary(rgeoda)\nGeoda_w &lt;- queen_weights(pol_pres15)\nsummary(Geoda_w)\n#                      name               value\n# 1 number of observations:                2495\n# 2          is symmetric:                 TRUE\n# 3               sparsity: 0.00228786229774178\n# 4        # min neighbors:                   1\n# 5        # max neighbors:                  13\n# 6       # mean neighbors:    5.70821643286573\n# 7     # median neighbors:                   6\n# 8           has isolates:               FALSE\n\n비교를 위해, 2015년 폴란드 대통령 선거 투표율에 대한 다변량 \\(C_i\\)를 지표를 살펴보자.\n\nlisa &lt;- local_multigeary(Geoda_w, \n    pol_pres15[c(\"I_turnout\", \"II_turnout\")], \n    cpu_threads = max(detectCores() - 1, 1),\n    permutations = 99999, seed = 1)\n\n연접 이웃을 비교 하면 위에서 poly2nb 함수를 통해 규정된 것과 동일하다.\n\nall.equal(card(nb_q), lisa_num_nbrs(lisa), \n          check.attributes = FALSE)\n# [1] TRUE\n\n다변량 \\(C_i\\) 값도 위와 동일하다.\n\nall.equal(lisa_values(lisa), c(locMvC_p),\n          check.attributes = FALSE)\n# [1] TRUE\n\n한 가지 차이점은 rgeoda에서 사용하는 접힌(folded) 양측 순위-기반 순열 유의확률 값의 범위가 \\([0,0.5]\\)로 제한된다는 점이며, 이는 spdep에서도 계산되지만, 다르게 처리될 수 있다는 것이다.\n\napply(attr(locMvC_p, \"pseudo-p\")[,c(\"Pr(z != E(Ci)) Sim\", \n                                \"Pr(folded) Sim\")], 2, range)\n#      Pr(z != E(Ci)) Sim Pr(folded) Sim\n# [1,]             0.0002         0.0001\n# [2,]             0.9990         0.4995\n\n이것은 \\([0,1]\\) 범위에서 \\(0.005\\)에 해당하는 컷오프 값이 \\([0,0.05]\\) 범위에서는 \\(0.0025\\)에 해당한다는 의미이다.\n\nlocMvC_p |&gt; hotspot(Prname = \"Pr(folded) Sim\",\n                    cutoff = 0.0025) -&gt; pol_pres15$hs_MvCa\n\n따라서 local_multigeary 함수는 클러스터 핵심 클래스를 설정할 때 기본 컷오프 값인 \\(0,05\\)를 사용했지만, 우리는 컷오프 값을 더 엄격하게 설정하고 lisa 객체의 출력 구성 요소에 FDR 조정을 적용하여 결과를 더 신뢰성 있게 만들 수 있다.\n\nmvc &lt;- factor(lisa_clusters(lisa), levels=0:2,\n              labels = lisa_labels(lisa)[1:3])\nis.na(mvc) &lt;- p.adjust(lisa_pvalues(lisa), \"fdr\") &gt;= 0.0025\npol_pres15$geoda_mvc &lt;- droplevels(mvc)\n\nregoda 순열 방식을 통해 약 80개의 추가 관측값이 흥미로운 케이스인 것으로 확인되었으며, 구현 세부 사항에 대한 추가 분석이 여전히 진행 중이다.\n\naddmargins(table(spdep = addNA(pol_pres15$hs_MvCa),\n                 rgeoda = addNA(pol_pres15$geoda_mvc)))\n#           rgeoda\n# spdep      Positive &lt;NA&gt;  Sum\n#   Positive      249    4  253\n#   &lt;NA&gt;           75 2167 2242\n#   Sum           324 2171 2495\n\n\n\n\n\n\n그림 15.9: FDR 조정 다변량 기어리 핫스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 \\([0,0.5]\\) 범위에서 0.0025가 .적용되었다. 왼편 패널은 합산 투표율을 spdep에 적용한 결과이고, 오른편 패널은 합산 투표율을 rgeoda에 적용한 결과이다. 행 표준화 이웃이 적용되었다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#연습문제",
    "href": "15.html#연습문제",
    "title": "15  공간적 자기상관 측도",
    "section": "\n15.4 연습문제",
    "text": "15.4 연습문제\n\n체스판의 조인-카운트 통계값이 rook과 queen 이웃 간에 매우 상이하게 나타나는 이유를 설명하라.\n15.1절에서 보여준 시뮬레이션을 체스판 다각형과 행 표준화된 queen 연접 이웃을 사용하여 반복하라. 공간적 자기상관이 보통 (피할 수 없는) 데이터의 모델 오지정을 나타낸다는 것을 이해하는 것이 중요한 이유를 설명하라.\n국지적 공간적 자기상관 통계량에 FDR 조정이 권장되는 이유를 설명하라.\n물음 2의 시뮬레이션 데이터에 대해 분석적 조건 접근법과 안장점 근사법을 사용한 \\(I_i\\)의 표준편차 값(검정 통계값)을 비교하라. 안장점 근사법의 장단점을 설명하라.\n\n\n\n\n그림 15.1: 투표율에 대한 모런 플롯으로 행 표준화된 가중치가 사용되었다.\n그림 15.2: 모런 회귀 영향 측도값의 분포로 행 표준화 행렬을 적용함.\n그림 15.3: 국지적 모런 통계량의 FDR 유의확률 값. 왼쪽 상단 패널에는 분석적 조건부 유의확률이, 오른쪽 상단 패널에는 순열 표준 편차를 활용한 조건부 유의확률이, 왼쪽 하단 패널에는 순열 순위 조건부 유의확률이 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n그림 15.4: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(유의수준은 0.005). 왼쪽 상단 패널에는 분석적 조건부 유의확률이, 오른쪽 상단 패널에는 순열 표준 편차를 활용한 조건부 유의확률이, 왼쪽 하단 패널에는 순열 순위 조건부 유의확률이 적용된 경우가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n그림 15.5: 국지적 모런 통계량의 FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 상단 패널에는 순열 표준 편차를 활용한 조건부 유의확률이, 오른쪽 상단 패널에는 기본(절편만 있는) 모델의 안장점 근사에 근거한 유의확률이 , 왼쪽 하단 패널에는 가중 기본(절편만 있는) 모델의 안장점 근사에 근거한 유의확률이, 오른쪽 하단 패널에는 가중 유형 모델의 안장점 근사에 근거한 유의확률이 적용된 경우가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n그림 15.6: 국지적 모런 통계량의 FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 패널에는 가중 유형 모델의 안장점 근사에 근거한 유의확률이, 오른편 패널에는 가중 유형 정확 접근법에 의거한 유의확률 의 결과가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n그림 15.7: FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 패널에는 국지적 모런 통계량에 의한 공간 클러스터, 가운데 패널에는 국지적 게티스-오드 통계량에 의한 공간 클러스터, 오른편 패널에는 국지적 기어리 통계량에 의한 공간 클러스터가 나타나 있다. 투표율 데이터에 행 표준화 이웃이 적용되었다.\n그림 15.8: FDR 조정 하스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 0.005가 적용되었다. 왼쪽 패널에는 첫 번째 라운드 투표율에 대한 공간 클러스터, 가운데 패널에는 두 번째 라운드 투표율에 대한 공간 클러스터, 오른편 패널에는 두 라운드 모두의 투표율에 대한 공간 클러스터가 나타나 있다. 행 표준화 이웃이 적용되었다.\n그림 15.9: FDR 조정 다변량 기어리 핫스팟 클러스터 지도로 양측검정이고 흥미로운 컷오프값으로 \\([0,0.5]\\) 범위에서 0.0025가 .적용되었다. 왼편 패널은 합산 투표율을 spdep에 적용한 결과이고, 오른편 패널은 합산 투표율을 rgeoda에 적용한 결과이다. 행 표준화 이웃이 적용되었다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "16.html",
    "href": "16.html",
    "title": "16  공간적 회귀분석",
    "section": "",
    "text": "16.1 마르코프 랜덤 필드와 다수준 모델\n\\[\nY=X\\beta+Zu+\\epsilon\n\\]\n\\[\n\\Sigma^{-1}=[(I-\\rho W)'(I-\\rho W)]\n\\]\n\\[\n\\Sigma^{-1}=(I=\\rho W)\n\\]\n\\[\n\\Sigma^{-1}=M=\\text{diag}(n_i)-W\n\\]\n\\[\n\\Sigma^{-1}=[(1-\\rho)I_n+\n\\rho M]\n\\]",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "16.html#마르코프-랜덤-필드와-다수준-모델",
    "href": "16.html#마르코프-랜덤-필드와-다수준-모델",
    "title": "16  공간적 회귀분석",
    "section": "",
    "text": "16.1.1 보스턴 주택가격 데이터셋",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "16.html#보스턴-데이터셋에-대한-다수준-모델",
    "href": "16.html#보스턴-데이터셋에-대한-다수준-모델",
    "title": "16  공간적 회귀분석",
    "section": "16.2 보스턴 데이터셋에 대한 다수준 모델",
    "text": "16.2 보스턴 데이터셋에 대한 다수준 모델\n\n16.2.1 IID 랜덤 효과: lme4 패키지의 활용\n\n\n16.2.2 IID와 CAR 랜덤 효과: hglm 패키지의 활용\n\n\n16.2.3 IID와 ICAR 랜덤 효과: R2BayesX 패키지의 활용\n\n\n16.2.4 IID, ICAR, Lerouzx 랜덤 효과: INLA 패키지의 활용\n\n\n16.2.5 ICAR 랜덤 효과: mgcv 패키지의 gam() 함수의 활용\n\n\n16.2.6 상위-수준 랜덤 효과: 요약",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "16.html#연습문제",
    "href": "16.html#연습문제",
    "title": "16  공간적 회귀분석",
    "section": "16.3 연습문제",
    "text": "16.3 연습문제",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  }
]