[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "공간데이터사이언스 개론",
    "section": "",
    "text": "서장\n데이터사이언스는 주어진 데이터를 바탕으로 질문에 대한 해답을 찾고, 그 과정을 타인과 효과적으로 소통하는 학문이다. 여기서 소통은 단순히 결과를 제시하는 것을 넘어, 사용된 데이터를 공유하고 해답 도출의 전 과정을 포괄적이며 재현 가능한 방식으로 투명하게 공개하는 것을 포함한다. 또한 데이터사이언스는 주어진 데이터가 질문에 답하기에 충분하지 않을 수 있음을 인정하며, 설령 해답이 도출되었다 하더라도 데이터 수집 또는 표본추출 방식에 따라 그 결과가 달라질 수 있음을 수용한다.\n이 책은 공간데이터의 기본 개념을 소개하고 설명한다. 포인트, 라인, 폴리곤, 래스터, 커버리지, 지오메트리 속성, 데이터 큐브, 참조계와 같은 기초 개념부터, 속성과 지오메트리가 어떻게 연결되고 이러한 연결이 분석에 어떤 영향을 미치는지에 관한 고차원 개념까지를 다룬다. 속성과 지오메트리 간의 관계를 서포트(support)라 하며, 서포트가 달라지면 속성의 특성도 변할 수 있다. 일부 데이터는 공간적 연속성에 기반해 생성되어 모든 지점에서 관찰이 가능하지만, 다른 데이터는 공간적 이산성에 기반해 특정한 구획 체계를 통해서만 관찰된다. 현대 공간데이터분석에서는 이러한 구획 체계 개념이 포인트 데이터, 지구통계학적 데이터, 에어리어 데이터를 포함한 다양한 데이터 유형에 폭넓게 적용된다. 공간적 재현의 중요성을 뒷받침하는 핵심 개념이 바로 서포트이며, 서포트에 대한 이해는 필수적이다. 이 책은 공간데이터를 분석에 활용하고자 하는 데이터 과학자를 주요 독자로 한다. 책 전반에 걸쳐 공간데이터분석의 절차와 방법을 설명하며, 예시에는 프로그래밍 언어 R을 사용한다. 향후에는 Python과 Julia를 활용한 예제도 추가할 예정이다(Bivand 2022a 참조).\n공간데이터에 대해 흔히 갖는 통념이 있다. 공간데이터란 관측 개체의 경위도값을 속성으로 포함한 데이터이며, 이 경위도값을 다른 변수들과 동일하게 취급해도 무방하다는 생각이다. 그러나 이러한 인식은 더 풍부한 연구 결과를 도출할 기회를 놓칠 뿐 아니라, 잘못된 결론에 이를 위험을 높인다. 다음의 세 가지 점을 살펴보자.\n이 책은 공간데이터, 좌표참조계, 공간분석과 관련된 다양한 개념 뿐만 아니라 sf(Pebesma 2018, 2022a), stars(Pebesma 2022b), s2(Dunnington, Pebesma, and Rubak 2023), lwgeom(Pebesma 2023)와 같은 여러 R 패키지를 함께 다룬다. 이와 더불어 공간적 tidyverse(Wickham et al. 2019; Wickham 2022) 확장 패키지와 이들 패키지와 연계하여 사용할 수 있는 공간분석 및 시각화 패키지들인 gstat(Pebesma 2004; Pebesma and Graeler 2022), spdep(Bivand 2022b), spatialreg(Bivand and Piras 2022), spatstat(Baddeley, Rubak, and Turner 2015; Baddeley, Turner, and Rubak 2022), tmap(Tennekes 2018, 2022), mapview(Appelhans et al. 2022)도 함께 소개한다.\n데이터사이언스와 마찬가지로 공간데이터사이언스도 특정 과학 분야의 하위 영역으로서 위로부터 형성된 것이 아니라, 공간데이터 활용과 관련된 다양한 학문 및 산업 분야에서의 상향식 발전을 통해 형성되어 온 분야이다. 학술대회, 심포지엄, 학회, 연구 프로그램 등을 통해 공간데이터사이언스를 정의하려는 시도가 이어지고 있으나, 그 응용 범위가 워낙 광범위하고 다양하기 때문에 결실을 맺기는 쉽지 않다. 이 책에 ’공간데이터사이언스’라는 제목을 붙인 이유는 이 분야의 경계를 명확히 규정하려는 의도에서 비롯된 것이 아니다. 지난 30~40년 동안 우리는 기본 아이디어, 데이터, 소프트웨어 기반의 분석 절차 등 연구의 전 과정을 기꺼이 공유해 온 수많은 연구자들과 함께해 왔으며, 이 책은 그러한 공동 경험을 정리한 결과물이다. 이를 통해 공간데이터사이언스의 발전에 작게나마 기여하고자 하는 것이 우리의 본래 의도이다. 따라서 이 책에서 다루는 주제의 선택은 필연적으로 저자들의 연구 관심과 경험에 일정 부분 편향될 수밖에 없다. 우리가 경험한 오픈 연구 커뮤니티의 형성에는 여러 플랫폼이 중요한 역할을 했다. ai-geostats, r-sig-geo 메일링 리스트, SourceForge, R-Forge, GitHub, 그리고 2006년부터 매년 열리고 있는 OpenGeoHub 여름학교가 그 예이다. 데이터사이언스라는 언어 장벽을 넘어서려는 수많은 노력의 결과, 오늘날 우리는 새로운 가능성과 흥미로운 관점이 열리고 있음을 실감하고 있다. 우리가 이 분야에 기여하고자 하는 이유는, 오픈사이언스가 더 나은 과학을 가능하게 하며, 더 나은 과학이 보다 지속가능한 세상을 만드는 데 기여할 수 있다고 믿기 때문이다.",
    "crumbs": [
      "서장"
    ]
  },
  {
    "objectID": "index.html#감사의-글",
    "href": "index.html#감사의-글",
    "title": "공간데이터사이언스 개론",
    "section": "감사의 글",
    "text": "감사의 글\n우리는 r-spatial 커뮤니티 전체에 깊이 감사드리며, 특히 다음에 열거한 분들께 특별한 감사를 전한다.\n\nr-spatial 패키지를 개발하거나 그 개발에 기여해 주신 분들\n트위터의 #rspatial 해시태그나 GitHub에서 토론에 참여해 주신 분들\n강좌, 여름학교, 학술 컨퍼런스에서 의견을 개진하거나 질문을 통해 토론에 기여해 주신 분들\n\n특히, s2 패키지를 구현한 듀이 더닝턴(Dewey Dunnington)과, 제6장 데이터 큐브의 그림을 준비해 준 사힐 반다리(Sahil Bhandari), 조너선 발만(Jonathan Bahlmann), 그리고 클라우스 빌케(Claus Wilke), 야쿠브 노보사드(Jakub Nowosad)의 적극적인 기여에 깊이 감사드린다. 또한 2021년과 2022년에 진행된 ‘R을 활용한 공간데이터사이언스(Spatial Data Science with R)’ 수업의 참가자들과, 다음의 GitHub 리포지터리에서 이슈, 풀 리퀘스트, 디스커션 등을 통해 적극적으로 참여해 주신 모든 분들께도 진심으로 감사드린다.\n\n이 책의 리포지터리(Nowosad, jonathom, JaFro96, singhkpratham, liuyadong, hurielreichel, PPaccioretti, Robinlovelace, Syverpet, jonas-hurst, angela-li, ALanguillaume, florisvdh, ismailsunni, andronaco)\nsf 리포지터리(aecoleman, agila5, andycraig, angela-li, ateucher, barryrowlingson, bbest, BenGraeler, bhaskarvk, Bisaloo, bkmgit, christophertull, chrisyeh96, cmcaine, cpsievert, daissi, dankelley, DavisVaughan, dbaston, dblodgett-usgs, dcooley, demorenoc, dpprdan, drkrynstrng, etiennebr, famuvie, fdetsch, florisvdh, gregleleu, hadley, hughjonesd, huizezhang-sherry, jeffreyhanson, jeroen, jlacko, joethorley, joheisig, JoshOBrien, jwolfson, kadyb, karldw, kendonB, khondula, KHwong12, krlmlr, lambdamoses, lbusett, lcgodoy, lionel-, loicdtx, marwahaha, MatthieuStigler, mdsumner, MichaelChirico, microly, mpadge, mtennekes, nikolai-b, noerw, Nowosad, oliverbeagley, Pakillo, paleolimbot, pat-s, PPaccioretti, prdm0, ranghetti, rCarto, renejuan, rhijmans, rhurlin, rnuske, Robinlovelace, robitalec, rubak, rundel, statnmap, thomasp85, tim-salabim, tyluRp, uribo, Valexandre, wibeasley, wittja01, yutannihilation, Zedseayou)\nstars 리포지터리(a-benini, ailich, ateucher, btupper, dblodgett-usgs, djnavarro, ErickChacon, ethanwhite, etiennebr, flahn, floriandeboissieu, gavg712, gdkrmr, jannes-m, jeroen, JoshOBrien, kadyb, kendonB, mdsumner, michaeldorman, mtennekes, Nowosad, pat-s, PPaccioretti, przell, qdread, Rekyt, rhijmans, rubak, rushgeo, statnmap, uribo, yutannihilation)\ns2 리포지토리(kylebutts, spiry34, jeroen, eddelbuettel)",
    "crumbs": [
      "서장"
    ]
  },
  {
    "objectID": "01.html",
    "href": "01.html",
    "title": "1  시작하기",
    "section": "",
    "text": "1.1 첫 번째 지도\n공간데이터를 표현하는 가장 전형적인 방법은 지도를 그리는 것이다. 그림 1.1은 그중에서도 단순한 형태의 지도를 예시로 보여준다.\n이 지도에는 다음과 같은 그래픽 요소가 포함되어 있다.\n폴리곤은 공간 지오메트리(geometry)의 한 형태다. 공간 지오메트리(포인트, 라인, 폴리곤, 픽셀)에 대해서는 3장에서 자세히 다룬다. 폴리곤은 여러 포인트가 선분으로 연결되어 형성되며, 포인트의 위치 표현과 측정 방법은 2장에서 설명한다. 그림 1.1에서 볼 수 있듯, 모든 경위선이 직선으로 나타나지는 않는다. 이는 지도에 특정 투영법이 적용되었음을 의미하며, 지도 투영에 대한 내용은 2장과 8.1절에서 다룬다.\n그림 1.1에서 컬러로 표현된 것은 BIR74 변수의 값이다. 각 값은 하나의 지오메트리, 즉 하나의 피처(feature)에 연결되어 있으며, 피처 속성과 지오메트리의 관계는 5장에서 다룬다. BIR74 변수는 출생아 수를 나타내는 지역별 빈도값(count)이다. 여기서 ’지역별’이라는 말은, 이 값이 지역 내 모든 지점과 직접적으로 대응되는 것이 아니라는 뜻이다. 지도의 컬러가 연속적으로 채색되어 있어 모든 지점이 해당 값을 가진다고 오해할 수 있지만, 실제로는 해당 값이 폴리곤 전체와 연결된 일종의 적분값임에 유의해야 한다.\n그림 1.1의 지도를 작성하려면 당연히 데이터가 필요하다. 여기서는 7.1절에서 사용된 파일을 불러와 사용하였다. 세 개 속성 변수에 대해 앞의 세 개 레코드만 요약한 결과는 다음과 같다.\n이 데이터 요약을 통해 다음과 같은 사실을 알 수 있다.\n패싯(facet) 플롯을 활용하면 그림 1.2와 같이 보다 복잡한 형태의 지도를 작성할 수 있다.\n리플릿(leaflet)을 사용하면 그림 1.3과 같은 인터랙티브 지도를 제작할 수 있다.\n그림 1.3: mapview로 그린 상호작용형 지도: 팬과 줌을 이용해 지도 스케일에 변화를 줄 수 있고 카운티를 클릭하면 해당 카운티의 속성을 보여주는 팝업 윈도우가 뜬다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#첫-번째-지도",
    "href": "01.html#첫-번째-지도",
    "title": "1  시작하기",
    "section": "",
    "text": "그림 1.1: 첫 번째 지도: 미국 노스캐롤라이나의 카운티별 출생아수, 1974~1978년\n\n\n\n\n폴리곤: 검은색 외곽선을 가진 폴리곤이며, 내부는 BIR74 변수(지도 제목)의 값에 따라 서로 다른 색상으로 채워져 있다.\n범례: 색상이 나타내는 값을 설명하며, 특정 컬러 팔레트(color palette)가 적용되어 있고 색상 변화 지점에는 컬러 단절값(color break)이 표시되어 있다.\n경위선망(그래티큘): 지도의 배경에 표시된다.\n축 눈금: 경도와 위도 값을 나타낸다.\n\n\n\n\n# Simple feature collection with 100 features and 3 fields\n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6\n# Geodetic CRS:  NAD27\n# # A tibble: 100 × 4\n#    AREA BIR74 SID74                                             geom\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;                               &lt;MULTIPOLYGON [°]&gt;\n# 1 0.114  1091     1 (((-81.5 36.2, -81.5 36.3, -81.6 36.3, -81.6 36…\n# 2 0.061   487     0 (((-81.2 36.4, -81.2 36.4, -81.3 36.4, -81.3 36…\n# 3 0.143  3188     5 (((-80.5 36.2, -80.5 36.3, -80.5 36.3, -80.5 36…\n# # ℹ 97 more rows\n\n\n데이터셋은 100개의 피처(레코드)와 3개의 필드(속성)로 구성되어 있다.\n지오메트리 유형은 MULTIPOLYGON이다(3장 참조).\n디멘션은 XY이다. 즉, 개별 포인트는 두 개의 좌표값으로 구성되어 있다.\nCRS(coordinate reference system, 좌표참조계)는 측지 좌표계이며, NAD27 데이텀을 기반으로한 경위도값을 사용한다(2장 참조).\n세 개의 속성 변수 다음에는 MULTIPOLYGON 유형의 geom 변수가 있는데, 이는 폴리곤 정보를 각도(°) 형식으로 저장하고 있다.\n\n\n\n\n\n\n\n그림 1.2: 미국 노스캐롤라이나 카운티별 영아돌연사증후군에 의한 사망아수의 패싯 지도, 1974~1978년과 1979~1984년",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#좌표참조계crs",
    "href": "01.html#좌표참조계crs",
    "title": "1  시작하기",
    "section": "\n1.2 좌표참조계(CRS)",
    "text": "1.2 좌표참조계(CRS)\n좌표참조계(CRS, coordinate reference system)는 공간데이터의 좌표값이 어떤 기준과 규칙에 따라 정의되는지를 나타낸다. 그림 1.1의 배경에 보이는 회색선은 경위선망, 즉 그래티큘(graticule)이다. 경위선이 \\(x\\), \\(y\\) 축과 직교하는 직선이 아니라는 점은, 이 데이터에 특정한 투영법(projection)이 적용되었음을 보여준다. 반면 그림 1.3에서는 노스캐롤라이나의 북쪽 경계가 곡선이 아닌 직선으로 나타나는데, 이는 또 다른 투영법이 사용되었음을 의미한다.\n그림 1.1에 나타난 경위도 좌표는 특정한 데이텀(datum), 여기서는 NAD27에 기반하고 있다.(역자주: 경위도 좌표는 절대적인 값이 아니라 데이텀에 따라 달라지는 상대적인 값임을 반드시 이해해야 한다. 동일한 지점이라도 데이텀에 따라 서로 다른 경위도 좌표를 가질 수 있으며, 반대로 동일한 좌표값이 데이텀에 따라 지표상의 서로 다른 지점을 가리킬 수도 있다.) 데이텀은 지구를 모형화하기 위해 어떤 지구타원체를 선택하고, 이를 지구와 어떻게 일치시킬 것인가―즉 지구타원체의 원점을 지구상의 어느 지점에, 어떤 방향으로 맞출 것인가―에 대한 일련의 사항을 규정한다. 예를 들어, GPS 수신기(예: 모바일 폰)를 통해 획득한 좌표값은 WGS84(World Geodetic System 1984) 데이텀에 기반한다. 이 좌표값을 NAD27(North American Datum 1927) 기준으로 해석하면, 동일한 좌표값이 실제 위치에서 약 30m 정도 차이이날 수 있다.\n투영법은 하나의 좌표계에서 다른 좌표계로 변환하기 위해, 두 좌표값 간의 대응 관계를 정의하는 함수이다.\n\n타원체 좌표(ellipsoidal coordinates): 지구를 수학적으로 모형화한 지구타원체(또는 지구구체) 상의 3차원 좌표로, 경도와 위도를 사용하여 표현한다.\n투영 좌표(projected coordinates): 지도 상의 2차원 평면 좌표계로, 일반적으로 \\(x\\) 좌표와 \\(y\\) 좌표 또는 동거(easting)와 북거(northing)로 나타낸다.\n\n한 데이텀을 다른 데이텀으로 변환하는 과정을 데이텀 변환이라고 한다. 투영과 좌표계는 공간참조계(spatial reference system)의 설정과 관련된 개념이며, 이에 대해서는 2장에서 자세히 설명한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#래스터-데이터와-벡터-데이터",
    "href": "01.html#래스터-데이터와-벡터-데이터",
    "title": "1  시작하기",
    "section": "\n1.3 래스터 데이터와 벡터 데이터",
    "text": "1.3 래스터 데이터와 벡터 데이터\n포인트, 라인, 폴리곤 지오메트리는 벡터(vector) 데이터의 대표적인 예이다. 벡터 지오메트리를 구성하는 좌표값은 지표상의 ‘정확한’ 위치를 나타낸다. 이에 반해, 래스터 데이터는 주로 정사각형 픽셀로 구성된 격자망(이를 래스터(raster)라고 부른다)에 각 셀의 속성값이 할당된 형태의 데이터이다. 래스터 데이터의 예는 그림 1.4에 제시되어 있다.\n\n\n\n\n\n그림 1.4: 브라질의 대서양 연안 도시 올린다에 대한 래스터 지도: (a) Landsat-7의 청색 밴드를 타나낸 것으로 서로 다른 컬러는 속성값의 차이를 나타냄. (b) 좌상의 10 X 10 픽셀만 확대하여 나타냄. (c) 3개의 표본 포인트로 구성된 벡터 데이터를 중첩하여 나타냄. (d) 표본 포인트로부터 반경 500 m를 나타낸 3개의 폴리곤으로 구성된 벡터 데이터를 중첩하여 나타냄.\n\n\n벡터 데이터와 래스터 데이터는 여러 방식으로 결합할 수 있다. 예를 들어, 그림 1.4(c)에 나타난 세 개의 포인트에 해당하는 래스터 값을 추출할 수 있으며, 그림 1.4(d)에 나타난 원 내부에 포함된 모든 래스터 값을 선택적으로 추출할 수도 있다.\n래스터에서 벡터로의 전환은 7.6절에서 다루며, 다음과 같은 내용을 포함한다.\n\n래스터 픽셀 값을 포인트의 속성값으로 전환하기\n래스터 픽셀 값을 폴리곤의 속성값으로 전환한 후, 동일한 속성값을 가진 폴리곤을 병합하기(‘폴리곤 생성’)\n특정 범위의 값을 가진 연속적인 픽셀 영역을 라인이나 폴리곤으로 표현하기(‘등치선 생성’)\n\n\n\n\n\n\n그림 1.5: 그림 1.1에 나타나 있는 카운티별 출생아 수(1974~1978)를 래스터화하여 나타낸 지도\n\n\n그림 1.5에 나타난 벡터에서 래스터로의 전환(폴리곤의 래스터화)은 매우 단순한 사례이다. 그러나 다른 형태의 벡터-투-래스터 전환은 보다 복잡한 통계적 모형화를 수반한다. 예를 들어 다음과 같은 경우가 있다.\n\n포인트 속성값을 내삽하여 그리드 셀에 할당하기(12장 참조)\n포인트의 밀도 분포를 추정하여 그리드 셀에 할당하기(11장 참조)\n폴리곤의 속성값을 면적 가중 내삽을 통해 그리드 셀에 할당하기(5.3절 참조)\n포인트, 라인, 폴리곤을 래스터로 직접 변환하기(7.6절 참조)",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#래스터-유형",
    "href": "01.html#래스터-유형",
    "title": "1  시작하기",
    "section": "\n1.4 래스터 유형",
    "text": "1.4 래스터 유형\n래스터 데이터의 디멘션은 행과 열이 공간 좌표계와 어떻게 연결되는가에 따라 결정된다. 그림 1.6은 그 다양한 가능성을 예시로 보여준다.\n\n\n\n\n\n그림 1.6: 다양한 래스터 지오메트리 유형\n\n\n그림 1.6에 나타나 있는 규칙(regular) 래스터는 일정한 모양(반드시 정사각형일 필요는 없음)의 그리드 셀로 구성되어 있으며, 가로축과 세로축이 \\(x\\)축(동거축)과 \\(y\\)축(북거축)과 일치한다. 그러나 이 외에도 다양한 형태의 래스터가 존재한다. 예를 들어, 가로축과 세로축이 \\(x\\)축 및 \\(y\\)축과 일치하지 않는 회전형(rotated) 래스터, 가로축과 세로축이 서로 직교하지 않는 전단형(sheared) 래스터, 특정 디멘션을 따라 셀 크기가 달라지는 직교형(rectilinear) 래스터이다. 마지막으로, 곡선형(curvilinear) 래스터는 셀의 크기나 방향이 한 디멘션에서만 결정되는 것이 아니라, 다른 디멘션의 변화에도 영향을 받는다.(역자주: 곡선형 래스터는 좌표축이 곡선 형태를 이루기 때문에, 셀의 크기와 방향이 한 축에서만 결정되는 것이 아니라 다른 축의 변화에도 의존한다. 이는 일반적인 직교 좌표 기반 래스터와 달리, 두 디멘션이 서로 얽혀 있는 구조를 가진다는 뜻이다.)\n특정 좌표참조계에 기반한 규칙 래스터가 있다고 하자. 이 래스터를 셀 구조를 그대로 유지한 채 다른 투영법으로 변환하면, 직교형 래스터가 될 수도 있고(예: 그림 1.3에서처럼 측지 좌표를 메르카토르 도법으로 변환하는 경우), 곡선형 래스터가 될 수도 있다(예: 그림 1.1에서처럼 측지 좌표를 람베르트 정형원추 도법으로 변환하는 경우). 이와 같은 변환 과정을 역으로 수행하면 원래의 래스터를 손실없이 정확히 복원할 수 있다.\n새로운 투영법이 적용된 규칙 그리드를 새로 생성하는 과정을 래스터(또는 이미지) 재투영(reprojection) 또는 워핑(warping)이라고 한다(7.8절 참조). 워핑 과정에서는 정보 손실이 발생할 수 있으며, 일반적으로 불가역적이고 여러 옵션 설정이 필요하다. 예를 들어, 새로운 셀 값을 생성할 때 인터폴레이션을 적용할지, 평균값이나 합계값을 계산할지 여부를 결정해야 하며, 이웃 셀 값을 활용한 재샘플링 적용 여부도 함께 고려해야 한다. 이러한 선택은 래스터 셀 값이 범주형인지 연속형인지에 따라 달라질 수 있다(1.6절 참조).",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#시계열-어레이-데이터-큐브",
    "href": "01.html#시계열-어레이-데이터-큐브",
    "title": "1  시작하기",
    "section": "\n1.5 시계열, 어레이, 데이터 큐브",
    "text": "1.5 시계열, 어레이, 데이터 큐브\n많은 공간데이터는 공간적 특성뿐만 아니라 시간적 특성도 함께 지닌다. 모든 관측치는 관측이 이루어진 특정 지점뿐 아니라, 관측이 수행된 특정 시점과도 결부되어 있다. 예를 들어, 노스캐롤라이나 카운티 데이터셋은 그림 1.2에서 보듯 두 시점의 관측값을 포함하고 있다. 원래 데이터셋에서는 이 두 시점의 값이 각각 별도의 변수로 저장되어 있었을 가능성이 크지만, 그림 1.2와 같이 두 개의 패싯 지도로 표현하려면 지오메트리를 반복하여 두 변수를 하나의 열로 길게 배열하는 형태로 변형해야 한다. 위컴(Wickham, 2014)은 이러한 형태를 타이디(tidy) 형태라고 부른다. 그러나 지오메트리와 연결된 긴 시계열 데이터를 다룰 때는, 시간별로 여러 열을 사용하는 방식도, 지오메트리를 반복해 하나의 열로 시간값을 나열하는 방식도 효율적이지 않을 수 있다. 이러한 경우에는 시간과 공간을 각각 하나의 차원으로 설정한 매트릭스나 어레이(array) 구조가 더 효과적일 수 있다. 이미지나 래스터 데이터는 본래 매트릭스 구조로 저장되며, 여기에 시간이 추가되면 3차원 어레이가 된다. 이렇게 여러 차원의 데이터를 저장 및 표현하는 일반적인 구조를 (시공간적) 데이터 큐브(data cube)라고 한다. 데이터 큐브는 차원의 수에 제한이 없는 어레이 구조를 의미하며, 벡터 데이터와 래스터 데이터 모두에 적용될 수 있다. 이에 대한 다양한 예시는 6장에서 다룬다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#서포트",
    "href": "01.html#서포트",
    "title": "1  시작하기",
    "section": "\n1.6 서포트",
    "text": "1.6 서포트\n단일 포인트 지오메트리가 아닌, 포인트 집합 지오메트리(다중 포인트, 라인, 폴리곤, 픽셀)를 가진 공간데이터의 경우 결부된 속성값은 해당 지오메트리와 몇 가지 서로 다른 방식으로 연결될 수 있다.\n\n지오메트리의 모든 포인트에 공통적으로 적용되는 상수값(constant value)\n지오메트리의 모든 포인트를 집합적으로 대표하는 집계값(aggregate value)\n각 지오메트리의 고유성을 나타내는 식별값(identity value)\n\n상수값의 예로는 폴리곤의 토지이용 속성이나 기반암 유형이 있고, 집계값의 예로는 카운티의 출생아수가 있으며, 식별값의 예로는 카운티 이름이 있다.(역자주: 폴리곤의 토지이용은 폴리곤 내 모든 지점에 공통적으로 적용될 수 있는 상수값이다. 반면, 카운티의 출생아 수는 카운티 내 모든 지점의 값을 합산한 집계값이므로, 특정 지점에 적용될 수는 없고 카운티 전체를 집합적으로 대표하는 값이다.)\n한 속성값과 결부된 공간적 개체를 해당 속성값의 서포트(support)라고 한다. 집계값은 ‘블록(block)’(폴리곤 또는 라인) 서포트를 가지며, 상수값은 ‘포인트’ 서포트를 가진다(동일한 값이 모든 포인트에 적용된다). 예를 들어, 그림 1.5는 폴리곤 서포트를 갖는 변수(카운티별 출생아 수)로부터, 카운티별 속성값을 해당 카운티를 구성하는 픽셀의 속성값으로 할당한 결과이다. 그러나 이렇게 생성된 래스터 지도는 의미가 없다. 속성값인 카운티별 ’총출생아 수’는 개별 래스터 셀과 무관하며, 속성값과 결부된 카운티 전체 경계조차 표시되어 있지 않다. 따라서 이 지도로부터 노스캐롤라이나 주 전체의 출생아 수나 출생아 밀도를 재계산할 수 없다.\n래스터 셀의 속성은 포인트 서포트를 가질 수도 있고, 블록 서포트를 가질 수도 있다. 포인트 서포트의 대표적인 예는 고도이다. 예를 들어 DEM(digital elevation model, 수치표고모형)에서는 보통 셀 중심점의 고도값을 셀 속성으로 저장한다. 블록 서포트(혹은 셀 서포트)의 예로는 위성영상을 들 수 있다. 이미지 픽셀의 속성값은 대개 해당 픽셀(또는 픽셀을 중심으로 한 일정 영역) 내부 값들의 평균이다. 대부분의 파일 포맷은 이러한 서포트 정보를 명시적으로 제공하지 않는다. 그러나 래스터 데이터를 애그리게이팅(aggregating) 하거나, 리그리딩(regridding) 하거나, 워핑(warping) 할 때(7.8절), 또는 포인트별 값을 추출할 때는 매우 중요한 요소가 된다.(역자주: 애그리게이팅은 공간 해상도를 낮추는 과정, 리그리딩은 그리드 체계를 바꾸는 과정, 워핑은 다른 투영법을 적용해 래스터 유형을 변환하는 것을 의미한다.)",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#공간데이터사이언스를-위한-소프트웨어",
    "href": "01.html#공간데이터사이언스를-위한-소프트웨어",
    "title": "1  시작하기",
    "section": "\n1.7 공간데이터사이언스를 위한 소프트웨어",
    "text": "1.7 공간데이터사이언스를 위한 소프트웨어\n이 책에서 기본적으로 사용하는 프로그래밍 언어는 R이며, 공간데이터사이언스를 위해 다양한 R 패키지를 활용한다. 이들 R 패키지 중 상당수는 여러 종류의 소프트웨어 라이브러리를 기반으로 동작하는데, 이러한 라이브러리들은 R만을 위해 개발된 것이 아니다. 예를 들어, 그림 1.7은 sf 패키지의 의존 관계(dependency)를 보여주며, 이를 통해 sf 패키지가 R 패키지뿐 아니라 시스템 라이브러리도 함께 사용하고 있음을 알 수 있다.\n\n\n\n\n\n그림 1.7: sf 패키지의 의존 관계: 직선은 강한 의존성을, 점선은 약한 의존성을 나타낸다.\n\n\nC 또는 C++로 작성된 라이브러리(GDAL, GEOS, PROJ, liblwgeom, s2geometry, NetCDF, udunits2)는 모두 R 커뮤니티가 아니라 (공간)데이터사이언스 전반의 다른 커뮤니티에서 개발, 유지, 활용되고 있다. 이러한 라이브러리를 사용함으로써 R 사용자들은 다른 커뮤니티와 공유하는 기술과 협업의 범위를 이해할 수 있다. R, Python, Julia는 인터랙티브한 인터페이스를 제공하기 때문에 많은 사용자가 이러한 라이브러리를 기반으로 한 응용 소프트웨어 사용자들보다 라이브러리에 더 직접적으로 접근할 수 있다. 이 책의 제1부에서는 이러한 라이브러리에 내재된 핵심 개념을 설명하며, 이는 공간데이터사이언스를 폭넓게 이해하는 데 큰 도움이 될 것이다.\n\n1.7.1 GDAL\nGDAL(Geospatial Data Abstraction Library)은 공간데이터 처리에서 ’스위스 만능칼’과 같은 역할을 한다고 할 수 있다. GDAL은 R, Python, PostGIS를 비롯해 100개가 넘는 다른 소프트웨어 프로젝트에서 폭넓게 사용되고 있다.\nGDAL은 공간데이터를 읽고 쓸 수 있게 해주는 라이브러리 가운데서도 핵심적인 라이브러리로, 수많은 다른 라이브러리에 의존한다. 약 100개가 넘는 라이브러리와 연동되며, 각 라이브러리는 특정 데이터 파일 포맷, 특정 데이터베이스, 특정 웹서비스 또는 특정 압축 코덱을 처리한다.\nCRAN에서 배포되는 바이너리 형식의 R 패키지에는 스태틱 링크 코드(statically linked code)만 포함되어 있다. 이는 CRAN이 패키지를 배포하는 시스템에 서드파티(third-party) 라이브러리가 설치되어 있다고 가정하지 않기 때문이다. 그 결과 CRAN에서 바이너리 형식의 sf 패키지를 설치하면 sf 패키지의 의존성뿐 아니라 모든 외부 라이브러리도 함께 다운로드되어, 설치 파일 용량이 약 100MB에 달한다.(역자주: CRAN은 The Comprehensive R Archive Network의 약자로, R 패키지를 저장하는 중앙 저장소이다. R 언어 자체의 과거와 현재 버전뿐 아니라 20,000개 이상의 R 패키지가 모여 있다. 1997년 쿠르트 호르닉(Kurt Hornik)과 프리드리히 라이슈(Friedrich Leisch)가 처음 만들었으며, 현재도 쿠르트 호르닉과 많은 자원봉사자가 운영하고 있다. 스태틱 링크 코드는 컴파일 시점에 필요한 라이브러리나 의존성을 실행 파일에 미리 포함시켜 만든 코드를 의미한다.)\n\n1.7.2 PROJ\nPROJ(혹은 PR\\(\\phi\\)J)는 지도 투영과 데이텀 변환을 위한 라이브러리로, 공간 좌표를 한 CRS에서 다른 CRS로 변환한다. PROJ에는 현재까지 알려진 수많은 투영법에 대한 데이터베이스가 포함되어 있으며, 데이텀 변환을 위한 고정밀 계수값을 담은 데이터 그리드에 접근할 수 있다. 또한 PROJ는 CRS에 관한 국제 표준을 따른다(Lott 2015). 좌표계와 PROJ에 대해서는 2장에서 자세히 다룬다.\n\n1.7.3 GEOS와 s2geometry\nGEOS(Geometry Engine Open Source)와 s2geometry는 지오메트리 연산을 위한 라이브러리이다. 이들 라이브러리를 활용하면 기하학적 측정(길이, 면적, 거리), 프레디케이트(predicate)(두 지오메트리가 포인트를 공유하는지 여부), 새로운 지오메트리 생성(두 지오메트리가 공유하는 포인트) 등의 연산을 수행할 수 있다.(역자주: 프레디케이트는 특정 조건이 참인지 거짓인지 판별하는 논리 연산을 의미한다. 공간데이터 연산에서는 두 지오메트리가 접하는지, 포함하는지, 겹치는지 등을 판정하는 함수나 연산자를 지칭한다. ‘(공간) 관계 연산자’ 등으로 번역하기도 하지만 여기서는 원어를 음역한 ’프레디케이트’를 그대로 사용한다.) GEOS는 이러한 연산을 2차원 평면(\\(R^2\\))에서 수행하며, s2geometry는 이를 3차원 구면(\\(S^2\\))에서 수행한다. CRS에 대해서는 2장에서, 그리고 2차원 공간과 3차원 공간을 다루는 차이점은 4장에서는 좀 더 깊이 논의한다.\n\n1.7.4 NetCDF, udunits2, liblwgeom\nNetCDF(UCAR 2020)는 파일 형식이자 NetCDF 파일을 읽고 쓰기 위한 C 라이브러리를 의미한다. NetCDF를 통해 모든 차원의 어레이를 정의할 수 있으며, 특히 기후 모형화 커뮤니티에서 공간 및 시공간 정보를 다루는 데 널리 사용된다. Udunits2(UCAR 2014; Pebesma, Mailud, and Hiebert 2016; Pebesma et al. 2022)는 측정 단위와 관련된 데이터베이스이자 소프트웨어 라이브러리로, 측정 단위 간 전환과 파생 단위 처리를 지원하며 사용자 정의 단위도 사용할 수 있다. liblwgeom ’라이브러리’는 PostGIS(Obe and Hsu 2015)의 소프트웨어 구성 요소로서, GDAL이나 GEOS에서는 다루지 않는 몇 가지 루틴을 포함한다. 예를 들어 PROJ가 포함된 GeographicLib 루틴에 손쉽게 접근할 수 있게 해준다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "01.html#연습문제",
    "href": "01.html#연습문제",
    "title": "1  시작하기",
    "section": "\n1.8 연습문제",
    "text": "1.8 연습문제\n\n래스터 데이터와 백터 데이터의 차이점 다섯 가지를 열거하시오.\n그림 1.1 아래에 나열되어 있는 것 외에, 지도의 그래픽 요소 다섯 개를 더 열거하시오.\n그림 1.5에 나타나 있는 수치 정보가 왜 오해를 불러일으키는지(혹은 무의미한지)에 대해 얘기해 보시오.\n지오메트리 연산을 \\(S^2\\)에서 수행하는 것과 \\(R^2\\)에서 수행하는 것의 차이가 가장 극명하게 드러나는 상황을 예로 들어 설명하시오.\n\n\n\n\n그림 1.1: 첫 번째 지도: 미국 노스캐롤라이나의 카운티별 출생아수, 1974~1978년\n그림 1.2: 미국 노스캐롤라이나 카운티별 영아돌연사증후군에 의한 사망아수의 패싯 지도, 1974~1978년과 1979~1984년\n그림 1.4: 브라질의 대서양 연안 도시 올린다에 대한 래스터 지도: (a) Landsat-7의 청색 밴드를 타나낸 것으로 서로 다른 컬러는 속성값의 차이를 나타냄. (b) 좌상의 10 X 10 픽셀만 확대하여 나타냄. (c) 3개의 표본 포인트로 구성된 벡터 데이터를 중첩하여 나타냄. (d) 표본 포인트로부터 반경 500 m를 나타낸 3개의 폴리곤으로 구성된 벡터 데이터를 중첩하여 나타냄.\n그림 1.5: 그림 1.1에 나타나 있는 카운티별 출생아 수(1974~1978)를 래스터화하여 나타낸 지도\n그림 1.6: 다양한 래스터 지오메트리 유형\n그림 1.7: sf 패키지의 의존 관계: 직선은 강한 의존성을, 점선은 약한 의존성을 나타낸다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>시작하기</span>"
    ]
  },
  {
    "objectID": "17.html",
    "href": "17.html",
    "title": "17  공간계량경제학적 모형",
    "section": "",
    "text": "17.1 정의\n공간 프로세스를 모형화하려는 시도 가운데 가장 초기의 공간계량경제학적 정식화 중 하나는, 잔차의 공간적 자기상관을 모형화하는 방식이다. 이는 공간오차모형(SEM)으로 다음과 같이 표현된다.\n\\[\n\\textbf{y}=\\textbf{X}\\beta+\\textbf{u},\\qquad \\textbf{u}=\\rho_\\text {Err} \\textbf{Wu}+\\epsilon\n\\]\n여기서 \\(\\textbf{y}\\)는 \\(N\\) 위치에서 측정된 반응변수의 \\((N\\times1)\\) 관측치 벡터, \\(\\textbf{X}\\)는 \\((N \\times k)\\) 공변량 행렬, \\(\\beta\\)는 \\((k \\times 1)\\) 계수 벡터, \\(\\textbf{u}\\)는 공간적 자기상관을 갖는 \\((N \\times 1)\\) 교란 벡터, \\(\\epsilon\\)은 독립항등분포를 따르는 \\((N \\times 1)\\) 교란 벡터, \\(\\rho_\\text{Err}\\)는 스칼라 형태의 공간 계수이다.\n이 모형과 유사한 다른 공간계량경제학 모형들은 혼합모형 프레임워크에는 부합하지 않는다. 여기서 모형화된 공간 프로세스는 반응변수, 공변량, 그리고 계수와 직접적으로 상호작용한다. 이러한 형태의 모형화 접근은 시계열 프레임워크를 단순히 2차원으로 확장한 오래된 전통에서 기원한 것으로 보인다.\n\\[\n\\textbf{u}=(\\textbf{I}-\\rho_\\text{Err}\\textbf{W})^{-1}\\epsilon,\\quad \\textbf{y}=\\textbf{X}\\beta+(\\textbf{I}-\\rho_\\text{Err}\\textbf{W})^{-1}\\epsilon,\\quad (\\textbf{I}-\\rho_\\text{Err}\\textbf{W})\\textbf{y}=(\\textbf{I}-\\rho_\\text{Err}\\textbf{W})\\textbf{X}\\beta+\\epsilon\n\\]\n만약 공변량과 반응변수가 동일한 공간 프로세스를 따른다면, 최소제곱법(OLS) 계수와 공간오차모형 계수 사이의 차이는 거의 없을 것이다. 그러나 실제로는 두 프로세스가 일치하지 않는 경우가 많으며, 이를 판별 및 조정하기 위해서는 Hausman 검정과 같은 추가 절차가 필요하다(Pace and LeSage 2008). 이러한 논의는, 공간 프로세스가 일치하는 경우 시계열 분석의 단위근(unit root)과 공적분(cointegration) 개념을 공간적으로 확장하려는 이전 연구와도 연결된다(Fingleton 1999).\n반응변수에만 공간 프로세스를 포함하는 모형을 공간래그모형(SLM)이라 하며, 종종 공간자기회귀모형(SAR, spatial autoregressive mode)이라고도 부른다(LeSage and Pace 2009). 더빈(Durbin) 모형은 여기에 공변량의 공간래그항을 추가한 형태이다. 공간더빈모형(spatial Durbin model)에 관한 종합적인 리뷰는 Mur와 Angulo(2006)를 참고할 수 있다. 만약 반응변수에 공간 프로세스를 포함하는 동시에 잔차에도 공간 프로세스를 포함시키면, 두 가지 형태의 모형이 가능하다. 하나는 모든 모형 요소를 포함하는 일반중첩모형(GNM, general nested model)이고, 다른 하나는 공간래그 공변량을 포함하지 않는 공간자기회귀-자기회귀모형(SARAR, spatial autoregressive-autoregressive model) 또는 공간자기회귀결합모형(SAC, spatial autoregressive combined model)이다. 반면, 반응변수나 잔차에 공간 프로세스를 모형화하지 않고, 단순히 공변량의 공간래그항을 선형모형에 추가할 수도 있다. 이를 공간래그X모형(SLX, spatial lag of X model)이라고 한다(Elhorst 2010; Bivand 2012; LeSage 2014; Halleck Vega and Elhorst 2015). GNM은 다음과 같이 표현된다.\n\\[\n\\textbf{y}=\\rho_\\text{Lag}\\textbf{Wy}+\\textbf{X}\\beta+\\textbf{WX}\\gamma+\\textbf{u},\\qquad \\textbf{u}=\\rho_\\text{Err}\\textbf{Wu}+\\epsilon\n\\]\n여기서 \\(\\gamma\\)는 \\((k' \\times 1)\\) 파라미터 벡터이다. \\(k'\\)는 절편과 일부 공변량을 정의하며, 행표준화 공간가중치행렬을 사용하고 공간래그 절편을 포함하지 않는 경우 \\(k'=k-1\\)이다.\n이 기본 모형에 특정 제약을 가하면 다양한 변형 모형이 도출된다. \\(\\gamma = 0\\)으로 설정하면 이중 공간계수 모형인 SAC/SARAR 모형이, \\(\\rho_\\text{Err}=0\\)으로 설정하면 공간더빈모형(SDM, spatial Durbin model)이, \\(\\rho_\\text{Lag}=0\\)으로 설정하면 공간더빈오차모형(SDEM, spatial Durbin error model)이 된다. 더 강한 조건을 부여할 수도 있는데, \\(\\gamma = 0\\)과 \\(\\rho_\\text{Err}=0\\)로 설정하면 공간래그모형(SLM), \\(\\gamma=0\\)와 \\(\\rho_\\text{Lag}=0\\)으로 설정하며 공간오차모형(SEM), \\(\\rho_\\text{Lag}=0\\)과 \\(\\rho_\\text{Err}=0\\)으로 설정하면 공간래그X모형(SLX)이 된다.\n공변량이 관측된 새로운 위치에 대해 예측을 수행하는 것과 관련된 문제는 오래전부터 인식되어 왔지만, 그 가능성에 대한 체계적인 검토와 실질적 진전은 상당한 시간이 지나서야 이루어졌다(Bivand 2002; Goulard, Laurent, and Thomas-Agnan 2017; Laurent and Margaretic 2021). MLE로 적합된 SLM, SDM, SEM, SDEM, SAC, GNM 모형을 예측에 적용하는 방법은 ‘Google Summer of Code(구글 썸머 오프 코드)’ 프로젝트를 수행한 마틴 구브리(Martin Gubri)의 공로가 크다. 또한, 결측 데이터를 다루는 유사한 모형에 관한 연구(Suesse 2018)는 보스턴 주택 데이터셋에서 검열된 중앙값 주택가격을 분석하는데 시사점을 제공한다. 예측 문제를 다루다 보면 해당 모형의 축약 형태(reduced form)가 매우 중요하다는 점을 인식하게 된다. 특히 SLM, SDM, SAC, GNM 모형처럼 반응변수의 공간 프로세스가 회귀계수와 상호작용하는 경우에는, 보다 단순화된 형태의 표현이 분석과 해석에 도움이 될 수 있다.(역자주: 여기서 ’축약 형태’란 공간계량경제학이나 회귀분석에서 모형을 단순화하여, 반응변수를 설명변수와 오차항만의 함수로 나타낸 식을 말하며, 효과 계산과 예측 분석에서 핵심적인 역할을 한다. 예를 들어 SLM에서는 단위행렬에서 공간계수와 공간가중치행렬의 곱을 뺀 행렬의 역행렬을 곱해 풀면 축약 형태가 되며, 이 역행렬이 공간 파급 효과를 나타낸다.)\n반응변수와 회귀계수 간 이러한 상호작용의 결과, 공변량의 단위 변화가 회귀계수 값에 비례하여 반응변수에 직접 효과를 미치려면, 공간래그 반응변수의 계수가 0이어야 한다. 만약 공간 계수가 0이 아니라면, 전역적 파급효과가 작용하게 되며, 그 크기는 회귀계수 만큼이나 중요한 정보가 된다(LeSage and Pace 2009; Elhorst 2010; Bivand 2012; LeSage 2014; Halleck Vega and Elhorst 2015). SDEM 및 SLX 모형의 경우, 각 공변량의 총 파급효과(total spillover effect)는 해당 공변량의 계수와 공간래그 공변량 계수의 합으로 정의되며, 국지적 파급효과(local spillover effect)는 이를 기반으로 선형결합을 사용해 표준오차를 계산하여 나타낸다.\n이것은 GNM 데이터 생성 프로세스에서 확인할 수 있다.\n\\[\n(\\textbf{I}-\\rho_\\text{Err}\\textbf{W})(\\textbf{I}-\\rho_\\text {Lag}\\textbf{W})\\textbf{y}=(\\textbf{I}-\\rho_\\text {Err}\\textbf{W})(\\textbf{X}\\beta+\\textbf{WX}\\gamma)+\\epsilon\n\\]\n이를 다음과 같이 변형하여 나타낼 수 있다.\n\\[\n\\textbf{y}=(\\textbf{I}-\\rho_\\text{Lag}\\textbf{W})^{-1}(\\textbf{X}\\beta+\\textbf{WX}\\gamma)+(\\textbf{I}-\\rho_\\text{Lag}\\textbf{W})^{-1}(\\textbf{I}-\\rho_\\text{Err}\\textbf{W})^{-1}\\epsilon\n\\]\n이 식에서 \\(\\rho_\\text{Lag}\\)와 \\(\\beta\\) 사이에는 상호작용이 존재하며, \\(\\gamma\\)가 존재할 경우에는 세 변수 간의 상호작용이 발생한다. 이는 다음의 편도함수에서 확인할 수 있다: \\(\\partial y_i/\\partial x_{jr}=((\\textbf{I}-\\rho_\\text{Lag}\\textbf{W})^{-1}(\\textbf{I}\\beta_r+\\textbf{W}\\gamma_r))_{ij}\\). 여기서 밀집 행렬 \\(S_r(\\textbf{W})=((\\textbf{I}-\\rho_\\text{Lag}\\textbf{W})^{-1}(\\textbf{I}\\beta_r+\\textbf{W}\\gamma_r))\\)의 주대각 요소는 직접 효과(direct effect)을 나타내고, 비대각 요소는 간접 효과(indirect effect)를 나타낸다.\nPiras와 Prucha(2014)는 Raymond J. G. M. Florax, Folmer, Rey(2003)를 재검토하고 수정하였으며, Hendry(2006)와 Raymond J. G. M. Florax, Folmer, Rey(2006)의 논평도 참고하였다. 이들은 모형 선택 시 통상적으로 사용되는 사전 검정(pre-test) 전략보다, 해당 분석 상황에 적합한 가장 일반적인 모형을 먼저 추정하는 전략이 더 바람직하다고 결론지었다.(역자주: 여기서 ’사전 검정 전략’이란 모형을 선택하기 전에 잔차의 공간적 자기상관 등 사전 가설검정을 수행하고, 그 결과에 따라 SLM, SEM 등 최종 모형을 결정하는 방법을 말한다. 그러나 표본 의존성과 모형 누락 위험이 있어, Piras와 Prucha(2014)는 가장 일반적인 모형을 먼저 적합한 뒤 필요시 단순화하는 방식을 권고하였다.) 이러한 결과에 비추어, 본 장에서는 사전 검정 기반의 모형 선택은 사용하지 않는다.\n현재 spatialreg 패키지가 주력하고 있는 개선 사항 중 하나는 공간래그 공변량 처리 방법의 향상이다. 이를 위해 Durbin 인수를 사용하여, 공간래그 형태로 추가할 공변량의 하위 집합을 지정하는 논리값이나 수식을 받을 수 있도록 하였다. 일부 공변량, 예를 들어 더미 변수와 같은 경우에는 공간래그 형태로 포함하지 않는 것이 바람직하다는 주장도 있다. 공간래그 공변량이 선택되면, 다음 과제는 영향력을 계산할 때 이를 어떻게 적절하게 처리할 것인가 하는 문제이다. 이러한 개선된 기능은 MCMC 또는 MLE로 적합된 횡단면 모형에 적용되며, 향후 공간 패널 모형에도 적용될 예정이다.\n거의 다루어지지 않은 주제이지만, 기능적 형태 가정(functional form assumption)을 언급할 가치가 있다.(역자주: 여기서 ’기능적 형태 가정’이란 반응변수와 독립변수 간의 관계가 특정한 수학적 형태(예: 선형, 로그-선형, 다항식)를 따른다고 전제하는 것이다. 이러한 가정이 실제 데이터 생성 프로세스를 잘 반영하지 못하면 추정 결과에 편향이 발생할 수 있다. 공간계량경제학에서는 반응변수, 공간 효과, 공변량 간 관계를 특정 형태로 가정하는 경우가 많다.) 이 문제는, 예를 들어 McSpatial 패키지에서 구현된 공간분위수회귀(spatial quatile regression, McMillen 2013)와 같은 유연한 구조가 유용한 상황과 관련이 있다. 또한 McSpatial 패키지의 일부 함수, 신규 패키지 spldv(Sarrias and Piras 2022), 그리고 spatialprobit 패키지와 ProbitSpatial 패키지(Wilhelm and Matos 2013; Martinetti and Geniaux 2017)에서 다루는 이산형 반응변수 관련 문제도 있다. McSpatial 패키지의 MCMC 구현은 LeSage와 Pace(2009)에 기반하고 있다. 마지막으로, Wagner와 Zeileis(2019)는 SLM 모형이 재귀적 분할(recursive partitioning) 설정에서 어떻게 활용될 수 있는지를 보여주며, 이를 spatialreg 패키지의 lagsarlm() 함수를 이용해 구현하는 lagsarlmtree 패키지에서 제시하였다.\nspatialreg 패키지(Bivand and Piras 2022)를 이용한 횡단면(cross-sectional) MLE와 일반화 모멘트법(GMM, generalised method of moments) 추정, 그리고 sphet 패키지를 통해 공간계량경제학 스타일의 공간 회귀모형에 대한 리뷰(Bivand and Piras 2015)는 여전히 대부분 유효하다. 이 리뷰에서는 R 패키지에서 제공하는 추정량을 다른 프로그래밍 언어의 대체 구현과 비교하였으나, 베이지안 공간계량경제학 스타일의 공간 회귀는 다루지 않았다. Millo와 Piras(2012)가 설명한 공간 패널 추정량에 대해서는 많은 변화가 있었지만, 본 장에서는 다루지 않는다.\nBivand, Millo와 Piras(2021)는 공간계량경제학적 분석을 위한 R 패키지의 다양한 기능을 포괄적으로 다루며, Bivand와 Piras(2015)를 업데이트하고 GMM 및 공간 패널 모형화의 최근 발전을 포함하고 있다. 따라서 이 장에서는 보스턴 주택가격 데이터셋을 사용한 Bivand(2017)의 예제 중 일부만을 간략히 다룰 것이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>공간계량경제학적 모형</span>"
    ]
  },
  {
    "objectID": "17.html#최대우도추정법-spatialreg-패키지의-활용",
    "href": "17.html#최대우도추정법-spatialreg-패키지의-활용",
    "title": "17  공간계량경제학적 모형",
    "section": "\n17.2 최대우도추정법: spatialreg 패키지의 활용",
    "text": "17.2 최대우도추정법: spatialreg 패키지의 활용\n단일 공간계수를 가지는 모형(SEM 및 SDEM은 errorsarlm() 함수 사용, SLM 및 SDM은 lagsarlm() 함수 사용)에는 Ord(1975)가 처음 제시한 방법이 적용된다. 다음 표는 최대우도추정법(MLE)을 사용하여 앞서 설명한 모형을 추정할 수 있는 함수를 정리한 것이다.\n\n\n모형\n모형명\nMLE 함수\n\n\n\nSEM\n공간오차\nerrorsarlm(..., Durbin = FALSE)\n\n\nSEM\n공간오차\nspautolm(..., family = \"SAR\")\n\n\nSDEM\n공간더빈오차\nerrorsarlm(..., Durbin = TRUE)\n\n\nSLM\n공간래그\nlagsarlm(..., Durbin = FALSE)\n\n\nSDM\n공간더빈\nlagsarlm(..., Durbin = TRUE)\n\n\nSAC\n공간자기회귀결합\nsacsarlm(..., Durbin = FALSE)\n\n\nGNM\n일반중첩\nsacsarlm(..., Durbin = TRUE)\n\n\n\nerrorsarlm()과 lagsarlm() 추정 함수는 유사한 인수를 받는다. 첫 번째(formula)와 두 번째(data) 인수는 대부분의 모형 추정 함수에서 공통적으로 사용되며, 세 번째 인수는 listw 공간가중치 객체이다. na.action 인수는 결측값이 있는 관측 개체의 공간가중치를 어떻게 처리할지를 정의하며, 다른 모형 추정 함수와 동일하게 동작한다. weights 인수는 분산 항에서 관측값별 변동성을 나타내는 가중치를 제공하는 데 사용되지만, lagsarlm() 함수에서는 이 옵션이 제공되지 않는다.\nDurbin 인수는 이전의 type 및 etype 인수를 대체하며, 지정하지 않으면 기본값은 FALSE로 간주된다. 지정하는 경우, FALSE 또는 TRUE 값을 줄 수 있는데, TRUE로 설정하면 모든 공간래그 설명변수가 포함된다. 또는 포함할 공간래그 설명변수를 지저하는 일면 공식(one-sided formula)을 줄 수 있다.(역자주: 여기서 ’일면 공식’이란 R에서 좌변 없이 ~ 변수1 + 변수2 형태로 작성된 공식을 말하며, 주로 변수 집합을 지정할 때 사용된다. 여기서는 공간래그로 포함할 설명변수를 선택하는 데 쓰인다.) method 인수는 로그우도 함수에서 로그 행렬식 항을 계산하는 방법을 지정하며, 기본값 \"eigen\"은 중간 규모의 데이터셋에 적합하다. interval 인수는 stats 패키지의 optimize() 함수를 통해 공간 계수를 탐색하는 범위를 지정한다. tol.solve() 인수는 base 패키지의 solve() 함수에 전달되며, 회귀계수 간 스케일 차이가 큰 데이터셋에서 분산-공분산 행렬의 역행렬을 계산하는 데 필요하다. 기본값은 base::solve() 함수에서 사용하는 값보다 훨씬 크다. control 인수는 추정 함수의 실행을 세밀하게 조정하는 제어값 리스트를 받는다.\nsacsarlm() 함수는 SAC 및 GNM 형식에서 두 개의 공간 프로세스를 모형화할 때 서로 다른 두 개의 공간가중치를 사용할 수 있도록, 두 번째 공간가중치와 interval 인수를 받을 수 있다. 기본값은 동일한 공간가중치를 사용하는 것이며, 수치 최적화에는 기본적으로는 stats 패키지의 nlminb() 함수가 사용된다. 시작값은 휴리스틱이 방식으로 선택된다. lagsarlm()함수와 마찬가지로 weights 인수는 지원하지 않는다.\n대규모 데이터셋을 사용할 경우, 계수의 분산-공분산 행렬 계산 시 분석적 점근적(analytic asymptotic) 접근 방식 대신 수치적 헤세 행렬(numerical Hessian) 접근 방식이 사용된다.(역자주: ‘분석적 점근적’ 접근 방식은 수학적으로 유도된 공식에 따라 분산–공분산 행렬을 계산하는 방법이며, 표본 크기가 충분히 크다는 가정하에 효율적이다. 반면, ‘수치적 헤세 행렬’ 접근 방식은 모수에 대한 로그우도의 2차 미분을 수치적으로 근사하여 행렬을 구하는 방법으로, 대규모 데이터셋에서 계산 안정성과 정확성을 확보하기 위해 사용된다.)\n\n17.2.1 보스턴 주택 가격 데이터셋 예시\n다음 예제는 Bivand(2017)를 기반으로 하며, 16장에서 생성된 객체들을 활용한다.\n\nlibrary(spatialreg)\neigs_489 &lt;- eigenw(lw_q_489)\nSDEM_489 &lt;- errorsarlm(form, data = boston_489, \n      listw = lw_q_489, Durbin = TRUE, zero.policy = TRUE,\n      control = list(pre_eig = eigs_489))\nSEM_489 &lt;- errorsarlm(form, data = boston_489, \n      listw = lw_q_489, zero.policy = TRUE,\n      control = list(pre_eig = eigs_489))\n\n기본값인 \"eigen\" 방법을 사용할 경우, 미리 계산된 고유값을 control 리스트 인수를 통해 전달할 수 있다.\n\ncbind(data.frame(model=c(\"SEM\", \"SDEM\")), \n      rbind(broom::tidy(Hausman.test(SEM_489)), \n            broom::tidy(Hausman.test(SDEM_489))))[,1:4]\n#   model statistic  p.value parameter\n# 1   SEM      52.0 2.83e-06        14\n# 2  SDEM      48.7 6.48e-03        27\n\n489개의 트랙트 데이터셋에 대한 두 가지 Hausman 검정 결과, 회귀계수가 비공간적 회귀분석의 회귀계수와 유의하게 다르다는 점이 확인되었으며, 이는 공간 프로세스의 패턴이 일치하지 않음을 시사한다.(역자주: Hausman 검정은 두 추정량이 모두 일관성을 가지지만 한쪽이 더 효율적일 것으로 가정될 때, 그 효율성이 실제로 유지되는지 확인하는 통계 검정이다. 공간통계 분석에서는 비공간 회귀와 공간 회귀의 계수를 비교하여, 계수 차이가 유의하면 공간 효과가 존재함을 시사한다.)\n\neigs_94 &lt;- eigenw(lw_q_94)\nSDEM_94 &lt;- errorsarlm(form, data=boston_94, listw=lw_q_94,\n                      Durbin = TRUE,\n                      control = list(pre_eig=eigs_94))\n# Warning in RET$pfunction(\"adjusted\", ...): Completion with error &gt;\n# abseps\n\n# Warning in RET$pfunction(\"adjusted\", ...): Completion with error &gt;\n# abseps\n\n# Warning in RET$pfunction(\"adjusted\", ...): Completion with error &gt;\n# abseps\n\n# Warning in RET$pfunction(\"adjusted\", ...): Completion with error &gt;\n# abseps\nSEM_94 &lt;- errorsarlm(form, data = boston_94, listw = lw_q_94,\n                     control = list(pre_eig = eigs_94))\n\n94개의 대기오염 모형 출력 구역에 대한 Hausman 검정에서는 계수 간 유의한 차이가 발견되지 않았다.\n\ncbind(data.frame(model=c(\"SEM\", \"SDEM\")), \n      rbind(broom::tidy(Hausman.test(SEM_94)), \n            broom::tidy(Hausman.test(SDEM_94))))[, 1:4]\n#   model statistic p.value parameter\n# 1   SEM     15.66   0.335        14\n# 2  SDEM      9.21   0.999        27\n\n이러한 결과는 SEM과 SDEM 모형이 대기오염 모형 출력 구역 수준에서 최소제곱법이나 SLX 모형에 비해 거의 추가적인 차이를 만들지 않았음을 보여준다. 이러한 사실은 우도비 검정을 통해 확인할 수 있다.\n\ncbind(data.frame(model=c(\"SEM\", \"SDEM\")),\n      rbind(broom::tidy(LR1.Sarlm(SEM_94)),\n            broom::tidy(LR1.Sarlm(SDEM_94))))[,c(1, 4:6)]\n#   model statistic p.value parameter\n# 1   SEM     2.593   0.107         1\n# 2  SDEM     0.216   0.642         1\n\nspatialreg 패키지의 LR.Sarlm() 함수를 사용하면 중첩(nested) 모형 간 우도비 검정을 실행할 수 있지만, 여기서는 lmtest 패키지의 lrtest() 함수를 사용하며, 결과는 동일하다.(역자주: 여기서 ’중첩 모형’이란 하나의 모형이 다른 모형의 특수한 형태로 포함되어 있는 경우를 말한다. 예를 들어, 공간더빈모형(SDM)에서 일부 계수를 0으로 두면 공간래그모형(SLM)이 되므로, SLM은 SDM에 중첩되어 있다. 우도비 검정은 이러한 중첩 관계를 전제로 두 모형의 적합도를 비교한다.) 트랙트와 모형 출력 구역 모두에서 공간래그 공변량을 포함하는 모형이 더 선호된다는 것으로 나타났다.\n\no &lt;- lmtest::lrtest(SEM_489, SDEM_489)\nattr(o, \"heading\")[2] &lt;- \"Model 1: SEM_489\\nModel 2: SDEM_489\"\no\n# Likelihood ratio test\n# \n# Model 1: SEM_489\n# Model 2: SDEM_489\n#   #Df LogLik Df Chisq Pr(&gt;Chisq)    \n# 1  16    274                        \n# 2  29    311 13  74.4    1.2e-10 ***\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\no &lt;- lmtest::lrtest(SEM_94, SDEM_94)\nattr(o, \"heading\")[2] &lt;- \"Model 1: SEM_94\\nModel 2: SDEM_94\"\no\n# Likelihood ratio test\n# \n# Model 1: SEM_94\n# Model 2: SDEM_94\n#   #Df LogLik Df Chisq Pr(&gt;Chisq)    \n# 1  16   59.7                        \n# 2  29   81.3 13  43.2    4.2e-05 ***\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSLX 모형은 최소제곱법으로 적합되며, 로그우도 값을 반환하므로 잔차에 공간 프로세스 요소를 포함할 필요가 있는지를 검정할 수 있다. 트랙트 데이터셋의 경우, 이를 포함해야 한다는 결과가 명확히 나타났다.\n\nSLX_489 &lt;- lmSLX(form, data = boston_489, listw = lw_q_489,\n                 zero.policy = TRUE)\no &lt;- lmtest::lrtest(SLX_489, SDEM_489)\nattr(o, \"heading\")[2] &lt;- \"Model 1: SLX_489\\nModel 2: SDEM_489\"\no\n# Likelihood ratio test\n# \n# Model 1: SLX_489\n# Model 2: SDEM_489\n#   #Df LogLik Df Chisq Pr(&gt;Chisq)    \n# 1  28    231                        \n# 2  29    311  1   159     &lt;2e-16 ***\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n그러나 모형 출력 구역 데이터에서는 그와 반대되는 결과가 나타났다.\n\nSLX_94 &lt;- lmSLX(form, data = boston_94, listw = lw_q_94)\no &lt;- lmtest::lrtest(SLX_94, SDEM_94)\nattr(o, \"heading\")[2] &lt;- \"Model 1: SLX_94\\nModel 2: SDEM_94\"\no\n# Likelihood ratio test\n# \n# Model 1: SLX_94\n# Model 2: SDEM_94\n#   #Df LogLik Df Chisq Pr(&gt;Chisq)\n# 1  28   81.2                    \n# 2  29   81.3  1  0.22       0.64\n\n이러한 결과는 주택 단위 수를 트랙트와 모형 출력 구역별로 집계해 사례 가중치를 적용했을 때도 동일하게 유지되었다.\n\nSLX_489w &lt;- lmSLX(form, data = boston_489, listw = lw_q_489,\n                  weights = units, zero.policy = TRUE)\nSDEM_489w &lt;- errorsarlm(form, data = boston_489,\n                        listw = lw_q_489, Durbin = TRUE,\n                        weights = units, zero.policy = TRUE,\n                        control = list(pre_eig = eigs_489))\no &lt;- lmtest::lrtest(SLX_489w, SDEM_489w)\nattr(o, \"heading\")[2] &lt;- \"Model 1: SLX_489w\\nModel 2: SDEM_489w\"\no\n# Likelihood ratio test\n# \n# Model 1: SLX_489w\n# Model 2: SDEM_489w\n#   #Df LogLik Df Chisq Pr(&gt;Chisq)    \n# 1  28    311                        \n# 2  29    379  1   136     &lt;2e-16 ***\n# ---\n# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSLX_94w &lt;- lmSLX(form, data = boston_94, listw = lw_q_94,\n                 weights = units)\nSDEM_94w &lt;- errorsarlm(form, data = boston_94, listw = lw_q_94,\n                       Durbin = TRUE, weights = units,\n                       control = list(pre_eig = eigs_94))\no &lt;- lmtest::lrtest(SLX_94w, SDEM_94w)\nattr(o, \"heading\")[2] &lt;- \"Model 1: SLX_94w\\nModel 2: SDEM_94w\"\no\n# Likelihood ratio test\n# \n# Model 1: SLX_94w\n# Model 2: SDEM_94w\n#   #Df LogLik Df Chisq Pr(&gt;Chisq)\n# 1  28   97.5                    \n# 2  29   98.0  1  0.92       0.34\n\n이 경우와 Bivand(2017)에서 제시된 논거를 바탕으로, 가중치 사용은 정당화된다. 이는 주택 단위 수가 트랙트의 경우 5개에서 3,031개까지, 대기오염 모형 출력 구역의 경우는 25개에서 12,411개까지 다양하기 때문이다. 이러한 이유와, 가중치를 활용하는 GNM 모형이 아직 개발되지 않았다는 점 때문에, GNM 모형을 출발점으로 삼아 일반 모형에서 더 단순한 모형으로의 검정을 수행할 수 없다. 대신 SDEM 모형을 출발점으로 설정하고, Hausman 검정을 사용하여 관측 단위 선택에 지침을 얻는다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>공간계량경제학적 모형</span>"
    ]
  },
  {
    "objectID": "17.html#공간-효과-추정",
    "href": "17.html#공간-효과-추정",
    "title": "17  공간계량경제학적 모형",
    "section": "\n17.3 공간 효과 추정",
    "text": "17.3 공간 효과 추정\n전역적 효과는 공간래그 반응변수를 포함하는 모형(SLM, SDM, SAC, GNM)의 적합 결과를 보고할 때 핵심적인 요소로 간주된다(LeSage and Pace 2009). 전역적 효과를 공간래그 공변량(SLX, SDEM)을 포함하는 다른 모형으로 확장하려는시도도 이루어졌다(Elhorst 2010; Bivand 2012; Halleck Vega and Elhorst 2015). SLM, SDM, SAC, GNM 모형은 MLE 또는 GMM을 사용하여 적합시킬 경우, 계수의 분산-공분산 행렬을 활용할 수 있다. 계수 추정치를 평균으로 하고, 추정된 분산-공분산 행렬로부터 분산을 가져와 다변량 정규분포를 구성한 뒤, 이로부터 난수를 추출할 수 있다. 베이지안 방법으로 적합한 경우에는 표본이 사전에 주어지므로 별도의 추출이 필요 없다. SDEM의 경우, 비래그 공변량의 회귀계수에 대한 표본은 직접(direct) 효과를 나타내고, 공간래그 공변량의 회귀계수에 대한 표본은 간접(indirect) 효과를 나타내며, 이 둘을 합한 값이 총(total) 효과를 이룬다.\nSLX와 SDEM 모형에서는 추론을 위해 샘플링이 필요하지 않으므로, MLE로 적합된 모형에 대해서는 선형결합을 사용한다. 여기서는 공기오염 변수에 대해서만 결과를 제시한다. 모형 출력 보고 방법과 관련된 문제는 아직 완전히 해결되지 않았다. 이는 개별 공변량에 대해 세 가지 효과 값을 보고해야 하기 때문이다. 공간래그 공변량이 포함될 경우, 기존의 두 개의 계수는 세 가지 효과로 대체된다. 여기서는 공기오염 변수에 대한 예시를 보여준다.\n\nsum_imp_94_SDEM &lt;- summary(impacts(SDEM_94))\nrbind(Impacts = sum_imp_94_SDEM$mat[5,], \n      SE = sum_imp_94_SDEM$semat[5,])\n#           Direct Indirect   Total\n# Impacts -0.01276 -0.01845 -0.0312\n# SE       0.00235  0.00472  0.0053\n\nSLX와 SDEM 모형에서 직접 효과는 동일한 관측 단위에서 공기오염 변화가 반응변수에 미치는 영향이며, 간접 효과(지역 효과)는 인접한 관측 단위에서 공기오염 변화가 반응변수에 미치는 영향이다.\n\nsum_imp_94_SLX &lt;- summary(impacts(SLX_94))\nrbind(Impacts = sum_imp_94_SLX$mat[5,], \n      SE = sum_imp_94_SLX$semat[5,])\n#          Direct Indirect    Total\n# Impacts -0.0128 -0.01874 -0.03151\n# SE       0.0028  0.00556  0.00611\n\n같은 방법을 가중 공간 회귀분석에 적용한 결과, 공기오염이 주택 가치에 미치는 총 효과는 감소했으나 여전히 통계적으로 유의하였다.\n\nsum_imp_94_SDEMw &lt;- summary(impacts(SDEM_94w))\nrbind(Impacts = sum_imp_94_SDEMw$mat[5,], \n      SE = sum_imp_94_SDEMw$semat[5,])\n#           Direct Indirect    Total\n# Impacts -0.00592 -0.01076 -0.01668\n# SE       0.00269  0.00531  0.00559\n\n전체적으로, 대기오염 모형 출력 구역 수준으로 집계된 공간래그 공변량만을 포함하는 가중 공간 회귀모형이 대부분의 모형 오지정 오류를 해결하는 것으로 보인다. Bivand(2017)에서 더 자세히 논의된 바와 같이, 이는 오지정된 대체 모형들보다 오염 제거에 대한 지불의향이 훨씬 더 크다는 점을 보여준다.\n\nsum_imp_94_SLXw &lt;- summary(impacts(SLX_94w))\nrbind(Impacts = sum_imp_94_SLXw$mat[5,], \n      SE = sum_imp_94_SLXw$semat[5,])\n#           Direct Indirect    Total\n# Impacts -0.00620 -0.01221 -0.01842\n# SE       0.00326  0.00628  0.00629",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>공간계량경제학적 모형</span>"
    ]
  },
  {
    "objectID": "17.html#예측",
    "href": "17.html#예측",
    "title": "17  공간계량경제학적 모형",
    "section": "\n17.4 예측",
    "text": "17.4 예측\n보스턴 구역 데이터셋에서 응답변수인 중위 주택가격의 17개 관측치가 누락되어 있다. 이를 채우기 위해 \"Sarlm\" 객체에 대한 predict() 메서드를 사용한다. 이 메서드는 Goulard, Laurent, and Thomas-Agnan(2017)을 기반으로 마틴 구브리(Martin Gubri)가 재작성하였으며 Laurent와 Margaretic(2021)도 참고할 수 있다. pred.type 인수는 해당 논문에서 제시된 예측 전략을 지정한다.\n이 예시에서는 pred.type 설정을 달리하여 SDEM 모형의 다양한 변종으로 샘플 외 예측을 수행한다. 이를 통해 예측 결과의 차이를 확인할 수 있으며, 이는 연구할 가치가 있는 중요한 주제임을 시사한다. 누락 변수 처리에 대해서는 여러 대안이 제시되어 있다(Gómez-Rubio, Bivand, and Rue 2015; Suesse 2018). 예측에 대한 관심이 높아지는 또 다른 이유는, 예측이 기계학습 접근 방식의 기본 요소이기 때문이다. 기계학습에서는 검증 및 테스트 데이터셋을 대상으로 한 예측 성능이 모형 사양 선택을 이끈다. 그러나 공간적 의존성을 지닌 공간데이터에서 훈련 및 검정 데이터셋을 선택하는 문제는 여전히 해결되지 않았으며, 이는 독립 표본 데이터의 경우와는 확연히 다른 복잡성을 지닌다.\n여기서는 검열된 트랙트 관측값에 대해 세 가지 상이한 예측 유형을 적용하고, USD 단위의 주택 중위값으로 복원하기 위해 지수 변환을 수행한다. 이때 newdata 객체의 row.names() 함수가 공간가중치행렬의 \"region.id\" 속성과 일치해야 샘플 외 예측이 가능하다는 점에 유의해야 한다.\n\nnd &lt;- boston_506[is.na(boston_506$median),]\nt0 &lt;- exp(predict(SDEM_489, newdata = nd, listw = lw_q,\n                  pred.type = \"TS\", zero.policy  =TRUE))\nsuppressWarnings(t1 &lt;- exp(predict(SDEM_489, newdata = nd,\n                                    listw = lw_q,\n                                    pred.type = \"KP2\",\n                                    zero.policy = TRUE)))\nsuppressWarnings(t2 &lt;- exp(predict(SDEM_489, newdata = nd,\n                                    listw = lw_q,\n                                    pred.type = \"KP5\",\n                                    zero.policy = TRUE)))\n\nINLA 패키지의 \"slm\" 모형을 사용하면 모형 적합 함수 호출 과정에서 누락된 반응변수 값을 함께 예측할 수 있다. 다만 \"slm\" 모형은 아직 실험적 단계이므로 약간의 설정 코드가 필요하다.\n\nlibrary(INLA)\n# Loading required package: foreach\n# Loading required package: parallel\n# Loading required package: sp\n# This is INLA_23.04.24 built 2023-04-24 19:15:35 UTC.\n#  - See www.r-inla.org/contact-us for how to get help.\n#  - To enable PARDISO sparse library; see inla.pardiso()\n# \n# Attaching package: 'INLA'\n# The following object is masked _by_ '.GlobalEnv':\n# \n#     f\nW &lt;- as(lw_q, \"CsparseMatrix\")\nn &lt;- nrow(W)\ne &lt;- eigenw(lw_q)\nre.idx &lt;- which(abs(Im(e)) &lt; 1e-6)\nrho.max &lt;- 1 / max(Re(e[re.idx]))\nrho.min &lt;- 1 / min(Re(e[re.idx]))\nrho &lt;- mean(c(rho.min, rho.max))\nboston_506$idx &lt;- 1:n\nzero.variance = list(prec = list(initial = 25, fixed = TRUE))\nargs.slm &lt;- list(rho.min = rho.min, rho.max = rho.max, W = W,\n                 X = matrix(0, n, 0), Q.beta = matrix(1,0,0))\nhyper.slm &lt;- list(prec = list(prior = \"loggamma\", \n                              param = c(0.01, 0.01)),\n                  rho = list(initial = 0, prior = \"logitbeta\",\n                             param = c(1,1)))\nWX &lt;- create_WX(model.matrix(update(form, CMEDV ~ .), \n                             data = boston_506), lw_q)\nSDEM_506_slm &lt;- inla(update(form, \n                            . ~ . + WX + f(idx, model = \"slm\",\n                                         args.slm = args.slm,\n                                         hyper = hyper.slm)),\n                 data = boston_506, family = \"gaussian\",\n                 control.family = list(hyper = zero.variance),\n                 control.compute = list(dic = TRUE, cpo = TRUE))\nmv_mean &lt;- exp(SDEM_506_slm$summary.fitted.values$mean[\n               which(is.na(boston_506$median))])\n\nINLA 패키지는 예측값에 대한 주변분포(marginal distribution)의 격자형 추정치를 제공하며, 이를 통해 예측값에 내재된 불확실성을 평가할 수 있다.(역자주: 여기서 ’예측값에 대한 주변분포’란 각 예측값이 가질 수 있는 불확실성을 나타내는 확률분포를 말한다. INLA 패키지는 이를 일정 간격의 격자점에서 계산하여 근사하는 방식을 사용하며, 이를 통해 예측값의 신뢰구간이나 변동 범위를 평가할 수 있다.)\n\ndata.frame(fit_TS = t0[,1], fit_KP2 = c(t1), fit_KP5 = c(t2),\n    INLA_slm = mv_mean, censored = \n      boston_506$censored[as.integer(attr(t0, \"region.id\"))])\n#     fit_TS fit_KP2 fit_KP5 INLA_slm censored\n# 13   23912   29477   28147    31112    right\n# 14   28126   27001   28516    31314    right\n# 15   30553   36184   32476    41298    right\n# 17   18518   19621   18878    21160    right\n# 43    9564    6817    7561     6830     left\n# 50    8371    7196    7383     6885     left\n# 312  51477   53301   54173    56274    right\n# 313  45921   45823   47095    46447    right\n# 314  44196   44586   45361    42805    right\n# 317  43427   45707   45442    48025    right\n# 337  39879   42072   41127    41462    right\n# 346  44708   46694   46108    45847    right\n# 355  48188   49068   48911    49138    right\n# 376  42881   45883   44966    47747    right\n# 408  44294   44615   45670    46164    right\n# 418  38211   43375   41914    43913    right\n# 434  41647   41690   42398    41551    right\n\n공간적 회귀분석을 위한 도구 모음은 여전히 완전하지 않으며, 그 빈틈을 메우는 데는 시간이 필요하다. 여러 공간적 회귀분석 전통 간에 이해와 발전을 거의 공유하지 않는 점은 여전히 아쉬운 부분이다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>공간계량경제학적 모형</span>"
    ]
  },
  {
    "objectID": "17.html#연습문제",
    "href": "17.html#연습문제",
    "title": "17  공간계량경제학적 모형",
    "section": "\n17.5 연습문제",
    "text": "17.5 연습문제\n\nPiras와 Prucha(2014), 그리고 Raymond J. G. M. Florax, Folmer과 Rey(2003)를 참조하여, 사전 테스트 전략을 선택했을 때, 속성만 포함된 데이터셋과 지자체 구역 변수를 추가한 속성 데이터셋의 선형모형에서 잔차의 공간적 의존성이 나타나는지 답하시오. 사전 테스트가 어떤 모형을 지목하는지에 대해 답하시오.\n자치구역 더미 변수를 포함하거나 자치구역 레짐(regime) 모형을 실행하는 것이 잔차의 공간적 의존성을 줄이는 데 도움이 될 수 있는지에 대해 답하시오.\n속성만 포함한 모형과 자치구역 변수를 추가한 모형에 대해 MLE를 사용하여 SEM 모형을 실행하시오(GMM 코드 예시는 Bivand, Millo와 Piras(2021)를 참조). 이어서 SDEM 모형으로 확장하시오. 또한 SLX 모형을 실행하고, 해당 모형의 잔차에 대한 공간적 자기상관 검정 결과를 해석하시오. SEM과 SDEM 모형에 대한 Hausman 검정에서 나타난 매우 높은 유의성을 해석하시오.\n속성만 포함한 모형과 자치구역 변수를 추가한 모형에 대해 GNM 모형을 실행하시오. 이러한 모형을 SDM 또는 SDEM 형식으로 단순화할 수 있는지에 대해 답하시오.\n16장 연습문제에서 얻은 모형 추정 결과가 이 장의 결과보다 더 명확한 통찰을 제공하는지에 대해 답하시오.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>공간계량경제학적 모형</span>"
    ]
  },
  {
    "objectID": "A.html",
    "href": "A.html",
    "title": "부록 A — 예전 R 공간 패키지",
    "section": "",
    "text": "rgdal과 rgeos 패키지의 퇴역\nsf와 stars와 같은 최신 패키지가 등장하기 전부터 R을 사용해 온 오랜 사용자라면, maptools, sp, rgeos, rgdal과 같은 오래된 공간 패키지에 더 익숙할 것이다. 그렇다면, 기존 코드나 이들 패키지에 의존하는 다른 R 패키지를 갱신해야 할 필요가 있는지 궁금할 것이다. 그에 대한 대답은 간단하다. “그렇다.”\nmaptools, rgdal, rgeos 패키지는 2023년에 퇴역했다. 여기서 ’퇴역’이란 더 이상 유지 보수가 이뤄지지 않고, 그 결과로 CRAN에서 해당 패키지가 아카이브로 전환되는 것을 의미한다. 다만 R-Forge가 유지되는 한, 소스 코드 저장소 자체는 계속 남아 있을 것이다. 퇴역의 한 가지 이유는 관리자의 은퇴이며, 더 중요한 이유는 이들 패키지의 기능이 이미 새로운 패키지들로 대체되었기 때문이다. 새로운 관리자가 R-Forge 저장소를 인수할 가능성은 매우 낮다. 이는 GEOS, GDAL, PROJ 라이브러리의 발전과 함께 패키지 코드가 점진적으로 변화해 왔고, 많은 부분이 오래된 구조를 포함해 유지와 이해가 어렵기 때문이다.\nrgeos와 rgdal 패키지의 퇴역과 함께, sp 패키지가 이들과 맺고 있던 기존 연결성은 sf 패키지와의 연결로 대체되었다. 여기에는 예를 들어 좌표참조계(CRS) 식별자의 검증이나, 링이 내부 홀인지 외부 링인지 확인하는 작업 등이 포함된다. maptools 패키지에서 선택된 일부 함수도 sp 패키지로 이전되었다.",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>예전 R 공간 패키지</span>"
    ]
  },
  {
    "objectID": "A.html#sf와-sp-패키지의-연결성-및-차별성",
    "href": "A.html#sf와-sp-패키지의-연결성-및-차별성",
    "title": "부록 A — 예전 R 공간 패키지",
    "section": "sf와 sp 패키지의 연결성 및 차별성",
    "text": "sf와 sp 패키지의 연결성 및 차별성\nsf와 sp 패키지는 여러 측면에서 차이를 보인다. 가장 두드러진 차이는 sp 클래스가 엄격한 S4 클래스를 사용하는 반면, sf는 보다 유연한 S3 클래스 계층을 사용한다는 점이다. sf 객체는 data.frame 또는 tibble에서 파생되므로, 기존 R 생태계, 특히 tidyverse 계열 패키지와의 연동이 용이하다. sf 객체는 기하 데이터를 리스트-컬럼(list-column)에 저장하며, 이로 인해 기하 데이터가 항상 리스트 요소 형태로 유지된다. 반면, sp 패키지는 데이터 구조를 덜 엄격하게 설계하여, 예를 들어 SpatialPoints나 SpatialPixels의 모든 좌표를 행렬 형태로 저장한다. 이러한 방식은 리스트-컬럼으로는 구현할 수 없지만, 특정 문제에서는 더 나은 성능을 제공한다. sf 객체 x를 sp 객체로 변환하려면 다음과 같이 수행한다.\n\nlibrary(sp)\ny = as(x, \"Spatial\")\n\n그리고, 반대로 sp 객체를 sf 객체로 변환하려면 다음과 같이 한다.\n\nx0 = st_as_sf(y)\n\n이러한 변환에는 몇 가지 제약이 있다.\n\nsp는 LINESTRING과 MULTILINESTRING, 또는 POLYGON과 MULTIPOLYGON 지오메트리를 구분하지 않는다. 예를 들어, LINESTRING을 sp로 변환한 후 다시 sf로 변환하면 MULTILINESTRING으로 반환된다.\nsp는 GEOMETRYCOLLECTION를 지원하지 않으며, ‘빅 세븐’ (3.1.1절) 범주에 포함되지 않는 지오메트리를를 표현할 구조가 없다.\n혼합된 지오메트리를 포함한 GEOMETRY 유형의 sf 또는 sfc 객체는 sp 객체로 변환할 수 없다.\n속성-지오메트리 관계 속성은 sp로 변환 시 손실된다.\n두 개 이상의 지오메트리 리스트-컬럼을 가진 sf 객체는 sp로 변환 시 부차적인 리스트-컬럼이 삭제된다.",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>예전 R 공간 패키지</span>"
    ]
  },
  {
    "objectID": "A.html#코드와-패키지-마이그레이션",
    "href": "A.html#코드와-패키지-마이그레이션",
    "title": "부록 A — 예전 R 공간 패키지",
    "section": "코드와 패키지 마이그레이션",
    "text": "코드와 패키지 마이그레이션\nsf의 GitHub 위키 페이지(https://github.com/r-spatial/sf/wiki/Migrating)에는 rgeos, rgdal, sp의 메서드 및 함수와 그에 데응하는 sf 메서드 및 함수의 목록이 정리되어 있다. 이 자료는 기존 코드나 패키지를 sf로 전환할 때 유용하다.\n가장 간단한 마이그래이션 사례는 rgdal 패키지의 readOGR() 함수만으로 파일을 읽던 코드를 sf 패키지의 read_sf() 함수로 바꾸는 것이다. 기존 코드가 sp 클래스를 기대한다면, sf로 읽은 뒤 sp로 변환하는 방식이 편리하다.(역자주: 여기서 ’마이그레이션(migration)’은 기존 시스템이나 환경에서 새로운 시스템이나 환경으로 코드나 데이터를 이전 및 전환하는 과정을 의미한다. 여기서는 구 버전 R 공간 패키지에서 최신 패키지로 코드를 옮기고 호환성을 확보하는 과정을 가리킨다.)\n\nx = as(sf::read_sf(\"file\"), \"Spatial\")\n\n다만 readOGR() 함수를 계속 사용할 경우에는 아규먼트를 더 주의해서 다뤄야 한다. 현재 우리는 rgdal, rgeos, maptools 없이, 가능하면 sp 없이도 전반이 동작하도록 과거 도서 ’R을 활용한 응용 공간데이터분석(Applied Spatial Data Analysis with R)’(Virgilio Gómez-Rubio, Bivand, Pebesma, Gómez-Rubio, 2013)의 모든 코드를 변환하는 작업을 진행 중이다. 관련 스크립트는 다음에서 확인할 수 있다. https://github.com/rsbivand/sf_asdar2ed",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>예전 R 공간 패키지</span>"
    ]
  },
  {
    "objectID": "A.html#raster와-terra-패키지",
    "href": "A.html#raster와-terra-패키지",
    "title": "부록 A — 예전 R 공간 패키지",
    "section": "raster와 terra 패키지",
    "text": "raster와 terra 패키지\nraster 패키지는 2010년부터 R에서 래스터 데이터 분석의 핵심 도구로 사용되어 왔으면, 이후 ‘공간데이터분석과 모델링(Geographic Data Analysis and Modeling)’(Hijmans 2023a) 패키지로 발전하여 다양한 공간데이터 처리에 활용되었다. raster 패키지는 벡터 데이터를 처리를 위해 sp 객체를 사용하고, GDAL 라이브러리 형식의 데이터 입출력시 terra를 활용한다. 후속 패키지인 terra는 ‘공간데이터분석(Spatial Data Analysis)’(Hijmans 2023b)을 위한 도구로, “raster 패키지와 매우 유사하지만 […] 더 많은 기능을 제공하며, 사용하기 쉽고, […] 더 빠르다.” terra 패키지는 벡터 데이터용 자체 클래스를 제공하면서도 대부분의 sf 객체를 받아들인다. 다만, 위에서 언급한 sp 변환 시와 유사한 제약이 적용된다. 또한 terra 패키지는 GDAL, GEOS, PROJ와 직접 연결 되므로 별도의 패키지가 필요 없다.\nraster 또는 terra 패키지의 래스터 레이어나 래스터 스택은 st_as_stars() 함수를 사용해 stars 객체로 변환할 수 있다. terra의 SpatVector 객체는 sf의 st_as_sf() 함수를 통해 를 변환할 수 있다.\n로버트 히즈먼(Robert Hijmans)이 저술한 온라인 저서 ’R과 terra를 활용한 공간데이터사이언스(Spatial Data Science with R and “terra”)’(https://rspatial.org/terra)에서는 terra를 활용한 공간데이터분석 방법을 자세히 다룬다. sf, stars 및 이 책에서 다루는 여러 r-spatial 패키지는 r-spatial GitHub 조직에 속해 있으며(여기서 r과 spatial 사이에는 하이픈이 있다. 히즈먼의 조직에는 하이픈이 없음). 해당 조직 블로그(https://r-spatial.org/book) 에서 책 링크를 확인할 수 있다.\nsf, stars, terra 패키지는 공통의 목표를 공유하고 있지만 접근 방식에서 차이를 보인다. 데이터 분석, 소프트웨어 엔지니어링, 커뮤니티 운영에 대한 강조점이 서로 달라 일부 사용자에게 혼란을 줄 수 있지만, 이러한 다양성은 R 패키지 생태계를 더욱 풍부하게 만들고 선택지를 확장한다. 이느 사용자가 R로 공간데이터를 다루는 과정에서 새로운 시도를 이어가도록 장려하며, 궁극적으로 R spatial의 발전과 확신에 기여한다.",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>예전 R 공간 패키지</span>"
    ]
  },
  {
    "objectID": "B.html",
    "href": "B.html",
    "title": "부록 B — R 기초",
    "section": "",
    "text": "파이프 오퍼레이터\n|&gt; (파이프) 기호는 ’그렇다면’이라고 읽으면 이해하기 쉽다.\na |&gt; b() |&gt; c() |&gt; d(n = 10)\n위의 코드는 a를 b() 함수에 전달한 후, 결과를 c() 함수에 전달하고, 다시 d() 함수에 전달하며, 마지막 호출에서 n = 10을 지정하는 것과 같다. 즉, 다음과 동일하다.\nd(c(b(a)), n = 10)\n혹은 중간 결과를 변수에 담아 다음과 같이 쓸 수도 있다.\ntmp1 &lt;- b(a)\ntmp2 &lt;- c(tmp1)\ntmp3 &lt;- d(tmp2, n = 10)\n많은 사람들은 이러한 파이프 형태가 실행 순서가 읽는 순서(왼쪽에서 오른쪽)를 따르기 때문에 읽기 쉽다고 생각한다. 중첩 함수 호출과 마찬가지로, 중간 결과에 이름을 붙일 필요가 없다. 그러나 중첩 함수 호출과 마찬가지로, 예상과 다른 중간 결과를 디버그하기는 어렵다. 또한 중간 결과는 메모리에 존재하므로, 어느 방식도 메모리 할당을 절약하지 못한다는 점에 유의해야 한다. 이 책에서 사용하는 R 4.1.0에 도입된 네이티브 파이프(|&gt;)는 magrittr 패키지의 %&gt;% 파이프로 안전하게 대체할 수 있다.",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R 기초</span>"
    ]
  },
  {
    "objectID": "B.html#데이터-구조",
    "href": "B.html#데이터-구조",
    "title": "부록 B — R 기초",
    "section": "데이터 구조",
    "text": "데이터 구조\nChambers (2016)가 언급했듯이, “R에서 존재하는 모든 것은 객체”이다. 여기에는 데이터 객체뿐 아니라 언어 객체나 함수와 같이 특수 객체도 포함된다. 이 절에서는 R의 기본 데이터 구조를 살펴본다.\n동질 벡터\n데이터 객체는 데이터를 포함하며, 경우에 따라 메타데이터도 가진다. 데이터는 항상 벡터 형태이며, 벡터는 하나의 유형만 가질 수 있다. 유형은 typeof() 함수로 확인하고, 길이는 length() 함수로 확인한다. 벡터는 c() 함수로 생성한다.\n\ntypeof(1:10)\n# [1] \"integer\"\nlength(1:10)\n# [1] 10\ntypeof(1.0)\n# [1] \"double\"\nlength(1.0)\n# [1] 1\ntypeof(c(\"foo\", \"bar\"))\n# [1] \"character\"\nlength(c(\"foo\", \"bar\"))\n# [1] 2\ntypeof(c(TRUE, FALSE))\n# [1] \"logical\"\n\n이런 종류의 벡터를 동질(homogeneous) 벡터라고 부르는데, 이는 한 가지 유형의 데이터만을 포함할 수 있기 때문이다.\n또한 벡터는 길이가 0일 수도 있다는 점에 유의해야 한다.\n\ni &lt;- integer(0)\ntypeof(i)\n# [1] \"integer\"\ni\n# integer(0)\nlength(i)\n# [1] 0\n\n벡터의 요소는 [] 혹은 [[]]를 사용하여 추출할 수 있으며, 할당 구문에서는 해당 요소를 다른 값으로 대체할 수도 있다.\n\na &lt;- c(1,2,3)\na[2]\n# [1] 2\na[[2]]\n# [1] 2\na[2:3]\n# [1] 2 3\na[2:3] &lt;- c(5,6)\na\n# [1] 1 5 6\na[[3]] &lt;- 10\na\n# [1]  1  5 10\n\n차이점은 []는 인덱스 범위(또는 복수 인덱스)에 대해 작업할 수 있는 반면, [[]]는 단일 벡터 요소에만 접근한다는 점이다.\n이질 벡터: list\n\n두 번째 벡터 유형은 list로, 서로 다른 유형의 데이터를 함께 담을 수 있다는 점에서 이질(heterogeneous) 벡터라고 불린다.\n\nl &lt;- list(3, TRUE, \"foo\")\ntypeof(l)\n# [1] \"list\"\nlength(l)\n# [1] 3\n\n리스트에서 []와 [[]]는 추가적인 차이가 있다. []는 항상 리스트 자체를 반환하는 반면, [[]]는 해당 리스트 요소의 내용을 반환한다.\n\nl[1]\n# [[1]]\n# [1] 3\nl[[1]]\n# [1] 3\n\n교체를 수행할 때, 리스트를 지정할 경우에는 []를 사용하고, 새로운 값을 지정할 경우에는 [[]]를 사용한다.\n\nl[1:2] &lt;- list(4, FALSE)\nl\n# [[1]]\n# [1] 4\n# \n# [[2]]\n# [1] FALSE\n# \n# [[3]]\n# [1] \"foo\"\nl[[3]] &lt;- \"bar\"\nl\n# [[1]]\n# [1] 4\n# \n# [[2]]\n# [1] FALSE\n# \n# [[3]]\n# [1] \"bar\"\n\n리스트의 각 요소에 이름을 부여할 수 있다.\n\nl &lt;- list(first = 3, second = TRUE, third = \"foo\")\nl\n# $first\n# [1] 3\n# \n# $second\n# [1] TRUE\n# \n# $third\n# [1] \"foo\"\n\nl[[\"second\"]]처럼 이름을 사용하거나, 더 간단한 표기법을 사용할 수도 있다.\n\nl$second\n# [1] TRUE\nl$second &lt;- FALSE\nl\n# $first\n# [1] 3\n# \n# $second\n# [1] FALSE\n# \n# $third\n# [1] \"foo\"\n\n이름을 사용하는 것은 편리해 보일 수 있지만, 먼저 이름 속성에서 이름을 찾아야 한다는 점에 유의해야 한다(아래 참조).\nNULL과 리스트 요소의 제거\nNULL은 R에서 널(null) 값을 표현하는 방식이다. 단순 비교에서는 직관적이지 않은 결과가 나올 수 있으므로 주의해야 한다.\n\n3 == NULL # not FALSE!\n# logical(0)\nNULL == NULL # not even TRUE!\n# logical(0)\n\n따라서 NULL은 특별히 취급할 필요가 있으며, 이를 확인할 때는 is.null() 함수가 유용하다.\n\nis.null(NULL)\n# [1] TRUE\n\n리스트에서 특정 요소를 제거하려면, 해당 요소를 제외한 새로운 리스트를 만들면 된다.\n\nl &lt;- l[c(1,3)] # remove second, implicitly\nl\n# $first\n# [1] 3\n# \n# $third\n# [1] \"foo\"\n\n또는, 제거하려는 요소에 NULL을 할당하는 방법도 있다.\n\nl$second &lt;- NULL\nl\n# $first\n# [1] 3\n# \n# $third\n# [1] \"foo\"\n\n속성\n예를 들어, 임의의 메타데이터 객체를 데이터 객체에 결합할 수 있다.\n\na &lt;- 1:3\nattr(a, \"some_meta_data\") = \"foo\"\na\n# [1] 1 2 3\n# attr(,\"some_meta_data\")\n# [1] \"foo\"\n\n이 메타데이터는 조회하거나 다른 값으로 교체할 수 있다.\n\nattr(a, \"some_meta_data\")\n# [1] \"foo\"\nattr(a, \"some_meta_data\") &lt;- \"bar\"\nattr(a, \"some_meta_data\")\n# [1] \"bar\"\n\n본질적으로 객체의 속성은 이름이 지정된 리스트이며, 전체 리스트를 다음과 같이 불러오거나 설정할 수 있다.\n\nattributes(a)\n# $some_meta_data\n# [1] \"bar\"\nattributes(a) = list(some_meta_data = \"foo\")\nattributes(a)\n# $some_meta_data\n# [1] \"foo\"\n\nR은 여러 속성을 특별하게 취급하며, 전체 내용은 ?attributes에서 확인할 수 있다. 이제 몇 가지 주요 속성에 대해 살펴보자.\n객체 클래스와 class 속성\nR의 모든 객체는 “클래스를 가진다.” class(obj)는 obj의 클래스명을 담은 문자 벡터를 반환한다. 일부 객체는 기본 벡터처럼 암시적 클래스를 가진다.\n\nclass(1:3)\n# [1] \"integer\"\nclass(c(TRUE, FALSE))\n# [1] \"logical\"\nclass(c(\"TRUE\", \"FALSE\"))\n# [1] \"character\"\n\n클래스는 명시적으로 설정할 수도 있다. 이를 위해 attr() 함수를 사용하거나, 표현식의 왼쪽에 class를 배치하여 지정할 수 있다.\n\na &lt;- 1:3\nclass(a) &lt;- \"foo\"\na\n# [1] 1 2 3\n# attr(,\"class\")\n# [1] \"foo\"\nclass(a)\n# [1] \"foo\"\nattributes(a)\n# $class\n# [1] \"foo\"\n\n이 경우 새로 지정된 클래스가 기존의 암시적 클래스를 덮어쓴다. 이렇게 하면 메서드 이름에 클래스 이름을 덧붙여 foo 클래스용 메서드를 정의할 수 있다.\n\nprint.foo &lt;- function(x, ...) { \n    print(paste(\"an object of class foo with length\", length(x)))\n}\nprint(a)\n# [1] \"an object of class foo with length 3\"\n\n이러한 메서드를 제공하는 목적은 일반적으로 소프트웨어를 더 쉽게 사용할 수 있도록 하는 것이지만, 동시에 객체를 더 불투명하게 만들 수도 있다. 따라서 클래스 속성을 제거한 후 객체를 출력해 “무엇으로 구성되어 있는지” 확인하는 것이 유용하다.\n\nunclass(a)\n# [1] 1 2 3\n\n좀 더 구체적인 예로, sf 패키지를 사용해 폴리곤을 생성하는 경우를 생각해보자.\n\nlibrary(sf) |&gt; suppressPackageStartupMessages()\np &lt;- st_polygon(list(rbind(c(0,0), c(1,0), c(1,1), c(0,0))))\np\n# POLYGON ((0 0, 1 0, 1 1, 0 0))\n\n이는 WKT(well-known-text) 형식으로 출력된다. 데이터 구조를 확인하려면 다음과 같이 하면 된다.\n\nunclass(p)\n# [[1]]\n#      [,1] [,2]\n# [1,]    0    0\n# [2,]    1    0\n# [3,]    1    1\n# [4,]    0    0\n\n\ndim 속성\ndim 속성은 행렬이나 어레이(array)의 차원을 설정한다.\n\na &lt;- 1:8\nclass(a)\n# [1] \"integer\"\nattr(a, \"dim\") &lt;- c(2,4) # or: dim(a) = c(2,4)\nclass(a)\n# [1] \"matrix\" \"array\"\na\n#      [,1] [,2] [,3] [,4]\n# [1,]    1    3    5    7\n# [2,]    2    4    6    8\nattr(a, \"dim\") &lt;- c(2,2,2) # or: dim(a) = c(2,2,2)\nclass(a)\n# [1] \"array\"\na\n# , , 1\n# \n#      [,1] [,2]\n# [1,]    1    3\n# [2,]    2    4\n# \n# , , 2\n# \n#      [,1] [,2]\n# [1,]    5    7\n# [2,]    6    8\n\n\nnames 속성\n이름이 지정된 벡터는 names 속성에 해당 이름을 저장한다. 위에서는 리스트 예시를 보았고, 숫자 벡터의 예시는 다음과 같다.\n\na &lt;- c(first = 3, second = 4, last = 5)\na[\"second\"]\n# second \n#      4\nattributes(a)\n# $names\n# [1] \"first\"  \"second\" \"last\"\n\n다른 이름 속성으로는 행렬이나 어레이의 dimnames가 있다. 이 속성은 차원의 이름뿐 아니라, 각 차원에 연결된 값의 레이블도 지정한다.\n\na &lt;- matrix(1:4, 2, 2)\ndimnames(a) &lt;- list(rows = c(\"row1\", \"row2\"),\n                    cols = c(\"col1\", \"col2\"))\na\n#       cols\n# rows   col1 col2\n#   row1    1    3\n#   row2    2    4\nattributes(a)\n# $dim\n# [1] 2 2\n# \n# $dimnames\n# $dimnames$rows\n# [1] \"row1\" \"row2\"\n# \n# $dimnames$cols\n# [1] \"col1\" \"col2\"\n\ndata.frame 객체는 행과 열을 가지며, 각각의 행과 열에는 이름이 지정되어 있다.\n\ndf &lt;- data.frame(a = 1:3, b = c(TRUE, FALSE, TRUE))\nattributes(df)\n# $names\n# [1] \"a\" \"b\"\n# \n# $class\n# [1] \"data.frame\"\n# \n# $row.names\n# [1] 1 2 3\n\n\nstructure의 사용\n프로그래밍 시, 객체를 반환하기 전에 속성을 추가하거나 수정하는 패턴은 매우 흔하다. 예를 들어 다음과 같다.\n\nf &lt;- function(x) {\n   a &lt;- create_obj(x) # call some other function\n   attributes(a) &lt;- list(class = \"foo\", meta = 33)\n   a\n}\n\n마지막 두 문장은 다음과 같이 축약할 수 있다.\n\nf &lt;- function(x) {\n   a &lt;- create_obj(x) # call some other function\n   structure(a, class = \"foo\", meta = 33)\n}\n\n여기서 structure() 함수는 첫 번째 아규먼트로 받은 객체의 속성을 추가하거나 교체하고, 값이 NULL이면 해당 속성을 제거한다.",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R 기초</span>"
    ]
  },
  {
    "objectID": "B.html#multipolygon-객체-분할하기",
    "href": "B.html#multipolygon-객체-분할하기",
    "title": "부록 B — R 기초",
    "section": "\nMULTIPOLYGON 객체 분할하기",
    "text": "MULTIPOLYGON 객체 분할하기\nMULTIPOLYGON이 포함된 sf 객체는 여러 개의 개별 조각으로 분리할 수 있다. 예를 들어, 위의 예시와 같이 nc 데이터셋을 사용한다고 가정해 보자.\n\nsystem.file(\"gpkg/nc.gpkg\", package = \"sf\") |&gt; \n    read_sf() -&gt; nc\n\nnc 객체의 속성을 확인하면 다음과 같은 내용을 볼 수 있다.\n\nattributes(nc)\n# $names\n#  [1] \"AREA\"      \"PERIMETER\" \"CNTY_\"     \"CNTY_ID\"   \"NAME\"     \n#  [6] \"FIPS\"      \"FIPSNO\"    \"CRESS_ID\"  \"BIR74\"     \"SID74\"    \n# [11] \"NWBIR74\"   \"BIR79\"     \"SID79\"     \"NWBIR79\"   \"geom\"     \n# \n# $row.names\n#   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\n#  [16]  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30\n#  [31]  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n#  [46]  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n#  [61]  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n#  [76]  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n#  [91]  91  92  93  94  95  96  97  98  99 100\n# \n# $class\n# [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n# \n# $sf_column\n# [1] \"geom\"\n# \n# $agr\n#      AREA PERIMETER     CNTY_   CNTY_ID      NAME      FIPS \n#      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt; \n#    FIPSNO  CRESS_ID     BIR74     SID74   NWBIR74     BIR79 \n#      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt;      &lt;NA&gt; \n#     SID79   NWBIR79 \n#      &lt;NA&gt;      &lt;NA&gt; \n# Levels: constant aggregate identity\n\ngeom이라는 이름의 지오메트리 컬럼이 있음을 확인할 수 있으며, 이 컬럼만 추출할 수 있다.\n\nnc$geom\n# Geometry set for 100 features \n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6\n# Geodetic CRS:  NAD27\n# First 5 geometries:\n# MULTIPOLYGON (((-81.5 36.2, -81.5 36.3, -81.6 3...\n# MULTIPOLYGON (((-81.2 36.4, -81.2 36.4, -81.3 3...\n# MULTIPOLYGON (((-80.5 36.2, -80.5 36.3, -80.5 3...\n# MULTIPOLYGON (((-76 36.3, -76 36.3, -76 36.3, -...\n# MULTIPOLYGON (((-77.2 36.2, -77.2 36.2, -77.3 3...\n\n해당 컬럼만 포함된 객체가 다음과 같은 속성을 가지고 있음을 확인할 수 있다.\n\nattributes(nc$geom)\n# $n_empty\n# [1] 0\n# \n# $crs\n# Coordinate Reference System:\n#   User input: NAD27 \n#   wkt:\n# GEOGCRS[\"NAD27\",\n#     DATUM[\"North American Datum 1927\",\n#         ELLIPSOID[\"Clarke 1866\",6378206.4,294.978698213898,\n#             LENGTHUNIT[\"metre\",1]]],\n#     PRIMEM[\"Greenwich\",0,\n#         ANGLEUNIT[\"degree\",0.0174532925199433]],\n#     CS[ellipsoidal,2],\n#         AXIS[\"geodetic latitude (Lat)\",north,\n#             ORDER[1],\n#             ANGLEUNIT[\"degree\",0.0174532925199433]],\n#         AXIS[\"geodetic longitude (Lon)\",east,\n#             ORDER[2],\n#             ANGLEUNIT[\"degree\",0.0174532925199433]],\n#     USAGE[\n#         SCOPE[\"Geodesy.\"],\n#         AREA[\"North and central America: Antigua and Barbuda - onshore. Bahamas - onshore plus offshore over internal continental shelf only. Belize - onshore. British Virgin Islands - onshore. Canada onshore - Alberta, British Columbia, Manitoba, New Brunswick, Newfoundland and Labrador, Northwest Territories, Nova Scotia, Nunavut, Ontario, Prince Edward Island, Quebec, Saskatchewan and Yukon - plus offshore east coast. Cuba - onshore and offshore. El Salvador - onshore. Guatemala - onshore. Honduras - onshore. Panama - onshore. Puerto Rico - onshore. Mexico - onshore plus offshore east coast. Nicaragua - onshore. United States (USA) onshore and offshore - Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Delaware, Florida, Georgia, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin and Wyoming - plus offshore . US Virgin Islands - onshore.\"],\n#         BBOX[7.15,167.65,83.17,-47.74]],\n#     ID[\"EPSG\",4267]]\n# \n# $class\n# [1] \"sfc_MULTIPOLYGON\" \"sfc\"             \n# \n# $precision\n# [1] 0\n# \n# $bbox\n#  xmin  ymin  xmax  ymax \n# -84.3  33.9 -75.5  36.6\n\n네 번째 리스트 요소의 내용을 불러온다.\n\nnc$geom[[4]] |&gt; format(width = 60, digits = 5)\n# [1] \"MULTIPOLYGON (((-76.009 36.32, -76.017 36.338, -76.033 36...\"\n\n해당 객체의 클래스가 리스트임을 확인한다.\n\ntypeof(nc$geom[[4]])\n# [1] \"list\"\n\n해당 객체의 속성을 확인한다.\n\nattributes(nc$geom[[4]])\n# $class\n# [1] \"XY\"           \"MULTIPOLYGON\" \"sfg\"\n\n그리고 length를 확인한다.\n\nlength(nc$geom[[4]])\n# [1] 3\n\n길이 속성은 외부 링의 개수를 나타낸다. 멀티폴리곤은 하나 이상의 폴리곤으로 구성될 수 있으며, 대부분의 카운티는 하나의 폴리곤만 가지고 있음을 알 수 있다.\n\nlengths(nc$geom)\n#   [1] 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n#  [32] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 1 1 1 1 1\n#  [63] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1\n#  [94] 1 2 1 1 1 1 1\n\n멀티폴리곤은 여러 폴리곤으로 구성된 리스트이다.\n\ntypeof(nc$geom[[4]])\n# [1] \"list\"\n\n네 번째 멀티폴리곤의 첫 번째 폴리곤 역시 리스트인데, 이는 폴리곤이 외부 링을 포함하고 그 뒤에 하나 이상의 내부 링(구멍)이 올 수 있기 때문이다.\n\ntypeof(nc$geom[[4]][[1]])\n# [1] \"list\"\n\n해당 폴리곤이 외부 링 하나만 가지고 있음을 확인할 수 있다.\n\nlength(nc$geom[[4]][[1]])\n# [1] 1\n\n해당 폴리곤의 유형, 차원, 그리고 첫 번째 좌표 집합은 다음과 같이 출력할 수 있다.\n\ntypeof(nc$geom[[4]][[1]][[1]])\n# [1] \"double\"\ndim(nc$geom[[4]][[1]][[1]])\n# [1] 26  2\nhead(nc$geom[[4]][[1]][[1]])\n#       [,1] [,2]\n# [1,] -76.0 36.3\n# [2,] -76.0 36.3\n# [3,] -76.0 36.3\n# [4,] -76.0 36.4\n# [5,] -76.1 36.3\n# [6,] -76.2 36.4\n\n속성은 변경 가능하다. 예를 들어, 세 번째 좌표의 위도 값을 다음과 같이 수정할 수 있다.\n\nnc$geom[[4]][[1]][[1]][3,2] &lt;- 36.5",
    "crumbs": [
      "부록",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R 기초</span>"
    ]
  },
  {
    "objectID": "08.html",
    "href": "08.html",
    "title": "8  공간데이터의 플로팅",
    "section": "",
    "text": "8.1 모든 지도는 투영법을 가지고 있다.\n지구는 둥글지만, 플로팅 장치는 평면이다. 2.2.2절에서 언급했듯이, 어떤 방식으로든 평면 장치에 지구를 플로팅하는 순간 우리는 특정한 투영법을 적용한 것이다. 즉, 타원체 좌표를 특정한 방식으로 데카르트 좌표로 전환하는 것이다. 이는 우리가 ‘아무것도 하지 않았다고’ 생각하는 경우(역자주: 투영법을 적용하지 않았다고 생각하는 경우)(그림 8.1의 왼쪽)나, 우주에서 본 것처럼 세상을 ‘있는 그대로’ 보여준다고 생각하는 경우(그림 8.1의 오른쪽)에도 마찬가지이다. 평면상의 모든 지도는 투영법을 갖는다.\n왼쪽 지도는 다음의 코드로 작성하였다.\nlibrary(sf)\nlibrary(rnaturalearth)\nw &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nplot(st_geometry(w))\n지구 전체를 타원체 좌표로 표현할 때, 사용되는 투영법이 기본 투영법임은 다음과 같이 확인할 수 있다.\nst_is_longlat(w)\n# [1] TRUE\n그림 8.1(왼쪽)에 사용된 투영법은 등장방형 도법(정거원통 도법)으로, 경도를 \\(x\\)축, 위도를 \\(y\\)축에 선형적으로 대응시켜 지도에서 가로와 세로 방향의 거리 단위가 동일하게 유지되도록 한다.(역자주: 지구의 동서 범위는 360°, 남북 범위는 180°이므로, 이 지도의 가로세로비는 정확히 2:1이다.) 따라서 지구의 일부 영역을 이 도법으로 플로팅할 때에도 동서와 남북 방향의 거리 단위가 동일하게 유지되도록 플롯 비율을 선택해야 한다. 이는 비투영 sf 또는 stars 데이터셋에 대한 plot() 메서드의 기본 동작이며, ggplot2::geom_sf() 함수의 기본 설정이기도 하다(8.4절).(역자주: 비투영 객체는 경위도 좌표계를 가진 객체를 의미하며, 이를 plot() 메서드를 통해 플롯하면 기본적으로 경위도값을 평면 좌표처럼 취급한다. 지구 전체에 대해 이 방식으로 플롯하면 시각적으로 등장방형 도법과 동일하게 보인다.)\n플로팅 전에 투영법을 적용해 데이터를 변형할 수도 있다. 예를 들어, 독일을 플로팅하려면 국가 경계 sf 객체로 불러온 후, st_transform() 함수로 원하는 투영법을 적용한다.\nDE &lt;- st_geometry(ne_countries(country = \"germany\",\n                              returnclass = \"sf\"))\nDE |&gt; st_transform(\"+proj=eqc +lat_ts=51.14 +lon_0=90w\") -&gt;\n    DE.eqc\n여기서 eqc는 PROJ의 ’등장방형 도법’을 의미한다. lat_ts는 투영 파라미터로, 표준 위선(참인 축척이 나타나는 위선)의 위치를 지정한다. 이 표준 위선에서는 동서와 남북 방향의 길이 단위가 동일해진다. 일반적으로 이 값은 지도의 바운딩 박스의 중간 지점에 해당한다.\n그림 8.2의 두 지도를 비교해 보면, 축 값만 다를 뿐 두 지도는 동일하다. 왼쪽 지도는 타원체 좌표(도 단위)를, 오른쪽 지도는 투영 좌표(데카르트 좌표)(미터 단위)를 사용한다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#sec-every",
    "href": "08.html#sec-every",
    "title": "8  공간데이터의 플로팅",
    "section": "",
    "text": "그림 8.1: 국가 경계: 왼쪽은 경위도를 x, y 좌표로 선형변환한 플라트 카레(Plate Carrée) 도법이며, 오른쪽은 무한히 먼 거리에서 지구를 바라본 것 처럼 표현한 정사 도법이다.\n\n\n\n\n\n\n\n\n\n\n# [1] 51.14\n\n\n\n\n\n\n그림 8.2: 등장방형 도법이 적용된 독일. 왼쪽 지도의 단위는 도이고 정거원통 도법이 적용된 오른쪽 지도의 단위는 미터이다.\n\n\n\n8.1.1 데이터에 맞는 투영법 선정\n안타깝게도 만능 해법은 없다. 모든 지점 모든 방향에서 축척이 동일한 투영법은 없으며, 이 속성은 오직 지구본만 갖는다. 널리 쓰이는 투영법은 보통 다음 중 하나를 보존한다:\n\n면적: 정적 도법\n형태: 정형 도법(예: 메르카토르 도법)(역자주: 형태가 유지되기 위해서는 각도가 유지되어야 하기 때문에 정각 도법이라고도 부른다.)\n거리의 일부 속성: 등장방형 도법은 모든 지점의 경선 방향 거리를, 정거방위 도법은 투영 원점으로부터의 거리를 보존한다.)\n\n또한 일부 도법은 두 속성의 절충을 지향한다.(역자주: 주로 면적과 형태를 절충하며, 이를 절충 도법이라 부른다. 대표적으로 로빈슨 도법(Robinson projection)과 빈켈 트리펠 도법(Winkel Tripel Projection)이 있다.) 투영 파라미터는 지도에서 어떤 지역을 중앙과 가장자리에 배치할지, 어느 지역을 위와 아래에 둘지, 어디가 가장 크게 확대될지를 결정한다. 이러한 선택을 돕는 가이드라인은 있으나 절대적인 규준은 없으며, 맥락에 따라 정치적 결단에 가까울 때도 있다.\n다양한 투영법을 적용해 결과를 비교해 보는 일은 흥미롭고 교육적이다. 다만 지도 제작의 주된 목적이 투영법 자체에 대한 관심 충족이나 지식 축적이 아니라면, 널리 알려졌거나 최소한 덜 생소한 투영법을 선택해 ’어떤 투영법을 고를 것인가’에 머무르기 보다 ’선택한 투영법을 어떻게 적용할 것인가’로 논의를 진전시키는 편이 바람직하다. 한편 세계지도를 위한 투영법 선택과 관련해서는 일정한 합의가 있다. 대부분의 경우, 정적 도법이 플라트 카레 도법이나 웹 메르카토르 도법보다 선호된다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#포인트-라인-폴리곤-그리드-셀-플로팅",
    "href": "08.html#포인트-라인-폴리곤-그리드-셀-플로팅",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.2 포인트, 라인, 폴리곤, 그리드 셀 플로팅",
    "text": "8.2 포인트, 라인, 폴리곤, 그리드 셀 플로팅\n지도는 통계 데이터를 플로팅하는 특별한 형식으로 볼 수 있으므로, 플로팅의 일반 규칙이 지도에도 그대로 적용된다. 다만 지도 특유의 문제가 존재하며, 예를 들면 다음과 같다.\n\n매우 작은 폴리곤의 경우, 플로팅 시 사라질 수 있다.\n데이터에 따라 지도 심볼이 서로 겹쳐 일부 심볼이 부분적으로만 보일 수 있다. 이때 투명도를 조정하면 겹친 심볼을 식별하는 데 도움이 된다.\n포인트 피처 또는 포인트 심볼을 플로팅하는 경우, 포인트가 쉽게 겹쳐 다른 포인트 뒤에 완전히 가려질 수 있다. 이럴 때는 커널 밀도 지도(11장)가 더 유용할 수 있다.\n라인 피처 또는 라인 심볼을 플로팅하는 경우, 색이 잘 구분되지 않을 수 있으며, 라인 너비와 무관하게 서로 겹칠 수 있다.\n\n\n8.2.1 컬러\n컬러 심볼이 적용된 폴리곤을 플로팅할 때는 폴리곤 경계를 표시할지 생략할지를 선택해야 한다. 경계선이 지나치게 눈에 띄면 회색 톤이나 폴리곤 컬러와 충돌이 덜한 색을 경계에 적용할 수 있다. 반대로 경계를 완전히 생략하면 (거의) 동일한 컬러의 폴리곤을 시각적으로 구별하기 어렵다. 컬러가 서로 다른 토지 피복 유형을 표현하는 경우에는 경계 생략이 큰 문제가 되지 않을 수 있다. 그러나 컬러가 집계값(예: 인구수)의 크기를 표현한다면 지도 오독을 유발할 수 있다.(역자주: 인구 1,000명인 폴리곤이 서로 인접해 있을 때 경계를 없애면 마치 훨씬 넓은 지역의 인구가 여전히 1,000명인 것처럼 보일 수 있다.) 특히 인구수처럼 공간 외연 속성은 오독의 위험이 크다. 더 나아가, 이러한 속성은 경계를 유지하더라도 폴리곤 내부를 컬러로 채우는 코로플레스 맵(choropleth map)이 본질적으로 적절하지 않을 수 있다. 이는 컬러가 폴리곤이 가진 속성의 크기뿐 아니라 폴리곤의 면적도 함께 전달하기 때문이다.(역자주: 이런 이유로 공간 외연 속성은 코로플레스 맵이 아니라 도형표현도로 나타내는 것이 지도학적으로 합리적이다. 그럼에도 불구하고 총합이나 총빈도를 코로플레스 맵으로 표현한 지도가 인터넷에 넘쳐난다.)\n연속형 컬러 스킴(컬러의 단절이 없는 팔레트)은 연속형 공간 현상을 표현할 때 주로 쓰이지만, 지도학적 실용성보다는 시각적 매력도가 더 중요한 채택 이유이다.\n\n지도에서 특정 컬러를 범례의 특정 값과 일대일로 맞추는 것은 인간의 시각 한계를 고려할 때 실용성이 크지 않다.(역자주: 연속형 컬러 스킴은 미세한 컬러 차이로 미세한 값 차이를 구분하게 하는데, 효과적인 정보 전달 측면에서 지도학적 실효성이 없다).\n데이터 값의 범위와 컬러 범위가 비선형적으로 연결되는 일이 흔해, 값의 상대적 차이를 분간하기 더 어렵게 만든다.\n\n따라서 값의 식별보다 공간적 현상의 연속성 재현이 더 중요한 한해 연속형 컬러 스킴의 사용이 정당화될 수 있다. 대표적인 예는 고해상도 DTM(digitnal terrain model, 수치지형모형)을 채색으로 표현하는 경우다. 적절한 컬러 스킴과 팔레트는 hcl.colors() 또는 palette.colors() 함수에서 찾을 수 있으며, RColorBrewer(Neuwirth 2022), viridis(Garnier 2021), colorspace(Ihaka et al. 2023; Zeileis et al. 2020) 등의 패키지에서도 제공된다.\n\n8.2.2 컬러 단절값: classInt\n\n연속형 공간적 속성을 제한된 컬러(또는 기호)로 플로팅하려면, 데이터를 몇 개의 계급으로 구분해야 한다. R의 classInt 패키지(Bivand 2022)는 이를 수행하는 여러 방법을 제공하며, 기본값은 ’등개수 분류법(quantile)’이다.(역자주: 등개수 분류법은 각 계급에 동일한 개수의 관측치를 할당하는 방법이다.)\n\nlibrary(classInt)\n# set.seed(1) if needed ?\nr &lt;- rnorm(100)\n(cI &lt;- classIntervals(r))\n# style: quantile\n#   one of 1.49e+10 possible partitions of this variable into 8 classes\n#   [-2.29,-1.27)  [-1.27,-0.698) [-0.698,-0.426) [-0.426,-0.147) \n#              13              12              13              12 \n#  [-0.147,0.129)    [0.129,0.47)     [0.47,1.06)      [1.06,2.1] \n#              12              13              12              13\ncI$brks\n# [1] -2.290 -1.272 -0.698 -0.426 -0.147  0.129  0.470  1.059  2.105\n\nclassInt 패키지의 classIntervals() 함수에서 n 인수로 계급 수를 설정하고, style 인수로 계급 구분 방식을 선택한다. 사용 가능한 옵션에 ‘fixed’, ‘sd’, ‘equal’, ‘pretty’, ‘quantile’, ‘kmeans’, ‘hclust’, ‘bclust’, ‘fisher’, ‘jenks’이다.(역자주: ‘sd’는 표준편차 분류법, ‘equal’은 등간격 분류법, ‘fisher’와 ‘jenks’는 자연단절 분류법, ‘kmeans’, ‘hclust’, ’bclust’는 군집화 기반 계급 구분이다.) n을 지정했더라도 ’pretty’를 선택하면 무시될 수 있으며, n을 지정하지 않으면 nclass.Sturges()가 사용된다. 자동으로 n을 선택하는 다른 방법도 제공된다. 관측치가 3,000개를 초과하면, ’fisher’와 ’jenks’에서는 10% 샘플을 사용해 계급을 산출한다.\n\n8.2.3 그래티큘 및 관련 요소\n그래티큘(graticule)은 일정한 위도 또는 경도를 따라 지도상에 그어진 선의 네트워크이다. 그림 1.1에서는 회색으로, 그림 1.2에서는 흰색으로 표시되어 있다. 그래티큘은 기본적으로 위치에 대한 참조물로 지도에 그려진다. 예를 들어 그림 1.1의 첫 번째 지도에서는 플로팅된 지역이 북위 35도, 서경 80도 근처에 있음을 읽을 수 있다. 투영 좌표에 기반한 그래티큘은 모든 선이 직선으로 나타나고 좌표값이 특정 지점으로부터의 거리를 의미하므로, 경위도 그래티큘에 비해 쓰임새가 크지 않다.(역자주: 통상적으로 투영 좌표에 기반한 격자망은 그래티큘이 아니라 그리드(grid)라 부른다.) 그래도 독자가 이러한 그래티큘에 익숙하고 좌표값의 단위가 제공된다면, 크기나 거리를 해석하는데 도움을 줄 수 있다. 그래티큘의 형태는 사용한 투영법의 특성을 반영한다. 따라서 그래티큘을 통해 투영법에 대한 정보를 유추할 수 있다. 등장방형 도법이나 메르카토르 도법은 수직선과 수평선을 갖고, 원추 도법은 경선이 직선(방사형)으로 나타나며 간격이 달라지고, 많은 정적 도법에서는 경선이 곡선으로 표현된다.(역자주: 이는 과도한 일반화일 수 있다. 세계 전체를 나타내는 타원형 형태의 정적 도법(예: 에케르트 IV 도법)에서는 경선이 곡선으로 표현되지만, 정적원통 도법(정축의 경우)에서는 경위선이 모두 직선으로 나타난다).\n그림 8.1과 다수의 다른 지도에서 실제 참조물 역할을 하는 것은 그래티큘이라기 보다는 주 경계, 국가 경계, 해안선, 강, 도로, 철도와 같은 지리적 요소들이다. 이러한 요소가 지도상에 적절히 배치된다면 그래티큘은 생략하는 편이 좋다. 그래티큘을 생략하면 일반 플롯의 중요 구성요소인 축, 눈금, 레이블도 사라지므로, 실질적인 지도 데이터로 채울 수 있는 플로팅 공간을 더 확보할 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#베이스-플롯",
    "href": "08.html#베이스-플롯",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.3 베이스 플롯",
    "text": "8.3 베이스 플롯\nsf 및 stars 객체에 적용되는 plot() 메서드는 유용한 데이터 탐색용 플롯을 빠르고 간편하게 만들어 준다. 더 높은 품질과 사용자 자율성을 원한다면 ggplot2(Wickham et al. 2022), tmap(Tennekes 2022, 2018), mapsf(Giraud 2022)와 같은 패키지를 활용하면 된다.\nplot() 메서드의 기본값은 주어진 ’모든 것’을 플로팅하는 것이다. 이는 다음을 의미한다.\n\n지오메트리만 주어지면(sfc), 컬러 없이 지오메트리만 플로팅된다.\n지오메트리와 속성이 함께 주어지면, 속성 값에 따라 지오메트리에 컬러가 부여된다. factor나 logical 속성에는 질적 컬러 스킴, 그 외에는 연속형 컬러 스킴이 적용되며 컬러 범례가 추가된다.\n여러 속성이 주어지면 여러 지도가 플로팅된다. 색상 할당은 각 하위 지도별로 이루어지므로 지도마다 다른 컬러 스킴이 적용된다. 기본값으로 범례는 생략된다.\n여러 속성을 가진 stars 객체의 경우 첫 번째 속성만 플로팅되며, 3차원 래스터 큐브의 경우 세 디멘션을 따라 생성되는 모든 슬라이스가 하위 플롯으로 플로팅된다.\n\n\n8.3.1 플롯에 범례 첨가하기\nstars 및 sf 객체의 plot() 메서드는 플롯 영역 한쪽에 컬러 범례를 표시할 수 있다(그림 1.1). 이를 위해 base::plot() 함수는 플롯 영역을 두 부분으로 나누어 두 개의 플롯을 생성한다. 하나는 지도, 다른 하나는 범례다. plot() 함수는 기본값으로 그래픽 장치를 초기화하며(예: layout(matrix(1)) 이는 이후 플롯이 이전의 영역 분할 영향을 받지 않도록 하기 위한 설정이다. 그러나 이 때문에 이미 만들어진 플롯에 그래픽 요소를 추가할 수 없게 된다. 컬러 범례가 있는 기존 플롯에 요소를 첨가하려면, 먼저 plot() 명령에서 reset = FALSE로 장치 초기화를 막고, 이어지는 호출에서는 add = TRUE를 사용한다. 예시는 그림 8.3에 제시되어 있다.\n\nlibrary(sf)\nnc &lt;- read_sf(system.file(\"gpkg/nc.gpkg\", package = \"sf\"))\nplot(nc[\"BIR74\"], reset = FALSE, key.pos = 4)\nplot(st_buffer(nc[1,1], units::set_units(10, km)), col = 'NA', \n     border = 'red', lwd = 2, add = TRUE)\n\n\n\n\n\n\n그림 8.3: 범례가 있는 베이스 플롯에 주석 달기\n\n\n단일 stars 레이어가 표시되는 경우, 주석 추가는 같은 방식으로 수행된다. 여러 슬라이스를 가진 래스터 큐브의 stars 패싯 플롯에 주석을 더하려면, ‘후크(hook)’ 함수를 정의해 각 슬라이스마다 개별적으로 호출되도록 하면 된다.(역자주: ’후크 함수’는 stars의 plot()이 패싯의 각 슬라이스를 그린 직후 실행되는 사용자 정의 콜백이다. 이 함수 안에서 text(), points(), segments(), box() 같은 베이스 그래픽스를 호출해 레이블, 스케일바, 북침, 보조선 등을 패널마다 자동으로 추가할 수 있다.) 이는 다음과 같이 수행할 수 있으며, 결과는 그림 8.4에 제시되어 있다. 후크 함수는 패싯 파라미터, 패싯 레이블, 바운딩 박스에 접근할 수 있다.\n\nlibrary(stars)\n# Loading required package: abind\nsystem.file(\"tif/L7_ETMs.tif\", package = \"stars\") |&gt;\n    read_stars() -&gt; r\nst_bbox(r) |&gt; st_as_sfc() |&gt; st_sample(5) |&gt; \n    st_buffer(300) -&gt; circ\nhook &lt;- function() { \n    plot(circ, col = NA, border = 'yellow', add = TRUE)\n}\nplot(r, hook = hook, key.pos = 4)\n# downsample set to 1\n\n\n\n\n\n\n그림 8.4: 다중 슬라이스를 가진 stars 플롯에 주석 달기\n\n\n베이스 plot() 메서드는 그래픽 장치의 해상도에 접근한다. 따라서 stars 및 stars_proxy 객체의 고밀도 래스터는 사용 중인 장치에 맞는 해상도로 다운샘플링되어, 해당 밀도로만 픽셀이 플로팅된다.\n\n8.3.2 베이스 플롯의 투영법\n베이스 plot() 메서드는 타원체 좌표를 가진 데이터를 등장방형 도법으로 플로팅하며(그림 8.2), 표준 위선 파라미터의 기본값으로 바운딩 박스의 중간 위도를 사용한다. 이 값을 제어하려면 플로팅 전에 다른 파라미터를 가진 등장방형 도법을 적용하거나 asp 파라미터를 직접 설정해 기본 동작을 해제하면 된다(예: asp = 1은 플라트 카레 도법의 지도를 생성한다(그림 8.1 왼쪽)). 기존 플롯 위에 후속 플롯을 중첩하려면, 후속 플롯에도 동일한 CRS가 적용되어야 한다. 베이스 plot 메서드는 CRS 일치 여부를 검사하지 않는다.\n\n8.3.3 컬러와 컬러 단절값\n베이스 plot에서는 nbreaks 인수로 컬러 단절값의 개수를 설정하고, breaks 인수로 제 컬러 단절값을 담은 숫자 벡터를 지정하거나, classInt::classIntervals() 함수의 style 인수에 전달할 스타일 문자열을 지정할 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#ggplot2-패키지를-활용한-지도-제작",
    "href": "08.html#ggplot2-패키지를-활용한-지도-제작",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.4 ggplot2 패키지를 활용한 지도 제작",
    "text": "8.4 ggplot2 패키지를 활용한 지도 제작\nggplot2 패키지(Wickham et al. 2022; Wickham 2016)는 더 복잡하면서도 보기 좋은 그래프를 만들 수 있게 해준다. 이 패키지에는 sf 패키지의 발전과 함께 도입된 geom_sf 레이어가 있어, 아름다운 지도를 만드는 데 도움을 준다. 이에 대한 소개는 Moreno와 Basille(2018)에서 찾을 수 있다. 첫 번째 예시는 그림 1.2에 나와 있으며, 이 플롯에 사용된 코드는 다음과 같다.\n\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nnc.32119 &lt;- st_transform(nc, 32119) \nyear_labels &lt;- \n    c(\"SID74\" = \"1974 - 1978\", \"SID79\" = \"1979 - 1984\")\nnc.32119 |&gt; select(SID74, SID79) |&gt; \n    pivot_longer(starts_with(\"SID\")) -&gt; nc_longer\n\n\nggplot() + geom_sf(data = nc_longer, aes(fill = value), linewidth = 0.4) + \n  facet_wrap(~ name, ncol = 1, \n             labeller = labeller(name = year_labels)) +\n  scale_y_continuous(breaks = 34:36) +\n  scale_fill_gradientn(colours = sf.colors(20)) +\n  theme(panel.grid.major = element_line(colour = \"white\"))\n\n코드를 살펴보면, 패싯 형태의 플롯팅을 위해 사전에 두 개의 속성을 pivot_longer() 함수로 스택(길게 피벗)했다는 것을 알 수 있다. 이것이 ‘타이디’ 데이터의 핵심 개념이며, sf 객체에 대한 pivot_longer() 함수는 지오메트리 열도 함께 스택한다.\nggplot2 패키지는 그래픽 객체를 먼저 생성한 뒤 플롯팅하므로, 모든 요소의 CRS를 제어할 수 있으며 이후 추가되는 객체는 첫 번째 레이어의 CRS로 자동 변환된다. 또한 회색 배경의 얇은 흰색 선(기본값)으로 그래피큘을 표시하며, 특정 데이텀(기본값은 WGS84)을 사용한다. geom_sf()는 다른 geom과 결합할 수 있어, 주석 추가 등 다양한 작업을 수행할 수 있다.\nstars 패키지의 경우, geom_stars가 존재하지만, 집필 시점 기준으로 활용성이 다소 제한적이다. 지도 레이아웃과 벡터 데이터 큐브는 geom_sf를 사용하고, 규칙 래스터는 geom_raster, 직교형 래스터는geom_rect를 추가로 사용한다. 사용자가 다운샘플링 비율을 지정하면 다운샘플링을 수행하지만, 화면 크기에 접근해 자동으로 비율을 선택하는 기능은 없다. 이 정도 기능만으로도 충분한 경우가 많으며, 예를 들어 그림 8.5는 다음 명령으로 생성되었다.\n\nlibrary(ggplot2)\nlibrary(stars)\nr &lt;- read_stars(system.file(\"tif/L7_ETMs.tif\", package = \"stars\"))\nggplot() + geom_stars(data = r) +\n        facet_wrap(~band) + coord_equal() +\n        theme_void() +\n        scale_x_discrete(expand = c(0,0)) + \n        scale_y_discrete(expand = c(0,0)) +\n        scale_fill_viridis_c()\n\n\n\n\n\n\n그림 8.5: ggplot2와 geom_stars로 제작된 패싯 래스터 플롯\n\n\n더 정교한 ggplot2 패키지 기반의 stars 객체 플롯은 ggspatial 패키지(Dunnington, 2022)를 사용해 제작할 수 있다. 더 고품질의 지도를 만들기 위한 옵션으로 tmap 패키지가 있으며, ggplot2와 직접 호환되지는 않지만 형식적으로 유사한 스타일의 지도를 생성할 수 있다(8.5절).\n서로 다른 CRS를 가진 여러 피처 레이어들을 geom_sf로 함께 그리면, 모든 레이어가 첫 번째 레이어의 CRS로 변환된다. ‘기준’ CRS를 더 세밀하게 제어하려면 coord_sf를 사용하면 된다. 이렇게 하면, 예를 들어 투영 좌표계에서 작업하면서도 sf 객체가 아닌 일반 data.frame으로 주어진 그래픽 요소(예: WGS84에 기반한 타원체 경위도 좌표)를 함께 결합해 표현할 수 있다.",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#tmap-패키지를-활용한-지도-제작",
    "href": "08.html#tmap-패키지를-활용한-지도-제작",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.5 tmap 패키지를 활용한 지도 제작",
    "text": "8.5 tmap 패키지를 활용한 지도 제작\ntmap 패키지(Tennekes, 2022, 2018)는 R에서 공간데이터를 플로팅하는 참선한 접근을 제시한다. 이 패키지는 grid 패키지를 기반으로 그래픽 객체를 먼저 구성한 뒤 출력하며, 지도 요소를 + 기호로 연결하는 문법은 ggplot2 패키지와 유사하지만, 그 외에는 ggplot2 패키지와 완전히 독립적이고 상호 호환되지 않는다. 또한 고품질의 전문 지도를 만들 수 있는 다양한 옵션을 제공하며, 여러 기본값도 신중하게 설계되어 있다. 유사한 두 속성의 지도를 한번에 생성하려면 tm_polygons() 함수에 두 변수를 동시에 지정하면 된다.(역자주: ggplot2 패키지로 지도를 제작하는 접근은 ’지도도 그래프다’라는 관점에 서 있다. tmap 패키지로 지도를 제작하는 접근은 ’지도는 지도다’라는 관점에 서 있다. tmap 패키지는 현존하는 여러 언어의 지도 제작 도구 가운데 지도학적 원칙을 가장 충실히 반영한 도구로 평가되며, 이는 R을 선택할 강력한 이유가 된다. 최근 tmap 4.0이 도입되면서 문법이 한층 정교해지고 기능이 보완되었다. 아래의 예시 지도들도 4.0 버전으로 제작된 것이다. 자세한 내용은 https://r-tmap.github.io/tmap/를 참조하라.)\n\nlibrary(tmap)\nsystem.file(\"gpkg/nc.gpkg\", package = \"sf\") |&gt;\n    read_sf() |&gt; st_transform('EPSG:32119') -&gt; nc.32119\ntm_shape(nc.32119) + \n    tm_polygons(c(\"SID74\", \"SID79\"), title = \"SIDS\") +\n    tm_layout(legend.outside = TRUE, \n              panel.labels = c(\"1974-78\", \"1979-84\")) +\n    tm_facets(free.scales=FALSE)\n\n\n\n\n\n\n그림 8.6: tmap: tm_polygons() 함수에 두 개의 속성을 동시에 지정하여 플로팅하기\n\n\n또는 pivot_longer() 함수로 얻은 긴 테이블 형식 데이터에 tm_polygons(\"SID\") 와 tm_facets(by = \"name\")를 조합해도 동일한 지도를 생성할 수 있다.\ntmap 패키지는 stars 객체도 지원하며, 예시는 그림 8.7에 제시되어 있다. tmap 패키지를 활용한 추가 사례 지도는 14~16장에 제시되어 있다.\n\ntm_shape(r) + tm_raster()\n\n\n\n\n\n\n그림 8.7: tmap 패키지를 활용해 제작한 래스터 플롯",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#인터랙티브-지도-leaflet-mapview-tmap-패키지",
    "href": "08.html#인터랙티브-지도-leaflet-mapview-tmap-패키지",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.6 인터랙티브 지도: leaflet, mapview, tmap 패키지",
    "text": "8.6 인터랙티브 지도: leaflet, mapview, tmap 패키지\n그림 1.3과 같은 인터랙티브 지도는 R의 leaflet, mapview, tmap 패키지를 사용해 생성할 수 있다. mapview 패키지는 leaflet 패키지의 기본 기능을 확장하여 지도 범례, 피처 클릭 팝업의 세부 조정, 래스터 데이터 지원, FlatGeobuf 형식의 대규모 피처 세트를 위한 스케일러블 지도, 줌과 팬 동기화에 반응하는 패싯 지도를 제공한다. tmap 패키지는 두 가지 모드를 지원하여 다음과 같이 'view'를 지정하면, 모든 tmap 명령이 상호작용형 html/leaflet 위젯에 적용된다.\n\ntmap_mode(\"view\")\n\n반면 'plot'을 지정하면, 모든 결과물은 다시 R의 정적 그래픽 장치로 출력된다.\n\ntmap_mode(\"plot\")",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "08.html#연습문제",
    "href": "08.html#연습문제",
    "title": "8  공간데이터의 플로팅",
    "section": "\n8.7 연습문제",
    "text": "8.7 연습문제\n\n인도네시아와 캐나다에 대해 등장방형 도법, 정사 도법, 그리고 람베르트 정적원추 도법을 적용한 지도 플롯을 생성하시오. 각 투영법에 대해 해당 국가에 적절한 투영 파라미터를 선택하시오.\n그림 8.3의 플롯을 ggplot2 패키지와 tmap 패키지를 각각 사용하여 재생성하시오.\n그림 8.7의 플롯을 viridis 색상 팔렡트로 재생성하시오.\ntmap의 인터랙티브 모드('view' 모드)를 사용하여 그림 8.7을 다시 플로팅하고, 가능한 상호작용을 탐색하시오. 또한 + tm_facets(as.layers = TRUE)를 추가한 후 레이어의 켜기/끄기를 시험하고, 투명도를 0.5로 설정하시오.\n\n\n\n\n그림 8.1: 국가 경계: 왼쪽은 경위도를 x, y 좌표로 선형변환한 플라트 카레(Plate Carrée) 도법이며, 오른쪽은 무한히 먼 거리에서 지구를 바라본 것 처럼 표현한 정사 도법이다.\n그림 8.2: 등장방형 도법이 적용된 독일. 왼쪽 지도의 단위는 도이고 정거원통 도법이 적용된 오른쪽 지도의 단위는 미터이다.\n그림 8.3: 범례가 있는 베이스 플롯에 주석 달기\n그림 8.4: 다중 슬라이스를 가진 stars 플롯에 주석 달기\n그림 8.5: ggplot2와 geom_stars로 제작된 패싯 래스터 플롯\n그림 8.6: tmap: tm_polygons() 함수에 두 개의 속성을 동시에 지정하여 플로팅하기\n그림 8.7: tmap 패키지를 활용해 제작한 래스터 플롯",
    "crumbs": [
      "공간데이터사이언스와 R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>공간데이터의 플로팅</span>"
    ]
  },
  {
    "objectID": "02.html",
    "href": "02.html",
    "title": "2  좌표계",
    "section": "",
    "text": "2.1 물리량, 단위, 데이텀\nVIM(‘International Vocabulary of Metrology(국제 측정학 어휘)’, BIPM et al. 2012)에 따르면 물리량(quantity)은 “현상, 물체, 또는 물질의 성질 중, 그 성질이 수치와 기준에 의거해 표현될 수 있는 크기(magnitude)를 가진 것”으로 정의된다.(역자주: 물리량은 단순한 수량이 아니라 측정 가능한 속성을 의미한다.) 여기서 “기준은 측정 단위, 측정 절차, 기준 물질 또는 이러한 것들의 조합일 수 있다.”라고 기술한다. 모든 데이터가 물리량으로 구성되어 있는지에 대해서는 논란의 여지가 있을 수 있지만, 적절한 데이터 처리를 위해서는 수치(또는 기호)가 무엇을 의미하는지, 특히 수치가 어떤 기준에 근거하고 있는지에 대한 정보가 반드시 필요하다는 점에 대해서는 논란의 여지가 없다.\n측정 시스템은 기본 물리량에 대한 기본단위와, 기본 단위를 조합하여 정의한 파생단위로 구성된다. 예를 들어, SI 단위계(Bureau International des Poids et Mesures 2006)는 다음 일곱 가지 기본 단위로 이루어져 있다. 길이(미터, m), 질량(킬로그램, kg), 시간(초, s), 전류(암페어, A), 열역학적 온도(켈빈, K), 물질의 양(몰, mol), 그리고 광도(칸델라, cd)이다. 파생단위는 기본단위의 정수 거듭제곱의 곱으로 정의되며, 속도(\\(\\text{m s}^{-1}\\))나 밀도(\\(\\text{kg m}^{-3}\\)), 면적(\\(\\text{m}^{2}\\)) 등이 이에 해당한다.\n이 일곱 가지 SI 기본단위로 표현되지 않는 것을 무단위(unitless) 측정치라 한다. 무단위 측정치는 크게 두 가지로 구분할 수 있다. 첫째, 단위가 상쇄되는 경우로, 질량 분율(kg/kg)이나 각도(rad = m/m)가 여기에 속한다. 둘째, 계수 단위를 사용하는 경우로, 예를 들어 ‘사과 5개’와 같이 사물이나 사건을 단순히 세는 경우이다. 이 두 경우는 모두 수학적으로는 무차원으로 취급되지만, 의미적으로는 서로 구별된다. 예컨대 각도와 사과 개수를 더하는 것은 전혀 의미가 없지만, 사과 5개와 오렌지 3개는 과일 개수라는 상위 범주(superclass)로 묶어 해석하면 더할 수 있다.(역자주: ‘개’, ‘명’, ’마리’와 같이 사물이나 사건을 셀 때 사용하는 단위를 계수 단위(counting unit)라고 한다. 이러한 계수 단위는 일상적으로는 단위처럼 인식되지만, SI 에서는 차원이 없는 무차원 단위로 취급된다. 예컨대 ’과일 개수’와 같은 계수 단위는 SI 단위에는 속하지 않지만, 서로 다른 객체(사과와 오렌지 등)를 공통의 범주 아래에서 합산할 수 있도록 하는 연산적 틀을 제공한다.) 많은 데이터 변수는 이처럼 SI 기본단위나 유도단위로 환원할 수 없는 단위를 갖는다. Hand(2004)는 사회과학에서 지능과 같은 변수를 측정하는 척도를 포함하여, 이러한 다양한 측정 척도를 단위 개념의 맥락에서 논의하고 있다.\n많은 물리량의 자연스러운 원점은 0이다. 이는 양의 차이를 계산했을 때 음수 값도 의미를 갖는다는 점에서 알 수 있다. 위치나 시간의 경우에도 차이는 자연스럽게 0을 기준으로 해석된다. 다시 말해, 거리는 위치의 차이를, 지속 시간은 시간의 차이를 의미한다. 절대적 위치(좌표)와 절대적 시간은 다른 절대적 시공간 점들을 의미 있게 측정하기 위해 고정된 원점을 필요로 하며, 이를 데이텀(datum)이라 부른다. 공간에서의 데이텀은 하나 이상의 차원을 포함한다. 데이텀에 측정 단위(스케일)가 결합되면 이를 참조계(reference system)라고 한다.\n이후에서는 공간적 위치를 타원체 좌표 또는 데카르트 좌표로 표현하는 방법을 자세히 살펴본다. 다음 절에서는 시간 및 공간 참조계와, R에서 이러한 참조계를 다루는 방법을 설명한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#타원체-좌표계",
    "href": "02.html#타원체-좌표계",
    "title": "2  좌표계",
    "section": "\n2.2 타원체 좌표계",
    "text": "2.2 타원체 좌표계\n\n\n\n\n\n그림 2.1: 2차원 극 좌표와 데카르트 좌표\n\n\n그림 2.1은 2차원 극 좌표(polar coordinate)와 데카르트 좌표(Cartesian coordinate)를 보여준다. 해당 지점의 데카르트 좌표는 \\((x,y)=(3,4)\\)로 주어지고, 극 좌표는 \\((r,\\phi)=(5,\\text{arctan(4/3)})\\)로 주어지는데 \\(\\text{arctan(4/3)}\\)는 대략 \\(0.93\\) 라디안 혹은 \\(53^\\circ\\)이다. 여기서 \\(x\\), \\(y\\), \\(r\\)은 모두 길이 단위이고 \\(\\phi\\)는 각도 단위(무단위 길이/길이 비)라는 점에 유의할 필요가 있다. 데카르트 좌표와 극 좌표 간의 변환은 매우 간단하다.\n\\[\nx=r\\cos\\phi,\\quad y=r\\sin\\phi, \\text{ and}\n\\]\n\\[\nr=\\sqrt{x^2+y^2}, \\quad \\phi=\\text{atan2}(y,x)\n\\]\n여기서 \\(\\text{atan2}\\)이 \\(\\text{atan}(y/x)\\)대신 사용되었는데, 오른쪽 일사분면에 위치가 있기 때문이다.\n\n2.2.1 구체 혹은 타원체 좌표\n3차원의 경우, 데카르트 좌표는 \\((x,y,z)\\)로 주어지고, 극 좌표는 \\((r,\\lambda,\\phi)\\)로 주어진다.\n\n\\(r\\)은 구체의 반지름이다.\n\\(\\lambda\\)는 경도로, \\((x,y)\\) 평면에서 양의 \\(x\\)축으로부터 반시계방향으로 측정된다.\n\\(\\phi\\)는 위도로, \\((x,y)\\) 평면과 해당 벡터가 이루는 각도이다.\n\n그림 2.2는 데카르트 지심 좌표(Cartesian geocentric coordinate)와 타원체 좌표(ellipsoidal coordinate)를 보여준다.\n\n\n\n\n\n그림 2.2: 세 개의 거리로 표현되는 데카르트 지심 좌표(왼편)와 두 개의 각도와 하나의 타원체고로 표현되는 타원체 좌표(오른편)\n\n\n\\(\\lambda\\)는 \\(-180^\\circ\\)에서 \\(180^\\circ\\) 사이(혹은 \\(0^\\circ\\)에서 \\(360^\\circ\\) 사이)의 값을 가지며, \\(\\phi\\)는 \\(-90^\\circ\\)에서 \\(90^\\circ\\) 사이의 값을 갖는다. 타원체가 아니라 반지름이 고정된 구체(혹은 구체 상의 위치)를 전제로 한다면, 위의 \\(r\\) 값을 생략한 \\((\\lambda,\\phi)\\) 만으로도 모든 위치를 고정할 수 있다.\n이 정의가 유일한 것은 아니라는 점에 유의해야 한다. 예를 들어, 위도 대신 해당 벡터와 \\(z\\)축 사이의 각도(극각)을 사용할 수도 있다. 또한, 좌표를 \\((\\phi,\\lambda)\\) 순서로 표기하는 오랜 전통도 존재하지만, 이 책에서는 경도-위도 형식인 (\\(\\lambda,\\phi\\))를 사용한다. 그림 2.2에 표시된 지점은 \\((\\lambda,\\phi)\\) 형식으로 표현되는, 각도 단위의 타원체 좌표를 가진다.\n# POINT (60 47)\n지심 좌표값은 미터 단위로 주어진다.\n# POINT Z (2178844 3773868 4641765)\n타원체 상의 지점에 대해서는 각도를 나타내는 두 가지 방법이 있다(그림 2.3). 하나는 타원체의 중심을 기준으로 측정된 각도(\\(\\psi\\)), 또는 해당 지점을 지나는 접선에 수직으로 측정된 각도(\\(\\phi\\))이다.\n\n\n\n\n\n그림 2.3: 타원체 상의 각도: 측지 위도(파란색)와 지심 위도(붉은색)\n\n\n지구를 표현하는 데 가장 널리 사용되는 파라메트릭 모형은 회전타원체(ellipsoid of revolution)이다. 회전타원체는 길이가 서로 다른 반장축과 반단축을 가진 타원체로, 한쪽 방향이 약간 납작해진 구(또는 구체, spheroid)라고 할 수 있다(Iliffe and Lott 2008). 실제로, 지구의 남북 길이는 동서 길이보다 약간(약 0.33%) 짧다. 이 모형에서 경도는 항상 원을 따라 측정되고(그림 2.2), 위도는 타원을 따라 측정된다(그림 2.3). 그림 2.3을 양 극을 지나는 지구의 단면도로 본다면, 별도의 언급이 없는 경우 위도는 파란선으로 표시된 측지 위도(geodetic latitude)를 의미한다. 이에 대응하여 지심 위도(geocentric latitude)라는 개념도 존재한다.(역자주: 측지 위도는 적도면과, 특정 지점에서 회전타원체에 접하는 평면의 법선이 이루는 각도를 의미한다. 반면 지심 위도는 적도면과, 특정 지점과 지구 중심을 잇는 직선이 이루는 각도를 의미한다. 완전한 구를 가정하면 두 위도는 일치한다. 측지 위도의 경우 위도 1도의 남북 길이는 고위도로 갈수록 길어지지만, 지심 위도에서는 일정하게 나타난다.)\n경도와 위도에 고도(altitude)나 높이(elevation)를 더하면, 회전타원체의 위나 아래에 있는 지점의 위치까지 정의할 수 있으며, 이를 통해 완전한 3차원 위치 참조계를 구성할 수 있다. 고도를 정의할 때는 다음을 선택해야 한다.\n\n고도 0의 기준을 어디에 둘 것인가: 회전타원체 상에 둘 것인가, 아니면 평균 해수면을 근사한 지오이드(geoid) 표면을 기준으로 할 것인가?\n양(+)의 방향을 어디로 할 것인가?\n‘위쪽’ 방향을 어떻게 정의할 것인가: 회전타원체 표면에 수직인 방향으로 할 것인가, 아니면 지오이드 표면에 수직인, 중력의 방향으로 할 것인가?\n\n응용 분야와 요구되는 측정 정밀도에 따라 이러한 선택들이 중요해질 수 있다.\n지구는 완전한 회전타원체가 아니기 때문에, 다양한 회전타원체가 제안되어 사용되고 있다. 이들 회전타원체는 반장축과 반단축의 길이와 같은 파라미터 값이 서로 다를 수 있고, 지구에 정합시키는 방식 또한 다를 수 있다. 이처럼 특정한 방식으로 규정된 회전타원체를 데이텀(datum)이라 하며, 좌표참조계(coordinate reference system)와 함께 2.3절에서 간략히 다룬다.\n\n2.2.2 투영 좌표계와 거리\n투영 좌표계(projected coordinate system)는 지구 표면의 위치를 2차원 평면 위에서 표현하는 좌표계이다. 종이 지도와 컴퓨터 화면이 지구본보다 훨씬 더 실용적이고 널리 사용되기 때문에, 우리는 공간데이터를 대개 이러한 2차원 평면에 투영된 형태로 보게 된다. 이차원 공간에서 위치를 계산한다는 것은 곧 투영 좌표를 사용한다는 뜻이다. 타원체 좌표를 평면으로 투영하면 형태, 방향, 면적 중 하나 이상이 반드시 왜곡된다(Iliffe and Lott 2008).\n데카르트 좌표에서 두 지점 \\(p_i\\)와 \\(p_j\\) 간의 거리는 유클리드 거리로 계산되며, 2차원의 경우 \\(p_i=(x_i,y_i)\\)이므로 다음의 수식으로 주어진다.\n\\[\nd_{ij}=\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}\n\\]\n3차원의 경우는 \\(p_i=(x_i,y_i,z_i)\\)이므로, 다음의 수식으로 주어진다.\n\\[\nd_{ij}=\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2}\n\\]\n이 거리는 지점 \\(i\\)와 지점 \\(j\\) 사이의 직선거리를 뜻한다. 즉, 두 지점을 직선으로 연결했을 때 그 선분의 길이를 의미한다.\n반지름이 \\(r\\)인 원 위에서, 두 지점 \\(c_1=(r,\\phi_1)\\)와 \\(c_2=(r,\\phi_2)\\) 사이의 호 길이는 다음과 같이 주어진다. \\[\ns_{ij}=r|\\phi_1-\\phi_2|=r\\theta\n\\]\n여기서 \\(\\theta\\)는 \\(\\phi_1\\)과 \\(\\phi_2\\) 사이의 각도를 라디안 단위로 나타낸다. \\(\\theta\\)가 매우 작을 경우, 호가 직선에 가까워지므로 \\(s_{ij}\\approx d_{ij}\\)가 성립한다.\n반지름이 \\(r'\\)인 구체 위의 두 지점 \\(p_1=(\\lambda_1,\\phi_1)\\)과 \\(p_2=(\\lambda_2,\\phi_2)\\)를 지나는 원(중심은 구체의 중심과 일치)에서, 두 지점 사이의 호의 길이를 대권거리(great circle distance)라 하며, 이는 \\(s_{12}=r\\theta_{12}\\)로 표현된다. 따라서 \\(p_1\\)과 \\(p_2\\) 사이의 각도 \\(\\theta_{12}\\)(라디안 단위)는 다음과 같이 주어진다.\n\\[\n\\theta_{12}=\\arccos(\\sin\\phi_1\\cdot \\sin\\phi_2+\\cos\\phi_1\\cdot \\cos\\phi_2\\cdot\\cos(|\\lambda_1-\\lambda_2|))\n\\]\n타원체 위의 두 지점 사이의 호의 길이를 계산하는 일은 훨씬 더 복잡하다. Karney(2013)은 이에 대해 심도 있는 논의를 제시하였으며, PROJ 라이브러리의 일부인 GeographicLib에서 구현된 방법에 대한 상세한 설명도 제공한다.\n이러한 거리 계산 방법들이 실제로 서로 다른 값을 산출한다는 점을 보이기 위해, 우리는 베를린과 파리 사이의 거리를 계산하였다. WGS84 타원체와 완전 구체 각각에 대해 거리를 구했으며, 여기서 gc_는 대권거리를, str_은 지심 좌표값을 이용한 직선거리를 나타낸다.\n# Units: [km]\n#  gc_ellipse str_ellipse   gc_sphere  str_sphere \n#      879.70      879.00      877.46      876.77\n\n2.2.3 한정 공간과 비한정 공간\n2차원 및 3차원 유클리드 공간(\\(R^2\\)와 \\(R^3\\))은 비한정 공간(unbounded space)이다. 이 공간의 모든 선은 무한한 길이를 가지며, 면적이나 부피는 자연적인 상한이 없다. 이에 비해 원(\\(S^1\\))이나 구(\\(S^2\\))와 같은 공간은 한정 공간(bounded space)이다. 이 경우 점의 개수는 무한할 수 있지만, 원의 둘레와 면적, 구의 반지름과 표면적, 부피는 유한하다.\n이 차이는 사소해 보일 수 있으나, 공간데이터 처리에서는 흥미로운 도전 과제를 유발한다. 예를 들어, \\(R^2\\) 상의 폴리곤은 명확히 내부와 외부가 구분된다. 그러나 \\(S^2\\) 공간인 구체 상에서 모든 폴리곤은 구를 두 영역으로 나누며, 어느 쪽을 내부로, 어느 쪽을 외부로 정의할지는 탐색 방향(traversal direction)에 따라 달라진다. 이러한 \\(S^2\\) 지오메트리에서의 차이는 4장에서 다시 논의한다.(역자주: 탐색 방향이란 폴리곤 경계를 따라가는 방향을 의미한다. 일반적으로 평면(\\(R^2\\))에서는 경계를 시계 방향으로 탐색하면 왼쪽에 있는 영역이 내부로, 반시계 방향으로 탐색하면 오른쪽에 있는 영역이 내부로 간주된다. 그러나 구현 방식이나 좌표계 종류(예: 구면 좌표계)에 따라 내부와 외부의 정의가 달라질 수 있으므로, 적용 환경에 맞는 판정 규칙을 확인해야 한다.)",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#crs",
    "href": "02.html#crs",
    "title": "2  좌표계",
    "section": "\n2.3 CRS",
    "text": "2.3 CRS\nLott(2015)를 따라, 다음과 같은 개념 정의를 사용한다(이탤릭체는 Lott의 정의를 그대로 옮겨 온 것이다)\n\n좌표계는 지점에 좌표를 부여하는 방법을 규정하는 수학적 규칙의 집합이다.\n데이텀은 좌표계의 원점, 축척, 방향을 정의하는 파라미터 또는 파라미터의 집합이다.\n측지 데이텀은 2차원 또는 3차원 좌표계와 지구와의 관계를 설명하는 데이텀이다.(역자주: 즉, 지구에 부여된 2차원 또는 3차원 좌표계를 정의하는 데이텀이다.)\nCRS(좌표참조계)는 특정 데이텀을 바탕으로 특정 객체에 부여된 좌표계이다. 측지 데이텀과 수직 데이텀의 경우, 그 객체는 지구이다.(역자 주: 측지 데이텀은 지구 표면상의 위치를 규정하는 수평 데이텀이며, 수직 데이텀은 말 그대로 지표의 높이를 규정하는 데이텀이다).\n\n이 개념에 대한 보다 상세하고 친절한 설명은 Iliffe와 Lott(2008)에서 찾아볼 수 있다.\n지구의 형태는 규칙적이지 않다. 지표면의 기복이 매우 불규칙하다는 사실은 널리 알려져 있지만, 평균해수면 개념과 연결되는 일정한 중력면, 즉 지오이드(geoid) 또한 불규칙한 형상을 띤다. 지오이드를 단순화한 모형 가운데 가장 일반적으로 사용되는 것은 회전타원체로, 이는 두 개의 동일한 반단축을 가진 타원이다. 이 회전타원체를 지구와 어떻게 맞출 것인지가 데이텀을 규정한다. 타원체를 지구의 어느 부분에 일치시킬지, 또는 어떤 기준점을 사용할지에 따라 타원체의 적합도는 달라질 수 있으며, 이러한 이유로 다양한 데이텀이 존재한다. 일부 데이텀은 특정 지각판에 대한 적합도를 중시하기도 하고(예: ETRS89), 다른 데이텀은 전 세계적인 평균 적합도를 지향하기도 한다(예: WGS84). 국지적 적합도에 중점을 둘수록 해당 지역에서의 위치 근사 오차는 작아진다.\n위의 정의에서 알 수 있듯이, 경도와 위도로 표현된 좌표값은 해당 데이텀이 함께 제공될 때에만 지구 좌표계로서 의미를 가지며, 이를 통해 해석상의 모호성을 제거할 수 있다.\n특정 투영법이 적용된 데이터는 반드시 해당하는 참조 타원체(데이텀)와 결부되어 있다는 점에 유의해야 한다. 데이텀 전환 없이 투영법만 변경하는 작업은 좌표 전환(coordinate conversion)이라고 하며, 이는 해당 데이텀에 결부된 특정 타원체상의 좌표값을 기준으로 수행된다. 좌표 전환 과정은 정보 손실이 없고 가역적이며, 전환에 사용되는 파라미터와 수식은 변하지 않는다.\n새로운 데이텀에 따라 좌표를 재계산하는 과정을 좌표 변환(coordinate transformation)이라 한다. 좌표 전환과 달리, 좌표 변환은 근사적으로 수행된다. 이는 데이텀이 지구에 대한 모형 적합의 결과물이므로, 데이텀 간 변환 또한 하나의 적합된 모형으로 간주되기 때문이다. 변환 함수 역시 경험적으로 도출되며, 적합도나 정확성의 설정에 따라 다양한 변환 경로가 존재할 수 있다.\n판 구조론은 글로벌 데이텀에서 고정된 객체의 위치가 시간이 흐름에 따라 변할 수 있음을 보여준다. 이는 데이텀 간 좌표 변환이 시간에 따라 달라질 수 있음을 시사한다. 예를 들어, 지진과 같은 지각 운동으로 인해 특정 지역의 좌표가 갑작스럽게 변동할 수 있다. 국지적 데이텀은 특정 지각판에 고정하여 정의할 수도 있지만(예: ETRS89), 이를 보다 역동적으로 설정하여 시간에 따른 위치 변화를 반영하도록 할 수도 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#proj와-지도-정확도",
    "href": "02.html#proj와-지도-정확도",
    "title": "2  좌표계",
    "section": "\n2.4 PROJ와 지도 정확도",
    "text": "2.4 PROJ와 지도 정확도\n오늘날 오픈소스 지리공간 소프트웨어 분야에서 활동하는 사람들 중에는 PROJ 이전의 시기를 기억하는 이가 거의 없다. PROJ(Evenden, 1990)는 1970년대에 포트란 기반 프로젝트로 시작되어, 1985년 지도 투영을 위한 C 라이브러리로 공개되었다. 이 라이브러리는 직접 투영과 역투영을 수행할 수 있는 명령줄 인터페이스를 제공했으며, 이를 다른 소프트웨어와 연동하여 투영 및 재투영 작업을 즉시 실행할 수 있었다. 당시에는 데이텀이 단순히 주어진 것으로 간주되었고, 데이텀 간 변환 기능은 지원되지 않았다.\n2000년대 초, PROJ는 PROJ.4라는 이름으로 불리게 되었는데, 이는 고정된 버전 번호가 접미사로 붙은 형태였다. GPS의 보급 확대를 비롯한 여러 요인으로 좌표계 간 변환 수요가 증가하자, PROJ.4는 기본적인 데이텀 지원 기능을 갖추게 되었다. 이후 PROJ는 CRS를 다음과 같은 형식으로 정의하게 된다.\n+proj=utm +zone=33 +datum=WGS84 +units=m +no_defs\n‘키=값’ 쌍은 + 기호로 시작하며, 공백으로 구분된다. 이러한 형식은 PROJ 프로젝트가 수십 년 동안 4.x 버전을 유지하면서, 일반적으로 ’PROJ.4 문자열’로 불리게 되었다. 아래는 그 몇 가지 예시이다.\n+ellps=bessel +towgs84=565.4,50.3,465.6,-0.399,0.344,-1.877,4.072\n이 문자열은 해당 데이텀이 Bessel 타원체를 사용하며, 이를 WGS84(주로 GPS의 기준으로 널리 사용됨)로 변환하기 위해 7개(또는 경우에 따라 3개)의 파라미터가 필요함을 잘 보여준다.\nPROJ.4 외에도 다양한 투영법 관련 데이터베이스가 구축되었는데, 그중 가장 널리 알려진 것이 EPSG(European Petroleum Survey Group) 레지스트리이다. 각국의 지도 제작 기관은 자국 CRS의 +towgs84 파라미터(즉, WGS84로 변환하기 위한 파라미터)에 대해 최적 추정값을 계산하고, 이를 지속적으로 갱신하여 EPSG 등록부를 통해 배포해 왔다. 일부 좌표 변환에는 데이텀 그리드(datum grid)가 함께 제공되었는데, 이는 PROJ.4의 일부로도 배포되었다. 데이텀 그리드는 결국 래스터 형식의 지도이며, 데이텀 변환 시 발생하는 경도, 위도, 고도 변화값을 모든 지점에 대해 미리 계산해 둔 데이터를 의미한다.\nPROJ.4에서는 모든 좌표 변환이 반드시 WGS84를 경유하여 수행되었다. 서로 다른 데이텀을 가진 데이터를 재투영할 때도, 중간 단계로 WGS84로 변환한 뒤 목표 좌표계로 변환해야 했다. 이로 인해 최대 약 100m의 오차가 발생할 수 있었는데, 이는 비교적 넓은 지역을 대상으로 하는 지도 제작에서는 수용 가능한 수준이었다. 그러나 정밀 농업, UAV(무인항공기) 운용 계획, 객체 추적 등 일부 응용 분야에서는 이보다 훨씬 높은 정밀도의 좌표 변환이 요구된다.\n2018년, ‘GDAL 좌표계 공동 개발(Coordinate System Unification)’ 이니셔티브가 성공적으로 추진된 이후, 오픈소스 지리공간 소프트웨어 스택의 혜택을 받아온 여러 기업들이 PROJ의 보다 현대적이고 고도화된 좌표 변환 시스템 개발을 지원하였다. 그 결과 PROJ.4는 5, 6, 7, 8, 9 버전을 거치며 지속적으로 발전했고, 명칭도 PROJ또는 PR\\(\\phi\\)J)로 변경되었다.\n가장 주목할 만한 변화는 다음과 같다.\n\nPROJ.4 문자열의 한계와 WKT-2 도입: PROJ.4 문자열은 여전히 새로운 CRS를 정의하는 데 사용할 수 있지만, 모든 CRS를 포괄하기에는 한계가 있음이 드러났다. 이를 대체하기 위해 WKT-2 형식이 도입되었으며, 이에 대해서는 다음 절에서 설명한다.\nWGS84dml ‘허브 데이텀’ 지위 폐지: 좌표 변환 시 WGS84와 같은 특정 데이텀을 중간 단계로 거칠 필요 없이, 직접 데이텀 간 변환이 가능해졌다.\n다중 변환 경로(파이프라인) 지원: 하나의 CRS(A)에서 다른 CRS(B)로 이동할 때 사용할 수 있는 다수의 변환 또는 전환 경로가 존재할 수 있으며, 각 경로에 대한 정확도 정보가 제공되면 등록할 수 있다. PROJ는 기본적으로 가장 정확한 경로를 자동 선택하지만, 사용자가 직접 선택할 수도 있다.\n변환 파이프라인 구성 가능: 변환 파이프라인은 축 교환, 단위 변환 등 여러 기본 변환 단계를 연결하여 구성될 수 있다.\n데이텀 그리드 배포 방식 변경: 데이텀 그리드는 더 이상 라이브러리에 포함되지 않으며, 대신 콘텐츠 전송 네트워크(CDN)를 통해 제공된다. PROJ는 네트워크 접근을 켜거나 끌 수 있는 옵션을 제공하며, 실제 필요한 그리드 구간만 다운로드해 로컬 캐시에 저장해 이후에도 사용할 수 있다.\n에포크(epoch) 기반 좌표 변환 지원: 시간-의존적 좌표 변환이 가능해져, 소스와 타깃 시간 정보를 포함하는 4차원 좌표계 간 변환이 지원된다.(역자주: 지구의 좌표계는 시간이 지남에 따라 점진적으로 변화해 왔으며, 특정 시점(에포크)에 기반한 위치 정의가 가능해졌다는 의미다.)\n축 순서 사용자 정의 가능: 예를 들어 위도–경도(Lat–Lon) 또는 경도–위도(Lon–Lat)와 같은 축 순서를 자유롭게 변경할 수 있다.\n\n이러한 개선을 통해 좌표 변환의 정확도는 이제 1미터 이하 수준까지 향상될 수 있다. 특히 주목할 만한 변화는 마지막 항목에 있다. 수십 년 동안 경도–위도 순서를 따르는 타원체 좌표의 축 순서는 자명한 것으로 여겨져 왔으나, 이제 더 이상 그렇지 않다. 섹션 7.7.6에서는 이러한 변화에 어떻게 대응할 수 있는지를 살펴본다.\n\n\n\n\n\n그림 2.4: 영국의 OSGB 1936(EPSG:4277)를 ETRS89(EPSG:4258)로 변환하는데 사용되는 수평 데이텀 그리드\n\n\n\n\n\n\n\n그림 2.5: 영국의 ETRS89(EPSG:4937)를 ODN 고도(EPSG:5701)로 변환하는데 사용되는 수직 데이텀 그리드\n\n\n그림 2.4의 수평 데이텀 그리드 예시와 그림 2.5의 수직 데이텀 그리드 예시는 cdn.proj.org에서 다운로드한 것이다. 경우에 따라 데이텀 그리드에는 픽셀 단위의 정밀도 값이 포함되기도 한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#wkt-2",
    "href": "02.html#wkt-2",
    "title": "2  좌표계",
    "section": "\n2.5 WKT-2",
    "text": "2.5 WKT-2\nLott(2015)는 CRS의 인코딩 방식과 CRS 간 변환을 WKT(well-known text)로 표현하는 표준을 정리하였다. 이 표준(및 포맷)은 비공식적으로 WKT-2라고 불린다. 앞서 언급했듯이, GDAL과 PROJ는 이 표준을 지원한다. 예를 들어, 특정 CRS인 EPSG:4326은 WKT-2 형식으로 다음과 같이 표현된다.\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n이 예시는 축 순서가 위도–경도로 설정된 좌표계를 보여준다. 그러나 실제로 사용되는 대부분의 좌표계는 경도–위도 순서를 따른다. WGS84 타원체에 대한 앙상블(ensemble)은 다양한 버전과 업데이트를 포함하고 있으며, 어떤 앙상블을 사용하는지에 따라 수 미터 수준의 오차가 발생할 수 있다. OGC:CRS84는 longitude–altitude 순서를 명시적으로 정의하고 있어 GRS84의 대안으로 권장되지만, 데이텀 앙상블 문제까지 해결해 주지는 않는다.\nPROJ의 역사와 최근 변화는 Knudsen과 Evers(2017), Evers와 Knudsen(2017)의 연구를 바탕으로 정리한 Bivand(2020)에 잘 요약되어 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "02.html#연습문제",
    "href": "02.html#연습문제",
    "title": "2  좌표계",
    "section": "\n2.6 연습문제",
    "text": "2.6 연습문제\nR을 활용하여 아래의 연습문제를 풀되, 패키지는 사용하지 않는다. 적절한 기본 함수를 찾아 활용하도록 한다.\n\n자연 원점(0)을 갖지 않는 지리적 측도 세가지를 나열하시오.\n다음의 \\((x,y)\\) 좌표, \\((10,2)\\), \\((-10,-2)\\), \\((10,-2)\\), \\((0,10)\\)을 극 좌표로 변환하시오.\n다음의 \\((r,\\phi)\\) 좌표, \\((10,45^\\circ)\\), \\((0,100^\\circ)\\), \\((5,359^\\circ)\\)를 데카르트 좌표로 변환하시오.\n지구를 반지름이 6,371 km인 완전한 구체로 가정하고, 다음 네 쌍의 (\\(\\lambda, \\phi\\)) 지점 간의 대권거리를 각도 단위로 계산하시오. 각 쌍의 위도와 경도는 각도 단위로 주어진다. \\((10,10)\\)과 \\((11,10)\\), \\((10,80)\\)과 \\((11,80)\\), \\((10,10)\\)과 \\((10,11)\\), \\((10,80)\\)과 \\((10,81)\\)\n\n\n\n\n그림 2.1: 2차원 극 좌표와 데카르트 좌표\n그림 2.2: 세 개의 거리로 표현되는 데카르트 지심 좌표(왼편)와 두 개의 각도와 하나의 타원체고로 표현되는 타원체 좌표(오른편)\n그림 2.3: 타원체 상의 각도: 측지 위도(파란색)와 지심 위도(붉은색)\n그림 2.4: 영국의 OSGB 1936(EPSG:4277)를 ETRS89(EPSG:4258)로 변환하는데 사용되는 수평 데이텀 그리드\n그림 2.5: 영국의 ETRS89(EPSG:4937)를 ODN 고도(EPSG:5701)로 변환하는데 사용되는 수직 데이텀 그리드",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>좌표계</span>"
    ]
  },
  {
    "objectID": "05.html",
    "href": "05.html",
    "title": "5  속성과 서포트",
    "section": "",
    "text": "5.1 속성-지오메트리 관계와 서포트\n피처 속성은 변경하지 않고 피처의 기하 특성만 수정하더라도, 피처는 변한 것으로 간주된다. 이는 피처가 지오메트리와 속성의 결합으로 구성되기 때문이다. 예를 들어, 지오메트리를 컨벡스헐(convex hull)이나 센트로이로(centroid) 대체했을 때, 새롭게 생성디는 피처가 기존 속성 값과 의미 있게 관계를 유지할 수 있을까? 이 답은 상황에 따라 다르다.\nLINESTRING 지오메트리를 갖는 도로망을 예로 들어보자. 데이터셋에 도로 폭이라는 속성이 포함되어 있고, 어떤 도로의 속성값이 10 m라고 하자. 그렇다면 해당 도로의 특정 구간의 도로 폭에 대해 우리는 무엇을 말할 수 있을까? 이는 도로 폭 속성이 도로의 모든 지점에서 동일한 폭을 의미하는지(즉, 폭이 일정하다는 것을 의미하는지), 아니면 최소값이나 평균값과 같은 집계 속성을 의미하는지에 따라 달라진다. 최소값의 경우를 좀 더 살펴보자. 최소 도로 폭은 해당 도로에서 임의로 특정 구간을 선택했을 때, 그 구간의 최소 폭이 주어진 최소 도로 폭보다 작지 않음을 의미한다. 그러나 이것이 반드시 그 하위 구간의 최소 폭을 뜻하는 것은 아니다. 이 사례는 속성-지오메트리 관계(AGR, attribute-geometry relationship)가 두 가지 ’유형’으로 구분될 수 있음을 보여한다.\n폴리곤 데이터의 경우, 상수 AGR(포인트 서포트)의 예로 다음의 변수를 들 수 있다.\n상수 AGR 변수의 전형적인 특성은 지오메트리가 인위적으로 생성된 것이 아니며, 센서 장치(예: 원격탐사의 이미지 픽셀 경계)와도 관련이 없다는 것이다. 대신, 지오메트리는 관찰된 변수를 매핑함으로써 결정된다. 집계 AGR의 예로는 다음과 같은 변수를 들 수 있다.\n집계 AGR 변수의 전형적인 특성은, 그 지오메트리가 법률적 규정, 관측 장치, 분석상의 선택 등에서 비롯된 것이며, 관찰 변수 그 자체와 본질적으로 연결되어 있지는 않다는 점이다.\n세 번째 유형의 AGR는 속성이 피처 지오메트리의 식별자 역할을 하는 경우에 해당한다. 개별 지오메트리가 변수의 특정 값과 고유하게 연결되어 있을 때, 이를 식별 변수라고 한다. 즉, 동일한 값을 가지는 다른 지오메트리가 존재하지 않는 경우다. 예를 들어, 카운티 이름은 해당 카운티를 식별하며, 카운티 내 어떤 하위 지역에도 동일한 이름이 적용될 수 있다(포인트 서포트). 그러나 임의의 하위 구역을 고려하면, 이 변수는 더 이상 식별자 역할을 하지 못하고 단순한 상수 속성값으로 변하게 된다. 하나의 예를 들면 다음과 같다.\n여기서 중요한 점은, 공간정보가(단순화를 위해 시간은 무시한다고 할 때) 서로 다른 현상 유형으로 구분될 수 있다는 것이다(Scheider et al. 2016).\n그러나 이러한 현상 유형이 지오메트리 유형(포인트, 라인, 폴리곤, 래스터 셀)과 일대일로 대응하는 것은 아니다.\n속성-지오메트리 관계를 적절히 정의하고, 이에 대한 정보가 누락되었거나 지오메트리의 변화(즉, 서포트의 변화)가 정보 변화를 초래하는 경우 경고 메시지를 표출하는 것은, 공간데이터의 서포트와 관련된 일반적인 공간데이터 분석 오류(Stasch et al. 2014)를 피하는 데 도움이 될 수 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#속성-지오메트리-관계와-서포트",
    "href": "05.html#속성-지오메트리-관계와-서포트",
    "title": "5  속성과 서포트",
    "section": "",
    "text": "상수(constant) AGR: 속성값이 지오메트리의 모든 부분에 동일하게 적용된다. 즉, 피처가 무수히 많은 지점으로 구성되어 있고, 각 지점이 동일한 속성값을 가지는 경우를 말한다. 지구통계학에서는 이를 포인트 서포트를 가진 변수라고 부른다.\n집계(aggregate) AGR: 속성값이 지오메트리 전체를 요약한 값이다. 즉, 피처가 하나의 관측값을 가지며, 그 값이 지오메트리 전체를 대표하는 경우를 말한다. 지구통계학에서는 이를 블록 서포트를 가진 변수라고 부른다.\n\n\n\n토지이용도에서의 토지이용\n지질도에서의 암석 단위 또는 지질층\n토양도에서의 토양 유형\n기복도에서의 고도 클래스\n기후 구분도에서의 기후 지역\n\n\n\n인구: 인구수 혹은 인구밀도\n지역별로 요약된 사회경제적 변수\n원격탐사 픽셀별 평균 반사율\n지역별 총 오염물질 배출량\n이산화질소 농도에 대한 블록 평균: 보통 정사각형 블록에 대한 블로 크리깅(12.5절) 또는 구역 평균값을 예측하는 분산 모형을 통해 산출된다.\n\n\n\n\n카운티 내부의 임의의 지점(또는 지역)은 여전히 그 카운티에 속하므로 ‘카운티 이름’ 변수에서 동일한 값을 가져야 한다. 그러나 해당 지점(또는 지역)은 더 이상 카운티 전체 지오메트리를 대표하는 식별자로 기능할 수 없다.\n\n\n\n필드: 연속적인 공간상의 모든 지점이 특정 속성값을 가지는 경우(예를 들어, 고도, 대기질 또는 토지이용)\n객체: 위치의 이산적 집합으로 규정되는 경우(예를 들어, 주택, 나무, 사람)\n집계값: 필드의 총계 또는 평균, 라인 혹은 폴리곤 객체의 총빈도 혹은 밀도로 계산되는 값\n\n\n\n포인트는 필드에서의 표본추출 위치일 수도 있고(예: 대기질 관측소), 객체의 위치일 수도 있다.\n라인은 객체(예: 도로, 강)일 수도 있고, 필드를 나타내는 등치선일 수도 있으며, 행정구역의 경계일 수도 있다.\n래스터 픽셀과 폴리곤은 토지이용(커버리지)과 같은 범주형 필드와 연관될 수도 있고, 인구밀도와 같은 집계값과도 관련될 수 있다.\n래스터나 다른 형태의 메시 삼각망은 노드(포인트), 엣지(라인), 페이스(에어리어, 셀)에 각각 다른 변수를 가질 수 있다. 스태거드 그리드(staggered grid)를 이용해 편미분 방정식을 근사하는 경우(Haltiner and Williams 1980; Collins et al. 2013)가 이에 해당한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#애그리게이션과-속성-요약",
    "href": "05.html#애그리게이션과-속성-요약",
    "title": "5  속성과 서포트",
    "section": "\n5.2 애그리게이션과 속성 요약",
    "text": "5.2 애그리게이션과 속성 요약\n테이블(또는 data.frame) 레코드의 애그리게이션(aggregation)은 다음의 두 단계를 통해 수행된다.\n\n그룹 프레디케이트에 따라 레코드를 분류한다.\n애그리게이션 함수를 적용하여 각 그룹별 단일 요약 속성값을 계산한다.\n\nSQL에서 애그리게이션 과정은 다음의 예시처럼 이루어진다.\nSELECT GroupID, SUM(population) FROM table GROUP BY GroupID;\n여기서 애그리게이션 함수는 SUM이고 그룹화 프레디케이트는 GroupID이다.\nR의 dplyr 패키지는 이 작업을 두 단계로 수행한다. group_by() 함수는 레코드의 그룹 멤버십을 지정하고, summarise() 함수는 각 그룹에 대한 데이터 요약(예: sum 또는 mean)을 계산한다. 반면 베이스 R의 aggregate() 함수는 테이블, 그룹화 조건, 집계 함수를 인수로 받아 이 두 단계를 하나의 함수 호출로 처리한다.\n노스캐롤라이나 카운티의 예는 그림 5.1에 제시되어 있다. 타원 좌표 POINT(-79, 35.5)를 기준점으로 사분면을 설정하고, 각 카운티의 센트로이드가 속한 사분면에 따라 카운티를 그룹화한 뒤, 각 그룹별로 질병 사례 수를 합산하였다. 그 결과, 그룹별로 통합된 지오메트리가 생성되었음을 확인할 수 있다(3.2.6절 참조). 이러한 그룹별 애그리게이션은 필수적이다. 만약 카운티 지오메트리를 단순히 결합하여 MULTIPOLYGON을 생성했다면, 수 많은 중복 경계가 발생하여 밸리드하지 않은 지오메트리가 생성되었을 것이기 때문이다(3.1.2절 참조).\n\n\n\n\n\n그림 5.1: SID74가 네 개의 지역별로 합산되었다.\n\n\n결합된 카운티 폴리곤을 지도로 표현하는 데 기술적인 문제는 없지만, 그룹 합계가 그룹화된 카운티가 아니라 개별 카운티에 해당하는 값이라는 잘못된 인상을 줄 수 있다.\n이러한 방식의 애그리게이션의 특징은 각 레코드가 하나의 그룹에만 할당된다는 점이다. 이로 인해 그룹별 합계의 총합이 그룹화 이전 데이터의 총합과 동일하다는 유지되는 장점이 있다. 즉, 양(amount)을 나타내는 변수의 경우 정보가 손실되거나 추가되지 않는다. 새로 생성된 지오메트리는 원래 레코드의 지오메트리를 그룹 단위로 유니온(union)한 결과이다.\n\n\n\n\n\n그림 5.2: 노스케롤라이나 카운티 상의 타깃 블\n\n\n지오메트리를 결합하지 않고도 그룹별 합산값을 계산해야 하는 경우에는 공간 프레디케이트를 활용한다. 다만 이 방식에서는 하나의 레코드가 여러 그룹에 속할 수 있다는 점에 유의해야 한다. 예를 들어, 그림 5.2에서 직사각형을 타깃 에어리어로 설정하고, 각 직사각형과 교차 관계에 있는 카운티의 유병자를 합산하면 전체 합계는 훨씬 더 크게 나타날 것이다.\n#   sid74_sum_counties sid74_sum_rectangles \n#                  667                 2621\n반대로 contains나 covers와 같은 다른 프레디케이트를 사용하면 훨씬 작아진다. 이는 많은 카운티가 어떤 직사각형 안에도 완전히 포함되지 않기 때문이다. 그러나 이러한 결과가 큰 문제가 없거나 최소한 수용 가능한 경우도 있다. 예를 들어, 다음과 같은 경우가 이에 해당한다.\n\nPOINT 지오메트리를 폴리곤 단위로 애그리게이션하는 경우: 모든 포인트는 반드시 하나의 폴리곤에 포함되므로 누락 문제는 발생하지 않는다. 다만 포인트가 공유 경계선 위에 위치하면 문제가 될 수 있다. GEOS 라이브러리는 DE-9IM을 기반으로 해당 포인트를 두 폴리곤 모두에 집계하지만, s2geometry 라이브러리는 폴리곤을 ’반-개방(semi-open)’으로 정의하는 옵션을 제공하여, 폴리곤이 서로 중첩되지 않는 한 포인트를 최대 하나의 폴리곤에만 할당한다.\n아주 작은 폴리곤이나 래스터 픽셀을 더 큰 폴리곤으로 애그리게이션하는 경우: 예를 들어, 노스케롤라이나의 30 m 해상도의 고도 데이터를 카운티별로 평균낼 때, 경계 부근에서 일부 픽셀이 누락되더라도 그로 인한 집계 오류는 무시할 수 있을 정도로 작다.\n다대다(many-to-many) 매치에서 최대 면적 매치(single largest area match)가 적용된 경우(그림 7.4 참조)(역자주: 최대 면적 매치란, 겹치는 영역 중 면적이 가장 큰 영역에 모든 값을 할당하는 방식으로, 이러한 기준을 의도적으로 적용한 경우라면 일부 누락이 있더라도 결과가 만족스러울 수 있다.)\n\n보다 작은 에어리어를 보다 큰 에어리어로 합역하는 보다 포괄적인 접근 방법은 면적 가중 내삽을 적용하는 것이다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#면적-가중-내삽",
    "href": "05.html#면적-가중-내삽",
    "title": "5  속성과 서포트",
    "section": "\n5.3 면적 가중 내삽",
    "text": "5.3 면적 가중 내삽\n두 개의 데이터셋의 지오메트리와 속성을 결합하여, 소스 데이터셋의 속성값을 타겟 데이터셋의 지오메트리에 기반한 요약값으로 변환하고자 한다면, 면적 가중 내삽(area-weighted interpolation)이 가장 간단한 접근 방법이 될 수 있다. 이 방법은 소스와 타겟의 지오메트리가 겹치는 면적을 고려하여, 소스 속성값을 타겟 속성값으로 전환하기 위한 가중치로 활용한다(Goodchild and Lam 1980; Do, Thomas-Agnan, and Vanhems 2015a, 2015b; Do, Laurent, and Vanhems 2021). 이 기법은 보수적 합역(conservative region aggregation) 또는 재그리딩(regridding)으로도 알려져 있다(Jones 1999). 여기서는 Do, Thomas-Agnan과 Vanhems(2015b)의 표기법을 따르도록 한다.\n면적 가중 내삽은 타깃 에어리어 \\(T_j\\)에 대한 가중평균값을 산출한다. 이 값은 \\(T_j\\)와 겹치는 \\(p\\)개의 소스 구역 \\(S_i\\)의 속성값 \\(Y_i\\)에 대한 가중평균으로 계산된다.\n\\[\n\\hat Y_j(T_j)=\\sum\\limits_{i=1}^pw_{ij}Y_i(S_i)\n\\tag{5.1}\\]\n여기서 \\(w_{ij}\\)는 \\(T_j\\)와 \\(S_i\\)의 겹침의 정도에 따라 달라지며, 겹침 정도는 \\(A_{ij}=T_j\\cap S_i\\)로 표현된다. \\(w_{ij}\\)와 \\(A_{ij}\\)의 관계는 아래에서 자세히 설명한다.\n가중치를 계산하는 방법에는 여러 가지가 있으며, 외부 변수를 활용하는 방법(예: 대시메트릭 매핑, Mennis 2003 참조)도 그중 하나이다. 외부 변수를 사용하지 않고 가중치를 계산하는 단순한 방법은 두 가지가 있으며, 변수 \\(Y\\)가 공간 외연 변수인지 공간 내포 변수인지에 따라 달라진다.\n\n5.3.1 공간 외연 변수와 공간 내포 변수\n공간 외연 변수(spatially extensive variable)는 길이, 면적, 부피, 카운트(count)와 같이 물리적 크기와 관련된 양을 나타낸다. 대표적인 예로 인구수를 들 수 있다. 인구수는 특정 크기의 영역과 관련된 값이며, 해당 영역을 더 작은 영역으로 분할하면 인구수도 함께 분할되어야 한다. 인구가 공간적으로 균일하지 분포하지 않은 경우가 많기 때문에, 이 분할이 반드시 면적에 비례할 필요는 없지만, 더 작은 영역의 인구수 합계는 전체 영역의 인구수와 일치해야 한다. 공간 내포 변수(spatially intensive variable)는 영역의 면적에 비례하여 변하지 않는 변수이다. 즉, 영역이 분할되더라도 평균적인 의미에서 값이 그대로 유지된다. 대표적인 예로 인구밀도를 들 수 있다. 영역을 더 작은 영역으로 분할하더라도 연구밀도 값이 면적에 비례하여 할당되지는 않는다. 더 작은 영역들의 인구밀도를 합산한 값은 아무런 의미가 없으며, 이들 인구밀도의 평균이 전체 영역의 인구밀도와 유사하게 나타날 것이다.\n공간 외연 변수 \\(Y\\)가 공간상에 균등하게 분포한다고 가정하면, 소스 데이터의 구역 \\(S_i\\)에 대한 변수값 \\(Y_i\\)로부터, 타깃 구역과의 겹침으로 생성된 하위 구역(\\(A_{ij}=T_j\\cap S_i\\))의 속성값 \\(Y_{ij}\\)는 다음과 같이 계산할 수 있다.\n\\[\n\\hat Y_{ij}(A_{ij})=\\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\]\n여기서 \\(|\\cdot|\\)는 면적을 의미한다. \\(Y_j(T_j)\\)를 추청하려면, \\(T_j\\)와 겹쳐 생성된 모든 하위 구역의 값을 합산하면 된다.\n\\[\n\\hat Y_j(T_j)=\\sum\\limits_{i=1}^p\\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\tag{5.2}\\]\n반면 공간 내포 변수의 경우, 해당 변수값이 개별 소스 구역 \\(S_i\\) 내에서 일정하다고 가정하므로, 겹침에 의해 생성된 하위 구역의 추정값은 소스 구역의 전체의 값과 동일하다.\n\\[\n\\hat Y_{ij}=Y_i(S_i)\n\\]\n따라서 소스 구역의 값을 면적 가중 평균으로 계산하면, 타깃 구역 \\(T_j\\)에 대한 추정값을 얻을 수 있다.\n\\[\n\\hat Y_j(T_j)=\\sum\\limits_{i=1}^p\\frac{|A_{ij}|}{|T_j|}Y_i(S_i)\n\\tag{5.3}\\]\n\n5.3.2 대시메트릭 매핑\n대시메트릭 매핑(dasymetric mapping)은 더 큰 구역 체계의 변수값(예: 인구수)을 더 작은 구역 체계의 변수값으로 분배하는 방법이다. 이때 인구 분포와 관련된 다른 변수(예: 토지이용, 건물 밀도, 도로 밀도 등)를 활용한다. 대시매트릭 매핑의 가장 간단한 방식은 식 5.2에서 나타난 비율 \\(|A_{ij}|/|S_i|\\) 대신 또 다른 공간 외연 변수와 관련된 비율 \\(X_{ij}(S_{ij})/X_i(S_i)\\)을 사용하는 것이다. 이 방법을 적용하려면 소스 구역과 겹침 구역 모두에 대해 해당 변수의 값을 알고 있어야 한다.(역자주: 대시메트릭 매핑은 보조 정보를 활용해 주어진 공간 단위를 더 작은 단위로 분할하고, 원래의 속성값을 분할된 단위에 재할당함으로써 현상을 보다 세밀하게 재현하려는 공간분석 기법이다. 예를 들어, 서울시 동별 인구수 자료가 있을 때 서울시 토지이용도를 이용해 각 동을 토지이용 상태에 따라 세분하고, 토지이용 유형과 인구 분포 간의 관계를 토대로 동 전체 인구를 토지이용별로 재할당할 수 있다.) Do, Thomas-Agnan과 Vanhems(2015b)는 \\(X\\)와 \\(Y\\) 중 적어도 하나가 공간 내포 변수일 때 적용할 수 있는 대안적 접근법과, \\(X\\) 데이터가 상이한 구역 체계에서 제공되는 경우에 대한 논의를 제시한다.\n\n5.3.3 파일 포맷과 서포트\nGDAL의 벡터 API는 필드 도메인(field domains)을 읽고 쓰는 기능을 지원한다. 필드 도메인은 지오메트리가 분할되거나 결합될 때 속성 변수를 어떻게 처리할지를 지정하는 ‘분할 정책(split policy)’과 ’병합 정책(merge policy)’을 포함한다. 예를 들어, 공간 내포 변수의 경우 분할 시에는 ’중복(duplicate)’, 병합 시에는 ‘기하 가중(geometry weighted)’을 적용한다. 반면, 공간 외연 변수의 경우 분할 시에는 ’기하 비율(geometry ratio)’, 병합 시에는 ‘합(sum)’을 적용한다.(역자주: 인구밀도와 같은 공간 내포 변수의 경우, 폴리곤이 분할될 때는 동일한 값을 ‘중복’ 할당하고, 폴리곤이 병합될 때는 면적 비중을 고려하여 가중 평균을 계산한다. 반면, 인구수와 같은 공간 외연 변수의 경우, 폴리곤이 분할될 때는 면적 비중에 따라 가중 분할하고, 폴리곤이 병합될 때는 값을 합산한다.) 이 기능을 지원하는 파일 형식에는 GeoPackage와 FileGDB가 있다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#업스케일링과-다운스케일링",
    "href": "05.html#업스케일링과-다운스케일링",
    "title": "5  속성과 서포트",
    "section": "\n5.4 업스케일링과 다운스케일링",
    "text": "5.4 업스케일링과 다운스케일링\n업스케일링(upscaling)은 고해상도 데이터에서 저해상도 정보를 생성하는 과정을 의미하고, 다운스케일링(downscaling)은 저해상도 데이터에서 고해상도 정보를 추정하는 과정을 의미한다. 이 두 과정 모두 속성과 지오메트리의 관계, 즉 서포트의 변화를 수반하며, 각각 애그리게이션(aggregation)과 디스애그리게이션(disaggregation)과 동의어로 사용할 수 있다. 다운스케일링의 가장 단순한 형태는 폴리곤, 라인, 또는 그리드 셀의 값을 주어진 포인트 위치에서 표본 추출하는 것이다. 이 방법은 포인트 서포트를 가진 변수(예: ‘상수’ AGR)에는 적합하지만, 값이 합산값인 경우에는 대략적인 결과만 제공한다. 대표적인 도전 과제로는 (1) 저해상도 기상 예측 모형이나 기후 변화 모형에서 얻은 변수를 고해상도로 예측하는 작업, (2) 서로 다른 시공간 해상도를 가진 센서를 융합하여 위성 이미지에서 파생된 변수를 고해상도로 예측하는 작업이 있다.\n식 5.1과 이에 기반으로 한 식 5.2(공간 외연 변수) 및 식 5.3(공간 내포 변수)는 소스 구역 \\(S_i\\)와 타깃 구역 \\(T_j\\) 간에 겹침이 존재하기만 하면, 두 구역 간에 정보를 이동시킬 수 있음을 보여준다. 즉, 더 큰 구역 단위로의 이동(애그리게이션)이나 더 작은 구역 단위로의 이동(디스애그리게이션) 모두 가능하다는 의미다. 다만 이러한 방식의 타당성은 다음 가정이 성립하는 정도에 달려 있다. 소스 구역에서 공간 외연 변수는 균등하게 분포해야 하고, 공간 내포 변수는 일정한 값을 가져야 한다.\n디스애그리게이션은 라인이나 폴리곤 데이터로부터 포인트 값을 추출하는 것에서 시작된다. 포인트는 면적을 갖지 않으므로(\\(|A_{ij}|=0\\)) 식 5.2와 5.3은 적용할 수 없다. 그러나 지오메트리 내부의 값이 일정하다고 가정할 수 있다면, 공간 내포 변수인 경우 \\(Y_i(S_i)\\) 값을 포인트에 할당할 수 있다. 단, 모든 포인트가 고유하게 하나의 소스 지점 \\(S_i\\)에만 할당될 수 있어야 하며, 폴리곤 데이터의 경우 이는 \\(Y\\)가 커버리지 변수(3.4절)여야 함을 의미한다. 반면, 공간 외연 변수의 경우 포인트에 값을 추출하는 것은 무의미하다. 포인트는 면적이 없으므로 항상 0이 추출되기 때문이다(역자주: 공간 외연 변수는 면적에 비례하여 값이 커지는 변수이므로, 면적이 없는 포인트에서는 값이 정의되지 않는다).\n영역과 관련된 값이 해당 영역의 집계값일 경우, 면적 가중 내삽이나 대시매트릭 매핑에서 전제하는 ‘균일 분포’ 또는 ‘일정한 값’ 가정은 실제 상황과 차이가 있을 수 있다. 그럼에도 불구하고 이러한 단순한 접근법이 합리적인 근사치를 제공하는 경우가 있으며, 예를 들어 다음과 같은 상황이 있다.\n\n소스 구역과 타깃 구역이 거의 동일한 경우\n소스 구역 내의 변동성이 매우 작아, 변수값이 거의 균등 분포하거나 일정한 값을 보이는 경우\n\n다른 경우에는 이러한 방법으로 얻어진 결과가 타당성이 부족한 가정에 기반할 수 있다. 포인트나 더 작은 구역으로부터 더 큰 구역의 총량을 추정하기 위해 사용할 수 있는 통계적 애그리게이션 방법에는 다음이 있다.\n\n디자인 기반(design-based) 방법: 타깃 지역에서 확률 표본이 확보되어 있고, 포함 확률(inclusion probability)이 알려져 있어야 한다(Brus 2021, 10.4 절).\n모형 기반(model-based) 방법: 공간적 자기상관을 고려하는 랜덤 필드 모형을 가정한다(예: 블록 크리깅, 12.5절).\n\n또한 다른 디스애그리게이션 기법으로는 다음과 같은 것들이 있다.\n\n결정론적 평활화 기반 접근: 커널 기반 또는 스플라인 기반의 평활화 기법을 포함한다.\n통계적 모형 기반 접근: 에어리어-투-에어리어 크리깅과 에어리어-투-포인트 크리깅을 포함한다.",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "05.html#연습문제",
    "href": "05.html#연습문제",
    "title": "5  속성과 서포트",
    "section": "\n5.5 연습문제",
    "text": "5.5 연습문제\n다음의 연습문제를 풀되, 적절한 부분에서 R을 활용하라.\n\n노스케롤라이나 데이터셋(nc)에 nc$State = \"North Carolina\"와 같이 변수를 추가한다고 가정하자(모든 카운티에 동일한 주 이름이 할당됨). 속성-지오메트리 관계(AGR) 측면에서 이 변수에 어떤 값을 지정할 수 있을지 설명하시오.\nst_union(nc)으로 얻은 지오메트리로를 기반으로 새로운 sf 객체를 생성하고, State 변수에 \"North Carolina\" 값을 할당하시오. 이 경우, 해당 속성 변수에 어떤 agr을 지정할 수 있을지 설명하시오.\nnc 데이터셋에 st_area를 사용하여 area 변수를 추가하시오. 그런 다음 area 변수와 AREA 변수를 비교하시오. AREA의 단위는 무엇인지, 두 변수는 선형적인 관련성을 가지는지 말하시오. 만약 불일치가 존재한다면, 그 원인은 무엇인지 설명하시오.\narea는 공간 내포 변수인지 공간 외연 변수인자 말하시오. area의 agr은 상수, 식별, 집계값 중 어느 것에 해당하는지 답하시오.\n그림 5.3에서 5.3.1 절에 나타나 있는 방정식을 이용하여 (a) 점선 셀과 (b)네 개의 실선 셀을 모두 포함하는 정사각형에 대해 면적 가중 내삽의 결과를 계산하시오. (b)의 경우, (i) 공간 외연 변수인 경우와 (ii) 공간 내포 변수인 경우로 나누어 계산하시오. 그림에서 빨간 숫자는 소스 구역의 데이터 값이다.\n\n\n\n\n\n\n그림 5.3: 면적 가중 내삽의 예시 데이터\n\n\n\n\n\n그림 5.1: SID74가 네 개의 지역별로 합산되었다.\n그림 5.2: 노스케롤라이나 카운티 상의 타깃 블\n그림 5.3: 면적 가중 내삽의 예시 데이터",
    "crumbs": [
      "공간데이터",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>속성과 서포트</span>"
    ]
  },
  {
    "objectID": "part_1.html",
    "href": "part_1.html",
    "title": "공간데이터",
    "section": "",
    "text": "이 책의 제1부에서는 공간데이터사이언스의 핵심 개념을 다룬다. 지도, 투영, 벡터 및 래스터 데이터의 구조, 소프트웨어, 속성과 서포트, 데이터 큐브 등의 개념을 익히게 된다. 이 부분에서 R의 비중은 크지 않으며, 주로 텍스트 출력이나 그래프 작성에만 사용된다. 따라서 독자가 내용에 집중할 수 있도록 R 코드를 제시하거나 설명하지 않는다. R은 제2부에서 본격적으로 다루어진다. 이 책의 온라인 버전(https://r-spatial.org/book/)에서는 모든 R 코드를 확인할 수 있으며, 필요한 경우 클립보드에 복사해 실행해 볼 수 있다. R 코드 실행 결과는 # 기호로 시작하며, 코드 폰트로 표시된다.\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\n공간데이터사이언스 문제 해결을 위한 R 코드에 대한 보다 상세한 설명은 제2부부터 시작된다. 부록 B에는 R 데이터 구조에 대한 간략한 설명이 있으며, 더 자세한 내용은 Wickham(2014)을 참고하면 된다.",
    "crumbs": [
      "공간데이터"
    ]
  },
  {
    "objectID": "16.html",
    "href": "16.html",
    "title": "16  공간적 회귀분석",
    "section": "",
    "text": "16.1 마르코프 랜덤 필드와 다수준모형\n질병 매핑(disease mapping) 연구에서는 공간적으로 구조화된 임의효과를 다루기 위해 조건부 자기회귀(CAR, conditional autoregressive) 모형과 내재적 자기회귀(ICAR, intrinsic conditional autoregressive) 모형을 활용한 다양한 연구가 축적되어 있다. 이러한 모형은 다수준모형(multilevel model)으로 확장될 수 있으며, 공간적으로 구조화된 임의효과가 모형의 서로 다른 수준에서 적용될 수 있다(Bivand et al. 2017). 여러 변형을 시도해 보기 위해, 두 단계에 걸쳐 무이웃 관측값을 제거해야 한다. 먼저 트랙트(tract) 수준에서 무이웃 관측값을 제거하고, 이어서 모형 출력 구역 집계(model output zone aggregated) 수준에서 무이웃 관측값을 제거한다. 이는 트랙트 수준에서 관측값을 줄이면 모형 출력 구역 수준에서도 무이웃 결과가 발생하기 때문이다. 대부분의 모형 추정 함수는 family 인수를 사용하며, 이웃 간 관계를 마르코프 랜덤 필드로 표현한 공간 랜덤효과를 통해 각 관측값에 대해 일반화 선형 혼합효과모형을 적합한다. 다수준모형의 경우, 랜덤효과는 그룹 수준에서 모형화될 수 있으며, 아래의 예시에 그 적용 사례가 제시되어 있다.(역자주: ’마르코프 랜덤 필드’는 공간적 의존성을 확률적으로 표현하는 틀로, 각 공간단위의 값이 직접적으로는 이웃 공간단위의 값에만 조건부로 의존한다는 마르코프 성질을 2차원 이상의 격자나 네트워크 구조로 확장한 것이다. 마르코프 랜덤 필드를 사용하면 이웃 구조를 기반으로 공간적 자기상관성을 희소 행렬 형태로 표현할 수 있어 계산이 효율적이며, 이웃 관계와 의존성 강도를 직관적으로 해석할 수 있다. 이러한 특성 덕분에 마르크프 랜덤 필드는 CAR, ICAR, SAR 등 공간적 랜덤효과 모형의 수학적 기반으로 널리 활용된다.)\n공간적 회귀분석을 혼합효과모형의 틀에서 설명한 Pinheiro와 Bates(2000)와 McCulloch와 Searle(2001)의 논리는 중요하다.(역자주: 공간적 회귀분석이 혼합효과모형의 틀에서 잘 다루어질 수밖에 없는 이유는 다음과 같다. 혼합효과모형은 모든 관측값에 동일하게 적용되는 고정효과와, 특정 그룹 또는 지역 단위별로 달라지는 랜덤효과로 구성된다. 이러한 구조는 고정효과와 랜덤효과가 서로 다른 수준에서 발생하므로, 혼합효과모형이 본질적으로 다수준 구조를 표현하게 만든다. 공간적 회귀분석은 바로 이 랜덤효과에 공간적 자기상관 구조(CAR, ICAR, SAR 등)를 부여한 모형으로, 혼합효과모형의 확장형이자 다수준모형의 한 특수 사례라 할 수 있다.) 여기서는 Gómez-Rubio(2019)의 표기법을 따라 설명하고자 한다. 반응변수 \\(Y\\), 고정 공변량 \\(X\\), 회귀계수 \\(\\beta\\), 오차 항 \\(\\epsilon_i\\sim N(0, \\sigma^2), i=1,...,n\\)이 주어진 상태에서, 랜덤효과 \\(u\\)를 추가하면, 가우시안 선형 혼합효과모형은 다음과 같이 정의된다.\n\\[\nY=X\\beta+Zu+\\epsilon\n\\]\n여기서 \\(Z\\)는 랜덤효과를 위한 고정 디자인 행렬이다. 만약 랜덤효과가 \\(n\\)개라면 \\(n \\times n\\) 단위행렬이 되며, 관측값이 \\(m\\)개의 그룹으로 집계되어 \\(m&lt;n\\)의 랜덤효과만 존재하는 경우에는 각 관측값의 그룹 소속을 나타내는 \\(n \\times m\\) 행렬이 된다. 랜덤효과는 다변량 정규분포 \\(u\\sim N(0,\\sigma_u^2 \\sum)\\)로 모형화되며, \\(\\sigma_u^2 \\sum\\)은 랜덤효과의 분산-공분산 행렬이다.\nCAR 모형(Besag 1974)과 SAR(simultaneous autoregressive) 모형(Ord 1975; Hepple 1976)을 사용하는 학문 분야 간에는, 두 모형이 밀접하게 관련되어 있음에도 불구하고 서로 다른 전통이 형성되어 왔다. 이러한 구분은 오히려 두 모형의 전체 구조를 이해하는 데 방해가 될 수 있다. 실제로 두 모형을 요약한 주요 연구(Ripley 1981, 1988; Cressie 1993)를 공통으로 참조하면서도, 유사한 모형을 적용한 경험을 공유하는 데 어려움을 겪어 왔다. Ripley(1981, 1989)는 SAR 모형의 분산을 다음과 같이 제시했으며, 이는 정밀도 행렬(precision matrix) \\(\\sum^{-1}\\)로도 알려져 있다.\n\\[\n\\Sigma^{-1}=[(I-\\rho W)'(I-\\rho W)]\n\\]\n여기서 \\(\\rho\\)는 공간적 자기상관 계수, \\(W\\)는 비단일(non-singular) 공간가중치행렬이다. 한편 CAR 모형의 정밀도 행렬은 다음과 같이 주어진다.\n\\[\n\\Sigma^{-1}=(I-\\rho W)\n\\]\n여기서 \\(W\\)는 대칭이며 엄격히 양의 정부호(strictly positive definite)인 공간가중치행렬이다. 내재적(intrinsic) CAR 모형의 경우, 공간적 자가상관 계수를 추정하지 않으며 다음과 같이 정의된다.\n\\[\n\\Sigma^{-1}=M=\\text{diag}(n_i)-W\n\\]\n여기서 \\(n_i\\)는 \\(W\\)의 행 합이다. Besag-York-Mollié 모형은 내재적 CAR 구조를 갖는 ’공간적으로 구조화된 랜덤효과’와, 공간적 구조가 없는 ’비구조화된 랜덤효과’를 모두 포함한다. Leroux 모형 역시 Besag–York–Mollié 모형과 마찬가지로 두 가지 요소를 포함하지만, 차이점은 이를 하나의 랜덤효과 항에서 결합한다는 점이다.\n\\[\n\\Sigma^{-1}=[(1-\\rho)I_n+\n\\rho M]\n\\]\n이 모형들의 정의는 Gómez-Rubio(2020)를 참조할 수 있으며, Besag-York-Mollié와 Leroux 모형의 추정 문제는 Gerber와 Furrer(2015)에서 다루고 있다.\n에어리어 데이터 모형화의 이론적 기초를 다룬 최근 저작(Gaetan and Guyon 2010; Van Lieshout 2019)에서는 SAR과 CAR 모형의 유사성이 여러 장에서 언급된다. 배경 정보에 관심이 있는 독자는 이들 서적들을 참고하기 바란다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "16.html#마르코프-랜덤-필드와-다수준모형",
    "href": "16.html#마르코프-랜덤-필드와-다수준모형",
    "title": "16  공간적 회귀분석",
    "section": "",
    "text": "16.1.1 보스턴 주택가격 데이터셋\n여기서는 보스턴 주택가격 데이터셋을 사용한다. 이 데이터셋은 센서스 트랙트(tract) 경계에 맞추어 재구성된 것이다(Bivand 2017). 원래 데이터셋은 506개의 트랙트로 구성되었으며, 깨끗한 공기에 대한 지불 의사를 추정하기 위해 헤도닉(hedonic) 모형을 사용했다. 반응변수는 1970년 센서스에서 가구들이 주택 가치를 서열척도(가격 구간)로 응답한 자료를, 각 구간별 가구 수로 집계한 뒤 이를 기반으로 생성되었다. 이 반응변수는 센서스 원자료에서 좌측 및 우측 검열이 있었으며, 분석에서는 가우시안 분포를 따른다고 가정하였다.(역자주: 이 데이터는 원래 대기질 개선에 따른 주택가격 변화량을 추정하기 위한 헤도닉 모형에 투입된 것이다. 반응변수는 결국 센서스 트랙트별 중위 주택가격이며 최하위 가격 구간보다 낮은 주택(좌측 검열)과 최상위 가격 구간(50,000달러 초과)(우측 검열)은 결측 처리되었다.) 주요 공변량은 연간 질소산화물(NOX) 수준을 보여주는 기상 모형에 기반해 생성되었으며, 트랙트 수보다 적은 수의 모형 산출 구역 단위로 제공된다. 주택 응답 수는 트랙트별과 모형 출력 구역별로 차이가 있다. 다른 공변량도 여러 개 포함되어 있으며, 일부는 트랙트 수준에서 측정되었고, 일부는 타운 단위로만 측정되었다. 이 타운들은 대체로 대기오염 모형 출력 구역과 일치한다.\n우리는 먼저 spData 패키지(Bivand, Nowosad, and Lovelace 2022)에서 506개 트랙트 데이터셋을 불러온 뒤, 인접성 이웃 객체를 생성하고 이를 기반으로 행 표준화 공간가중치 객체를 만든다.\n\nlibrary(sf)\nlibrary(spData)\nboston_506 &lt;- st_read(system.file(\"shapes/boston_tracts.shp\",\n                      package = \"spData\")[1], quiet = TRUE)\n\n\nnb_q &lt;- spdep::poly2nb(boston_506)\nlw_q &lt;- spdep::nb2listw(nb_q, style = \"W\")\n\n중위 주택가격 데이터를 살펴보면, 검열된 값들이 결측값으로 처리되어 있으며, 이로 인해 총 17개 트랙트가 영향을 받은 것을 알 수 있다.\n\ntable(boston_506$censored)\n# \n#  left    no right \n#     2   489    15\n\n\nsummary(boston_506$median)\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#    5600   16800   21000   21749   24700   50000      17\n\n다음으로, 비검열 주택가격 값을 가진 나머지 489개 트랙트로 서브셋을 구성하고, 여기에 맞추어 이웃 객체도 조정한다. 이 과정 후에는 비이웃 관측값이 하나 발생한다.\n\nboston_506$CHAS &lt;- as.factor(boston_506$CHAS)\nboston_489 &lt;- boston_506[!is.na(boston_506$median),]\nnb_q_489 &lt;- spdep::poly2nb(boston_489)\nlw_q_489 &lt;- spdep::nb2listw(nb_q_489, style = \"W\",\n                            zero.policy = TRUE)\n\n상위 집계 수준을 정의하는 NOX_ID 변수를 활용하여, 트랙트 수준의 데이터를 대기오염 모형 출력 구역 단위로 집계한다. 이 과정에서 이웃 객체와 행표준화 공간가중치 객체를 생성하며, NOX 변수는 평균값으로 재계산하고, 찰스강 상에 위치한 관측 단위 여부를 나타내는 더미 변수 CHAS 역시 재계산한다. 여기서는 5.3.1절에서 설명한 원칙, 즉 공간 외연 변수와 공간 내포 변수를 구분하여 다루는 원칙을 따른다. NOX와 CHAS는 모두 카운트 변수가 아니므로, 합계를 통해 재계산할 수 없다.\n\nagg_96 &lt;- list(as.character(boston_506$NOX_ID))\nboston_96 &lt;- aggregate(boston_506[, \"NOX_ID\"], by = agg_96,\n                       unique)\nnb_q_96 &lt;- spdep::poly2nb(boston_96)\nlw_q_96 &lt;- spdep::nb2listw(nb_q_96)\nboston_96$NOX &lt;- aggregate(boston_506$NOX, agg_96, mean)$x\nboston_96$CHAS &lt;-\n    aggregate(as.integer(boston_506$CHAS)-1, agg_96, max)$x\n\n반응변수의 집계는 matrixStats 패키지의 weightedMedian() 함수를 사용하여, 주택가격 클래스의 중간값을 기준으로 계산한다. 주택가격 클래스별 주택 수를 산출하는 것은 매우 중요한데, 이는 센서스 공표 데이터를 검증하는 데에도 활용될 수 있다. 트랙트 수준에서 weightedMedian() 함수를 적용하면 공표된 값이 그대로 재현되는 것을 확인할 수 있다. 반응변수를 집계한 결과, 두 개의 출력 구역에서 가중 중위값이 센서스 문항의 최상위 주택가격 한계값(5만 달러)을 초과하는 것으로 나타났다. 이들 구역은, 최상위 가격 구간에 대해 적절히 대체할 값을 알 수 없다는 문제에도 영향을 받으므로, 최종적으로 분석에서 제외하였다. 주택가격 클래스별 주택 수를 계산하는 것은 공간 외연 변수의 집계에 해당하므로, 재계산 함수로 합계를 적용하는 것이 적절하다.\n\nnms &lt;- names(boston_506)\nccounts &lt;- 23:31\nfor (nm in nms[c(22, ccounts, 36)]) {\n  boston_96[[nm]] &lt;- aggregate(boston_506[[nm]], agg_96, sum)$x\n}\nbr2 &lt;- \n  c(3.50, 6.25, 8.75, 12.5, 17.5, 22.5, 30, 42.5, 60) * 1000\ncounts &lt;- as.data.frame(boston_96)[, nms[ccounts]]\nf &lt;- function(x) matrixStats::weightedMedian(x = br2, w = x,\n                                     interpolate = TRUE)\nboston_96$median &lt;- apply(counts, 1, f)\nis.na(boston_96$median) &lt;- boston_96$median &gt; 50000\nsummary(boston_96$median)\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#    9009   20417   23523   25263   30073   49496       2\n\n나머지 공변량은 트랙트 수준의 센서스 인구수를 가중치로 하여 가중평균을 산출함으로써(Bivand 2017) 집계한다. 이는 해당 공변량들이 카운트 데이터가 아니라 공간 내포 변수이기 때문에 적용되는 방식이다. 이 집계 과정을 마친 뒤, 이어서 서브셋을 구성한다.\n\nPOP &lt;- boston_506$POP\nf &lt;- function(x) matrixStats::weightedMean(x[,1], x[,2])\nfor (nm in nms[c(9:11, 14:19, 21, 33)]) {\n  s0 &lt;- split(data.frame(boston_506[[nm]], POP), agg_96)\n  boston_96[[nm]] &lt;- sapply(s0, f)\n}\nboston_94 &lt;- boston_96[!is.na(boston_96$median),]\nnb_q_94 &lt;- spdep::subset.nb(nb_q_96, !is.na(boston_96$median))\nlw_q_94 &lt;- spdep::nb2listw(nb_q_94, style=\"W\")\n\n이제 두 개의 데이터셋이 서로 다른 두 수준에서 존재한다. 하나는 하위 수준인 센서스 트랙트 수준이고, 다른 하나는 상위 수준인 대기오염 모형 출력 구역 수준이다. 하나는 검열된 관측값을 포함하며, 다른 하나는 이를 제외한 데이터이다.\n\nboston_94a &lt;- aggregate(boston_489[,\"NOX_ID\"], \n                        list(boston_489$NOX_ID), unique)\nnb_q_94a &lt;- spdep::poly2nb(boston_94a)\nNOX_ID_no_neighs &lt;-\n        boston_94a$NOX_ID[which(spdep::card(nb_q_94a) == 0)]\nboston_487 &lt;- boston_489[is.na(match(boston_489$NOX_ID,\n                                     NOX_ID_no_neighs)),]\nboston_93 &lt;- aggregate(boston_487[, \"NOX_ID\"],\n                       list(ids = boston_487$NOX_ID), unique)\nrow.names(boston_93) &lt;- as.character(boston_93$NOX_ID)\nnb_q_93 &lt;- spdep::poly2nb(boston_93,\n        row.names = unique(as.character(boston_93$NOX_ID)))\n\n원래 모형은 트랙트별 중위 주택가격의 로그값과 NOX 값 제곱 간의 관련성을 분석한 것이었으며, 여기에 트랙트별 주택가격과 다른 공변량들(예: 총 방 수, 총 연령, 민족, 사회적 지위, 중심가까지의 거리, 가장 가까운 방사형 도로까지의 거리, 범죄율, 도시 수준 변수 등)도 포함되었다(Bivand 2017). 이 데이터를 활용하여 공간 회귀모형을 적합할 때 발생할 수 있는 여러 문제를 살펴볼 것이다. 또한, 이 데이터는 다수준 이슈를 다루는 데에도 유용하다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "16.html#보스턴-주택가격-데이터셋에-대한-다수준모형",
    "href": "16.html#보스턴-주택가격-데이터셋에-대한-다수준모형",
    "title": "16  공간적 회귀분석",
    "section": "\n16.2 보스턴 주택가격 데이터셋에 대한 다수준모형",
    "text": "16.2 보스턴 주택가격 데이터셋에 대한 다수준모형\nZN, INDUS, NOX, RAD, TAX, PTRATIO 변수는 TASSIM 구역 내에서 변동이 거의 없어, 다수준모형에서는 이들 변수의 설명력이 고정효과가 아니라 랜덤효과에 의해 대부분 포착될 수 있다.\n\nform &lt;- formula(log(median) ~ CRIM + ZN + INDUS + CHAS + \n                I((NOX*10)^2) + I(RM^2) + AGE + log(DIS) +\n                log(RAD) + TAX + PTRATIO + I(BB/100) + \n                log(I(LSTAT/100)))\n\n\n16.2.1 IID 랜덤효과: lme4 패키지의 활용\nlme4 패키지(Bates et al. 2022)는 모형 출력 구역 수준에서 독립동일분포(IID, independent and identically distributed)를 따르는 비구조적 랜덤효과를 추가할 수 있도록 지원한다. 이는 모형 공식에 랜덤효과 항을 추가하거나 갱신하는 방식으로 구현된다.(역자주: ’독립동일분포’는 통계학에서 각 확률변수가 서로 독립이며(independent), 동일한 확률분포(identical distribution)를 따른다는 가정을 의미한다. 이는 표본의 모든 관측값이 서로 영향을 주지 않고, 같은 분포에서 동일한 확률법칙에 의해 생성된다는 것을 뜻한다. IID 가정은 확률론과 통계추론에서 자주 사용되며, 특히 회귀분석과 혼합효과모형의 랜덤효과를 단순화할 때 기본 전제로 활용된다.)\n\nlibrary(Matrix)\nlibrary(lme4)\nMLM &lt;- lmer(update(form, . ~ . + (1 | NOX_ID)), \n            data = boston_487, REML = FALSE)\n\n랜덤효과를 \"sf\" 객체에 복사하여, 이후 지도로 시각화할 수 있다.\n\nboston_93$MLM_re &lt;- ranef(MLM)[[1]][,1]\n\n\n16.2.2 IID와 CAR 랜덤효과: hglm 패키지의 활용\n동일한 모형을 hglm 패키지(Alam, Ronnegard, and Shen 2019)를 사용하여 추정할 수 있다. 이 경우, 랜덤효과 항은 한쪽 방향 포뮬러(one-sided formula)를 추가하는 방식으로 지정된다.(역자주: ’한쪽 방향 포뮬러’는 회귀모형에서 반응변수를 지정하지 않고 설명변수나 효과만을 기술하는 공식 형태를 말한다. 예를 들어, ~ 1 | group과 같이 작성하면, 종속변수 없이 그룹 단위의 랜덤효과 구조만을 정의하게 된다. 이는 주로 랜덤효과나 특정 구조적 효과를 모형에 추가할 때 사용되며, hglm 패키지와 같이 랜덤효과 항을 별도로 지정하는 함수에서 자주 활용된다.)\n\nlibrary(hglm) |&gt; suppressPackageStartupMessages()\nsuppressWarnings(HGLM_iid &lt;- hglm(fixed = form,\n                                  random = ~1 | NOX_ID,\n                                  data = boston_487,\n                                  family = gaussian()))\nboston_93$HGLM_re &lt;- unname(HGLM_iid$ranef)\n\nhglm 패키지는 공간적으로 구조화된 SAR 및 CAR 랜덤효과도 다룰 수 있도록 확장되었으며, 이 경우 희소 공간가중치행렬이 필요하다(Alam, Rönnegård, and Shen 2015). 여기서는 이진 공간가중치를 사용한다.\n\nlibrary(spatialreg)\nW &lt;- as(spdep::nb2listw(nb_q_93, style = \"B\"), \"CsparseMatrix\")\n\nand.family 인수를 사용하여 상위 수준에서 CAR 모형을 적합한다. 이 때 인덱싱 변수인 NOX_ID의 값은 \\(W\\)의 행 이름과 일치해야 한다.\n\nsuppressWarnings(HGLM_car &lt;- hglm(fixed = form,\n                                  random = ~ 1 | NOX_ID,\n                                  data = boston_487,\n                                  family = gaussian(),\n                                  rand.family = CAR(D=W)))\nboston_93$HGLM_ss &lt;- HGLM_car$ranef[,1]\n\n\n16.2.3 IID와 ICAR 랜덤효과: R2BayesX 패키지의 활용\nR2BayesX 패키지(Umlauf et al. 2022)는 공간 다수준모형을 포함한 다양한 구조화된 가법(additive) 회귀모형을 지원한다.(역자주: ’구조화된 가법 회귀모형’은 종속변수를 설명하기 위해 여러 개의 함수적 구성요소를 부가하는 형태를 가지면서, 각 구성요소에 사전 구조(prior structure)나 제약조건을 부여한 회귀모형을 말한다. 예를 들어, 선형항(고정효과), 비선형 평활항, 공간적 랜덤효과, 시계열 효과 등을 동일한 모형 안에서 더해 표현할 수 있으며, 각 항의 형태나 상관 구조를 사용자가 지정할 수 있다. 이러한 접근은 일반화 가법모형(GAM)을 확장한 개념으로, R2BayesX나 mgcv 패키지에서 다양한 구조의 항을 포함하는 모형을 구현할 수 있다.) 지원 모형 중 하나가 상위 수준에서의 IID 비구조적 랜덤효과 모형이며, 이를 지정하려면 sx 모형 항에 \"re\" 사양을 사용하면 된다(Umlauf et al. 2015). 이때 추정 방법으로 \"MCMC\" 메서드를 선택한다.\n\nlibrary(R2BayesX) |&gt; suppressPackageStartupMessages()\n\n\nBX_iid &lt;- bayesx(update(form, . ~ . + sx(NOX_ID, bs = \"re\")),\n                 family = \"gaussian\", data = boston_487,\n                 method = \"MCMC\", iterations = 12000,\n                 burnin = 2000, step = 2, seed = 123)\n\n\nboston_93$BX_re &lt;- BX_iid$effects[\"sx(NOX_ID):re\"][[1]]$Mean\n\n상위 수준의 \"nb\" 객체를 기반으로 \"mrf\"(Markov Random Field) 사양을 선택하여, 공간적으로 구조화된 내재적 CAR 랜덤효과를 지정한다. \"nb\" 객체의 \"region.id\" 속성에는 sx 효과 항의 인덱싱 변수와 일치하는 값이 포함되어야 한다. 이는 설계행렬 \\(Z\\)의 내부 구조화를 용이하게 하기 위함이다.\n\nRBX_gra &lt;- nb2gra(nb_q_93)\nall.equal(row.names(RBX_gra), attr(nb_q_93, \"region.id\"))\n# [1] TRUE\n\n앞서 살펴본 내재적 CAR 모형의 정의에서와 같이, 이웃 수는 대각 원소에 입력된다. 그러나 현재 구현에서는 희소 행렬이 아닌 밀집 행렬을 사용한다.\n\nall.equal(unname(diag(RBX_gra)), spdep::card(nb_q_93))\n# [1] TRUE\n\nsx 모형 항은 여전히 인덱싱 변수를 포함하며, 이번에는 내재적 CAR 정밀행렬을 거쳐 처리된다.\n\nBX_mrf &lt;- bayesx(update(form, . ~ . + sx(NOX_ID, bs = \"mrf\",\n                                         map = RBX_gra)), \n                 family = \"gaussian\", data = boston_487,\n                 method = \"MCMC\", iterations = 12000,\n                 burnin = 2000, step = 2, seed = 123)\n\n\nboston_93$BX_ss &lt;- BX_mrf$effects[\"sx(NOX_ID):mrf\"][[1]]$Mean\n\n\n16.2.4 IID, ICAR, Leroux 랜덤효과: INLA 패키지의 활용\nBivand, Gómez-Rubio와 Rue(2015) 및 Gómez-Rubio(2020)는 INLA 패키지(Rue, Lindgren, and Teixeira Krainski 2022)와 공간 회귀모형에 대한 inla() 모형 적합 함수를 사용하는 방법을 설명한다.\n\nlibrary(INLA) |&gt; suppressPackageStartupMessages()\n\n세부적인 차이는 있으나, 고정모형 공식을 비구조적 랜덤효과 항으로 갱신하는 접근 방식은 앞서 살펴본 방법과 매우 유사하다.\n\nINLA_iid &lt;- inla(update(form, . ~ . + f(NOX_ID, model = \"iid\")),\n                 family = \"gaussian\", data = boston_487)\n\n\nboston_93$INLA_re &lt;- INLA_iid$summary.random$NOX_ID$mean\n\n대부분의 구현과 마찬가지로, 공간가중치와 인덱싱 변수가 일치하도록 주의해야 한다. 여기서는 NOX_ID 변수를 직접 사용하는 대신, 1부터 93까지의 인덱스를 사용한다.\n\nID2 &lt;- as.integer(as.factor(boston_487$NOX_ID))\n\n동일한 희소 이진 공간가중치행렬을 사용하며, 내재적 CAR 표현은 내부적으로 생성된다.\n\nINLA_ss &lt;- inla(update(form, . ~ . + f(ID2, model = \"besag\",\n                                       graph = W)),\n                family = \"gaussian\", data = boston_487)\n\n\nboston_93$INLA_ss &lt;- INLA_ss$summary.random$ID2$mean\n\nGómez-Rubio(2020)가 제시한 희소 Leroux 표현은 다음과 같이 구성할 수 있다.\n\nM &lt;- Diagonal(nrow(W), rowSums(W)) - W\nCmatrix &lt;- Diagonal(nrow(M), 1) -  M\n\n이 모형은 지정된 정밀행렬과 함께 \"generic1\" 모형을 사용하여 추정할 수 있다.\n\nINLA_lr &lt;- inla(update(form, . ~ . + f(ID2, model = \"generic1\",\n                                       Cmatrix = Cmatrix)),\n                family = \"gaussian\", data = boston_487)\n\n\nboston_93$INLA_lr &lt;- INLA_lr$summary.random$ID2$mean\n\n\n16.2.5 ICAR 랜덤효과: mgcv 패키지의 gam() 함수의 활용\n비슷한 방식으로, mgcv 패키지의 gam() 함수(Wood 2022)는 \"nb\" 객체를 사용하여 \"mrf\" 항을 포함할 수 있다. 이 경우, \"nb\" 객체의 \"region.id\" 속성 값을 이웃 목록 구성 요소의 이름으로 복사해야 하며, 인덱싱 변수는 범주형이어야 한다(Wood 2017).\n\nlibrary(mgcv)\nnames(nb_q_93) &lt;- attr(nb_q_93, \"region.id\")\nboston_487$NOX_ID &lt;- as.factor(boston_487$NOX_ID)\n\n공간적으로 구조화된 항의 지정 방식은 앞선 예들과 다소 다르지만, 결과는 동일하다. bayesx() 함수의 \"REML\" 방법은 이 경우 gam() 함수의 \"REML\"을 사용하는 것과 동일한 결과를 산출한다.\n\nGAM_MRF &lt;- gam(update(form, . ~ . + s(NOX_ID, bs = \"mrf\",\n                                      xt = list(nb = nb_q_93))),\n               data = boston_487, method = \"REML\")\n\n상위 수준의 랜덤효과는 예측을 통해 추출할 수 있다. 동일한 상위 수준의 대기질 모형 출력 구역에 속하는 모든 하위 수준 트랙트는 동일한 값을 가진다는 것을 확인할 수 있다.\n\nssre &lt;- predict(GAM_MRF, type = \"terms\", \n                se = FALSE)[, \"s(NOX_ID)\"]\nall(sapply(tapply(ssre, list(boston_487$NOX_ID), c),\n           function(x) length(unique(round(x, 8))) == 1))\n# [1] TRUE\n\n따라서 각 상위 수준 단위에 대해 첫 번째 값을 반환하면 된다.\n\nboston_93$GAM_ss &lt;- aggregate(ssre, list(boston_487$NOX_ID), \n                              head, n=1)$x\n\n\n16.2.6 상위 수준 랜덤효과: 요약\nhglm(), bayesx(), inla(), 그리고 gam() 함수의 경우, 이산형 반응변수를 모형화하는 것도 가능하다. bayesx(), inla(), gam() 함수는 해당 공변량에 대한 기능 형태(functional form) 적합을 일반화하는 데 유리하다.(역자주: ’기능 형태 적합’은 독립변수와 종속변수 간의 관계를 수학적으로 표현하는 함수의 형태를 결정하고, 해당 함수에 데이터를 맞추는(fitting) 과정을 의미한다. 예를 들어, 선형함수, 다항식, 로그함수, 스플라인 등 다양한 형태가 가능하며, 선택된 기능 형태에 따라 변수 간 관계의 해석과 예측 결과가 달라질 수 있다. 특히 공간적 회귀분석에서는 지역 간 상관 구조나 공간적 이질성을 정확히 반영하기 위해, 데이터 특성에 맞는 기능 형태를 유연하게 지정하는 것이 중요하다.)\n그러나 이러한 다수준모형들이 추정한 대기질 변수의 회귀계수는 해석에 큰 도움이 되지 않는다. 모든 계수가 음의 값을 보인 것은 예상대로였지만, 모형 출력 구역 수준 효과와 IID 또는 공간적으로 구조화된 효과가 포함되면서, 관찰 스케일의 영향을 상위 스케일에서의 공변량 효과와 분리해 내기가 어려워졌다.\nFigure 16.1은 대기질 모형 출력 구역 수준의 IID 랜덤효과가 네 가지 모형 적합 함수 모두에서 매우 유사함을 보여준다. 모든 지도에서 중앙 도심 구역은 강한 음의 랜덤효과 값을 보이며, 중앙 도심 인근에서는 강한 양의 값이 나타나고, 교외 지역에서는 0에 가까운 값이 나타난다.\n\n\n\n\n\n그림 16.1: 대기질 모형 출력 구역 수준의 IID 랜덤효과(lme4, hglm, INLA, R2BayesX를 사용하여 추정). 응답변수 (log(median))의 범위는 2.1893이다.\n\n\nFigure 16.2는 공간적으로 구조화된 랜덤효과가 서로 매우 유사하며, \"SAR\" 공간적 평활도가 랜덤효과 값의 범위를 고려할 때 \"CAR\" 평활도보다 약간 더 부드럽다는 것을 보여준다.\n\n\n\n\n\n그림 16.2: 대기질 모형 출력 구역 수준의 공간적으로 구조화된 랜덤효과(lme4, hglm, INLA, R2BayesX, mgcv를 사용하여 추정).\n\n\n다수준 데이터를 처리할 수 있는 공간 회귀모형 적합 함수에 대한 보다 체계적인 비교 연구가 여전히 필요하지만, 최근 몇 년간 상당한 진전이 있었다. Vranckx, Neyens와 Faes(2019)는 질병 매핑 공간 회귀모형에 대한 비교 연구를 수행했으며, 주로 기대빈도를 오프셋으로 설정한 포아송 회귀 프레임워크에 초점을 맞췄다. Bivand와 Gómez-Rubio(2021)는 공간가중치행렬을 이용한 공간 생존모형 추정 방법과 공간 프로빗 모형 간의 비교를 다룬다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "16.html#연습문제",
    "href": "16.html#연습문제",
    "title": "16  공간적 회귀분석",
    "section": "\n16.3 연습문제",
    "text": "16.3 연습문제\n\nHSAR 패키지(https://cran.r-project.org/src/contrib/Archive/HSAR/HSAR_0.5.1.tar.gz)의 아테네 주택 데이터(spData 패키지 2.2.1 버전 포함)를 이용하여 다수준 데이터셋을 생성하시오. 각 자치구역의 속성 값이 해당 구역 내 모든 포인트 관측값에 복사되는 시점은 언제인지 설명하시오.\n상위 수준과 하위 수준 모두에서 이웃 객체를 생성하고, 두 수준 모두에서 greensp 변수의 공간적 자기상관을 검정하시오. 자치구역의 녹지 면적(㎡)을 포인트 서포트를 가지는 부동산 수준으로 복사하여 부여했을 때, 데이터 구조나 분석 결과에 어떤 중요한 영향이 발생하는지 설명하시오.\n위에서 생성한 공식 객체를 사용하여 상위 수준의 변수를 추가하는 것이 타당한지 평가하시오. mgcv 패키지의 gam() 함수를 이용해 선형 혼합효과모형을 적합하되, 자치구역 식별 변수(num_dep)를 사용하여 IID를 지정하시오. 하위 수준 변수만 사용한 모형과 하위와 상위 수준 변수 모두를 사용한 모형을 비교하고, 결론이 달라지는지 설명하시오.\nIID 랜덤효과를 \"mrf\"(마르코프 랜덤 필드)와 앞서 생성한 연접 이웃 객체로 대체하여 분석을 완성하시오. 자치구역 수준 변수(예: greensp)에 근거하여 결론을 내는 것이 타당한지에 대해 견해를 밝히시오.\n\n\n\n\n그림 16.1: 대기질 모형 출력 구역 수준의 IID 랜덤효과(lme4, hglm, INLA, R2BayesX를 사용하여 추정). 응답변수 (log(median))의 범위는 2.1893이다.\n그림 16.2: 대기질 모형 출력 구역 수준의 공간적으로 구조화된 랜덤효과(lme4, hglm, INLA, R2BayesX, mgcv를 사용하여 추정).",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>공간적 회귀분석</span>"
    ]
  },
  {
    "objectID": "14.html",
    "href": "14.html",
    "title": "14  근접성과 에어리어 데이터",
    "section": "",
    "text": "14.1 근접성의 재현: spdep 패키지의 경우\n공간적 자기상관을 그래프상의 이웃 관계를 통해 다루는 접근에서는, 해당 그래프가 주어진 것이며 연구자가 이를 선택한 것으로 간주한다. 이는 지구통계학적 접근과는 다른데, 지구통계학에서는 연구자는 경험적 베리오그램에서 거리를 어떻게 구간화할지, 어떤 함수를 적용할지, 그리고 베리오그램 적합을 어떻게 수행할지를 모두 선택한다. 두 접근법 모두 사전 선택을 포함하지만, 기저 상관성을 재현하는 방식에서는 서로 다르다(Wall 2004). 또한, 그래프 기반 이웃 규정 방식을 보다 넓은 맥락에서 설명하는 시도도 있다(Bavaud, 1998).\n이웃 관계 객체를 생성할 때, 이웃이 없는 구역 단위의 존재는 문제를 야기할 수 있다(Bivand and Portnov 2004). 섬이나 강으로 분리된 구역 단위가 이러한 무이웃 구역 단위에 해당하며, 이는 구역 단위에 에어리어 스포트가 적용되고 공유 경계와 같은 위상 관계가 사용되는 경우에 발생한다. 예를 들어, mgcv::gam과 같은 모형 적합 함수에서 mrf(마르코프 랜덤 필드) 항을 사용할 때, 방향은 필요하지 않지만 그래프가 분리된 하위 그래프들로 구성되는 있으면 에러가 발생한다.\n이러한 무이웃 문제는 포인트 간 거리를 기준으로 이웃을 규정하는 경우에도 발생할 수 있다. 예를 들어, 거리 임계값이 최근린 이웃 거리보다 작은 경우가 이에 해당한다. 공유 경계 기반의 연접성 규정은 좌표계의 종류(투영 좌표계이든 비투영 경위도 좌표이든)에 영향을 받지 않지만, 모든 포인트 기반 접근법은 결국 거리를 사용하므로, 적용하는 투영법의 선택이 결과에 영향을 미칠 수 있다.\nspdep 패키지는 이웃을 규정하는 nb 클래스를 제공한다. nb 클래스는 관측 개체 수를 길이로 하는 리스트이며, 각 구성 요소는 정수 벡터로 이루어진다. 이웃이 없는 경우는 0L이 단일 요소로 포함된 정수 벡터로 인코딩된다. 이웃이 있는 경우는 1L:n 범위 내의 값이 포함된 정수 벡터로 인코딩되며, 해당 값들은 이웃으로 정의된 관측 개체의 인덱스 값이다. 이러한 구조는 소위 ‘행 기반 희소 표현(row-oriented sparse representation)’ 방식이다.(역자주: ’행 기반 희소 표현’은 희소 행렬(전체 원소 중 대부분이 0인 행렬)을 행 단위로 저장하면서, 각 행에서 0이 아닌 원소의 위치와 값을 함께 기록하는 방식이다. 공간가중치행렬처럼 대부분의 원소가 0인 행렬을 메모리 효율적으로 저장하고, 관측 단위별 이웃 정보와 가중치를 빠르게 조회할 수 있다.) spdep 패키지는 nb 객체를 생성하는 다양한 방법을 제공하며, 이 표현과 생성 함수는 다른 패키지에서도 널리 사용된다.\nspdep 패키지는 nb 클래스(무방향 혹은 유방향 그래프)를 기반으로 listw 객체를 구성한다. listw 객체는 세 가지 구성 요소를 갖는 리스트로, nb 객체, 가중치 리스트, 그리고 가중치 계산 방식을 나타내는 단일 요소 문자 벡터가 포함된다. 사회과학 연구에서 가장 흔히 사용되는 방식은 ’행표준화가중치(row-standardized weights)’를 계산하는 것이며, 이 때 개별 관측 개체의 한 이웃 가중치는 해당 관측 개체의 이웃 수(즉, 카디널리티)의 역수, 즉, 1/card(nb)[i])로 변환된다.\n이 장에서는 2015년 폴란드 대통령 선거 데이터를 사용한다. 연구 지역은 총 2,495개의 지방자치단체와 바르샤바 구역으로 구성되어 있다(그림 14.1 참조). 이 지도는 tmap 패키지(8.5절)를 활용해 작성되었으며, 지방자치단체 유형이 표시되어 있다. 구역 단위는 sf 패키지의 sf 객체이며, 투표소 단위의 결과를 구역 단위로 집계한 데이터이다.\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\ndata(pol_pres15, package = \"spDataLarge\")\npol_pres15 |&gt;\n    subset(select = c(TERYT, name, types)) |&gt;\n    head()\n# Simple feature collection with 6 features and 3 fields\n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: 235000 ymin: 367000 xmax: 281000 ymax: 413000\n# Projected CRS: ETRS89 / Poland CS92\n#    TERYT                name       types\n# 1 020101         BOLESŁAWIEC       Urban\n# 2 020102         BOLESŁAWIEC       Rural\n# 3 020103            GROMADKA       Rural\n# 4 020104        NOWOGRODZIEC Urban/rural\n# 5 020105          OSIECZNICA       Rural\n# 6 020106 WARTA BOLESŁAWIECKA       Rural\n#                         geometry\n# 1 MULTIPOLYGON (((261089 3855...\n# 2 MULTIPOLYGON (((254150 3837...\n# 3 MULTIPOLYGON (((275346 3846...\n# 4 MULTIPOLYGON (((251770 3770...\n# 5 MULTIPOLYGON (((263424 4060...\n# 6 MULTIPOLYGON (((267031 3870...\nlibrary(tmap, warn.conflicts = FALSE)\n# Breaking News: tmap 3.x is retiring. Please test v4, e.g. with\n# remotes::install_github('r-tmap/tmap')\ntm_shape(pol_pres15) + tm_fill(\"types\")\nsf 객체의 위상 구조가 밸리드한지 확인한다.\nif (!all(st_is_valid(pol_pres15)))\n        pol_pres15 &lt;- st_make_valid(pol_pres15)\n2002년 초부터 2019년 4월까지 spdep 패키지에는 이웃 및 공간가중치 객체를 생성하고 처리하는 함수, 공간적 자기상관을 검정하는 함수, 그리고 모형 적합과 관련된 함수 등이 포함되어 있었다. 이 중 모형 적합과 관련 함수는 spatialreg 패키지로 분리되었으며, 이에 대해서는 이후 장에서 다룰 예정이다. 현재 spdep 패키지(Bivand 2022)는 sf 클래스와 sp 클래스 객체 모두를 지원한다.\nlibrary(spdep) |&gt; suppressPackageStartupMessages()",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#근접성의-재현-spdep-패키지의-경우",
    "href": "14.html#근접성의-재현-spdep-패키지의-경우",
    "title": "14  근접성과 에어리어 데이터",
    "section": "",
    "text": "그림 14.1: 2015년 폴란드 구역 단위 유형",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#연접성에-기반한-이웃의-규정",
    "href": "14.html#연접성에-기반한-이웃의-규정",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.2 연접성에 기반한 이웃의 규정",
    "text": "14.2 연접성에 기반한 이웃의 규정\nspdep 패키지의 poly2nb() 함수는 pl 인수를 통해 입력된 객체에서 폴리곤 경계를 구성하는 경계 포인트들을 이용한다. 입력 객체는 일반적으로 POLYGON 또는 MULTIPOLYGON 지오메트리를 가진 sf 또는 sfc 객체이다. 각 관측 개체에 대해, 최소 하나의 포인트(기본값인 퀸 방식, queen = TRUE) 또는 최소 두 개의 포인트(루크 방식, queen = FALSE)가 snap 거리 내에 다른 폴리곤의 경계 포인트에 위치하는 지를 확인한다. 거리 계산은 투영법에 관계없이 원 길이 단위에 기반한 평면 거리로 수행된다. 필요한 수의 충분히 가까운 점을 찾으면 검색이 중단된다.\n\nargs(poly2nb)\n\n#  function (pl, row.names = NULL, snap = sqrt(.Machine$double.eps),\n#    queen = TRUE, useC = TRUE, foundInBox = NULL)\nspdep 패키지 1.1-7부터 poly2nb() 함수는 후보 이웃을 찾고 foundInBox를 내부적으로 채우기 위해 sf 패키지의 GEOS 인터페이스를 사용한다. 이 경우, sf 패키지를 통한 GEOS의 공간 인덱싱(STRtree 쿼리 사용)이 기본값으로 설정된다.\n\npol_pres15 |&gt; poly2nb(queen = TRUE) -&gt; nb_q\n\nprint 메서드는 이웃 객체의 요약 구조를 출력한다.\n\nnb_q\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14242 \n# Percentage nonzero weights: 0.229 \n# Average number of links: 5.71\n\nsf 패키지 버전 1.0-0부터는 구체 지오메트리에 대해 기본적으로 s2 패키지(Dunnington, Pebesma, and Rubak 2023)가 사용된다. 이는 poly2nb() 함수에서 사용하는 st_intersects() 함수가 계산을 s2::s2_intersects_matrix() 함수로 전달하기 때문이다(4장 참조). spdep 패키지 버전 1.1-9부터는 sf_use_s2()가 TRUE일 경우 구체 인터섹션을 사용하여 후보 이웃을 찾는다. GEOS와 마찬가지로 s2 라이브러리도 빠른 공간 인덱싱을 사용한다.\n\nold_use_s2 &lt;- sf_use_s2()\n\n\nsf_use_s2(TRUE)\n\n\n(pol_pres15 |&gt; st_transform(\"OGC:CRS84\") -&gt; pol_pres15_ll) |&gt; \n    poly2nb(queen = TRUE) -&gt; nb_q_s2\n\n이 예시에서는 구면 인터섹션과 평면 인터섹션이 동일한 인접 이웃을 생성한다. 두 경우 모두 입력 지오메트리가 밸리드해야 한다.\n\nall.equal(nb_q, nb_q_s2, check.attributes=FALSE)\n# [1] TRUE\n\nnb 객체는 대칭적인 이웃 관계인 i에서 j, j에서 i를 모두 기록한다. 이는 nb 객체가 비대칭적인 관계도 허용하기 때문이다. 그러나 객체 생성 단계에서 이러한 중복은 큰 의미가 없다.\n대부분의 spdep 패키지 함수는 이웃 객체를 생성할 때 row.names 인수를 사용하며, 이 값은 region.id 속성으로 저장된다. row.names 인수가 지정되지 않으면, 첫 번째 인수의 row.names에서 값을 가져온다. region.id 속성은 nb 객체가 원 데이터와 동일한 순서로 정리되어 있는지를 확인하는 데 사용된다. nb 객체의 일부만 추출할 경우, 인덱스는 1:length(subsetted_nb) 범위 내 값으로 재설정되지만, region.id 속성을 통해 원본 객체와의 정확한 연결 정보를 확인할 수 있다. 이는 17.4절에서 간략히 논의할 공간적 회귀 모형의 표본 외 예측에서 사용된다.\n또는 n.comp.nb() 함수를 사용해 이 무방향 그래프의 연결성을 확인할 수도 있다. 일부 모형 추정 기법은 비연결 그래프를 지원하지 않지만, 비연결 그래프가 초래할 문제를 인지하는 것은 중요하다(Freni-Sterrantino, Ventrucci, and Rue 2018).\n\n(nb_q |&gt; n.comp.nb())$nc\n# [1] 1\n\n이 접근법은 이웃 객체를 그래프로 취급한 뒤, 해당 그래프에 대해 그래프 분석을 수행하는 것과 동일하다(Csardi and Nepusz 2006; Nepusz 2022). 먼저 이웃 객체를 이진 희소 행렬로 변환한 후, 그래프 분석을 수행한다(Bates, Maechler, and Jagan 2022).\n\nlibrary(Matrix, warn.conflicts = FALSE)\nlibrary(spatialreg, warn.conflicts = FALSE)\nnb_q |&gt; \n    nb2listw(style = \"B\") |&gt; \n    as(\"CsparseMatrix\") -&gt; smat\nlibrary(igraph, warn.conflicts = FALSE)\n(smat |&gt; graph.adjacency() -&gt; g1) |&gt; \n    count_components()\n# [1] 1\n\n다른 소프트웨어와의 호환성을 위해 이웃 객체를 GAL 형식으로 내보내거나 가져올 수 있다. 이를 위해 write.nb.gal()함수와 read.gal() 함수를 사용한다.\n\ntf &lt;- tempfile(fileext = \".gal\")\nwrite.nb.gal(nb_q, tf)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#그래프에-기반한-이웃의-규정",
    "href": "14.html#그래프에-기반한-이웃의-규정",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.3 그래프에 기반한 이웃의 규정",
    "text": "14.3 그래프에 기반한 이웃의 규정\n구역 단위가 적합한 재현이지만 평면상의 포인트로 관찰된 경우, 연접성은 그래프 기반 이웃을 사용해 근사할 수 있다. 이때 평면은 폴리곤 테셀레이션으로 분할되며, 각 폴리곤 내 모든 지점은 해당 포인트를 가장 가까운 포인트로 갖는다. 가장 간단한 형태는 삼각망(triangulation)을 사용하는 것이며, 여기서는 deldir 패키지의 deldir() 함수를 사용한다.(역자주: 주어진 포인트를 이용해 들로네 삼각망을 형성하고, 그것을 바탕으로 티센 폴리곤을 생성한 후 연접성에 기반하여 포인트 간 이웃 관계를 규정한다.) 이 함수는 \\(i\\)와 \\(j\\) 식별자를 반환하므로, 세로(긴) 형식으로 listw 객체를 구성하기가 용이하다. 이는 과거 S-Plus SpatialStats 모듈에서 사용된 방식이며, nb 객체(가로 형식)를 생성하기 위해 내부적으로 sn2listw() 함수에서 사용되는 방식이기도 하다. 한편 GEOS와 같은 다른 대안은 이웃을 식별하기 위한 충분한 정보를 반환하지 못한다.\n이러한 함수들이 반환한 결과는 graph2nb() 함수를 통해 nb 객체로 변환된다. 이때 sym 인수를 사용해 이웃 관계의 대칭성을 지정할 수 있다. 그래프 기반 방식을 적용하기 위해 폴리곤의 센트로이드(다중 폴리곤의 경우 가장 큰 폴리곤의 센트로이드)를 포인트 재현으로 활용한다. 물론 인구 가중 센트로이드를 구할 수 있다면 더 바람직하다.\n\npol_pres15 |&gt; \n    st_geometry() |&gt; \n    st_centroid(of_largest_polygon = TRUE) -&gt; coords \n(coords |&gt; tri2nb() -&gt; nb_tri)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14930 \n# Percentage nonzero weights: 0.24 \n# Average number of links: 5.98\n\n평균 이웃 수의 측면에서 보면 퀸 방식의 경계 연접성과 유사한 결과가 나타났다. 그러나 nbdists() 함수를 사용해 엣지 길이의 분포를 살펴보면, 상위 4분위수는 약 15 km이지만 최대값은 거의 300 km에 달한다. 이는 전체 지역을 포괄하는 컨벡스헐(convex hull)의 한쪽 변 길이에 버금가는 수준이다.(역자주: 컨벡스헐은 평면 또는 다차원 공간에 분포한 점 집합을 완전히 포함하는 가장 작은 볼록 다각형(또는 볼록 다면체)을 말한다. 쉽게 말해, 모든 점을 고무줄로 감싼 뒤 고무줄이 팽팽하게 당겨져 형성된 경계선이 컨벡스헐에 해당한다. 공간분석에서는 관측 지점의 외곽 경계를 정의하거나, 데이터 범위를 시각화하고 공간적 패턴을 파악하는 데 자주 활용된다. 컨벡스헐은 볼록다각형(convex polygon)의 성질을 가지므로, 내부의 임의의 두 점을 연결한 선분은 항상 헐 내부에 존재한다.) 최소 거리 역시 중요한데, 많은 도시 구역의 센트로이드가 주변 농촌 구역의 센트로이드와 매우 근접해 있기 때문이다.\n\nnb_tri |&gt; \n    nbdists(coords) |&gt; \n    unlist() |&gt; \n    summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     247    9847   12151   13485   14994  296974\n\n삼각망에 의거한 이웃 규정도 연결 그래프를 생성한다.(역자주: 여기서 ’연결 그래프’란 그래프상의 모든 지점이 직ㆍ간접적으로 연결되어 있는 그래프를 말한다.)\n\n(nb_tri |&gt; n.comp.nb())$nc\n# [1] 1\n\n그래프 기반 접근법에는 soi.graph(), relativeneigh(), gabrielneigh() 등의 메서드가 있으며, 여기서는 soi.graph() 함수만 살펴본다.\nsoi.graph() 함수에서 SOI는 영향권(sphere of influence)의 약자이다. 이 함수는 삼각망 이웃에서 비정상적으로 긴 엣지로 표현된 이웃 관계를 제거하여, 실질적인 의미를 갖는 이웃 관계만 남긴다. 이러한 비정상적으로 긴 엣지는 컨벡스헐의 가장자리에서 흔히 나타난다(Avis and Horton, 1985).\n\n(nb_tri |&gt; \n        soi.graph(coords) |&gt; \n        graph2nb() -&gt; nb_soi)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 12792 \n# Percentage nonzero weights: 0.205 \n# Average number of links: 5.13\n\n그러나 삼각망 기반 이웃 관계의 일부를 해체하면, 연결 그래프로서의 전체 특성은 사라지게 된다.\n\n(nb_soi |&gt; n.comp.nb() -&gt; n_comp)$nc\n# [1] 16\n\n이 알고리즘은 비정상적으로 긴 엣지를 제거하도록 설계되었지만, 농촌 구역이 하나의 도시 구역을 완전히 둘러싸고 있는 경우, 매우 가까운 도시-농촌 쌍의 엣지도 잘못 삭제될 수 있다. 이로 인해 15개의 도시-농촌 쌍이 메인 그래프로부터 분리되는 결과가 발생하였다.\n\ntable(n_comp$comp.id)\n# \n#    1    2    3    4    5    6    7    8    9   10   11   12   13 \n# 2465    2    2    2    2    2    2    2    2    2    2    2    2 \n#   14   15   16 \n#    2    2    2\n\n컨벡스헐에서 가장 긴 엣지들이 제거되었지만, 연결되지 않은 이웃 쌍이 발생하면서 ’구멍’이 형성되었다. nb_tri와 nb_soi의 차이는 그림 14.2에서 주황색으로 표시되어 있다.\n\n\n\n\n\n그림 14.2: 삼각망 이웃(오렌지색과 검은색)과 영향권 이웃(검은색)의 비교. 곳곳에 형성된 구멍은 모두 도시 구역이 농촌 구역으로 완전히 둘러싸여 있는 경우에 해당한다(그림 14.1 참조).",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#거리에-기반한-이웃의-규정",
    "href": "14.html#거리에-기반한-이웃의-규정",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.4 거리에 기반한 이웃의 규정",
    "text": "14.4 거리에 기반한 이웃의 규정\n거리 기반 이웃은 dnearneigh() 함수를 사용해 생성할 수 있다. bounds 인수를 통해 거리 구간을 설정할 수 있으며, d1과 d2는 각각 거리의 하한값과 상한값이다. 경위도 좌표계를 사용하고 좌표 객체 x가 주어지며 longlat = TRUE로 설정된 경우, WGS84 기준 타원체를 가정해 킬로미터 단위의 대권 거리를 계산한다. use_s2 = TRUE(기본값)로 설정하면 구체를 가정한 거리 계산을 수행한다(4장 참조). dwithin이 FALSE이고 s2 패키지 버전이 1.0.7보다 크면 s2_closest_edges() 함수가 사용되며, dwithin이 TRUE이고 use_s2 = TRUE이면 s2_dwithin_matrix() 함수가 사용된다. 두 방법 모두 빠른 구형 공간 인덱싱을 사용하지만, s2_closest_edges() 함수의 경우 최소 및 최대 경계를 지정하므로 dnearneigh() 함수의 R 코드에서 한 번의 실행만으로 충분하다.\ndbscan 패키지(Hahsler and Piekenbrock 2022)에 새로운 인수가 추가되어, 2차원 또는 3차원에서 평면 공간 인덱싱을 사용해 이웃을 찾는 기능이 보강되었으며, 대칭성을 확인하는 절차가 필요 없어졌다. 또한, 구면 기하학적 거리 측정을 위한 세 가지 인수도 추가되었다.\n\\(k\\)-최근린 이웃을 위한 knearneigh() 함수는 knn 객체를 반환하며, 이를 knn2nb() 함수를 사용해 nb 객체로 변환된다. 이 함수는 구면 거리 계산도 지원하는데, 이는 평면 거리와는 다른 최근린 이웃을 산출할 수 있기 때문이다. k 값은 작은 숫자로 설정하는 것이 일반적이다. 투영 좌표계에서는 dbscan 패키지를 사용해 최근린 이웃을 더 효율적으로 계산할 수 있다. 이렇게 생성된 nb 객체는 대개 대칭적이지 않으므로, knn2nb() 함수는 대칭성을 강제할 수 있는 sym 인수를 제공한다. 대칭성을 강제하면 모든 단위가 최소 k개의 이웃을 갖게 되지만, 모든 단위가 정확히 k개의 이웃을 갖는 것은 아니다. sf_use_s2() 함수가 TRUE인 경우, 입력 객체가 sf 또는 sfc 클래스일 때 knearneigh() 함수는 빠른 구형 공간 인덱싱을 사용한다.\nnbdists() 함수는 투영 좌표를 사용할 경우 좌표 단위로, 그렇지 않으면 킬로미터 단위로 이웃 관계 엣지의 길이를 반환한다. 거리 밴드의 상한을 설정하려면 먼저 첫 번째 최근린 이웃 거리의 최대값을 찾아야 하며, 이때 반환된 객체의 리스트 구조를 제거하기 위해 unlist() 함수를 사용할 수 있다. sf_use_s2() 함수가 TRUE이면, 입력 객체가 sf 또는 sfc 클래스일 때 nbdists() 함수는 빠른 구형 거리 계산을 사용한다.\n\ncoords |&gt; \n    knearneigh(k = 1) |&gt; \n    knn2nb() |&gt; \n    nbdists(coords) |&gt; \n    unlist() |&gt; \n    summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     247    6663    8538    8275   10124   17979\n\n여기서 첫 번째 최근린 이웃 거리의 최대값은 약 18 km이며, 이를 거리 상한으로 설정하면 모든 단위가 최소 하나 이상의 이웃을 갖게 된다.\n\ncoords |&gt; dnearneigh(0, 18000) -&gt; nb_d18\n\n이 사례에서 보듯, 관측 개체의 수가 많지 않으면 공간 인덱싱을 사용하더라도 실행 시간에서 큰 이점을 얻지 어렵다.\n\ncoords |&gt; dnearneigh(0, 18000, use_kd_tree = FALSE) -&gt; nb_d18a\n\n그리고 산출되는 객체 역시 동일하다.\n\nall.equal(nb_d18, nb_d18a, check.attributes = FALSE)\n# [1] TRUE\n\n\nnb_d18\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 20358 \n# Percentage nonzero weights: 0.327 \n# Average number of links: 8.16\n\n이웃이 없는 관측값은 없지만(이는 nb 객체의 print 메소드에서 확인할 수 있음), 그래프는 완전 연결 상태가 아니다. 한 쌍의 관측 개체가 서로의 유일한 이웃인 경우가 있기 때문이다.\n\n(nb_d18 |&gt; n.comp.nb() -&gt; n_comp)$nc\n# [1] 2\n\n\ntable(n_comp$comp.id)\n# \n#    1    2 \n# 2493    2\n\n임계값에 300m를 추가하면, 비이웃 관측 단위가 없는 이웃 객체가 생성되며 모든 관측 단위가 그래프를 통해 서로 도달 가능해진다.\n\n(coords |&gt; dnearneigh(0, 18300) -&gt; nb_d183)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 21086 \n# Percentage nonzero weights: 0.339 \n# Average number of links: 8.45\n\n\n(nb_d183 |&gt; n.comp.nb())$nc\n# [1] 1\n\n거리 기반 이웃의 특징 중 하나는, 면적이 작은 단위가 밀집된 지역일수록 이웃 수가 많아진다는 점이다. 예를 들어, 바르샤바 구역은 평균 면적이 훨씬 작지만 이 거리 기준으로 약 30개의 이웃을 가진다. 이웃 수가 많아지면, 개별 이웃의 영향이 더 많은 이웃에게 분산되어 관계가 완화된다.(역자주: 여기서 ’관계가 완화된다’는 것은 공간 가중 행렬에서 특정 관측 단위의 영향이 소수의 이웃에 집중되는 대신, 더 많은 이웃에 분산되어 각 이웃이 받는 영향이 상대적으로 약해지는 것을 의미한다.)\n나중에 사용하기 위해, 16 km의 임계값을 사용하여 비이웃 단위가 포함된 이웃 객체도 생성한다.\n\n(coords |&gt; dnearneigh(0, 16000) -&gt; nb_d16)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 15850 \n# Percentage nonzero weights: 0.255 \n# Average number of links: 6.35 \n# 7 regions with no links:\n# 569 1371 1522 2374 2385 2473 2474\n\n\\(k\\)-최근린 이웃을 사용하면 이웃의 수를 직접적으로 제어할 수 있으며, 비대칭 이웃을 허용하는 것도 가능하다.\n\n((coords |&gt; knearneigh(k = 6) -&gt; knn_k6) |&gt; knn2nb() -&gt; nb_k6)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14970 \n# Percentage nonzero weights: 0.24 \n# Average number of links: 6 \n# Non-symmetric neighbours list\n\n또는 대칭성을 부여할 수도 있다.\n\n(knn_k6 |&gt; knn2nb(sym = TRUE) -&gt; nb_k6s)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 16810 \n# Percentage nonzero weights: 0.27 \n# Average number of links: 6.74\n\n여기서 k 값은 완전 연결성을 보장할 만큼 크지만, 그래프가 반드시 평면성을 가지는 것은 아니다. 이는 엣지가 노드가 아닌 지점에서 교차하기 때문이며, 이러한 현상은 연접성 기반 이웃이나 그래프 기반 이웃에서는 발생하지 않는다.(역자주: 여기서 ’평면성을 가지지 않는다’는 것은, 네트워크를 2차원 평면 위에 배치했을 때 엣지가 서로 교차하는 경우가 발생함을 의미한다. 평면 그래프에서는 엣지가 반드시 노드에서만 교차해야 하지만, \\(k\\)-최근린 이웃 그래프는 거리 기준으로 연결되기 때문에 노드가 아닌 위치에서 엣지가 교차하는 비평면 구조가 나타날 수 있다.)\n\n(nb_k6s |&gt; n.comp.nb())$nc\n# [1] 1\n\n구체 상의 포인트인 경우(4장 참조), st_centroid() 함수의 출력이 달라질 수 있으므로, 포인트를 직접 역투영하기 보다는 역투영된 폴리곤 지오메트리에서 경위도 좌표를 추출한다.\n\nold_use_s2 &lt;- sf_use_s2()\n\n\nsf_use_s2(TRUE)\n\n\npol_pres15_ll |&gt; \n    st_geometry() |&gt; \n    st_centroid(of_largest_polygon = TRUE) -&gt; coords_ll\n\n구면 좌표의 경우, 이웃 판정을 위한 거리 구간의 경계값은 킬로미터 단위로 지정된다.\n\n(coords_ll |&gt; dnearneigh(0, 18.3, use_s2 = TRUE, \n                         dwithin = TRUE) -&gt; nb_d183_ll)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 21140 \n# Percentage nonzero weights: 0.34 \n# Average number of links: 8.47\n\n이 이웃들은 예상한 바와 같이 구면 거리 18.3 km 기준의 이웃들과는 다르다.\n\nisTRUE(all.equal(nb_d183, nb_d183_ll, check.attributes = FALSE))\n# [1] FALSE\n\ns2 패키지가 더 빠른 거리 기반 이웃 인덱싱을 제공하는 경우, 경위도 좌표에서는 기본적으로 s2_closest_edges() 함수가 사용된다.\n\n(coords_ll |&gt; dnearneigh(0, 18.3) -&gt; nb_d183_llce)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 21140 \n# Percentage nonzero weights: 0.34 \n# Average number of links: 8.47\n\n이 경우, 두 s2 기반 이웃 객체는 동일하다.\n\nisTRUE(all.equal(nb_d183_llce, nb_d183_ll,\n                 check.attributes = FALSE))\n# [1] TRUE\n\ns2 패키지를 사용해 빠른 구형 공간 인덱싱으로 \\(k\\)-최근린 이웃을 찾는다.\n\n(coords_ll |&gt; knearneigh(k = 6) |&gt; knn2nb() -&gt; nb_k6_ll)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14970 \n# Percentage nonzero weights: 0.24 \n# Average number of links: 6 \n# Non-symmetric neighbours list\n\n이 이웃들은 예상대로 평면 기준 k = 6 최근린 이웃과는 다르며, 전통적인 브루트포스(brute-force) 방식의 타원체 거리 계산 결과와도 약간 차이가 날 것이다.(역자주: 브루트포스 방식의 타원체 거리 계산은 지구를 타원체로 가정했을 때 두 지점 간 거리를 구하는 공식을 최적화 없이 모든 점 쌍에 대해 직접 적용하는 전수검사식 방법이다. 계산량이 많아 속도가 느리지만, 알고리즘이 단순하고 결과가 정확하다는 장점이 있다.)\n\nisTRUE(all.equal(nb_k6, nb_k6_ll, check.attributes = FALSE))\n# [1] FALSE\n\nnbdists() 함수도 sf 또는 sfc 클래스의 투입 객체가 경위도 좌표값을 가질 경우, s2 패키지를 사용해 구면 거리를 계산하며, 반환 거리는 킬로미터 단위로 표시된다.\n\nnb_q |&gt; nbdists(coords_ll) |&gt; unlist() |&gt; summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     0.2     9.8    12.2    12.6    15.1    33.0\n\n동일한 가중치 객체라도 평면 좌표를 사용할 경우와 구형 또는 타원체 지오메트리를 사용할 경우에는 계산된 거리 값이 약간 다르다(평면 지오메트리의 경우 거리는 투영 좌표계의 단위(보통 미터)로 반환되며, 타원체와 구형 지오메트리의 경우 거리는 킬로미터 단위로 반환된다).\n\nnb_q |&gt; nbdists(coords) |&gt; unlist() |&gt; summary()\n#    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#     247    9822   12173   12651   15117   33102\n\n\nsf_use_s2(old_use_s2)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#가중치-지정",
    "href": "14.html#가중치-지정",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.5 가중치 지정",
    "text": "14.5 가중치 지정\n이웃 객체를 기반으로 가중치 객체를 지정한다. 이 과정에서 몇 가지 선택을 해야 한다. nb2listw() 함수는 nb 객체를 바탕으로 listw 가중치 객체를 생성한다. 가중치 객체는 가중치 벡터 리스트와 가중치 스타일을 나타내는 선택값으로 구성된다. 이 때 중요한 사안 중 하나는 비이웃 관측 개체의 처리 방식이며, 이를 zero.policy 인수가 제어한다. 기본값은 FALSE로, 비이웃 관측 개체가 조재하면 오류를 발생시킨다. 이는 관측 개체가 이웃을 갖지 않으면 공간래그값(spatially lagged values)을 계산할 수 없기 때문이다.(역자주: ‘spatially lagged values’는 국내에서 ‘공간지연값’, ‘공간시차값’, ‘공간지체값’, ‘공간래그값’ 등 다양한 번역어가 사용된다. 본 역서에서는 ’공간래그값’을 표준 표기로 사용한다. 그 이유는 ’lag’가 시계열 분석에서 시간적 지연을 뜻하는 용어이지만, 공간통계에서의 시간과 무관하게 주변 공간 단위의 값을 공간가중치행렬을 이용해 가중 평균한 값을 의미한다. 따라서 ’지연’이나 ’지체’처럼 시간적 어감이 강한 번역어는 공간적 개념을 설명하는 데 부적절하므로, 학계에서 널리 쓰이는 음역어 ’래그’를 채택하였다.) 일반적으로 비이웃 관측 개체에 대해 공간래그값을 0으로 부여하는데, 이는 제로 값의 가중치 벡터와 데이터 벡터의 교차곱과 동일하기 때문에 zero.policy라는 이름이 붙여졌다.\n\nargs(nb2listw)\n\n#  function (neighbours, glist = NULL, style = \"W\", zero.policy =\n#    NULL)\n스타일 선택을 변경했을 때의 결과를 보여주기 위해, 아래에서 도우미 함수 spweights.constants를 사용한다. 이 함수는 listw 객체에 대한 여러 상수 값을 반환한다. 여기서 \\(n\\)은 관측 개체의 수이며, n1부터 n3은 \\(n-1,...,\\) nn은 \\(n^2\\)을 의미한다. \\(S_0\\), \\(S_1\\), \\(S_2\\)는 상수로, \\(S_0\\)는 가중치의 합을 나타낸다. 이러한 상수들에 대한 자세한 논의는 Bivand와 Wong(2018)를 참고하면 된다.\n\nargs(spweights.constants)\n\n#  function (listw, zero.policy = NULL, adjust.n = TRUE)\n\"B\" 바이너리 스타일은 각 이웃 관계에 단위 값(1)을 부여한다. 이 방식은 이웃을 규정하는 경계가 존재하는 가장자리 구역 단위에 비해, 더 많은 이웃을 가질 수 있는 내부 구역 단위에 상대적으로 더 높은 가중치를 부여하게 된다.\n\n(nb_q |&gt; \n    nb2listw(style = \"B\") -&gt; lw_q_B) |&gt; \n    spweights.constants() |&gt; \n    data.frame() |&gt; \n    subset(select = c(n, S0, S1, S2))\n#      n    S0    S1     S2\n# 1 2495 14242 28484 357280\n\n\"W\" 행 표준화 스타일은 연구 지역의 가장자리에 위치하여 필연적으로 더 적은 수의 이웃을 가질 수 밖에 없는 구역 단위에 더 높은 가중치를 부여한다. 이 방식은 먼저 각 이웃 관계에 단위 값을 가중치로 부여한 뒤, 이를 해당 구역 단의의 가중치 합으로 나누어 표준화한다. 비이웃 구역 단위의 경우 0을 0으로 나누게 되어 ‘부정(not-a-number)’ 값이 발생하지만, zero.policy를 TRUE로 설정하면 문제가 없다. 행 표준화 스타일에서는 \\(S_0\\)는 \\(n\\)과 같아진다.\n\n(nb_q |&gt; \n        nb2listw(style = \"W\") -&gt; lw_q_W) |&gt; \n    spweights.constants() |&gt; \n    data.frame() |&gt; \n    subset(select = c(n, S0, S1, S2))\n#      n   S0  S1    S2\n# 1 2495 2495 958 10406\n\n역거리 가중치는 여러 과학 분야에서 사용된다. 일부에서는 밀집된 역거리 행렬을 사용하지만, 이 경우 많은 역거리 값이 거의 0에 가까워 실제적으로 기여하는 바가 적으며, 특히 공간 프로세스 행렬 자체가 밀집된 경우 그 영향은 더욱 제한적이다. 역거리 가중치는 보통 다음과 같은 절차로 구성된다. 먼저 엣지 길이를 계산하고, 대부분의 가중치 값이 지나치게 크거나 작지 않도록 단위를 변환하며(예: 미터를 킬로미터로 변환), 이를 역수로 변환한 뒤, nb2listw() 함수의 glist 인수로 전달한다.(역자주: “밀집된 역거리 행렬에서 많은 값이 0에 가깝다”는 것은, 거리의 역수를 취했을 때 멀리 떨어진 단위들 간의 가중치가 극도로 작아져, 공간분석에서 거의 영향력을 행사하지 못한다는 의미이다. 특히 공간 프로세스 행렬 자체가 이미 대부분의 단위들 간 연결을 포함하고 있다면, 이러한 미소 가중치는 분석 결과에 실질적인 변화를 주지 않는다.)\n\nnb_d183 |&gt; \n    nbdists(coords) |&gt; \n    lapply(function(x) 1/(x/1000)) -&gt; gwts\n(nb_d183 |&gt; nb2listw(glist=gwts, style=\"B\") -&gt; lw_d183_idw_B) |&gt; \n    spweights.constants() |&gt; \n    data.frame() |&gt; \n    subset(select=c(n, S0, S1, S2))\n#      n   S0  S1   S2\n# 1 2495 1841 534 7265\n\n비이웃 단위의 경우, 기본 설정은 가중치 객체의 생성을 막아 두어, 이후 절차를 어떻게 진행할지에 대해 분석가가 입장을 정하도록 한다.\n\ntry(nb_d16 |&gt; nb2listw(style=\"B\") -&gt; lw_d16_B)\n# Error in nb2listw(nb_d16, style = \"B\") : Empty neighbour sets found\n\nnb와 listw 객체와 관련된 많은 함수에서 zero.policy 인수를 사용할 수 있다.\n\nnb_d16 |&gt; \n    nb2listw(style=\"B\", zero.policy=TRUE) |&gt; \n    spweights.constants(zero.policy=TRUE) |&gt; \n    data.frame() |&gt; \n    subset(select=c(n, S0, S1, S2))\n#      n    S0    S1     S2\n# 1 2488 15850 31700 506480\n\nspweights.constants() 함수의 adjust.n 인수는 기본적으로 TRUE로 설정되어 있어, 비이웃 관측 개체 수를 제외하므로 \\(n\\) 값이 작아지고 통계적 추론에 영향을 줄 수 있다. 원래의 \\(n\\) 값은 인수를 다르게 지정하면 확인할 수 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#고차-이웃의-정의",
    "href": "14.html#고차-이웃의-정의",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.6 고차 이웃의 정의",
    "text": "14.6 고차 이웃의 정의\n앞서 살펴본 퀸 인접성 기반 이웃 객체의 특성은 다음과 같다.\n\nnb_q\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 14242 \n# Percentage nonzero weights: 0.229 \n# Average number of links: 5.71\n\n\\(i\\)가 \\(j\\)의 이웃이고, \\(j\\)가 \\(k\\)의 이웃인 경우, 즉 이웃 그래프에서 두 단계를 거쳐 \\(i\\)에서 \\(k\\)로 이어지는 이웃 관계를 나타내는 객체를 만들고자 한다면, nblag() 함수를 사용할 수 있다. 이 함수는 자동으로 \\(i\\) 에서 \\(i\\)로 가는 자기 이웃 관계를 제거한다.\n\n(nb_q |&gt; nblag(2) -&gt; nb_q2)[[2]]\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 32930 \n# Percentage nonzero weights: 0.529 \n# Average number of links: 13.2\n\nnblag_cumul() 함수는 지정된 모든 차수의 이웃 목록을 누적하여 반환한다.\n\nnblag_cumul(nb_q2)\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 47172 \n# Percentage nonzero weights: 0.758 \n# Average number of links: 18.9\n\nunion.nb() 함수의 집합 연산은 두 개의 객체를 입력받아 처리하며, 이 예시에서는 동일한 결과를 생성한다.\n\nunion.nb(nb_q2[[2]], nb_q2[[1]])\n# Neighbour list object:\n# Number of regions: 2495 \n# Number of nonzero links: 47172 \n# Percentage nonzero weights: 0.758 \n# Average number of links: 18.9\n\n앞에서 이웃 객체를 그래프 형태로 변환하였는데, 이렇게 생성된 그래프 객체를 이용하면 그래프 탐색에 필요한 단계 수에 관한 정보를 얻을 수 있다.\n\ndiameter(g1)\n# [1] 52\n\n각 관측 개체에서 그래프를 통해 최단 경로로 도달하는 데 필요한 단계 수를 계산하여 \\(n \\times n\\) 크기의 sps 행렬을 생성한다. 이를 통해 동일한 최대값을 얻을 수 있다.\n\ng1 |&gt; shortest.paths() -&gt; sps\n(sps |&gt; apply(2, max) -&gt; spmax) |&gt; max()\n# [1] 52\n\n최대값을 가진 지방자치단체는 Lutowiska(루토비스카)로, 남동부의 끝에 위치해 있으며 우크라이나와 국경을 접하고 있다.\n\nmr &lt;- which.max(spmax)\npol_pres15$name0[mr]\n# [1] \"Lutowiska\"\n\n그림 14.3은 연접성 기반 이웃이 거리 기반 이웃과 마찬가지로 다른 관측값들과 동일한 유형의 관계를 나타낸다는 점을 보여준다. 일부 접근법에서는 거리 기반 이웃을 선호하는데, 예를 들어 역거리 가중 이웃은 모든 관측값이 서로 어떻게 연결되어 있는지를 명확히 드러내기 때문이다. 그러나 공간적 자기상관 검정이나 공간 회귀 모형 개발 과정에서는 공간 프로세스 모형의 역행렬을 사용하게 된다.(역자주: ’공간 프로세스 모형의 역행렬’이란, 공간적 자기상관이나 공간 회귀 모형을 계산할 때 수행되는 수학적 역연산을 의미한다. 이 연산 과정에는 공간가중치행렬을 반복적으로 곱하고 더하는 절차가 포함되며, 그 결과 모든 관측값이 서로 영향을 주고받는 관계가 모형에 자동으로 반영된다.) 이 역은 계수와 공간가중치행렬의 곱을 거듭제곱하여 더한 급수로 표현될 수 있으며, 이는 본질적으로 모든 관측값이 다른 모든 관측값과 관계를 맺고 있음을 전제로 한다. 희소 연접성 기반 이웃 객체는 이러한 의존성 구조를 명시적으로 기술하지 않더라도 풍부한 종속 관계를 포괄할 수 있다.\n\n\n\n\n\n그림 14.3: Lutowiska까지의 최단 경로 수와 거리의 관계. 왼쪽 지도는 Lutowiska까지의 최단 경로 수를, 오른쪽 그래프는 최단 경로 수와 거리의 관계를 보여준다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "14.html#연습문제",
    "href": "14.html#연습문제",
    "title": "14  근접성과 에어리어 데이터",
    "section": "\n14.7 연습문제",
    "text": "14.7 연습문제\n\n어떤 유형의 지오메트리 스포트가 이웃 객체를 생성하는 함수에 적합하지 설명하시오.\n이웃 객체를 생성하는 함수 중, 평면 재현에만 사용할 수 있는 것은 무엇인지 설명하시오.\n체스판에서 queen 연접성 대신 rook 연접성을 선택하면 어떤 차이가 발생하는지 설명하시오.\n이웃 집합의 카디널리티(이웃 수)와 행표준화가중치 사이에는 어떤 관계가 있으며, 이러한 관계가 어떻게 엣지 효과(edge effect) 분석을 가능하게 하는지 설명하시오. 3번 문제에서 만든 체스판을 사용하여 rook 이웃과 queen 이웃 각각에 대해 설명하시오.\n\n\n\n\n그림 14.1: 2015년 폴란드 구역 단위 유형\n그림 14.2: 삼각망 이웃(오렌지색과 검은색)과 영향권 이웃(검은색)의 비교. 곳곳에 형성된 구멍은 모두 도시 구역이 농촌 구역으로 완전히 둘러싸여 있는 경우에 해당한다(그림 14.1 참조).\n그림 14.3: Lutowiska까지의 최단 경로 수와 거리의 관계. 왼쪽 지도는 Lutowiska까지의 최단 경로 수를, 오른쪽 그래프는 최단 경로 수와 거리의 관계를 보여준다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>근접성과 에어리어 데이터</span>"
    ]
  },
  {
    "objectID": "15.html",
    "href": "15.html",
    "title": "15  공간적 자기상관 측도",
    "section": "",
    "text": "15.1 측도와 프로세스 오지정\nTobler(1970)가 제시한 지리학의 제1법칙, 즉 “모든 것은 다른 모든 것과 연관되어 있다. 그러나 가까이 있는 것은 멀리 떨어져 있는 것보다 더 많이 연관되어 있다”는 만고의 진리처럼 받아들여져서는 안된다. 이 법칙은 지나치게 단순화된 개념으로, 다른 잠재적 문제들을 가려 버릴 수 있다. 예를 들어 개체화(entitation)의 문제, 스포트 문제, 그리고 오지정(misspecification)의 문제가 이에 해당한다. 관측 단위의 크기가 기저 공간 프로세스의 스케일에 부합하는가? 주어진 관측 단위에서 나타나는 관심 변수의 공간적 패턴이 다른 변수의 공간적 패턴으로 설명될 수 있는가?(역자주: 여기에서 ’개체화’의 문제는 사용된 공간 단위가 해당 공간 현상을 분석하기에 적합한지와 관련된 문제로 소위 ’공간단위 임의성의 문제(MAUP, modifiable areal unit problem)’와 관련된 것이다. ’오지정’의 문제는 통계 모형에서 해당 현상을 설명하기에 적절하지 않은 방식으로 변수 설정이 이루어진 경우를 통칭하는 용어인데, 주로 주요 변수의 누락에서 비롯되는 문제를 지적한다.)\n토블러(Tobler, 1970)의 논문은 올슨(Olsson, 1970)의 논문과 함께 경제지리학(Economic Geography) 저널의 특별호에 실렸다. 그러나 올슨은 공간적 자기상관이 공간 현상에 필연적으로 내재된 속성이 아니라, 부적절한 개체화, 누락된 변수, 그리고/또는 부적절하게 설정된 함수 관계로 인해 발생하는 경우가 더 많다는 점을 간파했다. Olsson의 핵심 인용문은 228쪽에 있다.\n“이러한 자기상관의 존재는 Tobler(1970)가 말한 “모든 것은 다른 모든 것과 연관되어 있다. 그러나 가까이 있는 것은 멀리 떨어져 있는 것보다 더 많이 연관되어 있다”는 주장에 동의하고 싶어지게 만든다. 그러나 한편으로, 이러한 자기상관이 체계적인 오지정 오류를 가리고 있는 것처럼 보인다는 사실은 이 주장을 ’지리학의 제1법칙’으로 격상하는 것이 다소 성급하다는 점을 시사한다. 최악의 경우, 이 주장은 사후 오류(post hoc fallacy, 단순한 우연을 인과 관계로 잘못 해석하는 오류)의 공간적 변형에 불과할 수도 있다.”\n’제1법칙’으로서의 ’확고한 지위’는 존 스노(John Snow)가 지도를 통해 콜레라의 원인이 수인성임을 밝혀냈다는 ’믿음’과 매우 유사하다. 존 스노의 이야기는 GIS를 홍보하는 데 도움이 될 수 있지만, 실제 역사적 사실과는 거리가 있다. 존 스노는 소호(Soho) 지역을 탐문하기 전에 이미 강력한 작업 가설을 갖고 있었으며, 해당 지도는 브로드 스트리트(Broad Street) 펌프가 차단된 이후 그의 가설이 옳았음을 문서화하기 위해 작성된 것이었다(Brody et al. 2000).\n불행히도 공간적 자기상관 측도는 실제 공간 구조뿐 아니라, 모형화 과정에서의 잘못된 지정으로 인한 오류까지 반영할 수 있다(Schabenberger and Gotway 2005; McMillen 2003). 이를 이해하기 위해, 대표적인 공간적 자기상관 측도인 모런 통계량을 정의한 뒤(Cliff and Ord 1981, 17), 단순한 예시를 살펴보자.\n\\[\nI=\\frac {n\\sum_{(2)}w_{ij} z_i z_j}{S_0\\sum^n_{i=1}z^2_i}\n\\]\n여기서 \\(z_i=x_i-\\bar{x}\\), \\(x_i\\)는 해당 변수의 \\(n\\)개의 관측값 중 하나, \\(\\bar{x}=\\sum^n_{i=1}x_i/n\\), \\(\\sum_{(2)}=\\sum^n_{i=1}\\sum^n_{j=1}(i\\neq j)\\), \\(w_{ij}\\)는 공간가중치, \\(S_0=\\sum_{(2)}w_{ij}\\)이다. 먼저, 무작위 확률 변수에 대해 공간적 자기상관을 검토하기 위해 정규성 가정 하에서(인수를 randomisation = FALSE로 지정) 모런 검정을 수행한다. 검정 통계량은 \\(Z(I)=\\frac{I-E(I)}{\\sqrt{Var(I)}}\\)로 정의되며, 계산된 \\(z\\) 값을 \\(E(I)\\)와 \\(Var(I)\\)를 갖는 정규분포와 비교한다. 아래는 무작위 확률 변수에 공간적 자기상관이 존재하지 않는다는 귀무가설을 검정한 결과이다.\nlibrary(spdep) |&gt; suppressPackageStartupMessages()\nlibrary(parallel)\nglance_htest &lt;- function(ht) c(ht$estimate, \n    \"Std deviate\" = unname(ht$statistic), \n    \"p.value\" = unname(ht$p.value))\nset.seed(1)\n(pol_pres15 |&gt; \n    nrow() |&gt; \n    rnorm() -&gt; x) |&gt; \n    moran.test(lw_q_B, randomisation = FALSE,\n               alternative = \"two.sided\") |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#         -0.004772         -0.000401          0.000140 \n#       Std deviate           p.value \n#         -0.369320          0.711889\n이제, 약간의 공간적 경향성을 가진 가상의 변수를 생성하고, 이를 별도의 변수로 취급하지 않고 원래의 무작위 변수에 합산했다고 가정하자. 이 상태에서 동일한 검정을 적용하면 이번에는 강한 공간적 자기상관이 나타난다. 이는 공간적 경향성을 가진 변수를 모형에 포함하지 않아 발생한 변수 누락 오류로, 그 영향이 분석 결과에서 강한 공간적 자기상관으로 잘못 나타난 사례다.\nbeta &lt;- 0.0015\ncoords |&gt; \n    st_coordinates() |&gt; \n    subset(select = 1, drop = TRUE) |&gt; \n    (function(x) x/1000)() -&gt; t\n(x + beta * t -&gt; x_t) |&gt; \n    moran.test(lw_q_B, randomisation = FALSE,\n               alternative = \"two.sided\") |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#          0.043403         -0.000401          0.000140 \n#       Std deviate           p.value \n#          3.701491          0.000214\n공간적 경향성을 가진 변수를 선형모형의 독립변수로 포함하면, 잔차에서 공간적 자기상관이 사라지는 것을 확인할 수 있다.\nlm(x_t ~ t) |&gt; \n    lm.morantest(lw_q_B, alternative = \"two.sided\") |&gt; \n    glance_htest()\n# Observed Moran I      Expectation         Variance      Std deviate \n#        -0.004777        -0.000789         0.000140        -0.337306 \n#          p.value \n#         0.735886\n다양한 공간적 자기상관 측도는 여러 R 패키지에서 이용할 수 있다. 그 가운데 spdep 패키지(Bivand 2022b)가 핵심적인 역할을 담당하며, 패키지 간 차이는 주로 실행 설계와 관련된다(Bivand and Wong 2018). spdep 패키지를 사용하면 회귀 잔차에 대한 전역적 및 국지적 모런 검정을 수행할 수 있으며, 다른 패키지와 달리 정확(exact) 검정과 안장점 근사법(saddlepoint approximation)(Tiefelsdorf 2002; Bivand, Müller, and Reder 2009)을 모두 제공한다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#전역적-측도",
    "href": "15.html#전역적-측도",
    "title": "15  공간적 자기상관 측도",
    "section": "\n15.2 전역적 측도",
    "text": "15.2 전역적 측도\n\n15.2.1 범주 데이터를 위한 조인 카운트 통계량\n먼저 조인 카운트(join-count) 통계량을 살펴보자. 여기서 joincount.test() 함수는 \"factor\" 값 벡터 fx와 listw 객체를 입력받아, stats 패키지에서 정의된 htest(가설 검정) 객체들의 리스트를 반환한다. 반환되는 각 htest 객체는 fx 인수의 각 수준에 대해 하나씩 생성된다. 관찰된 카운트는 동일한 범주 수준을 가진 이웃 쌍의 수를 의미하며, 이를 동일 컬러 조인(same-colour joins)이라고 한다.\n\nargs(joincount.test)\n\n#  function (fx, listw, zero.policy = NULL, alternative = \"greater\",\n#    sampling = \"nonfree\", spChk = NULL, adjust.n = TRUE)\n이 함수는 가설 검정을 위한 alternative 인수와, 통계량의 분산을 구성하는 기준을 지정하는 sampling 인수를 입력받는다. 기본값 \"nonfree\"는 개념적으로 분석적 순열(analytical permutation)과 동일한 것이다.(역자주: ’분석적 순열’은 난수를 사용해 무작위 순열을 생성하지 않고, 가능한 모든 순열의 조합과 그에 따른 검정 통계량 분포를 수학 공식이나 조합론(combinatorics)을 통해 직접 계산하는 방식이다. 즉, 가설 검정을 위한 적률(예: 기대값, 분산 등)을 산출하는 공식이 명시적으로 제시되는 방식이다.) spChk 인수는 이전 버전과의 호환성을 위해 유지된다. 참고로, 앞에서 살펴본 지방자치단체 데이터에 대한 범주 유형별 카운트는 다음과 같다.\n\n(pol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = types, drop = TRUE) -&gt; Types) |&gt; \n    table()\n# \n#          Rural          Urban    Urban/rural Warsaw Borough \n#           1563            303            611             18\n\n네 개의 범주 유형, 즉 네 개의 수준이 있으므로, htest 객체 리스트를 재배열하여 추정 결과를 나타내는 행렬을 생성한다. 관찰된 동일 컬러 조인 카운트는 입력된 범주 수준의 카운트를 기반으로 계산한 기대값과 함께 표로 정리된다. 예를 들어, 바르샤바 구역 간에는 결합이 거의 없을 것으로 예상되는데, 이는 구역 수가 매우 적기 때문이다. 분산 계산은 선택된 listw 객체의 기본 상수와 입력 범주 수준의 카운트를 사용하여 수행된다. \\(z\\) 값은 관찰된 조인 카운트와 기대값의 차이를 분산의 제곱근으로 나누어 산출한다.\n조인 카운트 검정은 다중 컬러조인 카운트 상황으로 확장되도록 수정되었다(Upton and Fingleton 1985). spdep 패키지에서는 joincount.multi() 함수로 구현되어 있으며, 비자유 샘플링(non-free sampling)을 기반으로 표를 반환하되 \\(p\\) 값은 보고하지 않는다.(역자주: ’자유 샘플링(free sampling)’은 각 공간 단위에 레이블(예: 흑과 백)을 독립적으로 무작위 부여하는 방식으로, 샘플링(즉, 재배치)마다 흑백 비율이 달라질 수 있어 복원 샘플링과 유사하다. 반면 ’비자유 샘플링(nonfree sampling)’은 전체에서 흑과 백의 개수를 고정한 채로 무작위 재배치하는 방식으로, 원래 데이터의 비율을 유지하며 비복원 샘플링과 유사하다. 예를 들어 조인 카운트 통계량 검정에서 비자유 샘플링은 원래의 흑백 개수를 그대로 보존한 채 공간 단위의 위치만 바꾸는 방식이다.)\n\nTypes |&gt; joincount.multi(listw = lw_q_B)\n#                               Joincount Expected Variance z-value\n# Rural:Rural                    3087.000 2793.920 1126.534    8.73\n# Urban:Urban                     110.000  104.719   93.299    0.55\n# Urban/rural:Urban/rural         656.000  426.526  331.759   12.60\n# Warsaw Borough:Warsaw Borough    41.000    0.350    0.347   68.96\n# Urban:Rural                     668.000 1083.941  708.209  -15.63\n# Urban/rural:Rural              2359.000 2185.769 1267.131    4.87\n# Urban/rural:Urban               171.000  423.729  352.190  -13.47\n# Warsaw Borough:Rural             12.000   64.393   46.460   -7.69\n# Warsaw Borough:Urban              9.000   12.483   11.758   -1.02\n# Warsaw Borough:Urban/rural        8.000   25.172   22.354   -3.63\n# Jtot                           3227.000 3795.486 1496.398  -14.70\n\n바이너리 가중치를 적용하는 상항에서는 조인 카운트의 합에 해당 조인에 대한 가중치를 곱한 값도 여전히 정수로 나타난다. 그러나 행표준화가중치를 적용하면, 가중치가 대부분 1보다 작은 분수가 되므로 카운트, 기대값, 분산이 달라진다. 그럼에도 최종적인 \\(z\\) 값에는 큰 변화가 없다.\n그러나 역거리 기반의 listw 객체를 사용하면 \\(z\\) 값이 크게 변한다. 이는 가까운 센트로이드에 상대적으로 더 큰 가중치가 부여되기 때문이다.\n\nTypes |&gt; joincount.multi(listw = lw_d183_idw_B)\n#                               Joincount Expected Variance z-value\n# Rural:Rural                    3.46e+02 3.61e+02 4.93e+01   -2.10\n# Urban:Urban                    2.90e+01 1.35e+01 2.23e+00   10.39\n# Urban/rural:Urban/rural        4.65e+01 5.51e+01 9.61e+00   -2.79\n# Warsaw Borough:Warsaw Borough  1.68e+01 4.53e-02 6.61e-03  206.38\n# Urban:Rural                    2.02e+02 1.40e+02 2.36e+01   12.73\n# Urban/rural:Rural              2.25e+02 2.83e+02 3.59e+01   -9.59\n# Urban/rural:Urban              3.65e+01 5.48e+01 8.86e+00   -6.14\n# Warsaw Borough:Rural           5.65e+00 8.33e+00 1.73e+00   -2.04\n# Warsaw Borough:Urban           9.18e+00 1.61e+00 2.54e-01   15.01\n# Warsaw Borough:Urban/rural     3.27e+00 3.25e+00 5.52e-01    0.02\n# Jtot                           4.82e+02 4.91e+02 4.16e+01   -1.38\n\n\n15.2.2 모런 통계량\nspdep 패키지에서 모런 통계량은 moran.test() 함수로 구현되어 있다. 이 함수는 joincount.test() 함수와 유사한 인수를 가지지만, 샘플링 대신 랜덤화(randomisation) 가정을 토대로 측도의 분산을 계산한다. 또한 수치 값 대신 순위를 사용할 수도 있다(Cliff and Ord 1981, 46). 일부 오래된 소프트웨어에서는 분산 항목의 마지막 구성 요소가 생략된 채 표시되는데, drop.EI2 인수는 이를 재현해준다.(역자주: 모런 통계량과 기어리 통계량의 가설 검정에는 전통적으로 두 가지 접근법이 있다. ’랜덤화 가정’은 관측값을 공간단위에 무작위로 재배치하여 경험적 분포를 구성하는 방식으로, 전체 레이블 비율을 유지하는 비자유 샘플링과 유사하다. 반면 ’정규성(normality) 가정’은 관측값이 정규분포를 따른다고 가정하여 이론적 분포를 이용하는 방식으로, 자유 샘플링과 유사하다. 두 접근법은 기대값은 동일하지만 분산이 서로 다르며, 모두 적률(moment)에 대한 공식을 제시하는 분석적 순열 방식이다.)\n\nargs(moran.test)\n\n#  function (x, listw, randomisation = TRUE, zero.policy = NULL,\n#    alternative = \"greater\", rank = FALSE, na.action = na.fail,\n#    spChk = NULL, adjust.n = TRUE, drop.EI2 = FALSE)\nrandomisation 인수의 기본값은 TRUE이며, FALSE로 지정하면 정규성 가정 하에서 검정을 수행한다. 아래 사례를 통해, 단일 변수에 정규성 가정을 적용한 검정 결과와 절편만 포함된 회귀모형의 잔차에 대해 랜덤화 가정 하에서 수행한 검정 결과가 동일하게 나타남을 확인할 수 있다. 해당 변수는 2015년 폴란드 대통령 선거의 투표율이다. randomisation의 철자는 Cliff와 Ord(1973)의 표기를 따른 것이다.\n\npol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = I_turnout, drop = TRUE) -&gt; I_turnout\n\n\nI_turnout |&gt; moran.test(listw = lw_q_B, randomisation = FALSE) |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#          0.691434         -0.000401          0.000140 \n#       Std deviate           p.value \n#         58.461349          0.000000\n\nlm.morantest() 함수는 resfun 인수를 가지고 있는데, 이를 통해 검정에 사용할 잔차를 추출하는 함수를 지정할 수 있다. 이를 활용하면 종속 변수의 다른 중요한 특성을 모형화할 수 있다(Cliff and Ord 1981, 203). 단일 변수에 대한 표준 검정과 비교하기 위해, 여기서는 절편만 포함된 회귀모형을 사용하였으며 그 결과가 동일함을 확인할 수 있다.\n\nlm(I_turnout ~ 1, pol_pres15) |&gt; \n    lm.morantest(listw = lw_q_B) |&gt; \n    glance_htest()\n# Observed Moran I      Expectation         Variance      Std deviate \n#         0.691434        -0.000401         0.000140        58.461349 \n#          p.value \n#         0.000000\n\n정규성 가정과 랜덤화 가정 하에서의 검정 차이는, 변수의 첨도가 정상 범위를 벗어나는 경우 추가 항목이 더해진다는 점이다. 이때 사용되는 척도는 고전적인 첨도 측정법이다. 기본값인 랜덤화 가정 하에서는 결과가 크게 달라지지 않는다.\n\n(I_turnout |&gt; \n    moran.test(listw = lw_q_B) -&gt; mtr) |&gt; \n    glance_htest()\n# Moran I statistic       Expectation          Variance \n#          0.691434         -0.000401          0.000140 \n#       Std deviate           p.value \n#         58.459835          0.000000\n\n1970년대 초반부터 몬테카를로(Monte Carlo) 검정, 즉 호프(Hope) 유형의 검정 또는 순열 부트스트랩(permutation bootstrap)으로 알려진 검정 절차에 대한 관심이 제기되었다. 기본적으로 moran.mc() 함수는 \"htest\" 객체를 반환하지만, 내부적으로는 boot::boot() 함수를 사용하므로 return_boot = TRUE로 설정하면 \"boot\" 객체를 반환할 수도 있다. 또한 시뮬레이션 횟수는 nsim으로 지정하며, 이는 관측값을 무작위로 섞는 횟수를 의미한다.(역자주: 몬테카를로 검정 또는 순열 부트스트랩 검정은 가능한 모든 순열을 실제로 계산하지 않고, 그중 일부를 난수로 무작위 추출하여 검정 통계량의 분포를 근사하는 방식이다. 추출 횟수가 충분히 많을수록 근사 정확도가 높아지지만, 결과는 난수 생성에 따라 변동할 수 있다. 이에 비해 위에서 살펴본 분석적 순열은 적률(기대값, 분산 등)을 수학적 공식으로 직접 계산하여 검정 통계량의 분포를 구하는 방식으로, 난수 추출이 필요 없으며 동일한 데이터와 가정하에서는 언제나 같은 결과를 얻는다.)\n\nset.seed(1)\nI_turnout |&gt; \n    moran.mc(listw = lw_q_B, nsim = 999, \n             return_boot = TRUE) -&gt; mmc\n\n순열 부트스트랩은 각 무작위 순열의 결과를 보존하며, 통계량의 관측값(여기서는 모런 통계값)과 랜덤화 시뮬레이션의 평균값(\\(E(I)\\)와 동일한 역할)의 차이, 그리고 램덤화 시뮬레이션의 표준편차를 보고한다.\n몬테카를로 시뮬레이션의 분산과 랜덤화 가정 하에서의 분석적 분산을 비교하면, 보통 큰 차이가 없다. 이는 몬테카를로 검정이 불필요하다는 주장의 근거가 된다.\n\nc(\"Permutation bootstrap\" = var(mmc$t), \n  \"Analytical randomisation\" = unname(mtr$estimate[3]))\n#    Permutation bootstrap Analytical randomisation \n#                 0.000144                 0.000140\n\n전역적 기어리 통계량(Geary’s \\(C\\))은 geary.test() 함수로 구현되어 있으며, moran.test() 함수와 거의 동일한 인수 구조를 따른다. 게티스-오드(Getis-Ord \\(G\\)) 검정은 추가적인 인수를 가지는데, 이는 Bivand와 Wong(2018)이 지적한 바와 같이 초기 통계량의 변종이 이후에 나타났고, 특히 거리 기반 이웃 규정에서는 생성되는 무이웃 관측 개체를 처리하는 방식의 차이를 반영해야 하기 때문이다. Getis와 Ord(1992)의 194쪽에 따르면, \\(G^*\\)의 경우, \\(G\\)와는 달리 \\(i \\neq j\\) 합산 제약이 완화되어 \\(i\\)가 자기 자신을 이웃에 포함할 수 있다. 이렇게 하면 모든 관측 개체가 적어도 하나의 이웃을 가지게 되므로 무이웃 문제도 해결된다.\n마지막으로, 경험적 베이즈 모런 통계량은 비율 데이터에서 공간적 자기상관을 평가할 때 분모를 고려할 수 있게 해준다(Assunção and Reis 1999). 지금까지는 공간단위별로 유효 투표수와 투표권을 가진 인구수의 비율을 고려했으나, EBImoran.mc() 함수를 이용하면 투표권을 가진 인구수가 적은 공간단위에서 나타나는 극단적인 비율값이 가지는 통계적 불확실성을 반영할 수 있다. 그러나 결과에는 큰 변화가 없다.\n지금까지 다룬 전역적 공간적 자기상관 통계량은 이웃 그래프에 기반한 공간가중치를 활용한 측도들이다. 이러한 측도들을 매우 정교한 통계적 도구라고 부르기는 어렵다. 그 이유는 결과의 해석이 해당 변수의 평균 모형을 어떻게 설정하느냐에 크게 의존하기 때문이다. 만약 평균 모형이 절편만 포함한다면, 전역적 통계량은 공간적 자기상관 뿐만 아니라 다른 모든 종류의 오지정 문제에도 동시에 반응하게 된다. 공간단위의 선정과 관련된 개체화 문제가 일반적으로는 오지정 문제의 핵심적인 원인이 된다.(역자주: 공간적 자기상관 통계량이 측정하고 검정하는 대상에는 현상의 본질적인 공간적 자기상관성뿐 아니라, 측정 과정에서 비롯되는 기타 요인이나 오지정 문제가 함께 반영될 수 있다. 따라서 이러한 통계량을 현상의 공간적 자기상관성을 정밀하게 측정하는 척도로 단정하기는 어렵다는 의미이다.)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#국지적-측도",
    "href": "15.html#국지적-측도",
    "title": "15  공간적 자기상관 측도",
    "section": "\n15.3 국지적 측도",
    "text": "15.3 국지적 측도\n전역적 측도의 한계를 극복하기 위한 노력의 일환으로, 1990년대 초반부터 ’국지적 공간연관성 지표(LISA, local indicators of spatial association)’들이 등장하기 시작했다(Anselin 1995; Getis and Ord 1992, 1996).\n또한, 모런 플롯(혹은 모런 산포도)을 통해 관심 변수와 그 공간래그값(14장 참조) 간의 관련성을 시각화할 수 있게 되었다. 일반적으로 행표준화가중치를 사용하면 두 축을 보다 더 직접적으로 비교할 수 있다(Anselin 1996). moran.plot() 함수는 영향력 측정 객체(influence measures object)를 반환하며, 이를 통해 전역적 모런 통계량을 나타내는 직선의 기울기에 상대적으로 큰 영향을 미치는 관측 개체를 표시할 수 있다.(역자주: ’영향력 측정 객체’는 회귀분석 등에서 각 관측 개체가 분석 결과에 미치는 영향을 정량화한 지표들의 집합을 담는 결과 객체를 말한다. 여기에는 레버리지(leverage), Cook’s 거리, DFBETA, DFFITS, 공분산 비율 등과 같이 특정 관측 개체를 제거하거나 변경했을 때 추정치나 적합값이 얼마나 변하는지를 나타내는 통계량이 포함된다. moran.plot() 함수는 Moran 산점도를 작성하면서 이러한 영향력 측정 절차를 표준화된 관측값과 공간래그값 간의 관계에 적용하여, 각 공간단위가 국지적 모런 통계량에 미치는 상대적 영향을 파악할 수 있는 형태로 반환한다.) 그림 15.1에서는 영향력이 큰 관측 개체가 상당히 많다는 점을 확인할 수 있다. 이러한 관측값과 공간래그 관측값의 쌍은 집합적으로 전역적 측도를 구성하지만, 개별적으로도 탐색이 가능하다. 모런 플롯에서 오른쪽 상단 사분면에는 높은 값-높은 값(High-High) 쌍이, 왼쪽 하단 사분면에는 낮은 값-낮은 값(Low-Low) 쌍이 나타난다. 왼쪽 상단과 오른쪽 하단 사분면에는 각각 낮은 값-높은 값(Low-High)과 높은 값-낮은 값(High-Low) 쌍이 위치하며, 앞의 두 사분면에 비해 상대적으로 적게 나타난다. moran.plot() 함수에서 사분면은 변수값와 공간래그값의 평균을 기준으로 나뉘지만, 해당 값을 표준화한 경우에는 0을 기준으로 나뉜다.\n\n\n\n\n\n그림 15.1: 투표율에 대한 모런 플롯(행표준화 공간가중치행렬 적용)\n\n\n반환된 객체에서 회귀 영향 측도값(구체적으로는 hat influence measure, 햇 영향력 지표 혹은 레버리지 값)을 추출하여 지도를 작성하면(그림 15.2), 경계부에 위치한 공간단위들이 높은 값을 나타내는 것을 확인할 수 있다. 이는 아마도 행표준화 공간가중치행렬을 적용했기 때문일 수 있다.(역자주: 경계부의 공간단위는 상대적으로 적은 수의 이웃을 가지며, 행 표준화가 적용되었을 때 상대적으로 높은 가중치를 부여받게 된다.) 대도시나 그 주변 지역에서도 높은 값을 관찰할 수 있다.\n\nlibrary(tmap)\n# Breaking News: tmap 3.x is retiring. Please test v4, e.g. with\n# remotes::install_github('r-tmap/tmap')\npol_pres15$hat_value &lt;- infl_W$hat\ntm_shape(pol_pres15) + tm_fill(\"hat_value\")\n\n\n\n\n\n\n그림 15.2: 모런 회귀 영향 측도값의 분포(행표준화 공간가중치행렬 적용)\n\n\n\n15.3.1 국지적 모런 통계량\nBivand와 Wong(2018)은 국지적 모런 통계량(Moran’s \\(I_i\\))​과 국지적 게티스-오드 통계량(Getis-Ord \\(G_i\\))​과 같은 국지적 지표 사용에 영향을 미치는 문제들을 다루었다. 일부 문제는 국지적 지표 계산에 영향을 미치고, 다른 문제는 해당 값에 대한 통계적 추론에 영향을 준다. \\(n\\)개의 관측 단위에 대해 \\(n\\)개의 통계값이 산출되므로, 다중비교(multiple comparison) 문제를 해결할 필요가 있다.(역자주: ’다중비교 문제’란 여러 가설 검정을 동시에 수행할 때 우연에 의해 ’유의’로 판정되는 결과가 증가하는 현상이다. 예를 들어, 유의수준 0.05에서 독립된 검정을 5번 수행하면, 모두 유의하지 않을 확률은 \\(0.95^5\\approx 0.77\\)이고, 따라서 최소 한 번이라도 유의할 확률은 약 22.6%에 달한다. 국지적 통계량처럼 관측 개체마다 개별 검정을 수행하는 경우, 이러한 오류를 통제하기 위해 Bonferroni 보정이나 뒤에서 다룰 FDR과 같은 조정 방법이 필요하다.) Caldas de Castro와 Singer(2006)는 전형적인 데이터셋과 시뮬레이션 실험을 바탕으로, 확률값에 대한 FDR(false discovery rate, 오발견율) 조정이 무조정의 결과보다 흥미로운 클러스터를 더 잘 드러낸다고 결론지었다. 이를 바탕으로, Anselin(2019)은 FDR 조정을 재정의된 ’유의성‘ 기준치(Benjamin et al., 2018)와 결합하는 방식을 제안하였다. 예를 들어, 기존의 0.1, 0.05, 0.01 대신 0.01, 0.005, 0.001을 사용하는 방식이다. 또한 유의적(significant) 대신 흥미로운(interesting)이라는 용어 사용을 권고하였다. 이러한 논의는 Bivand(2022a)에서 더 자세히 다루어진다. 전역적 통계량과 마찬가지로, 오지정 문제는 여전히 혼란의 원인이며, 전역적 공간적 자기상관이 존재하는 상황에서 국지적 공간적 자기상관을 해석하는 일은 여전히 도전 과제이다(Ord and Getis 2001; Tiefelsdorf 2002; Bivand, Müller, and Reder 2009).\n\nargs(localmoran)\n\n#  function (x, listw, zero.policy = NULL, na.action = na.fail,\n#    conditional = TRUE, alternative = \"two.sided\", mlvar = TRUE,\n#    spChk = NULL, adjust.x = FALSE)\nBivand와 Wong(2018)는 국지적 모런 통계량의 표준편차를 분석적 공식에 기반한 방식과 조건부(conditional) 순열에 기반한 방식으로 비교하였다. 이에 대해 Sauer 등(2021)은 이러한 비교가 오해에 기반하고 있음을 명확히 보여주었다. Sokal, Oden과 Thomson(1998)은 총괄(total) 순열과 조건부 순열에 기반한 국지적 모런 통계량의 표준편차 공식을 제시한 바 있는데, Bivand와 Wong(2018)에서 사용된 분석 공식은 이전 관행에 따라 총괄 순열만 사용하였으며, 따라서 시뮬레이션 조건부 순열과 일치하지 않는다.(역자주: 국지적 공간적 자기상관 측도의 맥락에서 ’총괄 혹은 총체적 순열’은 데이터의 모든 값을 대상으로 무작위 재배치를 수행하는 방식이다. 반면 ’조건부 혹은 조건적 순열’은 특정 관측 단위의 값을 고정한 채 나머지 값만 무작위로 재배치한다. 두 방식 모두 랜덤화 가정에 기반하며, 적률(기대값, 분산 등)을 공식을 구하는 분석적 순열로도, 난수 시뮬레이션에 의한 순열 부트스트랩으로도 구현할 수 있다.) 적시에 제안된 풀 리퀘스트 덕분에, 이제 localmoran() 함수는 Sokal, Oden과 Thomson(1998)의 부록에 수록된 대안적 공식을 사용한 conditional 논리 인수(기본값은 TRUE)를 포함한다. localmoran() 함수의 mlvar와 adjust.x 인수가 필요한 이유는 Bivand와 Wong(2018)에 설명되어 있으며, 이를 통한 다른 패키지의 결과와 비교할 수 있다. 기본값인 two.sided를 설정하면 다음과 같은 결과를 얻을 수 있다.\n\nI_turnout |&gt; \n    localmoran(listw = lw_q_W) -&gt; locm\n\n국지적 모런 통계량을 합산한 뒤 공간가중치의 합으로 나누면 전역적 모런 통계량과 동일해지며, 이를 통해 국지적 수준에서 양 또는 음의 공간적 자기상관의 존재를 확인할 수 있다.\n\nall.equal(sum(locm[,1])/Szero(lw_q_W), \n          unname(moran.test(I_turnout, lw_q_W)$estimate[1]))\n# [1] TRUE\n\nstats::p.adjust() 함수를 사용해 다중비교를 조정한 결과, 조정을 적용하지 않을 경우 2,495개의 국지적 지표 중 15% 이상이 \\(p\\text{-value}&lt;0.005\\)를 가지는 것으로 나타났다. 그러나 FWER(family-wise error rate, 전체 오류율)을 제어하기 위해 Bonferroni 조정을 사용할 경우 이 비율은 1.5%로 감소한다. 다른 두 가지 조정 옵션도사용 할 수 있는데, \"fdr\"은 Benjamini와 Hochberg(1995)의 FDR 조정 방법으로 약 6%를, \"BY\"는 Benjamini와 Yekutieli(2001)의 또 다른 FDR 조정 방법으로 약 2.5%를 보였다.(역자주: Bonferroni 조정은 전역적 유의확률을 \\(\\alpha\\)라고 할 때, 국지적 측도에 대응하는 유의확률을 \\(\\alpha/n\\) 으로 계산하는 방법이다. 이에 비해 Benjamini와 Hochberg(1995)가 제안한 FDR 조정 방법은 여러 가설 검정에서 기각된 가설 중 실제로는 참인 비율을 제어하는 것을 목표로 하며, Bonferroni 조정보다 덜 보수적이어서 검정력이 높다. 이후 Benjamini와 Yekutieli(2001)는 BH 방법을 상관 구조가 존재하는 검정 상황에도 적용할 수 있도록 확장하였다.)\n\npva &lt;- function(pv) cbind(\"none\" = pv, \n    \"FDR\" = p.adjust(pv, \"fdr\"), \"BY\" = p.adjust(pv, \"BY\"),\n    \"Bonferroni\" = p.adjust(pv, \"bonferroni\"))\nlocm |&gt; \n    subset(select = \"Pr(z != E(Ii))\", drop = TRUE) |&gt; \n    pva() -&gt; pvsp\nf &lt;- function(x) sum(x &lt; 0.005)\napply(pvsp, 2, f)\n#       none        FDR         BY Bonferroni \n#        385        149         64         38\n\n전역적 측도에서는 분석적 방법에 대한 대안적 추론 방식으로 순열 부트스트랩이 사용된다. 그런데 분석적 분산 도출 방식과 순열 방식 모두 모든 관측값을 뒤섞는 것에 기반한다. 국지적 측도에서는 전체 순열보다 조건부 순열이 훨씬 더 적합하다. 이는 관측 개체 \\(i\\)의 값을 고정한채 나머지 \\(n-1\\)개의 값을 무작위로 샘플링하여 해당 이웃의 값을 결정하는 방식이다. 조건부 순열은 localmoran_perm() 함수로 제공되며, 여러 컴퓨팅 노드가 있는 경우 병렬 샘플링이 가능하고, 각 컴퓨팅 노드에서 난수 생성기의 시드를 설정할 수 있다. nsim 인수로 시뮬레이션 수를 지정하면, 시뮬레이션된 값 중 관측된 모런 통계값의 순위에 기반하여 확률값 추정치의 정밀도가 결정된다.\n\nlibrary(parallel)\ninvisible(spdep::set.coresOption(max(detectCores()-1L, 1L)))\nI_turnout |&gt; \n    localmoran_perm(listw = lw_q_W, nsim = 9999, \n                    iseed = 1) -&gt; locm_p\n\n그 결과, 다중비교 조정을 적용하지 않는 경우 전체 관측값의 15% 이상이 양측 \\(p\\text{-value}&lt;0.005\\) 로 나타났다. Bonferroni 조정을 적용하면 이 비율은 약 1.5%로 감소하였다. 여기서 \\(p\\) 값은 순열 샘플의 표준편차와 정규분포를 사용하여 계산되었다.\n\nlocm_p |&gt; \n    subset(select = \"Pr(z != E(Ii))\", drop = TRUE) |&gt; \n    pva() -&gt; pvsp\napply(pvsp, 2, f)\n#       none        FDR         BY Bonferroni \n#        380        148         64         39\n\n해당 변수가 반드시 정규분포를 따른다고 가정할 수 없으므로, 모든 시뮬레이션 값에서 관측값의 순위를 산정하고, 그 순위에 기반하여 균등분포에서의 확률값을 계산하는 방식으로 \\(p\\) 값을 구할 수도 있다.(역자주: 시뮬레이션을 통해 얻은 통계값들 중에서 관측 통계값과 같거나 그보다 더 극단적인 값을 보이는 경우의 개수를 이용해 일종의 근사 유의확률을 계산한다. 예를 들어 유의수준 0.005까지 확인하려면 999회의 시뮬레이션이 필요한데, 이는 유의확률의 최소 단위가 \\(1/(999+1)=0.001\\) 이기 때문이다.)\n\nlocm_p |&gt; \n    subset(select = \"Pr(z != E(Ii)) Sim\", drop = TRUE) |&gt; \n    pva() -&gt; pvsp\napply(pvsp, 2, f)\n#       none        FDR         BY Bonferroni \n#        391        127          0          0\n\n위의 결과는 \"BY\" 방식과 Bonferroni 방식을 적용한 경우, 9,999개의 샘플에서는 흥미로운 위치가 전혀 나타나지 않음을 보여준다. 그러나 샘플 수를 999,999로 늘리면 흥미로운 위치가 발견될 수 있다. 한편, FDR 조정과 판정 기준값(cut-off) 0.005를 적용하면, 약 5%의 위치가 흥미로운 위치로 나타난다.\n\npol_pres15$locm_pv &lt;- p.adjust(locm[, \"Pr(z != E(Ii))\"], \"fdr\")\npol_pres15$locm_std_pv &lt;- p.adjust(locm_p[, \"Pr(z != E(Ii))\"], \n                                   \"fdr\")\npol_pres15$locm_p_pv &lt;- p.adjust(locm_p[, \"Pr(z != E(Ii)) Sim\"],\n                                 \"fdr\")\n\n\n\n\n\n\n그림 15.3: 국지적 모런 통계량의 FDR 유의확률 값. 왼쪽 상단 패널은 분석적 조건부 유의확률, 오른쪽 상단 패널은 순열 표준편차를 이용한 조건부 유의확률, 왼쪽 하단 패널은 순열 순위에 기반한 조건부 유의확률을 각각 나타낸다(행표준화 공간가중치행렬 적용)\n\n\nFDR 조정과 판정 기준값 0.005를 적용한 결과, 그림 15.3에서 볼 수 있듯이 분석적 조건부 접근법, 순열 샘플링에서 추출된 값들의 적률을 활용한 접근법, 순열 샘플링에서 관측값의 순위를 활용한 접근법 모두 유사한 지도 패턴을 나타냈다. 이는 입력 변수의 분포가 정규분포에 매우 근접하기 때문에 나타난 현상이다.\n국지적 모런통계치를 제시할 때는 종종 ‘핫스팟’ 지도가 사용된다. 그러나 국지적 모런통계값은 입력 변수의 값이 낮든 높든 강한 양의 자기상관만 있으면 높은 값을 가지므로, 유사한 값을 지닌 이웃들의 ‘클러스터’가 어디에서 발생하는지를 낮은 값 클러스터와 높은 값 클러스터로 명확히 구분해 보이기는 어렵다. 이를 보완하기 위해 모런 플롯을 활용할 수 있다. 모런 플롯에서는 변수값과 공간래그값의 평균을 기준으로 범주형 사분면 변수를 생성한다. 이후, 기준 유의확률과 조정 절차에 따라 모런 통계값이 ’흥미로운’ 값으로 간주되지 않는 관측 개체는 사분면 범주 속성에서 NA값을 갖게 된다. 아래 사례에서는 FDR 조정된 조건부 유의확률 값을 사용했는데(그림 15.3, 왼쪽 상단 패널), 53개의 관측 개체가 \"Low-Low\" 클러스터에, 96개는 \"High-High\" 클러스터에 속했다. 이는 표준편차 기반의 순열 \\(p\\) 값(그림 15.3, 오른쪽 상단 패널)에서도 유사하게 나타난다. 순위 기반 순열 \\(p\\) 값(그림 15.3, 왼쪽 하단 패널)에서는 \"High-High\" 클러스터의 수가 줄고 \"Low-Low\" 클러스터 수가 증가한다.\n\nquadr &lt;- attr(locm, \"quadr\")$mean\na &lt;- table(addNA(quadr))\nlocm |&gt; hotspot(Prname=\"Pr(z != E(Ii))\", cutoff = 0.005, \n                droplevels=FALSE) -&gt; pol_pres15$hs_an_q\nlocm_p |&gt; hotspot(Prname=\"Pr(z != E(Ii))\", cutoff = 0.005, \n                  droplevels=FALSE) -&gt; pol_pres15$hs_ac_q \nlocm_p |&gt; hotspot(Prname=\"Pr(z != E(Ii)) Sim\", cutoff = 0.005,\n                  droplevels = FALSE) -&gt; pol_pres15$hs_cp_q\nb &lt;- table(addNA(pol_pres15$hs_an_q))\nc &lt;- table(addNA(pol_pres15$hs_ac_q))\nd &lt;- table(addNA(pol_pres15$hs_cp_q))\nt(rbind(\"Moran plot quadrants\" = a, \"Analytical cond.\" = b, \n  \"Permutation std. cond.\" = c, \"Permutation rank cond.\" = d))\n#           Moran plot quadrants Analytical cond.\n# Low-Low                   1040               53\n# High-Low                   264                0\n# Low-High                   213                0\n# High-High                  978               96\n# &lt;NA&gt;                         0             2346\n#           Permutation std. cond. Permutation rank cond.\n# Low-Low                       53                     56\n# High-Low                       0                      0\n# Low-High                       0                      0\n# High-High                     95                     71\n# &lt;NA&gt;                        2347                   2368\n\n\npol_pres15$hs_an_q &lt;- droplevels(pol_pres15$hs_an_q)\npol_pres15$hs_ac_q &lt;- droplevels(pol_pres15$hs_ac_q)\npol_pres15$hs_cp_q &lt;- droplevels(pol_pres15$hs_cp_q)\n\n\n\n\n\n\n그림 15.4: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(유의수준은 0.005). 왼쪽 상단 패널에는 분석적 조건부 유의확률, 오른쪽 상단 패널은 순열 표준편차 기반 조건부 유의확률, 왼쪽 하단 패널은 순열 순위 기반 조건부 유의확률이 적용된 경우를 보여준다.(행표준화 공간가중치행렬 적용)\n\n\nFigure 15.4는 분석적 조건부 표준편차, 순열 기반 표준편차, 순위 기반 확률 값의 세 가지 접근법에 대해 \\(\\alpha=0.005\\) 확률 값 컷오프를 적용했을 때 FDR 조정된 흥미로운 클러스터들 간의 차이가 거의 없음을 보여준다. \"High-High\" 클러스터의 핵심부는 대도시 지역에 위치한다.\nTiefelsdorf (2002)는 국지적 모런 통계량의 표준편차를 계산하는 표준 접근 방식에 수치적 추정치를 추가해야 한다고 주장하며, 이를 안장점 근사를 통해 구현하는 것이 계산적으로 효율적인 방법임을 보여주었다. localmoran.sad() 함수는 첫 번째 인수로 적합된 선형모형을 입력받으므로, 우선 절편만 포함된 기본 모형을 적합시켜야 한다. 그러나 구역별 유권자 수가 크게 다르므로, 이러한 효과를 통제하기 위해 최종적으로 가중 선형모형을 적합시킨다.\n\nlm(I_turnout ~ 1) -&gt; lm_null\n\n안장점 근사 방식은 조건부 순열만큼 계산 비용이 많이 든다. 이는 많은 샘플에 대해 단일 측정값을 계산하는 것이 아니라, 각 국지적 근사마다 상당한 수치 계산이 필요하기 때문이다.\n\nlm_null |&gt; localmoran.sad(nb = nb_q, style = \"W\",\n                                  alternative = \"two.sided\") |&gt;\n        summary() -&gt; locm_sad_null\n\n안장점 근사법의 주요 장점은 단순히 수치 변수를 사용하는 대신, 적합된 선형모형을 기반으로 잔차를 분석한다는 점이다. 절편만 포함된 모형을 사용하면 결과는 국지적 모런 통계량과 유사하지만, 관찰값에 가중치를 부여할 수 있다. 여기서는 투표권이 있는 인구수를 기준으로 가중치를 부여하며, 이를 통해 작은 단위의 관찰값은 낮은 가중치를 받는다.\n\nlm(I_turnout ~ 1, weights = pol_pres15$I_entitled_to_vote) -&gt;\n        lm_null_weights\nlm_null_weights |&gt;\n            localmoran.sad(nb = nb_q, style = \"W\",\n                           alternative = \"two.sided\") |&gt;\n        summary() -&gt; locm_sad_null_weights\n\n다음으로, 농촌, 도시, 기타 유형의 관측 개체를 구분하는 범주형 변수를 추가한다.\n\nlm(I_turnout ~ Types, weights=pol_pres15$I_entitled_to_vote) -&gt;\n        lm_types\nlm_types |&gt; localmoran.sad(nb = nb_q, style = \"W\",\n                                  alternative = \"two.sided\") |&gt;\n        summary() -&gt; locm_sad_types\n\n\nlocm_sad_null |&gt; hotspot(Prname=\"Pr. (Sad)\",\n                     cutoff=0.005) -&gt; pol_pres15$locm_sad0\nlocm_sad_null_weights |&gt; hotspot(Prname=\"Pr. (Sad)\",\n                     cutoff = 0.005) -&gt; pol_pres15$locm_sad1\nlocm_sad_types |&gt; hotspot(Prname=\"Pr. (Sad)\",\n                     cutoff = 0.005) -&gt; pol_pres15$locm_sad2\n\n\n\n\n\n\n그림 15.5: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 상단 패널에는 순열 표준편차를 활용한 조건부 유의확률, 오른쪽 상단 패널은 기본(절편만 있는) 모형의 안장점 근사에 기반한 유의확률, 왼쪽 하단 패널은 가중 기본(절편만 있는) 모형의 안장점 근사에 근거한 유의확률, 오른쪽 하단 패널은 가중 유형 모형의 안장점 근사에 기반한 유의확률을 나타낸다.(행표준화 공간가중치행렬의 적용)\n\n\n\nrbind(null = append(table(addNA(pol_pres15$locm_sad0)),\n                    c(\"Low-High\" = 0), 1),\n      weighted = append(table(addNA(pol_pres15$locm_sad1)),\n                        c(\"Low-High\" = 0), 1),\n      type_weighted = append(table(addNA(pol_pres15$locm_sad2)),\n                        c(\"Low-High\" = 0), 1))\n#               Low-Low Low-High High-High &lt;NA&gt;\n# null               19        0        55 2421\n# weighted            9        0        52 2434\n# type_weighted      13        0        81 2401\n\n그림 15.5의 왼쪽 상단 패널에는 비교를 위해 순열 순위 기반 클러스터가 제시되어 있다. 안장점 근사법은 더 풍부한 평균모형을 적용할 수 있으며, 관측 개체 \\(i\\)에서의 회귀 잔차 값을 그 이웃들의 값과 연결하는 본질적으로 국지적인 접근법이기 때문에, 안정접 근사법에 기반한 나머지 세 개의 패널은 상당히 다른 패턴을 보여준다. 절편만 포함한 기본 모형은 표준적인 결과와 매우 유사하지만, 유권자수에 따른 가중치 부여로 인해 대부분의 \"Low-Low\" 클러스터가 제거된다. 범주 유형 변수를 추가하면 도시 지역의 \"High-High\" 클러스터가 강화되지만, 바르샤바 구역들은 흥미로운 군집의 핵에서 제외된다. 바르샤바의 중앙 구역들은 높은 투표율을 보이며, 마찬가지로 높은 투표율을 보이는 다른 구역들에 의해 둘러싸여 있으나, 이는 공간적 자기상관에 의한 것이 아니라 모두 대도시 구역에 속하기 때문이다. 또한, 전역적 공간 프로세스를 통합한 경우 안장점 근사법을 활용할 수 있는데, 이를 통해 표준 접근법에서 나타나는 전역 및 지역 공간적 자기상관의 결합 효과를 제거할 수 있다.\n같은 결과를 정확 접근법으로도 얻을 수 있지만, 수치적분이 실패하는 경우가 있어 표준편차의 정확한 추정값 대신 NaN가 반환될 수 있다. 따라서 추가적인 조정이 필요할 수 있다(Bivand, Müller, and Reder 2009).(역자주: ’정확 접근법’은 검정 통계량의 분포를 평균과 분산만으로 추정하는 정규 근사나, 이를 개선한 안장점 근사와 달리, 필요한 모든 적률(moment)을 활용해 분포를 근사가 아닌 정확한 형태로 계산하는 방법이다. 이러한 접근은 정규성 가정과 관련되며, 계산 과정에서 상당한 전산 자원이 소요된다.)\n\nlm_types |&gt; localmoran.exact(nb = nb_q, style = \"W\", \n    alternative = \"two.sided\", useTP=TRUE, truncErr=1e-8) |&gt; \n    as.data.frame() -&gt; locm_ex_types\n\n\nlocm_ex_types |&gt; hotspot(Prname = \"Pr. (exact)\",\n                         cutoff = 0.005) -&gt; pol_pres15$locm_ex\n\n\n\n\n\n\n그림 15.6: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 패널에는 가중 유형 모형의 안장점 근사에 기반한 유의확률이, 오른쪽 패널은 가중 유형 모형의 정확 접근법에 기반한 유의확률이 제시되어 있다.(행표준화 공간가중치행렬의 적용)\n\n\n그림 15.6에서 볼 수 있듯이, 정확 접근법과 안장점 근사법은 동일한 회귀 잔차, 다중비교 조정 방식, 그리고 기준값 수준을 적용했을 때 거의 동일한 클러스터 분류 결과를 산출한다. 두 방법 간의 차이는, 아래에 나타난 것처럼, 정확 접근법이 4개의 추가적인 관측 개체를 흥미로운 사례로 탐지한다는 점이다.\n\ntable(Saddlepoint = addNA(pol_pres15$locm_sad2),\n      exact = addNA(pol_pres15$locm_ex))\n#            exact\n# Saddlepoint Low-Low High-High &lt;NA&gt;\n#   Low-Low        13         0    0\n#   High-High       0        81    0\n#   &lt;NA&gt;            2         2 2397\n\n\n15.3.2 국지적 게티스-오드 통계량\n국지적 게티스-오드 측도(Getis-Ord \\(G_i\\))(Getis and Ord 1992, 1996)는 표준화된 값으로 산출된다. include.self 인수를 사용하여 이웃 객체에 자신을 포함하도록 설정하면 \\(G^*_i\\) 측도값을 계산할 수 있다. return_internals = TRUE로 지정하면 관측값, 기대값, 그리고 이에 대한 분석적 분산값이 함께 반환된다.\n\nI_turnout |&gt; \n        localG(lw_q_W, return_internals = TRUE) -&gt; locG\n\n순열에 기반한 가설 검정도 수행할 수 있다.\n\nI_turnout |&gt; \n        localG_perm(lw_q_W, nsim = 9999, iseed = 1) -&gt; locG_p\n\n분석적 표준편차에 기반한 유의확률, 순열 기반 표준편차에 기반한 유의확률(첫 번째 두 열과 행), 순열 순위 기반 유의확률 간의 상관관계는 매우 강하다.\n\ncor(cbind(localG=attr(locG, \"internals\")[, \"Pr(z != E(Gi))\"], \n    attr(locG_p, \"internals\")[, c(\"Pr(z != E(Gi))\", \n                                  \"Pr(z != E(Gi)) Sim\")]))\n#                    localG Pr(z != E(Gi)) Pr(z != E(Gi)) Sim\n# localG                  1              1                  1\n# Pr(z != E(Gi))          1              1                  1\n# Pr(z != E(Gi)) Sim      1              1                  1\n\n\n15.3.3 국지적 기어리 통계량\nAnselin(2019)의 연구는 Anselin(1995)의 내용을 확장한 것으로, 조사이아 패리(Josiah Parry)의 기여(풀 리퀘스트: https://github.com/r-spatial/spdep/pull/66) 덕분에 최근 spdep 패키지에 추가되었다. 이로써 \\(I_i\\)와 \\(G_i\\)에 사용되던 조건부 순열 프레임워크를 국지적 기어리 통계량(\\(C_i\\))에도 적용할 수 있게 되었다.\n\nI_turnout |&gt; \n        localC_perm(lw_q_W, nsim=9999, iseed=1) -&gt; locC_p\n\n순열 표준편차 기반 유의확률과 순위 기반 유의확률 값은 \\(G_i\\)와 비교했을 때 상관관계가 그리 높지 않다. 이는 부분적으로 \\(C_i\\)가 값들의 유사성을 값들의 곱이 아니라 값들 간의 차이 함수로 표현하기 때문이며, 이러한 공간적 자기상관 개념화 차이가 반영된 결과로 해석된다.\n\ncor(attr(locC_p, \"pseudo-p\")[, c(\"Pr(z != E(Ci))\",\n                                 \"Pr(z != E(Ci)) Sim\")])\n#                    Pr(z != E(Ci)) Pr(z != E(Ci)) Sim\n# Pr(z != E(Ci))              1.000              0.966\n# Pr(z != E(Ci)) Sim          0.966              1.000\n\n\nlocC_p |&gt; hotspot(Prname = \"Pr(z != E(Ci)) Sim\",\n                  cutoff = 0.005) -&gt; pol_pres15$hs_C\nlocG_p |&gt; hotspot(Prname = \"Pr(z != E(Gi)) Sim\",\n                  cutoff = 0.005) -&gt; pol_pres15$hs_G\n\n\n\n\n\n\n그림 15.7: FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 패널은 국지적 모런 통계량에 따른 공간 클러스터를, 가운데 패널은 국지적 게티스-오드 통계량에 따른 공간 클러스터를, 오른편 패널은 국지적 기어리 통계량에 따른 공간 클러스터를 보여준다.(행표준화 공간가중치행렬의 적용)\n\n\n그림 15.7은 동일한 변수(투표율)와 동일한 공간가중치를 사용했을 때 \\(I_i\\), \\(G_i\\), \\(C_i\\)가 식별한 흥미로운 클러스터 핵심부가 매우 유사함을 보여준다. 통계적 추론에는 순위 기반 순열 FDR 조정 확률값이 사용되었고, 기준값은 \\(\\alpha=0.005\\)로 설정되었다. 대부분의 경우, \"High-High\" 클러스터의 핵심은 도시 지역이며, \"Low-Low\" 클러스터의 핵심은 북부의 인구 밀도가 낮은 농촌 지역과 남부 국경 근처의 독일 소수 민족 지역이다. 세 가지 측도는 클러스터 핵심을 명명하는 방식에서 약간 차이를 보인다. \\(I_i\\)는 모런 산점도 플롯의 사분면을 사용하고, \\(G_i\\)는 입력 변수의 평균을 기준으로 \"Low\"와 \"High\"를 구분하며(이는 \\(I_i\\) 튜플의 첫 번째 요소와 동일), \\(C_i\\)는 입력 변수의 평균값 기준으로 하지만 공간래그값에 대해서는 0을 기준으로 나눈다. 이전과 마찬가지로 해당 사례가 없는 클러스터 범주는 제외된다.\n비교를 위해, 다변량 \\(C_i\\)를 살펴보기 전에 두 번째(최종) 라운드 투표율에 대한 단변량 \\(C_i\\)를 먼저 살펴보자. 1차 투표에서 상위 두 후보 간의 결선 투표는, 1차 투표에서 명확한 선호를 보이지 않았던 일부 유권자의 참여를 유도할 수 있지만, 1차 투표에서 탈락한 후보에게 강한 충성심을 가졌던 일부 유권자의 참여를 저해할 수도 있다.\n\npol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = II_turnout) |&gt; \n        localC_perm(lw_q_W, nsim=9999, iseed=1) -&gt; locC_p_II\n\n\nlocC_p_II |&gt; hotspot(Prname = \"Pr(z != E(Ci)) Sim\",\n                     cutoff = 0.005) -&gt; pol_pres15$hs_C_II\n\n다변량 \\(C_i\\)(Anselin 2019)는 단변량 \\(C_i\\)가값들의 합을 변수 개수로 나누어 계산하며, 이때 순열은 고정되어 변수 간 상관관계가 변하지 않도록 한다.\n\npol_pres15 |&gt; \n        st_drop_geometry() |&gt; \n        subset(select = c(I_turnout, II_turnout)) |&gt;\n        localC_perm(lw_q_W, nsim=9999, iseed=1) -&gt; locMvC_p\n\n다변량 \\(C_i\\)는 단변량 \\(C_i\\)의 평균값임을 다음과 같이 확인할 수 있다.\n\nall.equal(locMvC_p, (locC_p+locC_p_II)/2,\n          check.attributes = FALSE)\n# [1] TRUE\n\n\nlocMvC_p |&gt; hotspot(Prname = \"Pr(z != E(Ci)) Sim\",\n                    cutoff = 0.005) -&gt; pol_pres15$hs_MvC\n\n\n\n\n\n\n그림 15.8: FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 패널에는 1차 투표율에 대한 공간 클러스터, 가운데 패널에는 2차 투표율에 대한 공간 클러스터, 오른쪽 패널에는 두 차례 투표율 모두에 대한 공간 클러스터가 나타나 있다.(행표준화 공간가중치행렬의 적용)\n\n\n그림 15.8은 다변량 측도가 개별 단변량 측도에서 흥미로운 케이스로 식별된 관측 개체들을 기본적으로 결합하고 있음을 보여준다. 이를 구체적으로 살펴보기 위해, 1차 및 2차 투표의 단변량 측도값을 결합한 뒤 이를 다변량 측도값과 대조하여 표로 정리할 수 있다.\n\ntable(droplevels(interaction(addNA(pol_pres15$hs_C),\n                             addNA(pol_pres15$hs_C_II), sep=\":\")), \n      addNA(pol_pres15$hs_MvC))\n#                      \n#                       Positive &lt;NA&gt;\n#   High-High:High-High       81    0\n#   NA:High-High              41   27\n#   Low-Low:Low-Low           25    0\n#   NA:Low-Low                43   11\n#   NA:Other Positive          1    0\n#   NA:Negative                0    1\n#   High-High:NA              15    0\n#   Low-Low:NA                11    3\n#   NA:NA                     36 2200\n\n다변량 \\(C_i\\)에서는 흥미로운 케이스로 식별된 관측 개체 중 47개는 단변량 \\(C_i\\) 어느 경우에서도 흥미로운 케이스로 나타나지 않았다(FDR, 판정 기준값 0.005). 1차와 2차 라운드 모두에서 흥미로운 것으로 나타난 관측값은 거의 모두 다변량에서도 흥미로운 것으로 분류되었지만, 두 라운드 중 한 라운드에서만 흥미로운 것으로 나타난 관측값은 보다 혼합된 결과를 보였다.\n\n15.3.4 rgeoda 패키지\nrgeoda 패키지(Li and Anselin 2022)는 GeoDa의 R 래퍼 패키지로, spdep 패키지와 유사한 기능을 제공하여 에어리어 데이터 공간적 자기상관을 탐색할 수 있게 한다. 활성 객체는 컴파일된 작업 공간의 메모리 주소를 참조하는 포인터로 관리되며, 모든 연산이 GeoDa와 동일하게 컴파일된 코드로 실행되므로 rgeoda 패키지는 매우 빠른 성능을 제공한다. 다만, 수정이나 기능 확장이 필요할 경우 유연성은 상대적으로 떨어진다.\n\nlibrary(rgeoda)\nGeoda_w &lt;- queen_weights(pol_pres15)\nsummary(Geoda_w)\n#                      name               value\n# 1 number of observations:                2495\n# 2          is symmetric:                 TRUE\n# 3               sparsity: 0.00228786229774178\n# 4        # min neighbors:                   1\n# 5        # max neighbors:                  13\n# 6       # mean neighbors:    5.70821643286573\n# 7     # median neighbors:                   6\n# 8           has isolates:               FALSE\n\n비교를 위해, 2015년 폴란드 대통령 선거 투표율에 대한 다변량 \\(C_i\\) 지표를 살펴보자.\n\nlisa &lt;- local_multigeary(Geoda_w, \n    pol_pres15[c(\"I_turnout\", \"II_turnout\")], \n    cpu_threads = max(detectCores() - 1, 1),\n    permutations = 99999, seed = 1)\n\n연접 이웃을 비교하면, 이는 위에서 poly2nb() 함수를 통해 정의된 것과 동일하다.\n\nall.equal(card(nb_q), lisa_num_nbrs(lisa), \n          check.attributes = FALSE)\n# [1] TRUE\n\n다변량 \\(C_i\\) 값도 위와 동일하다.\n\nall.equal(lisa_values(lisa), c(locMvC_p),\n          check.attributes = FALSE)\n# [1] TRUE\n\n한 가지 차이점은 rgeoda 패키지에서 사용하는 접힌(folded) 양측 순위 기반 순열 유의확률 값의 범위가 \\([0,0.5]\\)로 제한된다는 점이다. 이는 spdep 패키지에서도 계산되지만, 처리 방식은 다를 수 있다.\n\napply(attr(locMvC_p, \"pseudo-p\")[,c(\"Pr(z != E(Ci)) Sim\", \n                                \"Pr(folded) Sim\")], 2, range)\n#      Pr(z != E(Ci)) Sim Pr(folded) Sim\n# [1,]             0.0002         0.0001\n# [2,]             0.9990         0.4995\n\n이것은 \\([0,1]\\) 범위에서의 컷오프 값 \\(0.005\\)가, \\([0,0.5]\\) 범위에서는 \\(0.0025\\)에 해당함을 의미한다.\n\nlocMvC_p |&gt; hotspot(Prname = \"Pr(folded) Sim\",\n                    cutoff = 0.0025) -&gt; pol_pres15$hs_MvCa\n\n따라서 local_multigeary() 함수는 클러스터 핵심 클래스를 설정할 때 기본 판정 기준값인 \\(0.05\\)를 사용하지만, 우리는 이를 더 엄격하게 조정하고, lisa 객체의 출력 구성 요소에 FDR 조정을 적용함으로써 결과의 신뢰성을 높일 수 있다.\n\nmvc &lt;- factor(lisa_clusters(lisa), levels=0:2,\n              labels = lisa_labels(lisa)[1:3])\nis.na(mvc) &lt;- p.adjust(lisa_pvalues(lisa), \"fdr\") &gt;= 0.0025\npol_pres15$geoda_mvc &lt;- droplevels(mvc)\n\nregoda 패키지의 순열 방식을 적용한 결과 약 80개의 추가 관측값이 흥미로운 케이스로 확인되었으며, 구현 세부 사항에 대한 추가 분석이 여전히 진행 중이다.\n\naddmargins(table(spdep = addNA(pol_pres15$hs_MvCa),\n                 rgeoda = addNA(pol_pres15$geoda_mvc)))\n#           rgeoda\n# spdep      Positive &lt;NA&gt;  Sum\n#   Positive      249    4  253\n#   &lt;NA&gt;           75 2167 2242\n#   Sum           324 2171 2495\n\n\n\n\n\n\n그림 15.9: FDR 조정 다변량 \\(C_i\\) 핫스팟 지도(양측검정, 흥미로움의 판정 기준값은 \\([0,0.5]\\) 범위에서 0.0025 적용). 왼쪽 패널은 합산 투표율을 spdep 패키지에 적용한 결과이고, 오른쪽 패널은 합산 투표율을 rgeoda 패키지에 적용한 결과이다.(행표준화 공간가중치행렬의 적용)\n\n\n그림 15.9는 spdep 패키지에서 흥미로운 것으로 판정된 242개 관측값의 거의 모두가 rgeoda 패키지에서도 역시 흥미로운 것으로 판정되었지만, 후자는 추가로 86개를 더 흥미로운 것으로 판정했음을 보여준다. 물론 순열 결과의 변동성은 불가피하지만, 어느 한쪽 또는 양쪽 구현에 수정이 필요한지 여부는 여전히 규명되어야 한다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "15.html#연습문제",
    "href": "15.html#연습문제",
    "title": "15  공간적 자기상관 측도",
    "section": "\n15.4 연습문제",
    "text": "15.4 연습문제\n\n체스판의 조인 카운트 통계값이 rook 이웃과 queen 이웃 간에 크게 다른 이유를 설명하시오.\n15.1절에서 제시한 시뮬레이션을 체스판 다각형과 행 표준화된 queen 연접 이웃을 사용하여 반복하시오. 공간적 자기상관이 일반적으로 (피할 수 없는) 데이터의 모형 오지정 문제를 나타낼 수 있다는 점을 이해하는 것이 왜 중요한지 설명하시오.\n국지적 공간적 자기상관 통계량에 FDR 조정이 권장되는 이유를 설명하시오.\n문항 2의 시뮬레이션 데이터에 대해 분석적 조건 접근법과 안장점 근사법을 사용하여 국지적 모런 통계량(\\(I_i\\))의 표준편차 값(검정 통계값)을 비교하시오. 또한 안장점 근사법의 장단점을 설명하시오.\n\n\n\n\n그림 15.1: 투표율에 대한 모런 플롯(행표준화 공간가중치행렬 적용)\n그림 15.2: 모런 회귀 영향 측도값의 분포(행표준화 공간가중치행렬 적용)\n그림 15.3: 국지적 모런 통계량의 FDR 유의확률 값. 왼쪽 상단 패널은 분석적 조건부 유의확률, 오른쪽 상단 패널은 순열 표준편차를 이용한 조건부 유의확률, 왼쪽 하단 패널은 순열 순위에 기반한 조건부 유의확률을 각각 나타낸다(행표준화 공간가중치행렬 적용)\n그림 15.4: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(유의수준은 0.005). 왼쪽 상단 패널에는 분석적 조건부 유의확률, 오른쪽 상단 패널은 순열 표준편차 기반 조건부 유의확률, 왼쪽 하단 패널은 순열 순위 기반 조건부 유의확률이 적용된 경우를 보여준다.(행표준화 공간가중치행렬 적용)\n그림 15.5: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 상단 패널에는 순열 표준편차를 활용한 조건부 유의확률, 오른쪽 상단 패널은 기본(절편만 있는) 모형의 안장점 근사에 기반한 유의확률, 왼쪽 하단 패널은 가중 기본(절편만 있는) 모형의 안장점 근사에 근거한 유의확률, 오른쪽 하단 패널은 가중 유형 모형의 안장점 근사에 기반한 유의확률을 나타낸다.(행표준화 공간가중치행렬의 적용)\n그림 15.6: 국지적 모런 통계량의 FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 패널에는 가중 유형 모형의 안장점 근사에 기반한 유의확률이, 오른쪽 패널은 가중 유형 모형의 정확 접근법에 기반한 유의확률이 제시되어 있다.(행표준화 공간가중치행렬의 적용)\n그림 15.7: FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 패널은 국지적 모런 통계량에 따른 공간 클러스터를, 가운데 패널은 국지적 게티스-오드 통계량에 따른 공간 클러스터를, 오른편 패널은 국지적 기어리 통계량에 따른 공간 클러스터를 보여준다.(행표준화 공간가중치행렬의 적용)\n그림 15.8: FDR 조정 핫스팟 지도(양측검정, 흥미로움의 판정 기준값 0.005 적용). 왼쪽 패널에는 1차 투표율에 대한 공간 클러스터, 가운데 패널에는 2차 투표율에 대한 공간 클러스터, 오른쪽 패널에는 두 차례 투표율 모두에 대한 공간 클러스터가 나타나 있다.(행표준화 공간가중치행렬의 적용)\n그림 15.9: FDR 조정 다변량 \\(C_i\\) 핫스팟 지도(양측검정, 흥미로움의 판정 기준값은 \\([0,0.5]\\) 범위에서 0.0025 적용). 왼쪽 패널은 합산 투표율을 spdep 패키지에 적용한 결과이고, 오른쪽 패널은 합산 투표율을 rgeoda 패키지에 적용한 결과이다.(행표준화 공간가중치행렬의 적용)",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>공간적 자기상관 측도</span>"
    ]
  },
  {
    "objectID": "13.html",
    "href": "13.html",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "",
    "text": "13.1 대기질 데이터셋 준비\n여기서 사용할 데이터셋은 EEA(European Enviromental Agency, 유럽환경청)에서 제공하는 대기질 데이터셋이다. 유럽 회원국들은 대기질 측정 결과를 EEA에 보고하며, 검증된 데이터는 각 회원국에서 품질을 관리한 후 연 단위로 보고된다. 이러한 데이터는 정책 준수 여부를 평가하고 대응 조치를 마련하는 데 기초 자료로 활용된다.\nEEA의 대기질 전자보고(e-reporting) 웹사이트를 통해 유럽 회원국이 보고한 데이터에 접근할 수 있다. 여기서는 기본 측정 자료인 시간별(시계열) 데이터를 다운로드하였다. 웹 양식을 사용하면 선택한 데이터 기준이 손쉽게 HTTP GET 요청으로 변환된다. 예를 들어, 독일(CountryCode=DE)의 2017년(Year_from, Year_to) 모두 검증된(Source=E1a) \\(NO_2\\)(Pollutant=8) 데이터를 선택하면, 여러 CSV 파일과 해당 파일들의 URL 정보를 담은 텍스트 파일을 변환하는 URL이 생성된다. 각 CSV 파일에는 특정 측정소의 전체 기간에 대한 시간별 측정값이 포함되어 있다. 다운로드한 파일들은 dos2unix 명령줄 유틸리티를 이용해 인코딩을 변환하였다.\n마지막으로, 측정소 메타데이터가 담긴 단일 파일을 제외하고, 나머지 파일들은 모두 리스트 형태로 읽어들였다.\nfiles &lt;- list.files(\"aq\", pattern = \"*.csv\", full.names = TRUE)\nfiles &lt;- setdiff(files, \"aq/AirBase_v8_stations.csv\") # metadata file\nr &lt;- lapply(files, function(f) read.csv(f))\n그다음, 시간 변수를 POSIXct 형식으로 변환한 뒤, 시간 순서대로 정렬한다.\nSys.setenv(TZ = \"UTC\") # don't use local time zone\nr &lt;- lapply(r, function(f) {\n        f$t = as.POSIXct(f$DatetimeBegin) \n        f[order(f$t), ] \n    }\n)\n이 데이터셋에서 시간별 자료가 없는 소규모 하위 집합은 제거한다.\nr &lt;- r[sapply(r, nrow) &gt; 1000]\nnames(r) &lt;- sapply(r,\n               function(f) unique(f$AirQualityStationEoICode))\nlength(r) == length(unique(names(r)))\n# [1] TRUE\n그다음, xts 패키지의 cbind() 함수를 사용해 모든 파일을 병합하고, 시간을 기준으로 레코드를 매칭하여 결합한다.\nlibrary(xts) |&gt; suppressPackageStartupMessages()\nr &lt;- lapply(r, function(f) xts(f$Concentration, f$t))\naq &lt;- do.call(cbind, r)\n이 데이터셋에 대해 추가적인 선택을 수행하였다. 측정된 시간별 값 중 75% 이상이 유효한 측정소만을 선택한 것이다. 즉, 결측 시간별 값이 25%를 초과하는 측정소는 제외하였다. mean(is.na(x)) 함수는 벡터 x에서 결측값의 비율(fraction)을 계산하므로, 이 함수를 각 열(측정소)에 적용하면 된다.\nsel &lt;- apply(aq, 2, function(x) mean(is.na(x)) &lt; 0.25)\naqsel &lt;- aq[, sel]\n다음으로, 측정소 메타데이터를 읽어 들인 뒤, 독일(\"DE\") 농촌 배경 측정소에 해당하는 자료만 선별한다.\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nread.csv(\"aq/AirBase_v8_stations.csv\", sep = \"\\t\") |&gt;\n    as_tibble() |&gt; \n    filter(country_iso_code == \"DE\",\n           station_type_of_area == \"rural\",\n           type_of_station == \"Background\") -&gt; a2\n포함된 좌표값을 이용해 측정소 메타데이터를 담은 sf 객체를 생성한다.\nlibrary(sf) |&gt; suppressPackageStartupMessages()\na2.sf &lt;- st_as_sf(a2, crs = 'OGC:CRS84',\n  coords = c(\"station_longitude_deg\", \"station_latitude_deg\"))\n이제 앞에서 정리한 대기질 측정 데이터에서 농촌 배경 유형에 해당하는 측정소만 선별해야 한다. 측정소의 코드 정보는 메타데이터를 정리한 a2에 저장되어 있다.\nsel &lt;- colnames(aqsel) %in% a2$station_european_code\naqsel &lt;- aqsel[, sel]\ndim(aqsel)\n# [1] 8760   74\n측정소별 평균을 계산한 뒤, 이를 측정소 위치 객체와 조인한다.\ntb &lt;- tibble(NO2 = apply(aqsel, 2, mean, na.rm = TRUE), \n            station_european_code = colnames(aqsel))\ncrs &lt;- st_crs('EPSG:32632')\nright_join(a2.sf, tb) |&gt; st_transform(crs) -&gt; no2.sf \nread_sf(\"data/de_nuts1.gpkg\") |&gt; st_transform(crs) -&gt; de\n그림 12.1에는 이렇게 계산된 측정소별 평균 NO\\(_2\\) 농도와 국가 경계가 나타나 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "13.html#다변량-지구통계학",
    "href": "13.html#다변량-지구통계학",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "\n13.2 다변량 지구통계학",
    "text": "13.2 다변량 지구통계학\n다변량 지구통계학은 여러 변수를 결합하여 모형화, 예측, 시뮬레이션하는 것을 의미한다. 이를 수식으로 표현하면 다음과 같다.\n\\[\nZ_1(s)=X_i\\beta_i+e_1(s)\n\\]\n\\[\n...\n\\]\n\\[\nZ_n(s)=X_n\\beta_n+e_n(s)\n\\]\n이러한 모형을 구축하려면 각 변수별로 관측치, 경향 모형, 베리오그램이 필요하며, 나아가 각 변수쌍별로 잔차의 교차 베리오그램(cross-variogram)이 필요하다. 교차 베리오그램은 \\(e_i(s)\\)와 \\(e_j(s+h)\\) 사이의 공분산을 나타낸다. 이 교차 공분산이 0이 아니라면, \\(e_j(s+h)\\)의 정보는 \\(e_i(s)\\)를 예측(또는 시뮬레이션)하는 데 유용할 수 있다. 이는 특히 \\(Z_j(s)\\)가 \\(Z_i(s)\\) 보다 더 조밀하게 표집된 경우에 두드러진다. 이러한 방식의 예측과 시뮬레이션은 각각 코크리깅(cokriging) 및 코시뮬레이션(cosimulation)이라 부른다. 데모 스크립트를 실행하면 gstat 패키지를 이용한 예제를 확인할 수 있으며, 보다 자세한 내용은 Bivand, Pebesma와 Gómez-Rubio(2013)를 참고하라.\n\nlibrary(gstat)\ndemo(cokriging)\ndemo(cosimulation)\n\n다양한 변수가 동일한 위치에서 관측되는 경우, 예를 들어 여러 대기질 변수가 동일한 측정소에서 함께 수집되는 경우, 코크리깅(cokriging)의 통계적 이점이 미미할 수 있다. 그러나 진정한 다변량 모형화를 목표로 한다면 코크리깅을 수행하는 것이 바람직하다. 코크리깅을 통해 예측 벡터 \\(\\hat{Z}(s_0)=(\\hat{Z}_1(s_0),...,\\hat{Z}_n(s_0))\\)를 얻을 뿐만 아니라, 예측 오차의 전체 공분산 행렬도 구할 수 있다(Ver Hoef and Cressie 1993). 이 예측 오차 공분산 행렬을 이용하면, \\(\\hat{Z}(s_0)\\)의 임의의 선형 조합—예를 들어 \\(\\hat{Z}_2(s_0)-\\hat{Z}_1(s_0)\\)—에 대한 표준 오차를 계산할 수 있다.\n베리오그램과 교차 베리오그램은 자동으로 계산하고 적합할 수 있지만, 변수의 수가 많아질수록 다변량 지구통계 모형화의 관리가 어려워진다. 이는 필요한 베리오그램 및 교차 베리오그램의 수가 \\(n(n+1)/2\\)로 늘어나기 때문이다.\n또한, 여러 변수라는 의미가 동일한 변수의 여러 시점을 가리키는 경우에도 다변량(코크리깅) 예측 방법을 적용할 수 있다. 하지만 이 경우 두 시점 사이의 임의 시점에 대해 직접적으로 내삽하는 것은 불가능하다. 이러한 상황이나, 여러 시간 인스턴스에서 관측된 데이터를 처리해야 하는 경우에는 \\(Z(s,t)\\)와 같이 연속적인 시공간 결합 함수를 통해 변동성을 모형화할 수 있다. 다음 절에서 이를 다룬다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "13.html#시공간-지구통계학",
    "href": "13.html#시공간-지구통계학",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "\n13.3 시공간 지구통계학",
    "text": "13.3 시공간 지구통계학\n시공간 지구통계 프로세스는 시공간의 모든 위치에서 변수 값이 존재한다는 전제에 기반한다. 이를 \\(Z(s,t)\\)로 나타낼 수 있으며, 여기서 \\(s\\)와 \\(t\\)는 시공간에서 연속적으로 정의되는 인덱스이다. 관측치 \\(Z(s_i,t_j)\\)와 베리오그램(또는 공변동) 모형 \\(\\gamma(s,t)\\)가 주어지면, 표준 가우시안 프로세스 이론을 활용해 임의의 시공간 위치 \\((s_0,t_0)\\)에서 속성값 \\(Z(s_0,t_0)\\)를 예측할 수 있다.\n최근에 시공간 지구통계 데이터의 처리 및 모형화에 관한 현대적인 접근을 다룬 책들이 출간되었다. 예를 들어 Wikle, Zammit-Mangion과 Cressie(2019), Blangiardo와 Cameletti(2015) 등이 있다. 여기서는 Gräler, Pebesma와 Heuvelink(2016)를 참고하며, 이전 장에서 사용한 데이터셋을 바탕으로 간단한 예제를 제시한다.\n\n13.3.1 시공간 베리오그램 모형\n이 장의 서두에서 NO\\(_2\\) 시공간 매트릭스 데이터를 aq 객체에 저장하였으며, 이로부터 완전한 레코드를 보유한 농촌 배경 관측소만을 선택해 aqsel 객체를 생성하였다. 최종적으로 74개 관측소의 공간 위치를 다음과 같이 선택할 수 있다.\n\nsfc &lt;- st_geometry(a2.sf)[match(colnames(aqsel),\n                           a2.sf$station_european_code)] |&gt;\n  st_transform(crs)\n\n그다음, 시간과 측정소를 디멘션으로 하는 stars 벡터 큐브를 생성한다.\n\nlibrary(stars)\n# Loading required package: abind\nst_as_stars(NO2 = as.matrix(aqsel)) |&gt;\n    st_set_dimensions(names = c(\"time\", \"station\")) |&gt;\n    st_set_dimensions(\"time\", index(aqsel)) |&gt;\n    st_set_dimensions(\"station\", sfc) -&gt; no2.st\nno2.st\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#      Min. 1st Qu. Median Mean 3rd Qu. Max.  NA's\n# NO2  -8.1    3.02   5.66 8.39    10.4  197 16134\n# dimension(s):\n#         from   to         offset   delta            refsys point\n# time       1 8760 2017-01-01 UTC 1 hours           POSIXct    NA\n# station    1   74             NA      NA WGS 84 / UTM z...  TRUE\n#                                          values\n# time                                       NULL\n# station POINT (439814 ...,...,POINT (456668 ...\n\n이 데이터를 바탕으로 다음과 같이 시공간 베리오그램을 생성한다.\n\nlibrary(gstat)\n\n\nv.st &lt;- variogramST(NO2~1, no2.st[,1:(24*31)], tlags = 0:48, \n    cores = getOption(\"mc.cores\", 2))\n\n그 결과는 그림 13.1에 제시되어 있다.\n\n\n\n\n\n그림 13.1: 2017년 독일의 농촌 배경 측정소의 시간별 NO\\(_2\\) 농도에 대한 시공간 표본 베리오그램이다. 오른쪽의 컬러는 시간 지체를 나타내며, 노란색일수록 더 늦은 시간을 의미한다. 거리는 미터 단위이다.\n\n\n이 표본 베리오그램에는 특정한 베리오그램 모형을 적합할 수 있다. 여기서는 비교적 유연한 모형인 곱합(product-sum) 모형(Gräler, Pebesma, and Heuvelink 2016)을 적용하며, 그 적합 과정은 다음과 같다.\n\n# product-sum\nprodSumModel &lt;- vgmST(\"productSum\",\n    space = vgm(150, \"Exp\", 200000, 0),\n    time = vgm(20, \"Sph\", 6, 0),\n    k = 2)\n#v.st$dist = v.st$dist / 1000\nStAni &lt;- estiStAni(v.st, c(0,200000))\n(fitProdSumModel &lt;- fit.StVariogram(v.st, prodSumModel,\n    fit.method = 7, stAni = StAni, method = \"L-BFGS-B\",\n    control = list(parscale = c(1,100000,1,1,0.1,1,10)),\n    lower = rep(0.0001, 7)))\n# space component: \n#   model    psill range\n# 1   Nug   0.0166     0\n# 2   Exp 152.7046 83590\n# time component: \n#   model   psill range\n# 1   Nug  0.0001  0.00\n# 2   Sph 25.5736  5.77\n# k: 0.00397635996859073\n\n그림 13.2에 결과가 제시되어 있으며, 그림 13.3과 같이 와이어프레임 형태로도 플로팅할 수 있다. 이 모형의 적합은 선택된 파라미터에 다소 민감한데, 이는 사용 가능한 관측소 수가 상대적으로 적은 74개에 불과하기 때문일 수 있다.\n\n\n\n\n\n그림 13.2: 표본 베리오그램은 곱합 모형 적합 결과\n\n\n\n\n\n\n\n그림 13.3: 적합된 시공간 베리오그램 모형의 와이어프레임 플롯\n\n\n시공간 베리오그램의 적합 전략과 대체 모형에 대해서는 Gräler, Pebesma와 Heuvelink(2016)를 참고하라.\n이 적합 모형과 주어진 관측치를 바탕으로 시공간의 임의 위치에 대해 크리깅이나 시뮬레이션을 수행할 수 있다. 예를 들어, 누락된 시계열 값을 추정(또는 시뮬레이션)하는데 활용할 수 있다. 이러한 상황은 흔히 발생하며, 이에 대한 대응으로 12.4절에서는 관측치의 최대 25%를 제외하고 시계열 평균을 계산한 바 있다. 보다 더 합리적인 방법은 결측치를 시공간적 이웃의 관측치에 기반한 추정값이나 시뮬레이션 값으로 대체한 후 연간 평균을 계산하는 것이다.\n보다 일반적인 관점에서, 임의의 시공간 위치에서 추정을 수행할 수 있다. 이러한 과정을 특정 위치의 시계열 값을 예측하는 경우와 공간 슬라이스를 예측하는 경우를 통해 설명할 것이다(Gräler, Pebesma, and Heuvelink 2016). 이를 위해 두 개의 공간 지점을 무작위로 선택하고, 이들 두 지점에 대한 모든 시간 인스턴스를 포함한 stars 객체를 생성한다.\n\nset.seed(1331)\npt &lt;- st_sample(de, 2)\nt &lt;- st_get_dimension_values(no2.st, 1)\nst_as_stars(list(pts = matrix(1, length(t), length(pt)))) |&gt;\n    st_set_dimensions(names = c(\"time\", \"station\")) |&gt;\n    st_set_dimensions(\"time\", t) |&gt;\n    st_set_dimensions(\"station\", pt) -&gt; new_pt\n\n그다음, krigeST() 함수를 사용해 이 두 지점의 시공간 예측값을 구한다.\n\nno2.st &lt;- st_transform(no2.st, crs)\nnew_ts &lt;- krigeST(NO2~1, data = no2.st[\"NO2\"], newdata = new_pt,\n         nmax = 50, stAni = StAni, modelList = fitProdSumModel,\n         progress = FALSE)\n\n그 결과는 그림 13.4에 제시되어 있다.\n\n\n\n\n\n그림 13.4: 선택된 두 지점의 시공간 예측 시계열 플롯\n\n\n또한, 2017년 한 해 동안 일정한 시간 간격으로 생성된 일련의 래스터 지도에 대해 시공간 예측을 생성할 수 있으며, 이는 다음과 같이 수행된다.\n\nst_bbox(de) |&gt;\n  st_as_stars(dx = 10000) |&gt;\n  st_crop(de) -&gt; grd\nd &lt;- dim(grd)\nt4 &lt;- t[(1:4 - 0.5) * (3*24*30)]\nst_as_stars(pts = array(1, c(d[1], d[2], time = length(t4)))) |&gt;\n    st_set_dimensions(\"time\", t4) |&gt;\n    st_set_dimensions(\"x\", st_get_dimension_values(grd, \"x\")) |&gt;\n    st_set_dimensions(\"y\", st_get_dimension_values(grd, \"y\")) |&gt;\n    st_set_crs(crs) -&gt; grd.st\n\n예측은 다음과 같이 수행된다.\n\nnew_int &lt;- krigeST(NO2~1, data = no2.st[\"NO2\"], newdata = grd.st,\n         nmax = 200, stAni = StAni, modelList = fitProdSumModel,\n         progress = FALSE)\nnames(new_int)[2] = \"NO2\"\n\n그 결과는 그림 13.5에 제시되어 있다.\n\n\n\n\n\n그림 13.5: 네 개 시점의 시공간 예측 결과\n\n\n여기서는 nmax 인수 값을 크게 설정할 필요가 있었다. 이는 이산적인 이웃 선택에서 시간과 공간을 모두 고려해야 하며, 그로 인해 발생할 수 있는 시각적 왜곡(날카로운 경계)을 줄이기 위한 조치이다.(역자주: 시공간 크리깅에서는 예측값을 계산할 때 주변의 ‘이웃’ 데이터를 선택한다. 이웃을 선택할 때 공간 거리뿐 아니라 시간 차이까지 함께 고려하면, 적합한 이웃 수가 줄어들어 지도에 뚜렷하고 부자연스러운 경계선이 생길 수 있다. nmax 값을 크게 설정하면 이웃을 더 많이 포함시켜 이러한 경계를 완화할 수 있다.)\n\n13.3.2 불규칙 시공간 데이터\n관측 지점이 계속 변하거나, 고정된 관측 지점이라 하더라도 시간 프레임이 일관되지 않은 경우 stars 객체(벡터 데이터 큐브)는 이러한 데이터를 잘 처리하지 못한다. 이러한 불규칙 시공간 관측치는 sftime 패키지(Teickner, Pebesma, and Graeler 2022)에서 제공하는 sftime 객체로 표현할 수 있다. sftime 객체는 기본적으로 sf 객체에 지정된 시간 컬럼을 포함한 형태이다. 사용 예시는 gstat 패키지에서 제공되는 demo(sftime)에서 확인할 수 있다.",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  },
  {
    "objectID": "13.html#연습문제",
    "href": "13.html#연습문제",
    "title": "13  다변량 및 시공간 지구통계학",
    "section": "\n13.4 연습문제",
    "text": "13.4 연습문제\n\n13.1절에서 “관측소가 최소 75%의 완전한 데이터를 보유해야 한다”는 기준을 적용할 때, 전체 관측소의 몇 %가 제거되는지 말하시오.\nno2.st의 시간별 시계열 데이터에서 aggregate() 함수를 사용하여 일별 평균 농도를 계산하고, 이에 대한 시공간 베리오그램을 작성하시오. 이를 시간별 베리오그램과 비교하시오.\n그림 13.5에 표시된 날짜의 일별 평균값에 대해 시공간 내삽을 수행하고, 그 결과를 비교하시오.\n13.2절에서 소개된 데모 스크립트 예를 참고하여, 그림 13.5에 표시된 네 날짜의 일별 평균 관측소 데이터를 사용해 코크리깅을 수행하시오.\n위에서 제시한 시공간 크리깅 접근법이 가지는 차별점은 무엇인지 말하시오.\n\n\n\n\n그림 13.1: 2017년 독일의 농촌 배경 측정소의 시간별 NO\\(_2\\) 농도에 대한 시공간 표본 베리오그램이다. 오른쪽의 컬러는 시간 지체를 나타내며, 노란색일수록 더 늦은 시간을 의미한다. 거리는 미터 단위이다.\n그림 13.2: 표본 베리오그램은 곱합 모형 적합 결과\n그림 13.3: 적합된 시공간 베리오그램 모형의 와이어프레임 플롯\n그림 13.4: 선택된 두 지점의 시공간 예측 시계열 플롯\n그림 13.5: 네 개 시점의 시공간 예측 결과",
    "crumbs": [
      "공간통계분석과 공간모델링",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>다변량 및 시공간 지구통계학</span>"
    ]
  }
]