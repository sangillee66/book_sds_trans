---
date-modified: last-modified
number-sections: true
format: 
  html: 
    toc: true
code-link: true
code-copy: true
execute: 
  warning: false
  error: false
  freeze: auto
editor: visual
---

# 공간데이터의 통계적 모형화 {#sec-statistical}

지금까지 이 책은 주로 데이터를 기술하거나 탐색하는 문제를 다뤘다. 이는 기하학적 측정, 프레디케이트, 지오메트리 변환, 속성의 통계적 요약, 플로팅 등의 방법으로 이루어졌다. 특히 플로팅은 지오메트리와 속성 각각의 변동성을 보여줄 뿐만 아니라 두 요소의 결합 변동성까지 보여준다.

통계적 모형화는은 단순한 데이터의 기술 및 탐색을 넘어, 데이터를 모집단에서 추출된 표본으로 간주하고 모집단에 대한 추론을 수행하는 것을 목표로 한다. 예를 들어 변수들 간 관계를 정량화하고, 모집단의 모수를 추정하며, 인터폴레이션처럼 실제로 관측되지 않은 값을 예측하는 작업이 이에 해당한다.

이는 보통 데이터에 대한 모형을 수립하여 수행되며, 예를 들어 특정 모형은 관측값을 다음과 같이 분해한다.

$$
\mbox{관측값}=\mbox{설명된 부분}+\mbox{잔여 부분}
$$ {#eq-model}

여기서 '설명된 부분'은 일반적으로 관측 변수와 관련된 외부 변수(예측 변수, 공변량, 머신러닝에서는 혼동되게 *피처*라고도 함)와, 관측 변수의 변동성을 설명하기 위한 회귀 모형 등을 활용하여 산출된다. 반면 '잔여 부분'은 설명되지 않은 나머지 변동성을 의미한다. 이러한 통계적 모형화의 목적은 예측 변수와 관측 변수 간 관계의 특성과 크기를 파악하거나, 새로운 관측값을 예측하는데 있을 수 있다.

통계 모형과 표본 추출은 확률 개념에 근거한다. 그런데 공간데이터사이언스에서 확률은 자명한 것이 아니라, 특정한 방식으로 가정되어야 한다. (공간적) 무작위 표본 추출로 얻은 데이터가 주어지고 평균이나 합계을 추정하는 것이 목표라면, 표본 위치의 무작위성을 전제로 하는 *디자인 기반*(design-based) 접근법이 가장 적절하다(10.4절에서 더 자세히 설명한다). 반대로 관측값이 무작위로 추출되지 않았거나, 특정 위치의 값을 예측하여 지도화하는 것이 목적이라면 *모형 기반*(model-based) 접근법이 필요하다.(역자주: 디자인 기반 접근법은 표본 설계(예: 무작위 표본 추출)에 내재된 확률에 의존하여 전체 평균이나 총합을 추정하는 방식이다. 예를 들어, 전국 농경지에서 무작위로 선정한 지점의 토양 질소 함량을 바탕으로 전국 평균을 추정하는 경우가 이에 해당한다. 반면, 모형 기반 접근법은 데이터 생성 과정을 설명하는 통계적 가정에 따라 확률 구조를 정의하며, 표본이 무작위로 배치되지 않아도 적용할 수 있다. 예를 들어, 특정 위치의 대기질을 예측하기 위해 측정소 자료와 공간 회귀모형을 활용해 지도화하는 경우가 이에 해당한다.) 이 제3부의 나머지 장에서는 모형 기반 접근법을 다룬다.

## 비공간적 회귀분석과 머신러닝 모형을 통한 지도화

회귀모형이나 기타 머신러닝(ML) 모형은 비공간 문제에서 새로운 관측값을 예측하는 방식과 동일하게, 공간 및 시공간 데이터에도 적용할 수 있다.

1.  **추정**: 주어진 일련의 관측값에 대해, 해당 관측값에 대응하는 예측 변수 값을 사용하여 회귀 또는 머신러닝 모형을 적합시킨다. 머신러닝 용어로는 이 단계를 '훈련(training)'이라고 한다.

2.  **예측**: 새로운 상황에서 알려진 예측 변수 값을 적합된 모형에 적용하여 관측 변수 값을 예측하며, 가능하다면 예측오차나 예측구간도 함께 제시한다.

`sf` 클래스 객체는 본질적으로 `data.frame` 객체이므로 특별한 처리가 필요 없다. 예측 결과를 지도에 표현하려면, 예측된 값을 `sf` 객체에 추가하면 되며, 1장에서 불러온 `nc` 데이터셋을 사용하면 다음과 같이 구현할 수 있다.

```{r}
#| eval: false
nc |> mutate(SID = SID74/BIR74, NWB = NWBIR74/BIR74) -> nc1
lm(SID ~ NWB, nc1) |>
  predict(nc1, interval = "prediction") -> pr
bind_cols(nc, pr) |> names()
#  [1] "AREA"      "PERIMETER" "CNTY_"     "CNTY_ID"   "NAME"     
#  [6] "FIPS"      "FIPSNO"    "CRESS_ID"  "BIR74"     "SID74"    
# [11] "NWBIR74"   "BIR79"     "SID79"     "NWBIR79"   "geom"     
# [16] "fit"       "lwr"       "upr"
```

여기에서 우리는 다음과 같은 점을 확인할 수 있다.

-   `lm()` 함수는 선형모형을 추정하며, `sf` 객체에도 직접 적용할 수 있다.

-   모형의 결과가 `predict()` 함수에 전달되며, 이 함수는 `nc`와 동일하게 `sf` 객체인 `nc1`에 대한 예측값을 생성한다.

-   `predict()` 함수는 세 개의 열을 반환하는데, `fit`은 예측값을, `lwr`과 `upr`은 각각 95% 예측구간의 하한과 상한을 나타낸다.

-   이 세 열은 `bind_cols()` 함수를 사용해 최종 객체에 추가된다.

많은 회귀 및 머신러닝 유형의 문제들이 동일한 구조를 공유하므로, **caret**(Kuhn 2022)이나 **tidymodels**(Kuhn and Wickham 2022)과 같은 패키지는 다양한 모형 대안을 자동으로 평가ㆍ비교할 수 있으며, 여러 모형 평가 지표와 교차검증(cross-validation) 전략을 제공한다. 이러한 교차검증 접근법은 기본적으로 관측값들이 서로 독립이라는 가정에 기반한다. 그러나 공간데이터에서는 이 가정이 타당하지 않은 경우가 많다. 이는 공간적 자기상관(Ploton et al. 2020)이나 표본 데이터의 강한 공간 클러스터링(Meyer and Pebesma 2022), 혹은 두 가지 모두에 기인할 수 있다. 이러한 단순 교차검증을 대체하기 위한 방법을 제공하는 R 패키지로는 **spatialsample** (Silge and Mahoney 2023), **CAST**(Meyer, Milà, and Ludwig 2023), **mlr3spatial**(Becker and Schratz 2022), **mlr3spatiotempcv**(Schratz and Becker 2022) 등이 있다.(역자주: 여기서 말하는 ‘단순 교차검증’은 관측값이 서로 독립이라고 전제하고 무작위로 데이터를 나누는 전통적인 교차검증을 의미한다. 그러나 공간데이터에서는 공간적 자기상관이나 표본의 공간 클러스터링으로 인해 이 가정이 자주 위배된다. `spatialsample`, `CAST`, `mlr3spatial` 등에서 제공하는 방법은 이러한 비독립성을 완화하기 위해 공간적·시공간적 구조를 반영한 교차검증을 수행한다.)

표본의 강한 공간 클러스터링은 여러 이유로 발생할 수 있다. 하나는 서로 다른 데이터베이스를 결합해 하나의 표본 데이터를 구성하는 경우로, 각 데이터베이스가 서로 다른 샘플링 밀도를 갖기 때문에 주로 글로벌 데이터셋에서 나타난다(Meyer and Pebesma 2022). 또 다른 예로는 토지 피복 클래스를 샘플링하기 위해 폴리곤을 디지타이징한 뒤, 이 폴리곤 내부에서 위성 이미지의 픽셀 해상도로 포인트를 샘플링하는 경우가 있다.(역자주: 전자의 경우, 각 데이터베이스의 관측 밀도가 달라 특정 지역에 표본이 집중되며, 이 표본들은 서로 유사한 값을 보일 가능성이 높다. 후자의 경우, 특정 토지피복 폴리곤은 내부가 대체로 동질적이므로, 그 안에서 추출한 위성영상 픽셀들도 유사한 값을 나타낼 가능성이 높다.)

모형의 ‘잔여 부분’에 존재하는 공간적 상관성은 예측 변수 집합에 공간 좌표나 공간 좌표의 함수를 추가함으로써 줄일 수 있다. 그러나 이러한 방법은 외삽(extrapolation) 상황에서 과도하게 낙관적인 예측을 초래할 위험이 있으며, (교차)검증과 모형 평가에서도 동일한 문제가 발생할 수 있다.(역자주: 여기서 말하는 ‘과도하게 낙관적인 예측’이란, 모형이 실제 예측력을 과대평가하는 상황을 의미한다. 예를 들어 경향면 분석(trend surface analysis)처럼 좌표를 예측 변수로 사용하면, 공간적 자기상관 때문에 훈련 데이터와 가까운 검증 지점의 값이 지나치게 잘 맞는 것처럼 보인다. 그러나 이러한 모형은 훈련 범위를 벗어난 지역(외삽)에서는 예측 성능이 크게 저하될 수 있다.) 이에 대해서는 10.5절에서 더 자세히 논의한다.

## 서포트와 통계적 모형화

데이터의 서포트(1.6절; 5장) 개념은 공간데이터의 통계 분석에서 중요한 역할을 한다. 에어리어 데이터에 적용되는 기법(14\~17장)은 에어리어 서포트를 가진 데이터, 즉 여러 에어리어가 모여 전체 지역을 포괄하는 데이터를 대상으로 한다.

공간 외연 변수를 코로플레스 맵으로 나타내는 것은(예: 그림 1.1) 상당히 위험할 수 있다. 이는 정보가 폴리곤 크기와 연관되면서, 컬러로 표현된 속성값이 해당 폴리곤 전역에서 동일하게 나타나는 것처럼 보이기 때문이다. 이를 피하는 한 가지 방법은 공간 외연 변수를 공간 내포 변수로 변환하는 것이다. 예를 들어, *인구 수*와 같은 변수의 경우 폴리곤 면적으로 나누어 *인구 밀도*를 계산한 뒤 이를 지도에 나타낼 수 있다. 보건 데이터에서 그럼 1.1과 같이 연도별 발병자 수를 나타내는 경우에는, 폴리곤 면적으로 나누어 공간적 밀도를 구하기보다는 해당 폴리곤의 인구 수로 나누어 확률이나 *발병률*로 변환하는 것이 일반적이다. 이 경우에도 변수는 폴리곤 면적과 연관되지만, 그 스포트는 인구 총수와 관련된다. 이러한 총수는 후속 모형화, 예를 들어 16장에서 다루는 CAR 유형 모형에서 (포아송) 변동성을 추정하는 데 중요한 역할을 한다.

11장은 원칙적으로 포인트 서포트 관측 개체를 다루지만, 그렇다고 해서 관측 개체가 면적이 전혀 없는 0차원이라는 뜻은 아니다. 예를 들어, 나무 줄기 '포인트'의 경우 나무 지름보다 작은 거리에서는 다른 포인트가 존재할 수 없다. 또한 포인트 패턴 분석에서 포인트는 *관측 창*(observational window) 개념에 따라 정의되며, 이 관측 창은 완전한 포인터 데이터셋을 구성해야 한다(즉, 관측 창 외부에는 포인트가 없다)(역자주: 포인트 패턴 분석에서 ‘관측 창’은 분석 대상이 되는 공간 범위를 뜻하며, 이 범위 안의 포인트가 누락 없이 완전히 기록되어 있다고 가정한다. 일반적인 ‘연구 범위’ 개념과 유사하지만, 자료의 완전성을 전제로 한다는 점에서 더 엄격하다.) 관측 창 개념은 많은 분석 도구의 전제에 영향을 미친다. 만약 포인트가 라인 네트워크 상에서 관측된다면, 관측 창은 관측된 라인의 집합으로 구성되며, 포인트 간 거리는 해당 네트워크를 따라 측정된다.

지구통계학적 데이터(12장 및 13장)는 일반적으로 포인트 서포트 관측값에 기반하여, 연구 대상 지역 내 비관측 지점의 값을 예측하거나(공간적 인터폴레이션), 세부 지역의 평균값을 예측한다(블록 크리깅; 12.5절). 관측값이 포인트 값이 아니라 구역 전체의 집계값일 수도 있다(Skøien et al. 2014). 원격탐사 데이터에서 픽셀 값은 보통 픽셀 전체에 대한 집계값이다. 이 경우 구름으로 인한 이미지의 결함을 인접한 공간 및 시간의 픽셀 정보로 보완하는 것이 중요한 과제다(Militino et al. 2019).

서로 다른 공간 서포트를 가진 데이터를 결합할 때, 모든 데이터를 해상도가 가장 높은 데이터에 '맞추는' 경우가 종종 있다. 예를 들어, 행정구역 폴리곤과 래스터 레이어를 결합하는 경우, 래스터 레이어의 개별 픽셀 위치에서 폴리곤 속성값을 단순 추출하고, 이렇게 생성된 '관측값'을 기반으로 분석을 진행하는 방식이다. 그러나 이러한 방식으로 생성된 '데이터'를 분석하면 비합리적인 결과를 초래할 위험이 크다. 불확실성에 대응하기 위해서는 시뮬레이션을 활용한 적절한 다운샘플링 전략이 더 나은 대안이 될 수 있다. 특히 초보 사용자가 소프트웨어를 경각심 없이 사용할 경우가 우려되는데, 일부 소프트웨어는 구역 관련 속성값의 서포트 개념을 제대로 다루지 않거나, 안이한 다운샘플링에 대한 경고 조차 제공하지 않기 때문이다.

## 예측 모형에서의 시간

Schabenberger와 Gotway(2005)는 이미 오래전에, 많은 시공간 데이터의 통계 분석이 시간 차원을 먼저 축소한 뒤 해당 문제를 공간적으로 다루는 방식(시간 먼저, 공간 나중)이나, 공간 차원을 먼저 축소한 뒤 문제를 시간적으로 다루는 방식(공간 먼저, 시간 나중)으로 진행된다고 지적한 바 있다. 첫 번째 접근 방식의 예는 12장에서 볼 수 있다. 여기서는 1년 동안의 시간 단위 측정값 데이터셋(13장에서 자세히 설명됨)을 먼저 측정소의 평균 값으로 축소한 후(시간 먼저), 이 평균 값을 공간적으로 인터폴레이션하는(공간 나중) 과정을 보여준다.

원격탐사 분야에서의 예시는 다음과 같다.

-   Simoes et al. (2021)은 지도학습 기법과 시계열 딥러닝을 사용하여 픽셀 시계열을 토지이용 시퀀스로 분할한 후(시간 먼저), 결과로 생성된 맵 시퀀스를 평활화하여 개별 필셀이 나타내는 불가능한 전환을 제거한다(공간 나중).

-   Verbesselt et al. (2010)은 픽셀 시계열에서 급변점을 탐지하기 위해 비지도 구조적 변화 알고리즘을 적용하고(시간 먼저), 이후 이러한 급변점을 산림 파괴의 맥락에서 해석한다.

원격탐사 분야에서 공간 먼저, 시간 나중 접근 방식의 예로는, 단일 레이어(scene) 또는 단일 시즌에 속하는 레이어를 먼저 분류한 뒤, 분류된 레이어의 시간 순서를 비교하여 토지이용 또는 토지피복의 장기 변화를 평가하는 경우가 있다. Brown et al. (2022)가 그 예이다. 공간과 시간을 *함께* 고려하는 예로는 13장에서 다루는 시공간 인터폴레이션(spatiotemporal interpolation)과 Lu et al. (2016)이 원격탐사 맥락에서 제시한 연구가 있다.

## 디자인 기반 추정과 모형 기반 추정

통계적 추론은 표본 데이터를 바탕으로 모집단의 파라미터(모수)를 추정하는 것을 의미한다. 위치 $s$에서 측정된 속성값을 $z$라고 하면, 변수는 $z(s)$로 나타낼 수 있다. 이제 표본 데이터 $z(s_1),...,z(s_n)$르를 이용해 도메인 $D$의 면적 $|D|$에 대한 $z(s)$의 평균값을 추정한다고 하자.

$$
z(s)=\frac{1}{|D|}\int_{u\in D}z(u)du
$$

이 때 가능한 접근법은 크게 모형과 디자인 기반 두 가지다. 모형 기반 접근법에서는 $z(s)$를 초모집단 $Z(s)$의 실현으로 간주하며(확률 변수를 나타내기 위해 대문자를 사용), 예를 들어 다음과 같은 공간 변동성 모형을 가정할 수 있다.

$$
Z(s)=m+e(s),\quad \text{E}(e(s))=0, \quad \text{Cov}(e(s))=\Sigma(\theta)
$$

여기서 $m$은 상수(constant) 평균이고 $e(s)$는 평균이 0이며 공분산 행렬이 $\Sigma(\theta)$인 잔차를 의미한다. 이 경우, 공분산 함수 $\Sigma(\theta)$를 선택하고, $z(s)$로부터 매개변수 $\theta$를 추정한 다음, 블록 크리깅 예측값 $\hat{Z}(D)$를 계산한다(12.5절). 이 접근법은 $z(s)$가 공간적으로 어떻게 샘플링되었는지에 대한 가정을 필요로 하지 않지만, 공분산 함수를 적절히 선택하고 그 파라미터를 추정할 수 있어야 한다. 따라서 추론의 신뢰성은 가정된 모형이 타당한지 여부에 달려있다.

디자인 기반 접근법(De Gruijter and Ter Braak 1990; Brus 2021a; Breidt, Opsomer 등 2017)은 초모집단 모형이 아니라 위치의 무작위성을 가정한다. 따라서 이 접근법은 무작위 표본추출을 사용할 때만 정당화된다. 표본 데이터는 반드시 확률 표본추출을 통해 획득되어야 하며, $z(s)$의 모든 요소가 표본에 포함될 (양수) 확률이 수학적으로 규정된 특정 형태의 공간적 무작위 표본추출이 사용되어야 한다. 이 접근법에서 무작위 과정은 표본추출 과정이다. 즉 $z(s_1)$은 *무작위 펴본추출을 반복하여 얻은* 첫 번째 관측값이며, 이는 무작위 과정 $z(S_1)$의 한 실현이다. 디자인 기반 추정량은 이러한 포함 확률만 있으면 평균값을 표준오차와 함께 추정할 수 있다.(역자주: 포함 확률(inclusion probability)이란 모집단의 각 단위(예: 지역, 가구, 포인트)가 표본에 포함될 확률을 말한다. 디자인 기반 표본추출에서는 이 확률이 사전에 정의되고 계산 가능해야 하며, 이를 활용해 평균이나 총합을 편향 없이 추정할 수 있다.) 예를 들어 단순 무작위 표본이 주어진 경우, 가중치가 없는 표본 평균이 그대로 모집단 평균을 추정하는 데 사용되며, 모형 파라미터를 적합시킬 필요가 없다.

이제 질문은, $s_1$과 $s_2$가 서로 가까이 있을 때 $z(s_1)$과 $z(s_2)$가 상관될 것으로 기대할 수 있는가 하는 점이다. $z(s_1)$과 $z(s_2)$가 단지 두 개의 숫자에 불과하다면, 이 질문은 성립하지 않는다. 상관성을 논하려면 확률 변수와 같은 일종의 프레임워크가 필요하며, 이를 위해서는 이러한 상황을 재현할 수 있는 두 세트의 숫자를 만들어 내야 한다. 여기서 흔히 발생하는 오해는, Brus(2021a)가 설명한 바와 같이, 두 세트의 숫자가 항상 공간적으로 상관되어 있다고 생각하는 것이다. 그러나 이는 $Z(s_1)$과 $Z(s_2)$가 강한 상관성을 가진다고 가정하는 모형을 전제로 할 때만 성립한다('모형 의존'). 특정 무작위 표본(실현)에서 $z(s_1)$과 $z(s_2)$는 공간적으로 가까울 *수* 있지만, 반복적 무작위 표본추출을 통해 얻은 확률 변수 $z(S_1)$과 $z(S_2)$는 공간적으로 가깝지 않을 수 있으며, 표본 설계상 서로 독립일 수도 있다. 이 두 상황은 모순 없이 공존할 수 있으며, 어떤 추론 프레임워크를 선택하느냐의 문제일 뿐이다.

디자인 기반 프레임워크를 선택할지, 모형 기반 프레임워크를 선택할지는 연구 목적과 데이터 수집 방식에 따라 달라진다. 모형 기반 프레임워크는 다음과 같은 경우에 가장 적합하다.

-   개별 위치에 대한 예측이 필요하거나, 표본추출이 불가능할 만큼 작은 지역에 대한 예측이 필요한 경우

-   데이터가 무작위 표본추출 방식으로 수집되지 않은 경우(즉, 포함 확률이 알려져 있지 않거나, 특정 지역이나 시기에 대해 포함 확률이 0인 경우)

디자인 기반 접근법은 다음과 같은 경우에 가장 적합하다.

-   관측값이 공간 무작위 표본추출 과정을 통해 수집된 경우

-   전체 표본 지역(또는 하위 지역)에 대한 집계 속성이 필요한 경우

-   규제나 법적 목적 등에서, 모형 오지정 문제에 민감하지 않은 추정치가 필요한 경우

표본추출 절차를 계획해야 한다면(De Gruijter et al. 2006), 공간적 무작위 표본추출 방식을 고려하는 것은 매우 바람직하다. 이는 두 가지 추론 프레임워크를 모두 활용할 수 있는 가능성을 열어주기 때문이다.

## 좌표값을 활용한 예측 모형

데이터사이언스 프로젝트를 수행할 때, 좌표값을 예측 변수(또는 피처, 공변량) 중 하나로 포함하여 다른 변수와 동일하게 취급하는 경우가 있다. 그러나 이러한 접근에는 몇 가지 잠재적 위험이 존재한다.

예측 변수를 다룰 때와 마찬가지로, 원점 이동이나 단위(스케일) 변화에 민감하지 않은 예측 기법을 선택하는 것이 바람직하다. 2차원 문제를 가정할 경우, 예측 모형은 $x$축과 $y$축 또는 위도와 경도 축의 임의 회전에 민감해서는 안 된다. 투영된 2차원(데카르트) 좌표에서는, 예를 들어 $(x+y)^n$과 같은 $n$차 다항식을 사용하여 이러한 특성을 보장할 수 있으며, 이는 $(x)^n+(y)^n$ 형태 대신 사용된다. 2차 다항식의 경우에는 $xy$항을 포함시켜 타원형 경향면이 반드시 $x$축이나 $y$축에 정렬될 필요가 없도록 한다. 스플라인(spline) 요소를 포함하는 GAM 모형에서도, 상호작용을 허용하지 않는 독립적 스플라인 $s(x)$와 $s(y)$ 대신 2차원 스플라인 $s(x,y)$를 사용하는 것이 바람직하다.(역자주: 좌표값을 예측 변수로 사용할 때는, 모형이 좌표의 ‘위치나 단위, 회전’에 따라 결과가 달라지는 문제를 피해야 한다. 예를 들어, 위도와 경도 축을 조금만 돌려도 예측 결과가 크게 달라진다면, 모형은 좌표를 잘못 활용하고 있는 셈이다. 이를 막기 위해 좌표를 다항식이나 2차원 스플라인 형태로 처리하면, 회전이나 단위 변화에 덜 민감한 모형을 만들 수 있다.) 이러한 '규칙'에도 예외가 있다. 예를 들어, 연간 총 태양에너지 유입량을 설명할 때는 위도의 효과만으로 충분한 경우가 이에 해당한다.

데이터가 넓은 지역에 걸쳐 있는 경우, 타원체 좌표와 투영 좌표 중 어떤 것을 사용하는지에 따라 예측 모형화 결과가 크게 달라질 수 있다. 범위가 매우 넓거나 전 지구적인 모형에서는, 위도와 경도 좌표를 사용한 다항식이나 스플라인이 경도의 순환 특성과 극지점에서의 좌표 특이성을 무시하기 때문에 제대로 작동하지 않는다.(역자주: '경도의 순환 특성'이란 경도 값이 180°(또는 360°)를 넘으면 다시 처음으로 돌아가는 성질을 말한다. 예를 들어 경도 179°와 -179°는 실제로 불과 2° 떨어져 있지만, 단순 계산으로는 358° 차이가 난다. '극지점에서의 좌표 특이성'이란 위도 ±90°에서는 모든 경도가 같은 지점을 가리켜 경도 정보가 무의미해지는 현상을 말한다. 이 두 문제 때문에 위도와 경도를 그대로 모형에 사용하면 경계 근처나 극지방에서 불연속이나 왜곡이 발생할 수 있다.) 이러한 경우, 다항식이나 스플라인 기저 함수의 대안으로 구면 조화 함수(spherical harmonics)를 사용할 수 있다. 구면 조화 함수는 구면 위에서 연속성을 유지하며, 공간 주파수가 높아질수록 더 세밀한 변화를 표현할 수 있다.

많은 경우, 표본이 수집된 공간 좌표는 예측이 이루어질 공간 범위도 정의하므로, 좌표 변수는 다른 예측 변수와 뚜렷이 구별되는 특성을 가진다. 대부분의 단순한 예측 기법, 특히 많은 머신러닝 방법은 표본 데이터가 서로 독립적이라고 가정한다. 표본이 대상 지역에서 공간 무작위 표본추출로 수집된 경우, 디자인 기반 모형의 맥락에서는 이 가정을 정당화할 수 있다(Brus 2021b). 그러나 디자인 기반 접근에서는 좌표 공간을 무작위화의 대상 변수로 간주하므로, 새롭게 무작위로 선택된 위치에 대해서는 예측이 가능하지만 고정된 위치에 대한 예측은 불가능하다. 즉, 표본이 수집된 지역의 평균값은 추정할 수 있지만, 그 지역에 대한 공간적 인터폴레이션값은 얻을 수 없다.(역자주: 디자인 기반 접근에서는 새로 무작위로 뽑힌 위치는 표본추출 설계의 일부로 간주되므로, 그 위치의 값을 모집단 평균이나 총합 추정 과정에 포함시켜 예측할 수 있다. 반면, 이미 정해진 특정 위치는 표본추출 과정에서 무작위로 선정된 것이 아니므로, 그 값을 예측하려면 모형에 의존해야 하며, 이 경우는 모형 기반 접근이 필요하다.) 따라서 고정된 위치에 대한 예측이 필요하거나, 데이터가 공간 무작위 표본추출로 수집되지 않은 경우에는 모형 기반 접근(12장에서 설명)과 더불어 잔차의 공간적 및/또는 시간적 자기상관을 가정하는 방법을 고려해야 한다.

일반적으로 표본 데이터는 '기회적 표본(opportunistic sample)'인 경우가 많다(즉, “찾을 수 있는 것은 모두” 수집). 이후 이러한 데이터가 가중치 없이 예측 프레임워크에서 사용되면, 결과 모형은 예측 변수 공간 및/또는 공간 좌표 공간에서 과대표집된 영역으로 편향될 수 있다. 이 경우 단순한 (무작위) 교차검증 통계를 공간 예측 성능의 척도로 사용할 때, 실제보다 지나치게 낙관적인 결과가 나올 수 있다(Meyer and Pebesma 2021, 2022; Mila et al. 2022). 이러한 상황에서 공간적 교차검증(spatial cross-validation)과 같은 적응형 교차검증 기법이 예측 성능에 대한 보다 신뢰성 높은 평가값을 얻는 데 도움이 될 수 있다.(역자주: 기회적 표본은 체계적 표본 설계 없이 “얻을 수 있는 모든 데이터”를 모은 것으로, 대개 특정 지역이나 조건에 표본이 과도하게 몰린다. 이렇게 분포가 고르지 않은 데이터를 가중치 없이 예측 모형에 사용하면, 표본이 많은 영역에서는 성능이 높게 나오지만, 표본이 적거나 없는 영역은 실제보다 예측이 잘 되는 것처럼 보이는 편향이 발생한다. 무작위 교차검증을 적용하면 훈련 세트와 검증 세트가 공간적으로 가까운 지점에서 추출되어 이러한 편향이 더 심해지며, 그 결과 예측 성능이 과도하게 낙관적으로 평가될 수 있다. 이러한 문제를 완화하려면 훈련 세트와 검증 세트를 공간적으로 분리하는 공간적 교차검증과 같은 적응형 교차검증 기법을 사용하는 것이 효과적이다.)

## 연습문제

다음 연습문제를 R을 사용하여 해결하시오.

1.  10.1절의 `lm()` 함수 예제를 참고하여 랜덤 포레스트 모형(예: **randomForest** 패키지 사용)을 이용해 `SID` 값을 예측하고, 랜던 포레스트 예측값을 관측값과 함께 플로팅하되 $x=y$ 선도 함께 표시하시오.

2.  `nc` 데이터셋에서 1,000개의 포인트를 무작위로 추출하여 새로운 데이터셋을 만들고, 이 데이터셋에 10.1절의 선형회귀 모형을 다시 실행하시오. 적합된 모형의 `summary()`를 확인하고, 특히 추정 계수, 표준오차, 잔차 표준오차에 주목하시오. 원래 모형과 비교했을 때 무엇이 달라졌는지 설명하시오.

3.  7.4.6절의 수역-육지 분류를 `lda()` 함수 대신 `class::knn()` 함수를 사용하여 `k = 5`로 설정한 후 다시 수행하고, 예측값을 `lda()` 함수의 예측값과 비교하시오.

4.  `nc` 데이터셋을 사용하는 선형 모형과 이전 연습문제의 `knn` 예제에 대해, 1차 및 2차 공간 좌표 변수를 추가한 다항 선형 모형을 실행하고 결과를 비교하시오. 이를 위해 `st_centroid()` 함수를 사용하여 폴리곤의 중심점을 얻고, `st_coordinates()` 함수를 사용하여 `x` 및 `y` 좌표를 행렬 형태로 추출하시오.
