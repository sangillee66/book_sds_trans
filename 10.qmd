---
date-modified: last-modified
number-sections: true
format: 
  html: 
    toc: true
code-link: true
code-copy: true
execute: 
  warning: false
  error: false
  freeze: auto
editor: visual
---

# 공간데이터의 통계적 모델링 {#sec-statistical}

지금까지 이 책에서는 주로 데이터를 기술하거나 탐색하는 문제를 다뤘다. 이는 기하학적 측정, 프리디케이트, 지오메트리 변환, 속성의 통계적 요약, 플로팅 등의 방법을 통해 이루어졌다. 특히 플로팅은 지오메트리와 속성 각각의 변동성을 보여줄 뿐만 아니라 두 가지 모두의 변동성도 보여준다.

통계적 모델링은 단순히 데이터를 기술하거나 탐색하는 것을 넘어서, 데이터를 모집단에서 추출된 표본으로 간주하고, 모집단에 대한 평가(추론)를 시도하는 것을 목표로 한다. 예를 들어 변수들 간의 관계를 정량화하거나, 모집단의 모수를 추정하거나, 인터폴레이션 문제처럼 실제로 관측되지 않은 결과를 예측하는 등의 방법이 이에 해당한다.

이는 보통 데이터에 대한 모델 수립을 통해 수행되며, 예를 들어 특정 모델은 관측값을 다음과 같이 분해한다.

$$
\mbox{관측값}=\mbox{설명된 부분}+\mbox{잔여 부분}
$$ {#eq-model}

여기서 “설명된 부분”은 일반적으로 관측된 변수와 관련된 외부 변수(예측 변수, 공변량, 머신러닝에서는 혼동되게도 피처라고도 함)와, 관측된 변수의 변동성을 설명하기 위한 회귀 모델 등을 사용하여 얻는다. “잔여 부분”은 설명되지 않은 나머지 변동성을 의미한다. 이러한 통계적 모델링의 목적은 예측 변수와 관측 변수 간 관계의 특성 및 크기를 파악하려는 것일 수도 있고, 새로운 관측값을 예측하려는 것일 수도 있다.

통계 모델과 표본 추출은 확률 개념에 토대를 두고 있다. 그런데 공간데이터사이언스에서확률은 자명한 것이 아니라 특정한 방식으로 가정되어야 한다. (공간적) 무작위 표본 추출에서 얻은 데이터가 주어지고 평균이나 총합을 추정하는 것이 목표라면, 표본 위치의 무작위성을 가정하는 *디자인 기반* 접근법이 가장 좋은 분석 방법이다(10.4절에서 더 자세히 설명한다). 만약 관측값이 무작위로 추출되지 않았거나 특정 위치에서의 값을 예측하는 것(즉, 지도화하는 것)이 목적이라면, *모델 기반* 접근법이 필요하다. 이 파트의 나머지 장들은 모델 기반 접근법을 다룬다.

## 비공간적 회귀분석과 머신러닝 모델을 통한 지도화

회귀 모델이나 기타 머신러닝(ML) 모델은 비공간 문제에서 새로운 관측값을 예측하는 데 사용되는 방식과 동일하게 공간 및 시공간 데이터에도 적용할 수 있다.

1.  **추정**: 일련의 관측값에 대해, 해당 관측값에 대응하는 예측 변수 값을 사용하여 회귀 또는 머신러닝 모델을 적합시킨다(머신러닝 용어로는 이 단계를 "훈련"이라고도 함).

2.  **예측**: 새로운 상황에 대해 알려진 예측 변수 값을 적합된 모델과 결합하여 관측 변수 값을 예측하며, 가능하다면 예측 오차 또는 예측 구간도 함께 제시한다.

`sf` 클래스 객체는 그 자체가 `data.frame` 객체이므로 특별한 처리가 필요하지 않다. 예측 결과를 지도에 표현하려면, 예측된 값을 `sf` 객체에 추가해야 하며, 1장에서 불러온 `nc` 데이터셋을 사용해 다음과 같이 할 수 있다.

```{r}
#| eval: false
nc |> mutate(SID = SID74/BIR74, NWB = NWBIR74/BIR74) -> nc1
lm(SID ~ NWB, nc1) |>
  predict(nc1, interval = "prediction") -> pr
bind_cols(nc, pr) |> names()
#  [1] "AREA"      "PERIMETER" "CNTY_"     "CNTY_ID"   "NAME"     
#  [6] "FIPS"      "FIPSNO"    "CRESS_ID"  "BIR74"     "SID74"    
# [11] "NWBIR74"   "BIR79"     "SID79"     "NWBIR79"   "geom"     
# [16] "fit"       "lwr"       "upr"
```

여기에서 우리는 다음의 사항을 알 수 있다.

-   `lm` 함수는 선형 모델을 추정하며 `sf` 객체에 직접 적용할 수 있다.

-   모델의 결과가 `predict` 모델에 투입되는데, 이 모델은 `nc`와 마찬가지로 `sf` 객체인 `nc1`에 대한 예측값을 생성한다.

-   `predict`는 세 개의 열을 생성하는데, `fit`은 예측값을, `lwr`과 `upr`은 95% 예측 구간을 나타낸다.

-   이 세 열은 `bind_cols` 함수를 사용하여 최종 객체에 추가되었다.

많은 회귀 및 머신러닝 유형 문제들이 동일한 구조를 공유하기 때문에, `caret` (Kuhn 2022) 또는 `tidymodels` (Kuhn and Wickham 2022)와 같은 패키지는 광범위한 모델 대안에 대한 자동 평가 및 비교를 가능하게 하며, 다양한 모델 평가 기준과 교차 검증(cross-validation) 전략을 제공한다. 이러한 교차 검증 접근법은 기본적으로 독립 관측 가정에 기반한다. 그런데 공간데이터와 관련하여서는 이것이 반드시 합리적인 가정이라고 전제하기 어려운 경우가 상당히 많다. 이는 공간적 자기상관(Ploton et al. 2020) 때문이거나 표본 데이터에서의 강한 공간 클러스터링(Meyer and Pebesma 2022) 때문이거나, 둘 다 때문이다. 여러 R 패키지는 이러한 단순한 교차 검증을 대체하기 위한 방법을 제공하는데, 여기에는 `spatialsample` (Silge and Mahoney 2023), `CAST` (Meyer, Milà, and Ludwig 2023), `mlr3spatial` (Becker and Schratz 2022), 그리고 `mlr3spatiotempcv` (Schratz and Becker 2022)가 포함된다.

다양한 이유로 표본의 강한 공간 클러스터링이 나타날 수 있다. 하나는 서로 다른 데이터베이스를 결합하여 하나의 표본 데이터를 구성하는 경우이다. 이는 각 데이터베이스는 서로 다른 샘플링 밀도를 가지고 있기 때문인데, 보통 글로벌 데이터셋에서 나타난다(Meyer and Pebesma 2022). 또 다른 강한 클러스터링의 예는, 토지 피복 클래스를 샘플링하기 위해 폴리곤을 디지타이징하고 이들 폴리곤 내에서 위성 이미지의 픽셀 해상도로 포인트를 샘플링할 때 발생한다.

공간적 자기상관은 모델의 “잔여 부분"에서 나타날 수 있는데, 공간 좌표 또는 공간 좌표의 함수들을 예측 변수로 추가 투입하면 감소시킬 수 있다. 그러나 이는 인터폴레이션에서 지나치게 낙관적인 예측의 위험성을 수반하며, (교차) 검증 및 모델 평가에서도 동일한 문제를 야기한다. 이와 관련된 내용은 10.5절에서 더 논의된다.

## 서포트와 통계적 모델링

데이터의 서포트(1.6절; 5장) 개념은 공간 데이터의 통계 분석에서 중요한 역할을 한다. 에어리어 데이터에 대한 기법(14-17장)은 에어리어 서포트를 가진 데이터, 즉 에어리어들의 집합이 지역 전체를 포괄하는 데이터를 위한 것이다.

공간적으로 외연적인 변수를 코로플레스맵으로 나타내는 것은(1.1 그림과 같이) 상당히 위험한 선택일 수 있다. 왜냐하면 정보가 폴리곤 크기와 관련되면서 컬러로 표현된 속성값이 해당 폴리곤의 전역에서 나타나는 것처럼 보여질 수 있다. 해결하는 방법은 공간적으로 외연적인 변수를 공간적으로 내포적인 변수로 전환하는 것인데, 예를 들어 *인구 수*와 같은 변수의 경우 폴리곤 면적으로 나누어 *인구 밀도*를 산출하고 그것을 지도로 나타내는 것이다. 그럼 1.1에 나타나 있는 연도별 발병자 수와 같은 보건 데이터의 경우는, 폴리곤 면적으로 나누어 공간적 밀도를 계산하기보다는 관측값을 해당 폴리곤의 인구 수로 나누어 확률이나 *발병률*로 변환하는 것이 일반적이다. 이 경우, 여전히 폴리곤 면적과 연관되지만, 해당 변수의 서포트는 인구 총수와 관련되어 있다. 이러한 총수는 후속 모델링, 예를 들어 CAR 유형 모델(16장)에서 사용되는 (포아송) 변동성을 알려주는 데 중요한 역할을 한다.

11장은 원칙적으로 포인트 서포트 관측개체를 다루지만, 그렇다고 해서 관측개체가 면적이 전혀 없는 0차원인 것은 아니라는 점을 인식해야 한다. 예를 들어 나무 줄기 “포인트들”의 경우 나무 지름보다 작은 거리에서는 또 다른 포인트가 나타날 수가 없다. 또한, 포인트 패턴 분석에서 포인트는 *관측 창* 개념에 의거해 측정된 것으로, 해당 관측 창은 완벽한 포인터 데이터셋을 구성해야 한다(즉 관측 창 외부에는 포인트가 없다). 관측 창 개념은 많은 분석 도구에 영향을 미친다. 만약 포인트가 라인 네트워크 상에서 관측된다면, 관측 창은 관측된 라인의 집합으로 구성되며, 포인트 간 거리는 해당 네트워크 상에서의 거리로 측정된다.

지구통계학적 데이터(12장 및 13장)는 일반적으로 포인트 서포트 관측값에 기반하여 연구 대상 지역 내 비관측 지점의 값을 예측하거나(공간적 인터폴레이션), 세부 지역에 대한 평균값을 예측한다(블록 크리깅; 12.5절). 관측값이 포인트 값이 아니라 구역 전체의 집계값일 수도 있다(Skøien et al. 2014). 원격탐사 데이터에서 픽셀 값은 보통 픽셀 전체에 대한 집계값이다. 이 경우 구름으로 인한 이미지의 결함을 인접한 공간 및 시간의 픽셀로부터 메우는 것이 중요한 도전 과제이다(Militino et al. 2019).

서로 다른 공간 지원을 가진 데이터를 결합할 때, 모든 데이터를 가장 높은 해상도를 가진 데이터에 “맞추는" 경우가 종종 발생한다. 예를 들어 행정구역 폴리곤과 래스터 레이어를 결합하는 경우, 래스터 레이어의 개별 픽셀 위치에서 폴리곤의 속성 값을 단순 추출하고, 이렇게 생성된 “관측값”을 가지고 분석을 진행해나가는 방식이다. 당연히 이러한 방식으로 생성된 “데이터”를 분석하면 비합리적인 결과를 초래할 위험성이 훨씬 커진다. 불확실성에 대처하기 위해 시뮬레이션을 사용할 수 있는 적절한 다운샘플링 전략이 더 나은 대안이 될 것이다. 초보 사용자가 주어진 소프트웨어를 경각심 없이 사용하는 상황은 매우 우려스럽다. 왜냐하면 어떤 소프트웨어는 구역과 관련된 속성값의 서포트 개념을 잘 다루지 못하거나, 나이브한 다운샘플링에 대한 경고를 보여주지 않기 때문이다.

## 예측 모델에서의 시간

Schabenberger와 Gotway (2005)는, 많은 시공간 데이터에 대한 통계 분석이 시간 차원을 축소(삭감)한 후 해당 문제를 공간적으로 다루거나(시간 먼저, 공간 나중) 공간 차원을 축소한 후 문제를 시간적으로 다루는(공간 먼저, 시간 나중) 방식으로 진행된다는 점을 오래 전에 지적한 바 있다. 첫 번째 접근 방식의 예는 12장에서 제시되는데, 1년 동안의 시간 단위 측정값 데이터셋(13장에서 자세히 설명됨)을 먼저 측정소의 평균 값으로 축소한 후(시간 먼저), 이 평균 값을 공간적으로 인터폴레이션하는(공간 나중) 과정을 보여준다.

원격탐사 분야의 예시는 다음과 같다.

-   Simoes et al. (2021)은 지도 학습 기법과 시계열 딥 러닝을 사용하여 픽셀 시계열을 토지 이용 시퀀스로 분할한 후(시간 먼저), 결과로 생성된 맵 시퀀스를 평활화하여 독특한 필셀이 보여주는 불가능한 전환을 제거(공간 나중)한다.

-   Verbesselt et al. (2010)은 픽셀 시계열에서 급변점을 찾기 위해 (비지도) 구조적 변화 알고리즘을 사용하고(시간 먼저), 이러한 급변점을 이후에 산림 파괴의 맥락에서 해석한다.

원격탐사 분야에서 공간 먼저, 시간 나중 접근 방식의 예시는 단일 레이어(scene) 또는 단일 시즌에 속하는 레이어들을 우선 분류한 후, 분류된 레이어의 시간 순서를 비교하여 토지 이용이나 토지 피복의 다년간 변화를 평가하는 경우이다. Brown et al. (2022)가 그 예이다. 공간과 시간을 *함께* 고려하는 예시로는 13장에서 다루는 시공간 인터폴레이션(spatiotemporal interpolation)과 Lu et al. (2016)이 원격탐사 맥락에서 제시한 연구가 있다.

## 디자인-기반 추정과 모델-기반 추정

통계적 추론은 샘플 데이터를 통해 모집단에 대한 파라미터(모수)를 추정하는 행위를 의미한다. 위치 $s$에서 측정된 속성값을 $z$라고 하면 변수는 $z(s)$로 주어지고, 우리는 샘플 데이터 $z(s_1),...,z(s_n)$에서 도메인 $D$의 면적 $|D|$에 대한 \|$z(s)$의 평균값을 추정하는 것에 관심이 있다고 하자.

$$
z(s)=\frac{1}{|D|}\int_{u\in D}z(u)du
$$

이 때 우리 앞에는 모델-기반 접근법(model-based)과 디자인-기반 접근법(design-based)이라는 두 가지 가능성이 놓여 있다. 모델-기반 접근법은 $z(s)$를 초모집단 $Z(s)$의 실현으로 간주하며(확률 변수를 나타내기 위해 대문자를 사용함), 예를 들어 다음과 같은 공간 변동성을 설명하는 모델을 가정할 수 있다.

$$
Z(s)=m+e(s),\quad \text{E}(e(s))=0, \quad \text{Cov}(e(s))=\Sigma(\theta)
$$

여기서 $m$은 고정(constant) 평균이고 $e(s)$는 평균이 0이고 공분산 행렬이 $\Sigma(\theta)$인 잔차를 의미한다. 이는 공분산 함수 $\Sigma(\theta)$를 선택하고 $z(s)$로부터 그 매개변수 $\theta$를 추정한 다음, 블록 크리깅 예측값 $\hat{Z}(D)$를 계산해야 한다(12.5절). 이 접근법은 $z(s)$가 공간적으로 어떻게 샘플링되었는지에 대한 가정을 하지 않지만, 물론 공분산 함수를 선택하고 그 파라미터를 추정할 수 있어야 한다. 추론은 가정된 모델의 유효성에 따라 달라진다.

디자인-기반 접근법(De Gruijter and Ter Braak 1990; Brus 2021a; Breidt, Opsomer 등 2017)은 초모집단 모델이 아니라 위치에서의 무작위성을 가정한다. 따라서 이 접근법은 무작위 샘플링을 사용할 때만 정당화된다. 샘플 데이터는 반드시 확률 샘플링을 통해 획득되어야 하는데, $z(s)$의 모든 요소가 샘플에 포함될 (양수) 확률이 수학적으로 규정되어 있는 특정한 종류의 공간적 무작위 샘플링이 사용되어야 한다. 무작위 프로세스는 샘플링 프로세스이다. 즉, $z(s_1)$은 무작위 과정 $z(S_1)$의 실현으로 *무작위 샘플링을 반복하여 얻은* 첫 번째 관측치이다. 디자인-기반 추정량은 이러한 포함 확률만 있으면 평균 값을 표준 오차와 함께 추정할 수 있다. 이는 예를 들어 단순 무작위 샘플이 주어졌을 때, 비가중 샘플 평균이 그대로 모집단 평균을 추정하는 데 사용되며, 모델 파라미터를 적합시킬 필요가 없다.

이제 질문은 $s_1$과 $s_1$가 가까이 있을 때 $z(s_1)$과 $z(s_2)$가 서로 상관될 것으로 기대할 수 있는지 여부이다. $z(s_1)$과 $z(s_2)$가 단지 두 개의 숫자에 불과할 때는 이 질문이 성립하지 않는다. 상관성을 논하기 위해서는 확률 변수와 같은 일종의 프레임워크가 필요한데, 이 상황을 재현할 수 있는 두 세트의 숫자를 만들어 내야한다. 여기서의 오해는, Brus (2021a)가 설명한 바와 같이, 두 세트의 숫자가 항상 공간적으로 상관되어 있다고 생각하는 것이다. 그러나 이는 $Z(s_1)$과 $Z(s_2)$가 강한 상관성을 가지는 모델을 전제한 경우에만 성립한다(“모델-의존”). 특정 무작위 샘플(실현)에서 $z(s_1)$과 $z(s_2)$는 공간적으로 가까울 *수* 있지만, 반복적 무작위 샘플링을 통한 확률 변수 $z(S_1)$과 $z(S_2)$는 공간적으로 가깝지 않고, 디자인에 독립적이다. 이 두 상황은 서로 모순 없이 공존할 수 있으며, 어떤 추론 틀을 선택하느냐에 달린 문제일 뿐이다.

디자인-기반 프레임워크를 선택할지 모델-기반 프레임워크를 선택할지는 연구 목적과 데이터 수집 과정에 따라 달라진다. 모델-기반 프레임워크는 다음과 같은 경우에 가장 적합하다.

-   개별 위치에 대한 예측이 필요하거나, 샘플링하기에는 너무 좁은 지역에 대한 예측이 필요한 경우

-   해당 데이터가 무작위 샘플링 방식으로 수집되지 않은 경우(즉, 샘플 포함 확률이 알려져 있지 않거나 특정 지역이나 시간대에 대해 포함 확률이 0인 경우)

디자인-기반 접근법은 다음과 같은 경우에 가장 적합하다.

-   관측값이 공간 무작위 샘플링 과정을 통해 수집된 경우

-   전체 샘플 지역(또는 하위 지역)에 대한 집계 속성이 필요한 경우

-   규제나 법적 목적 등을 위해 모델의 오지정 문제에 민감하지 않은 추정치가 필요한 경우

샘플링 절차를 계획해야 하는 경우(De Gruijter et al. 2006), 공간 무작위 샘플링 방식을 고려하는 것은 매우 바람직한데, 이는 두 가지 추론 프레임워크를 모두 활용할 가능성을 열어주기 때문이다.

## 좌표값을 활용한 예측 모델

데이터사이언스 프로젝트를 수행할 때, 좌표값을 예측 변수(또는 피처, 공변량) 중 하나로 간주하고 다른 변수와 동일한 방식으로 취급하는 경우가 있다. 그런데, 여기에는 몇 가지 위험 요소가 도사리고 있다.

예측 변수를 다룰 때와 마찬가지로, 원점 이동이나 단위(스케일) 변화에 민감하지 않은 예측 방법을 선택하는 것이 좋다. 2차원 문제를 가정할 때, 예측 모델은 $x$-축과 $y$-축 또는 위도와 경도 축의 임의 회전에 민감해서는 안 된다. 투영된 2차원(데카르트) 좌표의 경우, 예를 들어 $(x+y)^n$과 같은 $n$차 다항식을 사용해 이러한 특성을 보장할 수 있으며, 이는 $(x)^n+(y)^n$ 형태 대신 사용된다. 2차 다항식의 경우 $xy$항을 포함시켜 타원형 경향면이 반드시 $x$-축이나 $y$-축에 정렬될 필요가 없도록 한다. 스플라인 요소를 포함하는 GAM 모델의 경우에도 상호작용을 허용하지 않는 독립적 스플라인 $s(x)$와 $s(y)$ 대신, 2차원에서의 스플라인 $s(x,y)$를 사용한다. 이러한 '규칙'에 당연히 예외가 있을 수 있는데, 예를 들어 연간 총 태양 에너지 유입을 설명하기 위해 순전히 위도의 효과만 필요한 경우이다.

데이터가 넓은 지역에 걸쳐 있는 경우, 타원 좌표와 투영 좌표를 사용하는 것의 차이가 당연히 커지기 때문에 둘 중 어느 좌표를 선택하느냐가 예측 모델링의 결과에 큰 영향을 미칠 수 있다. 매우 넓은 범위나 전 지구적 모델의 경우, 위도와 경도 좌표를 활용한 다항식이나 스플라인은 경도의 순환 특성과 극지점에서의 좌표 특이성을 무시하기 때문에 잘 작동하지 않는다. 이때, 구면 조화 함수(spherical harmonics)를 다항식에 대한 대체 함수나 스플라인 기저 함수로 활용할 수 있는데, 이는 구면 위에서 연속성을 가지며 공간 주파수가 높아질수록 더 세밀한 변화를 표현할 수 있는 함수이다.

많은 경우, 표본이 수집된 공간 좌표는 예측이 이루어질 공간도 정의하게 되기 때문에, 좌표 변수는 다른 예측 변수와는 선명하게 구별되는 특성을 가진다. 대부분의 간단한 예측 접근법, 특히 많은 머신러닝 기법은 표본 데이터를 독립적이라고 가정한다. 표본이 공간 대상 지역에서 공간 무작위 샘플링(표본추출)에 의해 수집된 경우, 디자인-기반 모델의 맥락에서는 이 가정이 정당화될 수 있다(Brus 2021b). 그러나 디자인-기반 접근에서는 좌표 공간을 우리가 무작위화의 대상 변수로 간주하기 때문에 새롭게 무작위로 선택된 위치에 대한 예측이 가능하지만 고정된 위치에 대한 예측은 불가능하다. 즉, 표본이 수집된 지역의 평균 값을 구할 수는 있지만, 해당 지역에 대한 공간적 인터폴레이션 값을 구할 수는 없다. 고정된 위치에 대한 예측이 필요하거나 데이터가 공간 무작위 표본추출로 수집되지 않은 경우, 모델-기반 접근(Chapter 12에서 설명)과 더불어 잔차의 공간 및/또는 시간적 자기상관을 가정하는 방법을 고려해야만 한다.

일반적인 경우는 샘플 데이터가 기회적으로 수집되고(“찾을 수 있는 것 모두”), 이후 가중치를 부여하지 않은 채 예측 프레임워크에서 사용되는 경우이다. 이로 인해 결과 모델은 과대표집된 영역(예측 변수 공간 및/또는 공간 좌표 공간)으로 편향될 수 있으며, 단순한(무작위) 교차 검증 통계가 공간 예측의 성능 척도로 사용될 때 지나치게 낙관적인 결과가 도출될 수 있다 (Meyer and Pebesma 2021, 2022; Mila et al. 2022). 공간적 교차 검증(spatial cross-validation)과 같은 적응형 교차 검증 측도가 예측 성능에 대한 유관성 높은 평가값을 얻는 데 도움이 될 수 있다.

## 연습문제

R을 활용하여 다음의 연습문제를 해결하라.

1.  10.1절의 `lm` 예제를 참고하여 랜덤 포레스트 모델을 사용해 `SID` 값을 예측하고(예: **randomForest** 패키지 사용), 랜덤 포레스트 예측값을 관측값과 함께 플로팅하되 $x=y$ 선도 함께 표시하시오.

2.  `nc` 데이터셋에서 1,000개의 포인트를 무작위로 샘플링하여 새로운 데이터셋을 만들고, 이 데이터셋에 10.1절의 선형 회귀 모델을 다시 실행한다. 적합된 모델의 `summary`를 살펴보라. 특히 추정 계수, 표준 오차, 잔차 표준 오차를 주목하라. 원 모델과 비교했을 때 무엇이 달라졌는가?

3.  7.4.6절의 수역-육지 분류를 `lda` 대신 `class::knn`을 사용하여 `k=5`의 값을 설정하여 다시 수행하고, 예측값을 `lda`의 예측값과 비교하라.

4.  `nc` 데이터셋을 사용하는 선형 모델과 이전 연습문제의 `knn` 예제에 대해 1차 및 2차 공간 좌표 변수를 추가한 다항 선형 모델을 실행하고 결과를 비교하라. 이를 위해 `st_centroid`를 사용하여 폴리곤의 중심점을 얻고, `st_coordinates`를 사용하여 `x` 및 `y` 좌표를 행렬 형태로 추출하라.
