{
  "hash": "62f999dfb4629e625219709658bb6ebc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate-modified: last-modified\nnumber-sections: true\nformat: \n  html: \n    toc: true\ncode-link: true\ncode-copy: true\nexecute: \n  warning: false\n  error: false\n  freeze: auto\neditor: visual\n---\n\n\n# 대규모 데이터와 클라우드 네이티브 {#sec-large}\n\n이 장에서는 R을 사용하여 대규모 공간 및 시공간 데이터셋을 처리하는 방법을 설명하며, **sf**와 **stars** 패키지의 활용에 초점을 둔다.(역자주: 영어 ‘large data’의 번역으로 ‘대규모 데이터’를 사용하기로 한다. ‘대용량’은 주로 저장 용량 측면에서 데이터가 큰 경우를 의미하는 반면, ‘대규모’는 데이터의 관측치 수가 매우 많아 규모가 큰 경우를 가리킨다. 따라서 더 포괄적인 의미를 담을 수 있다는 점에서 대규모를 기본적으로 선택한다. 다만, 문맥상 대용량이 더 적합한 경우에는 이를 함께 사용한다.) 여기서 ‘대규모’는 다음 세 가지로 구분된다.\n\n-   작업 메모리에 담기 어려울 만큼 크다.\n\n-   로컬 하드 드라이브 용량에 담기 어려울 만큼 크다.\n\n-   로컬 관리 인프라(네트워크 부착 스토리지)로 다운로드하기 어려울 만큼 크다.\n\n이 세 가지 범주는 (현재 기준) 대략 기가바이트, 테라바이트, 페타바이트 규모의 데이터셋에 대응한다고 볼 수 있다. 크기뿐 아니라 접근과 처리 속도도 중요한 요소이며, 특히 초대규모 데이터셋이나 인터랙티브 애플리케이션에서는 그 중요성이 더욱 커진다. 클라우드 네이티브 지리공간 포맷은 클라우드 인프라에서의 처리를 염두에 둔 형식으로, 컴퓨팅과 저장 비용 측면에서 최적화가 요구된다.(역자주: 여기서 ‘클라우드 네이티브’는 클라우드에서 쓰도록 처음부터 설계된 데이터 형식과 작업 방식이다. 파일을 통째로 내려받지 않고 객체 스토리지에서 필요한 부분만 바로 읽고, 데이터를 잘게 나눠 병렬로 처리하며, 가능하면 데이터를 옮기지 않고 연산을 데이터가 있는 곳에서 실행한다. 전통적인 로컬 파일 중심 방식과 구별된다.)\n\n다음과 같은 방식으로 비용을 절감할 수 있다.\n\n-   압축. 클라우드-최적화 GeoTIFF에 사용하는 LERC(제한 오류 래스터 압축)나 ZARR 어레이 데이터에 사용하는 BLOSC 압축기와 같은 기술을 활용한다.\n\n-   공간 하위 영역 또는 컬럼-지향 접근: 전자는 클라우드-최적화 GeoTIFF에 대해 HTTP Range 리퀘스트로 부분 읽기를 수행하고, 후자는 GeoParquet와 GeoArrow 포맷에 주로 적용된다.\n\n-   점진적 해상도 접근: 먼저 저해상도 데이터를 제공하고, 필요에 따라 해상도를 단계적으로 높여 간다(예: 점진적 JPEG, 이미지 피라미드/오버뷰).\n\n-   데이터 접근 최적화: 사용 중인 해당 클라우드 스토리지의 구조와 동작 방식에 맞추어 데이터 배치와 네이밍을 조정하거나, 해당 객체 스토리지 프로토콜이 제공하는 기능을 적극 활용한다.\n\n이 분야에는 만능 해법이 없다는 점을 유의해야 한다. 특정 접근 패턴에 맞춰 스토리지를 최적화하면 다른 방식의 접근 성능이 저하될 수 있다. 예를 들어, 래스터 데이터가 서로 다른 공간 해상도에서 공간 영역 접근에 최적화해 저장하면, 픽셀 시계열(시간 축을 따라 픽셀 값을 읽는 방식) 읽기 속도가 매우 느려질 수 있다. 압축은 스토리지와 대역폭(전송) 비용을 낮추지만, 읽기 시 압축 해제 과정이 필요하므로 처리 비용(시간과 CPU)이 증가한다.\n\n## 벡터 데이터: sf 패키지\n\n### 로컬 디스크에서 불러오기\n\n`st_read()` 함수는 GDAL을 사용해 디스크에서 벡터 데이터를 읽은 뒤, 해당 객체를 작업 메모리에 유지한다. 파일이 너무 커서 전부 메모리에 올리기 어렵다면 일부만 읽는 여러 옵션을 사용할 수 있다. 한 가지 방법은 `wkt_filter` 인수에 지오메트리를 담은 WKT 문자열을 지정하는 것이고, 이 경우 지정한 지오메트리와 인터섹션하는 대상 파일의 지오메트리만 반환된다. 아래에 사례가 제시되어 있다. 여기에서는 `st_read()` 함수 대신 `read_sf()` 함수를 사용했는데, 콘솔 출력을 억제하기 위해서다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n# Linking to GEOS 3.11.1, GDAL 3.6.4, PROJ 9.1.1; sf_use_s2() is TRUE\nfile <- system.file(\"gpkg/nc.gpkg\", package = \"sf\")\nc(xmin = -82,ymin = 36, xmax = -80, ymax = 37) |>\n    st_bbox() |> st_as_sfc() |> st_as_text() -> bb\nread_sf(file, wkt_filter = bb) |> nrow() # out of 100\n# Re-reading with feature count reset from 17 to 16\n# [1] 16\n```\n:::\n\n\n두 번째 옵션은 `st_read()` 함수의 `query` 인수를 사용하는 것으로, 이 인수는 ‘OGR SQL’로 작성한 쿼리를 받아 특정 레이어에서 피처를 선택하거나, 반환할 필드를 제한하는데 사용할 수 있다. 아래에 사례가 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- \"select BIR74,SID74,geom from 'nc.gpkg' where BIR74 > 1500\"\nread_sf(file, query = q) |> nrow()\n# [1] 61\n```\n:::\n\n\n`nc.gpkg`는 *파일 이름*이며, 레이어 이름은 `st_layers()` 함수로 확인할 수 있다. 레코드 시퀀스는 SQL의 `LIMIT`과 `OFFSET`을 사용해 부분 읽기가 가능하며, 51\\~60번째 레코드를 읽으려면 다음과 같이 한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- \"select BIR74,SID74,geom from 'nc.gpkg' LIMIT 10 OFFSET 50\"\nread_sf(file, query = q) |> nrow()\n# [1] 10\n```\n:::\n\n\n추가 쿼리 옵션으로 지오메트리 유형이나 폴리곤 면적을 기준으로 선택할 수 있다. 쿼리 대상이 공간데이터베이스인 경우, 해당 쿼리는 GDAL이 해석하지 않고 데이터베이스로 전달되므로 더 강력한 기능을 활용할 수 있다. 자세한 내용는 GDAL 문서의 \"OGR SQL 방언(dialect)\" 절을 참조하라.\n\n대용량 파일이나 디렉터리가 압축되어 있다면, 경로 앞에 `/vsizip`(Zip), `/vsigzip`(Gzip), `/vsitar`(Tar) 접두사를 붙여 압축 해제 없이 파일을 읽을 수 있다. 사용 방법은 접두사 + 압축 파일 경로 + 압축 내부 파일 경로 순서로 지정하면 된다. 다만 이 방식은 추가적인 압축 해제와 인덱싱 오버헤드로 인해 컴퓨팅 자원을 더 많이 소모할 수 있다.\n\n### 데이터베이스에서 불러오기, dbplyr 패키지\n\nGDAL은 여러 공간데이터베이스를 지원하며, 앞서 설명했듯 `query` 인수에 담긴 SQL 문을 데이터베이스로 전달한다. 그러나 DBI와 해당 드라이버, 그리고 **dbplyr** 패키지를 사용해 공간데이터베이스에 직접 읽고 쓰는 편이 더 유리한 경우도 있다. 이러한 사례는 다음과 같다. 여기에서, 데이터베이스 호스트와 사용자 이름은 환경 변수에서 가져오며, 데이터베이스 이름은 `postgis`이다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npg <- DBI::dbConnect(\n    RPostgres::Postgres(),\n    host = Sys.getenv(\"DB_HOST\"),\n    user = Sys.getenv(\"DB_USERNAME\"),\n    dbname = \"postgis\")\nread_sf(pg, query = \n        \"select BIR74,wkb_geometry from nc limit 3\") |> nrow()\n# [1] 3\n```\n:::\n\n\n공간 쿼리는 보통 다음과 같은 형태다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- \"SELECT BIR74,wkb_geometry FROM nc WHERE \\\nST_Intersects(wkb_geometry, 'SRID=4267;POINT (-81.50 36.43)');\"\nread_sf(pg, query = q) |> nrow()\n# [1] 1\n```\n:::\n\n\n여기서, 인터섹션 오퍼레이션은 데이터베이스 내에서 수행되며, 공간 인덱스가 존재하면 이를 활용한다. 데이터베이스 백엔드에서 **dplyr** 패키지를 사용할 때도 동일한 메커니즘이 작동한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr, warn.conflicts = FALSE)\nnc_db <- tbl(pg, \"nc\")\n```\n:::\n\n\n**dplyr** 패키지 문법으로 공간 쿼리를 작성하면, 해당 쿼리는 데이터베이스로 전달된다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_db |> \n     filter(ST_Intersects(wkb_geometry, \n                        'SRID=4267;POINT (-81.50 36.43)')) |>\n     collect()\n# # A tibble: 1 × 16\n#   ogc_fid  area perimeter cnty_ cnty_id name  fips  fipsno cress_id\n#     <int> <dbl>     <dbl> <dbl>   <dbl> <chr> <chr>  <dbl>    <int>\n# 1       1 0.114      1.44  1825    1825 Ashe  37009  37009        5\n# # ℹ 7 more variables: bir74 <dbl>, sid74 <dbl>, nwbir74 <dbl>,\n# #   bir79 <dbl>, sid79 <dbl>, nwbir79 <dbl>,\n# #   wkb_geometry <pq_gmtry>\nnc_db |> filter(ST_Area(wkb_geometry) > 0.1) |> head(3)\n# # Source:   SQL [3 x 16]\n# # Database: postgres  [edzer@localhost:5432/postgis]\n#   ogc_fid  area perimeter cnty_ cnty_id name   fips  fipsno cress_id\n#     <int> <dbl>     <dbl> <dbl>   <dbl> <chr>  <chr>  <dbl>    <int>\n# 1       1 0.114      1.44  1825    1825 Ashe   37009  37009        5\n# 2       3 0.143      1.63  1828    1828 Surry  37171  37171       86\n# 3       5 0.153      2.21  1832    1832 North… 37131  37131       66\n# # ℹ 7 more variables: bir74 <dbl>, sid74 <dbl>, nwbir74 <dbl>,\n# #   bir79 <dbl>, sid79 <dbl>, nwbir79 <dbl>,\n# #   wkb_geometry <pq_gmtry>\n```\n:::\n\n\n(참고로, PostGIS의 `ST_Area()` 함수가 `nc`의 `AREA` 필드와 동일한 값을 내놓더라도, 이는 의미가 없다. 경위도 좌표를 투영 좌표처럼 간주해 계산한 면적이기 때문이다.)\n\n### 온라인 리소스 또는 웹 서비스에서 불러오기\n\nGDAL 드라이버는 `https://`로 시작하는 온라인 리소스에서 읽는 것을 지원하며, 이때 URL 앞에 `/vsicurl/`을 붙여 사용한다. 특정 클라우드에 특화된 유사 드라이버도 있으며, Amazon S3는 `/vsis3/`, Google Cloud Storage는 `/vsigs/`, Azure는 `/vsiaz/`, Alibaba Cloud는 `/vsioss/`, OpenStack Swift Object Storage는 `/vsiswift/`를 사용한다. `/vsicurl/` 사용 예시는 9.3.2절을 참조하라.\n\n위 접두사에 `/vsizip/`을 결합하면 압축된 온라인 리소스에서 파일을 직접 읽을 수 있다. 다만 파일 형식에 따라 전체 파일을 한 번 이상 내려받아야 하는 상황이 발생할 수 있어, 항상 가장 효율적인 방법은 아니다. 클라우드 네이티브 포맷은 HTTP 리퀘스트에서 부분 읽기가 효과적으로 동작하도록 최적화되어 있다.\n\n### API, OpenStreetMap\n\n지리공간 데이터용 웹 서비스는 요청에 따라 데이터를 실시간으로 생성해 API로 접근할 수 있게 해준다.(역자주: API는 Application Programming Interface의 약자이며, 프로그램이 HTTP 요청 등 표준 방식으로 다른 서비스의 기능을 호출하고 데이터를 주고받게 하는 규칙과 명세를 말한다. 여기서는 데이터 제공자와 사용자가 합의된 규칙에 따라 데이터를 교환하도록 하는 인터페이스로 이해하면 된다.) 예를 들어 OpenStreetMap(OSM) 데이터는 GDAL 벡터 드라이버 등을 통해 일괄 다운로드하여 로컬에서 활용할 수 있다. 그러나 실제 사용자는 대개 일부 데이터만을 필요로 하거나 소규모 쿼리로 데이터를 쓰고자 한다. 이를 위해 OSM을 쿼리하는 여러 R 패키지가 제공된다.\n\n-   **OpenStreetMap** 패키지(Fellows와 Jan Peter Stotz의 JMapViewer 라이브러리, 2019)는 지도를 래스터 타일로 내려받아, 다른 피처를 플로팅할 때 배경 또는 참조 지도로 주로 사용된다.\n\n-   **osmdata** 패키지(Mark Padgham 외, 2017)는 벡터 데이터를 **sf** 또는 **sp** 형식의 포인트, 라인, 폴리곤으로 다운로드한다.\n\n-   **osmar** 패키지(CRAN 아카이브 제공)는 벡터 데이터를 반환할뿐 아니라, 도로 요소 간 연결 관계를 포함한 네트워크 토폴로지(`igraph` 객체)도 제공하고, 최단 경로 계산 함수도 포함한다.\n\n올바르게 구성된 API 호출이 URL의 형태로 주어지면, 세세한 옵션을 제공하는 GDAL OSM 드라이버(`st_read()` 함수에서 사용 가능)가 '.osm'(xml) 파일을 읽어 중요 태그를 가진 `points`, 면적이 없는 'way' 피처를 가진 `lines`, 'relation' 기반의 `multilinestrings`와 `miltipolygons`, 그리고 `other_relations`로 이루어진 다섯 개 레이어를 포함하는 데이터셋을 반환한다. 아래는 매우 작은 영역을 대상으로 한 간단한 OpenStreetMap 쿼리의 예시다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndownload.file(paste0(\"https://openstreetmap.org/api/0.6/map?\",\n       \"bbox=7.595,51.969,7.598,51.970\"),\n    \"data/ms.osm\", method = \"auto\")\n```\n:::\n\n\n다운로드한 파일에서 `lines` 레이어를 읽은 뒤, 첫 번째 속성을 다음과 같이 플로팅할 수 있다(그림 9.1). Overpass API는 OpenStreetMap 데이터에 대해 보다 일반적이고 강력한 쿼리 기능을 제공한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\no <- read_sf(\"data/ms.osm\", \"lines\")\np <- read_sf(\"data/ms.osm\", \"multipolygons\")\nst_bbox(c(xmin = 7.595, ymin = 51.969, \n          xmax = 7.598, ymax = 51.970), crs = 'OGC:CRS84') |>\n    st_as_sfc() |>\n    plot(axes = TRUE, lwd = 2, lty = 2, cex.axis = .5)\nplot(o[,1], lwd = 2, add = TRUE)\nplot(st_geometry(p), border = NA, col = '#88888888', add = TRUE)\n```\n:::\n\n\n![OpenStreetMap 벡터 데이터](https://r-spatial.org/book/09-Large_files/figure-html/fig-overpass-1.png){#fig-9-1}\n\n### GeoParquet와 GeoArrow\n\n클라우드 네이티브 분석에 특화된 두 포맷은 Apache Parquet와 Apache Arrow에서 파생된 GeoParquet와 GeoArrow다. 두 포맷은 테이블 데이터에 대한 컬럼 지향 저장 방식을 제공하며, 이는 레코드 지향 저장 방식에 다수의 레코드에서 특정 열만 선택적으로 읽는데 유리하다. 두 포맷의 Geo 확장에는 다음이 포함된다.\n\n-   지오메트리 컬럼 저장 방식: WKB(well-known binary) 또는 WKT(well-known text)로 저장할 수 있으며, 부분 지오메트리를 미리 인덱싱한 보다 효율적인 형식으로도 저장할 수 있다.\n\n-   CRS의 저장 방법(좌표참조계 메타데이터의 보존)\n\n이 책의 집필 시점 기준으로 두 포맷 모두 활발히 개발 중이며, GDAL 3.5부터는 이를 읽고 생성하기 위한 드라이버가 제공된다. 두 포맷 모두 압축 저장을 지원한다. 차이점은 (Geo)Parquet가 영속적 저장에 더 초점을 두는 반면, (Geo)Arrow는 빠른 접근과 계산에 중점을 둔다는 점이다. 예를 들어, Arrow는 인메모리 포맷과 온디스크 포맷 모두로 사용할 수 있다.(역자주: '영속적 저장(persistent storage)'은 데이터를 장기적으로 훼손 없이 보관하는 방식을, '인메모리(in-memory) 포맷'은 데이터를 주기억장치에 올려 처리하는 방식을, '온디스크(on-disk) 포맷'은 데이터를 저장 매체에 기록해 처리하는 방식을 각각 뜻한다.)\n\n## 래스터 데이터: stars 패키지\n\n래스터 데이터셋을 다룰 때 흔한 문제는 파일 용량이 지나치게 크다는 점뿐 아니라(단일 Sentinel-2 타일은 약 1GB), 관심 지역과 기간을 모두 커버하려면 수천에서 수백만 개까지 필요하다는 것이다. 2022년에 Sentinel 위성 운영 프로그램인 Copernicus는 매일 160 TB의 이미지 를 생산했다. 이는 데이터를 로컬 디스크에 내려받고, 메모리에 적재한 뒤, 분석하는 전통적인 R 사용 패턴이 더 이상 작동하지 않음을 시사한다.\n\nGoogle Earth Engine(Gorelick et al. 2017), Sentinel Hub, openEO.cloud 같은 클라우드 기반 지구 관측 프로세싱 플랫폼은 이러한 문제를 인식하고, 사용자가 페타바이트 규모의 데이터셋을 쉽게 다루고 상호작용할 수 있도록 한다. 이들 플랫폼은 다음과 같은 특성을 공유한다.\n\n-   계산은 가능한 한 늦게 수행된다(지연 평가)\n\n-   사용자가 요청한 데이터만 계산하고 반환한다.\n\n-   중간 결과를 저장하지 않고 즉석(on-the-fly) 계산을 선호한다.\n\n-   유용한 결과를 가진 지도를 신속히 생성하고 표시하여 인터렉티브 모형 개발을 가능하게 한다.\n\n이는 데이터베이스와 클라우드 기반 분석 환경을 대상으로 하는 **dbplyr** 패키지의 인터페이스와 유사하지만, 확인하려는 *대상*이 다르다. **dbplyr** 패키지의 지연 테이블에서는 보통 처음 *n*개의 레코드를 재빨리 확인하고자 하지만, 여기서는 전체 영역 또는 일부 영역에 대해 지도 형태의 결과 *개요*를 빠르게 보고자 한다. 이를 위해 해상도는 희생되며, 원본(관측) 해상도가 아니라 화면 해상도로 포시된다.\n\n예를 들어 화면에서 미국의 결과를 즉시 \"보고자\" 할 때 1000 × 1000 픽셀 해상도가 필요하다면, 그만큼의 픽셀에 대한 결과만 계산하면 된다. 이는 대략 3000 m × 3000 m 그리드 셀로 구성된 데이터에 해당한다. Sentinel-2 데이터의 해상도가 10 m이므로, 300배로 다운샘플링하여 3 km × 3 km 해상도로 작업할 수 있다. 이 경우, 기본 10 m ×10 m 해상도로 작업할 때와 비교해 처리, 저장, 네트워크 요구량이 $300^2\\approx10^5$배 줄어든다. 언급한 플랫폼에서는 지도를 확대하면 더 세밀한 해상도와 더 작은 범위에 대한 추가 계산이 촉발된다.\n\n이 원리에 따른 간단한 최적화 사례가 `stars` 객체의 `plot` 매서드 동작이다. 대용량 래스터를 플로팅할 때 플롯 이전에 어레이를 다운샘플링하여 시간을 크게 절약하며, 다운샘플링 정도는 플롯 영역의 크기와 장치 해상도(픽셀 밀도)를 기준으로 결정된다. 벡터 장치(예: PDF)에서는 R이 플롯 해상도를 75 dpi로 지정하며, 이는 픽셀 크기 약 0.34mm에 해당한다. 플롯을 확대하면 픽셀화가 보일 수 있지만, 확대된 장치에서 다시 플롯하면 목표 밀도로 재생성된다. 한편 `geom_stars()` 함수의 경우 사용자가 `downsample` 비율을 직접 지정해야 하는데, 이는 **ggplot2** 패키지의 해당 함수만으로 장치 크기를 직접 설정할 수 없기 때문이다.\n\n### stars 프록시 객체\n\n작업 메모리에 담기 어려울 만큼 큰 데이터셋을 처리하기 위해 **stars**는 `stars_proxy` 객체를 제공한다. 사용 예를 보이기 위해, 대용량 데이터셋(총 약 1GB)을 포함한 R 패키지 **starsdata**를 사용할 것이다. 설치는 다음과 같이 수행한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(timeout = 600) # or larger in case of slow network\ninstall.packages(\"starsdata\", \n  repos = \"http://cran.uni-muenster.de/pebesma/\", type = \"source\")\n```\n:::\n\n\n다음과 같이 **starsdata** 패키지에서 Sentinel-2 이미지를 '연결해올' 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stars) |> suppressPackageStartupMessages()\nf <- paste0(\"sentinel/S2A_MSIL1C_20180220T105051_N0206\",\n           \"_R051_T32ULE_20180221T134037.zip\")\ngranule <- system.file(file = f, package = \"starsdata\")\nfile.size(granule)\n# [1] 7.69e+08\nbase_name <- strsplit(basename(granule), \".zip\")[[1]]\ns2 <- paste0(\"SENTINEL2_L1C:/vsizip/\", granule, \"/\", base_name, \n    \".SAFE/MTD_MSIL1C.xml:10m:EPSG_32632\")\n(p <- read_stars(s2, proxy = TRUE))\n# stars_proxy object with 1 attribute in 1 file(s):\n# $EPSG_32632\n# [1] \"[...]/MTD_MSIL1C.xml:10m:EPSG_32632\"\n# \n# dimension(s):\n#      from    to offset delta            refsys    values x/y\n# x       1 10980  3e+05    10 WGS 84 / UTM z...      NULL [x]\n# y       1 10980  6e+06   -10 WGS 84 / UTM z...      NULL [y]\n# band    1     4     NA    NA                NA B4,...,B8\nobject.size(p)\n# 12576 bytes\n```\n:::\n\n\n이 과정에서 실제 픽셀 값을 전혀 불러오지 않고, 데이터셋에 대한 참조만 유지한 채 디멘션 테이블을 채운다. 또한 길고 복잡한 Sentinel-2 제품명(S2 파일명)을 활용해 `.zip` 파일 내부의 115개 파일 중 대상 파일을 GDAL이 식별할 수 있도록 한다.\n\n프록시 객체 개념을 바탕으로 다음과 같은 표현식을 정의할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np2 <- p * 2\n```\n:::\n\n\n그러나 이 경우 계산은 지연된다. 실제 데이터가 필요할 때에만 `p * 2`가 평가된다. 데이터가 필요한 시점은 다음과 같다.\n\n-   데이터를 플로팅할 때\n\n-   `write_stars()` 함수로 객체를 디스크에 쓸 때\n\n-   `st_as_stars()` 함수로 객체를 명시적으로 메모리에 불러올 때\n\n전체 객체를 담기엔 메모리가 부족한 경우, `plot()`과 `write_stars()`는 서로 다른 전략을 선택한다.\n\n-   `plot()` 함수는 화면에 표시될 픽셀만 다운샘플링하여 가져온다.\n\n-   `write_stars()` 함수는 데이터를 청크 단위로 읽고 처리한 뒤 기록한다.\n\n\n::: {.cell}\n\n:::\n\n\n![Sentinel-2의 10m 밴드를 다운샘플링한 경우](https://r-spatial.org/book/09-Large_files/figure-html/fig-plotp-1.png){#fig-9-2}\n\n고밀도 공간 이미지는 다운샘플링과 청크 처리가 구현되어 있지만, 고밀도 시계열이나 기타 고밀도 디멘션에는 적용되지 않는다. 예를 들어 그림 9.2의 `plot(p)` 출력은 각 밴드 존재하는 10,980 × 10,980 픽셀 전체가 아닌, 그래픽 장치에서 표시 가능한 픽셀만 가져온다. 적용된 다운샘플링 비율은 다음과 같이 구할 수 있다.\n\n\n::: {.cell}\n\n:::\n\n\n``` r\n# [1] 19\n```\n\n이 숫자는 원본 이미지의 19 × 19 크기 서브 이미지마다 오직 1픽셀만 읽어 플로팅했음을 뜻한다.\n\n### 프록시 객체에 대한 오퍼레이션\n\n`stars_proxy` 객체에는 전용 메서드가 다수 제공된다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmethods(class = \"stars_proxy\")\n#  [1] [               [[<-            [<-             adrop          \n#  [5] aggregate       aperm           as.data.frame   c              \n#  [9] coerce          dim             droplevels      filter         \n# [13] hist            image           initialize      is.na          \n# [17] Math            merge           mutate          Ops            \n# [21] plot            predict         print           pull           \n# [25] rename          select          show            slice          \n# [29] slotsFromS3     split           st_apply        st_as_sf       \n# [33] st_as_stars     st_crop         st_dimensions<- st_downsample  \n# [37] st_mosaic       st_normalize    st_redimension  st_sample      \n# [41] st_set_bbox     transmute       write_stars    \n# see '?methods' for accessing help and source code\n```\n:::\n\n\n우리는 이미 `plot()`과 `print()` 함수의 동작을 살펴보았고, `dim()` 함수는 디멘션 메타데이터 테이블에서 디멘션 정보를 읽어 온다.\n\n실제로 데이터를 가져오는 메서드는 `st_as_stars()`, `plot()`, `write_stars()`의 세 가지 함수이다. `st_as_stars()` 함수는 실제 데이터를 `stars` 객체로 읽어오며, 이때 `downsample` 인수가 다운샘플링 비율을 제어한다. `plot()` 함수도 데이터를 읽어 오되, 장치 해상도에 맞는 다운샘플링 값을 선택해 객체를 플로팅한다. `write_stars()` 함수는 `stars_proxy` 객체를 디스크에 기록한다.\n\n`stars_proxy` 객체에 대한 나머지 메서드는 래스터 데이터에 즉시 작용하지 않고, 객체에 연결된 *작업* 목록에 오퍼레이션을 추가만 한다. 실제 래스터 데이터가 불러오면(예: `plot()` 또는 `st_as_stars()` 함수가 호출 시) 그 시점에 이 목록의 명령이 실행된다.\n\n`st_crop()` 함수는 읽을 래스터의 범위(영역)를 제한한다. `c()` 함수는 `stars_proxy` 객체를 결합하며, 역시 실제 데이터를 곧바로 결합하는 것은 아니다. `adrop()` 함수는 빈 디멘션을 제거하고, `aperm()` 함수는 디멘션 순서를 변경한다.\n\n`write_stars()` 함수는 입력을 청크 단위로 읽고 처리한 뒤 기록하며, 사용자가 공간 청크의 크기를 제어할 수 있도록 `chunk_size` 인수를 제공한다.\n\n### 원격 래스터 리소스\n\nCOG(Cloud Optimised GeoTIFF)와 같은 포맷은 효율성과 리소스 절약을 염두에 두고 설계되었다. 예를 들어 메타데이터만 읽거나, 오버뷰(전체 이미지를 낮은 해상도로 축약한 버전)만 읽거나 `/vsixxx/` 메커니즘을 사용해 특정 공간 영역만 부분 읽기할 때 유용하다(9.1.3절 참조). COG는 GDAL의 GeoTIFF 드라이버로 생성할 수 있으며, `write_stars()` 함수 호출에서 적절한 데이터셋 생성 옵션을 지정하면 된다.\n\n## 초대규모 데이터 큐브\n\n어느 시점에는 다운로드가 사실상 불가능할 만큼 거대한 데이터셋을 분석해야 할 수 있다. 로컬 저장소가 충분하더라도 네트워크 대역폭이 병목이 될 수 있다. 예를 들어, Landsat과 Copernicus(Sentinel-x)의 위성 이미지 아카이브, 1950년부터의 전 세계 대기와 육지 표면, 해양 파도를 모형화한 ERA5(기후 재분석 모형, Hersbach et al. 2020) 등이 이에 해당한다. 이런 경우에는 데이터가 있는 클라우드의 가상 머신에 직접 접근하거나, 사용자가 가상 머신과 스토리지관리 없이 계산을 수행할 수 있게 하는 시스템을 이용하는 편이 가장 효과적일 수 있다. 아래에는 이 두 가지 옵션을 논의한다.\n\n### 에셋의 검색과 처리\n\n클라우드 가상 머신에서 작업할 때 첫 단계는 대개 작업 대상 에셋(파일)을 찾는 일이다. 보통 파일 목록을 받아온 뒤, 다음과 같은 파일명 패턴을 파싱하고 싶어진다.\n\n```         \nS2A_MSIL1C_20180220T105051_N0206_R051_T32ULE_20180221T134037.zip\n```\n\n파싱은 획득 날짜와 공간 타일 코드 정보를 담은 메타데이터를 대상으로 수행된다. 그러나 이런 방식으로 파일 목록을 나열하는 작업은 대체로 전산 부담이 크고, 타일 수가 수백만 개에 이르면 결과 후처리 또한 만만치 않다.\n\n이 문제의 한 가지 해결책은 카탈로그를 활용하는 것이다. 최근 빠르게 보급 중인 STAC(*Spatiotemporal Asset Catalogue*의 약자)은 바운딩 박스, 날짜, 밴드, 구름 피복률와 같은 속성으로 이미지 컬렉션을 쿼리할 수 있는 API를 제공한다. R의 **rstac** 패키지(Simoes, Carvalho, Brazil Data Cube Team 2023)는 이러한 쿼리를 구성하고, 반환된 항목과 에셋 정보를 관리하기 위한 R 인터페이스를 제공한다.\n\n결과 파일 처리 단계에서는 서로 다른 CRS(예: 여러 UTM 존)를 가진 이미지로부터 더 낮은 공간 또는 시간 해상도의 데이터 큐브를 구성할 수 있다. 이때 이미지 컬렉션에서 규칙 데이터 큐브를 생성하는 R 패키지로 **gdalcubes**(Appel 2023; Appel and Pebesma 2019)가 있으며, STAC(Appel, Pebesma, Mohr 2021)을 직접 쿼리해 사용할 이미지를 식별한다.\n\n### 클라우드 네이티브 스토리지: Zarr\n\nCOG가 래스터 이미지의 클라우드 네이티브 스토리지를 제공하는 반면, Zarr은 대규모 다차원 어레이를 위한 클라우드 네이티브 스토리지 포맷이다. Zarr은 NetCDF의 후속 포맷으로 볼 수 있으며, 기후 및 예측 커뮤니티에서 유사한 관례를 따르는 것으로 보인다(Eaton et al. 2022). Zarr '파일'은 실제로 압축된 데이터 청크를 담는 하위 디렉터리를 포함한 디렉터리 구조이다. 선택한 압축 알고리즘과 청킹 전략은 특정 하위 큐브를 읽고 쓰는 속도에 직접적인 영향을 미친다.\n\n`stars::read_mdim()` 함수를 통해 전체 데이터 큐브를 읽을 수도 있고, 옵션을 통해 하위 큐브만 읽을 수도 있다. 각 디멘션별로 오프셋, 픽셀 수, 스텝 크기(낮은 해상도로 읽기)를 지정할 수 있다(Pebesma 2022). 이와 유사하게, `stars::write_mdim()` 함수는 다차원 어레이를 Zarr, NetCDF, GDAL C++ 다차원 배열 API를 지원하는 다른 포맷으로 쓸 수 있다.\n\n원격(클라우드 기반) Zarr 파일을 읽으려면, URL 앞에 형식과 접근 프로토콜을 나타내는 지시자를 추가해 주어야 한다.\n\n``` r\ndsn = paste0('ZARR:\"/vsicurl/https://ncsa.osn.xsede.org',\n       '/Pangeo/pangeo-forge/gpcp-feedstock/gpcp.zarr\"')\n```\n\n그다음, 다음과 같이 처음 10개의 시간 스텝을 읽을 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stars)\nbounds = c(longitude = \"lon_bounds\", latitude = \"lat_bounds\")\n(r = read_mdim(dsn, bounds = bounds, count = c(NA, NA, 10)))\n# stars object with 3 dimensions and 1 attribute\n# attribute(s):\n#               Min. 1st Qu. Median Mean 3rd Qu. Max.\n# precip [mm/d]    0       0      0 2.25     1.6  109\n# dimension(s):\n#           from  to     offset  delta refsys x/y\n# longitude    1 360          0      1     NA [x]\n# latitude     1 180        -90      1     NA [y]\n# time         1  10 1996-10-01 1 days   Date\nst_bbox(r)\n# xmin ymin xmax ymax \n#    0  -90  360   90\n```\n:::\n\n\n이 예에서 두 가지 사항을 설명하면 다음과 같다.\n\n-   `count`의 `NA` 값은 해당 디멘션의 사용 가능한 모든 값을 가져오라는 뜻이다.\n\n-   `bounds` 변수는 데이터 소스가 최신 CF (1.10) 규칙을 따르지 않아 명시 지정이 필요하다. 이를 무시하면 위도 범위 \\[$-90,90$\\]을 벗어나는 바운딩 박스를 가진 래스터가 생성될 수 있다.\n\n### 데이터 API: GEE, openEO\n\n클라우드 상에 *존재하는* 가상 머신을 직접 관리하거나 프로그래밍하지 않고도 이미지에 바로 다룰 수 있는 플랫폼으로는 GEE(구글 어스 엔진), openEO, 기후 데이터 스토어가 있다.\n\nGEE는 대규모 지구 관측 데이터와 모형 산출물에 대한 접근을 제공하는 클라우드 플랫폼이다(Gorelick et al. 2017). 이 플랫폼은 6.3절에서 다룬 데이터 큐브 작업을 포함해 강력한 분석 기능을 제공하며, JavaScript와 Python 인터페이스를 지원한다. GEE의 코드는 오픈소스가 아니며, Python이나 R을 통해 서버 측에서 사용자 정의 함수를 업로드해 실행하는 방식은 지원하지 않는다. R의 **rgee** 패키지(Aybar 2022)는 GEE에 대한 R 클라이언트 인터페이스를 제공한다.\n\n온전히 오픈소스 소프트웨어로 구축된 클라우드 기반 데이터 큐브 처리 플랫폼도 등장하고 있으며, 그중 일부는 openEO API(Schramm et al. 2021)를 사용한다. 이 API는 Python 또는 R로 작성한 사용자 정의 함수(UDF)를 허용하며, 함수는 API를 통해 전달되어 픽셀 수준에서 실행된다. 예를 들어 사용자 정의 리듀서를 사용해 디맨션을 애그리게이션하거나 디멘션을 축소할 수 있다. R의 UDF는 처리할 데이터 청크를 `stars` 객체로 표현하고, Python에서는 `xarray` 객체를 사용한다.\n\n기타 플랫폼으로는 Copernicus 기후 데이터 스토어(Raoult et al. 2017)와 대기 데이터 스토어가 있으며, 이를 통해 ERA5를 포함한 ECMWF의 대기 및 기후 데이터를 처리할 수 있다. 이 두 스토어에 대한 인터페이스를 제공하는 R 패키지는 **ecmwfr**(Hufkens 2023)이다.\n\n## 연습문제\n\n다음 연습문제를 R을 사용하여 해결하시오.\n\n1.  위의 S2 이미지에 대해 `st_get_dimension_values()` 함수를 사용해 밴드 순서를 확인하고, 각 스펙트럴 밴드/색상이 무엇인지 파악하시오.\n\n2.  S2 이미지에 대해 `st_apply()` 함수와 적절한 `ndvi()` 함수를 사용하여 NDVI를 계산하시오. 결과를 화면에 플로팅한 뒤, GeoTIFF로 저장하시오. 플로팅과 쓰기의 실행 시간 차이에 대해 설명하시오.\n\n3.  S2 이미지를 RGB 합성으로 플로팅하시오. 먼저 `plot()` 함수의 `rgb` 인수를 사용하고, 이어서 `st_rgb()` 함수를 사용하시오.\n\n4.  S2의 바운딩 박스에서 무작위로 다섯 개의 점을 선택하고, 이 점들에서 밴드 값을 추출하시오. 반환된 객체를 `sf` 객체로 변환하시오.\n\n5.  `POINT(390000 5940000)`을 중심으로 반경 10km 원을 정의하고, `aggregate()` 함수를 사용하여 S2 이미지의 평균 픽셀 값을 계산하시오. 이미지를 30배 다운샘플링한 결과와 원래 해상도의 결과를 비교하고, 두 결과 간의 상대적 차이를 계산하시오.\n\n6.  다운샘플링된 S2 이미지에서 `hist()` 함수로 히스토그램을 계산하시오. 각 밴드에 대해서도 동일한 작업을 수행하시오. **ggplot2** 패키지를 사용해 네 개의 히스토그램을 모두 포함하는 단일 플롯을 작성하시오.\n\n7.  `st_crop()` 함수를 사용해 S2 이미지를 10km 원이 포함하는 영역으로 클리핑한 뒤 결과를 플로팅하시오. 인수 `crop = FALSE`를 설정했을 때 어떤 변화가 있는지 살펴보시오.\n\n8.  다운샘플링된 이미지를 사용하여, 네 개의 밴드에서 모든 픽셀 값이 1000보다 큰지의 여부를 나타내는 논리 레이어를 계산하시오. 네 개의 밴드에 대해 래스터 대수 표현식을 사용하거나 `st_apply()` 함수를 사용하시오.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}